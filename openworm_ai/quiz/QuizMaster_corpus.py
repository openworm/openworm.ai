import os
import json
import random
from openworm_ai.quiz.QuizModel import MultipleChoiceQuiz, Question, Answer
from openworm_ai.quiz.TemplatesCorpus import TEXT_ANSWER_EXAMPLE
from openworm_ai.utils.llms import ask_question_get_response, LLM_GPT4o

indexing = ["A", "B", "C", "D"]
TOKEN_LIMIT = 18_000  # ðŸ”¹ Keeps request within OpenAI's limits

# **STRICT Prompt to prevent external knowledge**
STRICT_GENERATE_Q = """
ðŸ”¹ **TASK:** Generate exactly <QUESTION_NUMBER> multiple-choice questions using **only** the provided text.  
- The questions must be **highly specific** and **cannot** come from general knowledge.  
- If the topic is not in the provided text, **DO NOT** generate a question about it.  
- Questions should challenge **researchers** and **advanced students**.  
- DO NOT include the sources in the questions (...according to [source])
ðŸ”¹ **FORMAT:**  
QUESTION: <Insert question>  
CORRECT ANSWER: <Correct answer>  
WRONG ANSWER: <Wrong answer 1>  
WRONG ANSWER: <Wrong answer 2>  
WRONG ANSWER: <Wrong answer 3>  

ðŸ“Œ **IMPORTANT:** If the text does not have enough content for <QUESTION_NUMBER> questions, generate as many as possible.  
"""


def load_limited_documents(
    directory="processed/json/wormatlas", max_tokens=TOKEN_LIMIT
):
    """Loads only the specified papers while staying within GPT-4o's token limit."""

    # **Only process these specific files**
    target_files = [
        "BasicCellInfo.json",
        "Introduction.json",
        "Rectum_and_Anus.json",
    ]

    documents = []
    total_tokens = 0

    for filename in target_files:
        file_path = os.path.join(directory, filename)

        if not os.path.exists(file_path):
            print(f"âš  Warning: {file_path} not found. Skipping...")
            continue  # Skip if the file is missing

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

                # Extract sections and enforce token limit
                extracted_text = ""
                for title, doc_contents in data.items():
                    extracted_text += f"\nðŸ“Œ **{title}**\n"
                    for section, details in doc_contents.get("sections", {}).items():
                        extracted_text += f"ðŸ”¹ **{section}**:\n"
                        if "paragraphs" in details:
                            extracted_text += (
                                " ".join([p["contents"] for p in details["paragraphs"]])
                                + "\n\n"
                            )

                # Estimate token count
                doc_tokens = len(extracted_text.split()) * 1.33
                if total_tokens + doc_tokens > max_tokens:
                    allowed_chars = int(
                        (max_tokens - total_tokens) * 4
                    )  # Approximate conversion
                    extracted_text = extracted_text[:allowed_chars] + "..."
                    doc_tokens = len(extracted_text.split()) * 1.33

                documents.append(extracted_text)
                total_tokens += doc_tokens

        except (json.JSONDecodeError, UnicodeDecodeError) as e:
            print(f"âš  Error reading {file_path}: {e}")

    return "\n\n".join(documents)


def save_quiz(num_questions=20, num_answers=4, llm_ver=LLM_GPT4o, temperature=0):
    """Generates and saves a quiz using GPT-4o while ensuring all content is from documents."""

    # Load trimmed document text
    document_text = load_limited_documents()
    if not document_text.strip():
        print("âš  Error: No valid documents found.")
        return

    # Create strict prompt
    question_prompt = (
        STRICT_GENERATE_Q.replace("<QUESTION_NUMBER>", str(num_questions))
        + TEXT_ANSWER_EXAMPLE
        + "\n\nðŸ”¹ **Use ONLY the following document knowledge for questions:**\n\n"
        + document_text
    )

    response = ask_question_get_response(question_prompt, llm_ver, temperature)

    # Ensure GPT-4o generated the expected number of questions
    questions_generated = response.count("QUESTION:")
    if questions_generated < num_questions * 0.8:
        print(
            f"âš  Error: The LLM generated only {questions_generated} valid questions. Aborting save."
        )
        return
    if questions_generated > num_questions:
        print(
            f"âš  Warning: GPT-4o generated {questions_generated} questions. Truncating to {num_questions}."
        )

    # Initialize quiz
    quiz = MultipleChoiceQuiz(
        title=f"{llm_ver.replace(':', '_')}_{num_questions}questions_celegans_4",
        source=f"Generated by {llm_ver}, temperature: {temperature}",
    )

    last_question = None
    indexing = ["1", "2", "3", "4"]
    question_count = 0

    # Parse and format the response into the quiz structure
    for line in response.split("\n"):
        if question_count >= num_questions:
            break  # Stop at exactly 100 questions

        if len(line.strip()) > 0:
            if "QUESTION" in line or line.strip().endswith("?"):
                question_text = line.split(":", 1)[-1].strip()
                print(f"Question: <{question_text}>")
                last_question = Question(question=question_text)
                quiz.questions.append(last_question)
                question_count += 1
            elif "CORRECT ANSWER" in line:
                correct_ans = line.split(":", 1)[-1].strip()
                print(f"CORRECT ANSWER: <{correct_ans}>")
                i = len(last_question.answers)
                last_question.answers.append(Answer(indexing[i], correct_ans, True))
            elif "WRONG ANSWER" in line:
                wrong_ans = line.split(":", 1)[-1].strip()
                print(f"WRONG ANSWER: <{wrong_ans}>")
                i = len(last_question.answers)
                last_question.answers.append(Answer(indexing[i], wrong_ans, False))

    # Ensure quiz has enough valid questions before saving
    if len(quiz.questions) < num_questions * 0.8:
        print(
            "âš  Error: Not enough valid questions were generated. Quiz will not be saved."
        )
        return

    print("===============================\n  Generated quiz:\n")
    print(quiz.to_yaml())

    quiz.to_json_file(
        f"openworm_ai/quiz/samples/{llm_ver.replace(':', '_')}_{num_questions}questions_celegans_4.json"
    )


if __name__ == "__main__":
    import sys

    llm_ver = LLM_GPT4o  # Always use GPT-4o
    print(f"Selected LLM: {llm_ver}")

    if "-ask" in sys.argv:
        quiz_json = f"openworm_ai/quiz/samples/{llm_ver.replace(':', '_')}_20questions_celegans_4.json"
        quiz = MultipleChoiceQuiz.from_file(quiz_json)

        total_qs = 0
        total_correct = 0
        wrong_answers = "Incorrect answers:\n"

        for qi, question in enumerate(quiz.questions):
            q = question["question"]

            from openworm_ai.quiz.Templates import ASK_Q

            answers = ""
            random.shuffle(question["answers"])

            presented_answers = {}
            for index, answer in enumerate(question["answers"]):
                ref = indexing[index]
                present = f"{ref}: {answer['ans']}"
                if answer["correct"]:
                    correct_answer = ref
                    correct_text = present
                presented_answers[ref] = present
                answers += f"{present}\n"

            full_question = ASK_Q.replace("<QUESTION>", q).replace("<ANSWERS>", answers)

            resp = ask_question_get_response(
                full_question, llm_ver, print_question=False
            ).strip()

            total_qs += 1
            correct_guess = resp == correct_answer

            print(
                f" >> {qi}) {q} â†’ Guess: {resp}, Correct: {correct_answer} â†’ {correct_guess}"
            )

    else:
        print(f"Debug: Using LLM {llm_ver} for saving quiz")
        save_quiz(20, 4, llm_ver, temperature=0.2)
