{"pages":[{"page":1,"text":"TOOLS AND RESOURCES\n\n\n\nThe NeuroML ecosystem for standardized\nmulti-scale modeling in neuroscience\nAnkur Sinha1†, Padraig Gleeson¹*†, Bóris Marin², Salvador Dura-Bernal3,4,\nSotirios Panagiotou⁵, Sharon Crook⁶, Matteo Cantarelli⁷, Robert C Cannon⁸,\nAndrew P Davison⁹, Harsha Gurnani¹⁰, Robin Angus Silver¹*\n\n1Department of Neuroscience, Physiology and Pharmacology, University College\nLondon, London, United Kingdom; ²Universidade Federal do ABC, São Bernardo\ndo Campo, Brazil; ³SUNY Downstate Medical Center, Brooklyn, United States; ⁴,\nCenter for Biomedical Imaging and Neuromodulation, Nathan Kline Institute for\nPsychiatric Research, Orangeburg, United States; ⁵Erasmus University Rotterdam,\nRotterdam, Netherlands; ⁶Arizona State University, Tempe, United States;\n7MetaCell Ltd, Cambridge, United States; 8Opus2 International Ltd, London,\n                     CNRS,  Gif‐ Sur‐ Yvette,  France;\nUnited Kingdom; ⁹     10University of Washington,\nSeattle, United States\n\n\n                                       eLife Assessment\n*For correspondence:                   This important work presents a consolidated overview of the NeuroML2 open community standard\np.gleeson@ucl.ac.uk (PG);              and provides convincing evidence for its central role within a broader software ecosystem for the\na.silver@ucl.ac.uk (RAS)               development of neuronal models that are open, shareable, reproducible, and interoperable. A major\n†These authors contributed             strength of the work is the continued development over more than two decades to establish, main-\nequally to this work                   tain, and adapt this standard to meet the evolving needs of the ﬁeld. This work is of broad interest\nCompeting interest: See page           to the sub-cellular, cellular, computational, and systems neuroscience communities undertaking\n38                                     studies involving theory, modeling, and simulation.\nFunding: See page 38\nPreprint posted\n11 December 2023                       Abstract Data-driven models of neurons and circuits are important for understanding how\nSent for Review                        the properties of membrane conductances, synapses, dendrites, and the anatomical connectivity\n31 January 2024                        between neurons generate the complex dynamical behaviors of brain circuits in health and disease.\nReviewed preprint posted               However, the inherent complexity of these biological processes makes the construction and reuse\n03 May 2024\nReviewed preprint revised              of biologically detailed models challenging. A wide range of tools have been developed to aid their\n30 October 2024                        construction and simulation, but differences in design and internal representation act as technical\nVersion of Record published            barriers to those who wish to use data-driven models in their research workﬂows. NeuroML, a model\n10 January 2025                        description language for computational neuroscience, was developed to address this fragmentation\nReviewing Editor: Eilif B Muller,      in modeling tools. Since its inception, NeuroML has evolved into a mature community standard\nUniversity of Montreal, Canada         that encompasses a wide range of model types and approaches in computational neuroscience. It\n      Copyright Sinha, Gleeson         has enabled the development of a large ecosystem of interoperable open-source software tools for\net al. This article is distributed     the creation, visualization, validation, and simulation of data-driven models. Here, we describe how\nunder the terms of the Creative        the NeuroML ecosystem can be incorporated into research workﬂows to simplify the construction,\nCommons Attribution License,           testing, and analysis of standardized models of neural systems, and supports the FAIR (Findability,\nwhich permits unrestricted use         Accessibility, Interoperability, and Reusability) principles, thus promoting open, transparent and\nand redistribution provided that\nthe original author and source         reproducible science.\nare credited.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                          1 of 44","md":"\n\nTOOLS AND RESOURCES\n\n# The NeuroML ecosystem for standardized multi-scale modeling in neuroscience\n\nAnkur Sinha<sup>1†</sup>, Padraig Gleeson<sup>1*†</sup>, Bóris Marin<sup>2</sup>, Salvador Dura-Bernal<sup>3,4</sup>, Sotirios Panagiotou<sup>5</sup>, Sharon Crook<sup>6</sup>, Matteo Cantarelli<sup>7</sup>, Robert C Cannon<sup>8</sup>, Andrew P Davison<sup>9</sup>, Harsha Gurnani<sup>10</sup>, Robin Angus Silver<sup>1*</sup>\n\n<sup>1</sup>Department of Neuroscience, Physiology and Pharmacology, University College London, London, United Kingdom; <sup>2</sup>Universidade Federal do ABC, São Bernardo do Campo, Brazil; <sup>3</sup>SUNY Downstate Medical Center, Brooklyn, United States; <sup>4</sup>Center for Biomedical Imaging and Neuromodulation, Nathan Kline Institute for Psychiatric Research, Orangeburg, United States; <sup>5</sup>Erasmus University Rotterdam, Rotterdam, Netherlands; <sup>6</sup>Arizona State University, Tempe, United States; <sup>7</sup>MetaCell Ltd, Cambridge, United States; <sup>8</sup>Opus2 International Ltd, London, United Kingdom; <sup>9</sup>CNRS, Gif-Sur-Yvette, France; <sup>10</sup>University of Washington, Seattle, United States\n\n## eLife Assessment\n\n*For correspondence: p.gleeson@ucl.ac.uk (PG); a.silver@ucl.ac.uk (RAS)\n\n†These authors contributed equally to this work\n\n**Competing interest:** See page 38\n\n**Funding:** See page 38\n\n**Preprint posted** 11 December 2023\n**Sent for Review** 31 January 2024\n**Reviewed preprint posted** 03 May 2024\n**Reviewed preprint revised** 30 October 2024\n**Version of Record published** 10 January 2025\n\n**Reviewing Editor:** Eilif B Muller, University of Montreal, Canada\n\nThis **important** work presents a consolidated overview of the NeuroML2 open community standard and provides **convincing** evidence for its central role within a broader software ecosystem for the development of neuronal models that are open, shareable, reproducible, and interoperable. A major strength of the work is the continued development over more than two decades to establish, maintain, and adapt this standard to meet the evolving needs of the field. This work is of broad interest to the sub-cellular, cellular, computational, and systems neuroscience communities undertaking studies involving theory, modeling, and simulation.\n\n## Abstract\n\nData-driven models of neurons and circuits are important for understanding how the properties of membrane conductances, synapses, dendrites, and the anatomical connectivity between neurons generate the complex dynamical behaviors of brain circuits in health and disease. However, the inherent complexity of these biological processes makes the construction and reuse of biologically detailed models challenging. A wide range of tools have been developed to aid their construction and simulation, but differences in design and internal representation act as technical barriers to those who wish to use data-driven models in their research workflows. NeuroML, a model description language for computational neuroscience, was developed to address this fragmentation in modeling tools. Since its inception, NeuroML has evolved into a mature community standard that encompasses a wide range of model types and approaches in computational neuroscience. It has enabled the development of a large ecosystem of interoperable open-source software tools for the creation, visualization, validation, and simulation of data-driven models. Here, we describe how the NeuroML ecosystem can be incorporated into research workflows to simplify the construction, testing, and analysis of standardized models of neural systems, and supports the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles, thus promoting open, transparent and reproducible science.\n\n© Copyright Sinha, Gleeson et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                          1 of 44\n","images":[{"name":"page_1.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_1_text_1_v2.jpg","height":28468.572,"width":229612.566,"x":101061.971,"y":128134.275,"original_width":1517,"original_height":146,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_text_2_v2.jpg","height":96879.503,"width":245318.611,"x":101164.304,"y":166134.212,"original_width":1620,"original_height":495,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_doc_title_1_v2.jpg","height":37315.896,"width":248796.826,"x":101988.164,"y":83718.091,"original_width":1643,"original_height":191,"rotation":0,"type":"layout_v2_doc_title"},{"name":"page_1_header_1_v2.jpg","height":26064.222,"width":61370.041,"x":22111.893,"y":27724.794,"original_width":406,"original_height":133,"rotation":0,"type":"layout_v2_header"},{"name":"page_1_text_3_v2.jpg","height":84188.884,"width":65566.509,"x":21344.949,"y":390806.916,"original_width":433,"original_height":430,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_footer_1_v2.jpg","height":6925.21,"width":192046.204,"x":21438.71,"y":591366.014,"original_width":1269,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_1_header_2_v2.jpg","height":6207.043,"width":58269.565,"x":217361.044,"y":37444.449,"original_width":385,"original_height":32,"rotation":0,"type":"layout_v2_header"},{"name":"page_1_paragraph_title_1_v2.jpg","height":7695.607,"width":62109.279,"x":101639.6,"y":293209.205,"original_width":411,"original_height":40,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_1_text_4_v2.jpg","height":67446.306,"width":71595.453,"x":21218.988,"y":502547.647,"original_width":473,"original_height":345,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_text_5_v2.jpg","height":15520.138,"width":71582.859,"x":21457.799,"y":481877.083,"original_width":473,"original_height":80,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_number_1_v2.jpg","height":6075.659,"width":15079.099,"x":336037.226,"y":591616.077,"original_width":100,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_1_text_6_v2.jpg","height":65547.813,"width":69290.294,"x":21252.856,"y":304899.23,"original_width":458,"original_height":335,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_paragraph_title_2_v2.jpg","height":8929.769,"width":31791.561,"x":101935.504,"y":398172.328,"original_width":210,"original_height":46,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_1_text_7_v2.jpg","height":6918.427,"width":50211.038,"x":21459.235,"y":378348.218,"original_width":332,"original_height":36,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_abstract_1_v2.jpg","height":162396.277,"width":248265.459,"x":101130.932,"y":398508.013,"original_width":1640,"original_height":829,"rotation":0,"type":"layout_v2_abstract"},{"name":"page_1_header_3_v2.jpg","height":16291.735,"width":12316.59,"x":339317.099,"y":32653.152,"original_width":82,"original_height":84,"rotation":0,"type":"layout_v2_header"},{"name":"page_1_header_4_v2.jpg","height":23262.165,"width":12097.241,"x":301428.164,"y":25493.89,"original_width":80,"original_height":119,"rotation":0,"type":"layout_v2_header"},{"name":"page_1_text_8_v2.jpg","height":70040.611,"width":249957.776,"x":101007.534,"y":304255.873,"original_width":1651,"original_height":358,"rotation":0,"type":"layout_v2_text"},{"name":"page_1_text_9_v2.jpg","height":14674.508,"width":69194.542,"x":21376.784,"y":356059.019,"original_width":457,"original_height":75,"rotation":0,"type":"layout_v2_text"}],"charts":[],"items":[{"type":"text","value":"TOOLS AND RESOURCES","md":"TOOLS AND RESOURCES","bBox":{"x":356.27,"y":47.78,"w":95.25,"h":8},"layoutAwareBbox":[{"x":355,"y":47,"w":95,"h":7,"startIndex":0,"endIndex":18}]},{"type":"heading","lvl":1,"value":"The NeuroML ecosystem for standardized multi-scale modeling in neuroscience","md":"# The NeuroML ecosystem for standardized multi-scale modeling in neuroscience","bBox":{"x":168.53,"y":104,"w":413.3,"h":20.5},"layoutAwareBbox":[{"x":166,"y":105,"w":406,"h":47,"startIndex":2,"endIndex":5}]},{"type":"text","value":"Ankur Sinha<sup>1†</sup>, Padraig Gleeson<sup>1*†</sup>, Bóris Marin<sup>2</sup>, Salvador Dura-Bernal<sup>3,4</sup>, Sotirios Panagiotou<sup>5</sup>, Sharon Crook<sup>6</sup>, Matteo Cantarelli<sup>7</sup>, Robert C Cannon<sup>8</sup>, Andrew P Davison<sup>9</sup>, Harsha Gurnani<sup>10</sup>, Robin Angus Silver<sup>1*</sup>","md":"Ankur Sinha<sup>1†</sup>, Padraig Gleeson<sup>1*†</sup>, Bóris Marin<sup>2</sup>, Salvador Dura-Bernal<sup>3,4</sup>, Sotirios Panagiotou<sup>5</sup>, Sharon Crook<sup>6</sup>, Matteo Cantarelli<sup>7</sup>, Robert C Cannon<sup>8</sup>, Andrew P Davison<sup>9</sup>, Harsha Gurnani<sup>10</sup>, Robin Angus Silver<sup>1*</sup>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":326}]},{"type":"text","value":"<sup>1</sup>Department of Neuroscience, Physiology and Pharmacology, University College London, London, United Kingdom; <sup>2</sup>Universidade Federal do ABC, São Bernardo do Campo, Brazil; <sup>3</sup>SUNY Downstate Medical Center, Brooklyn, United States; <sup>4</sup>Center for Biomedical Imaging and Neuromodulation, Nathan Kline Institute for Psychiatric Research, Orangeburg, United States; <sup>5</sup>Erasmus University Rotterdam, Rotterdam, Netherlands; <sup>6</sup>Arizona State University, Tempe, United States; <sup>7</sup>MetaCell Ltd, Cambridge, United States; <sup>8</sup>Opus2 International Ltd, London, United Kingdom; <sup>9</sup>CNRS, Gif-Sur-Yvette, France; <sup>10</sup>University of Washington, Seattle, United States","md":"<sup>1</sup>Department of Neuroscience, Physiology and Pharmacology, University College London, London, United Kingdom; <sup>2</sup>Universidade Federal do ABC, São Bernardo do Campo, Brazil; <sup>3</sup>SUNY Downstate Medical Center, Brooklyn, United States; <sup>4</sup>Center for Biomedical Imaging and Neuromodulation, Nathan Kline Institute for Psychiatric Research, Orangeburg, United States; <sup>5</sup>Erasmus University Rotterdam, Rotterdam, Netherlands; <sup>6</sup>Arizona State University, Tempe, United States; <sup>7</sup>MetaCell Ltd, Cambridge, United States; <sup>8</sup>Opus2 International Ltd, London, United Kingdom; <sup>9</sup>CNRS, Gif-Sur-Yvette, France; <sup>10</sup>University of Washington, Seattle, United States","bBox":{"x":168.53,"y":251.35,"w":393.78,"h":80.25},"layoutAwareBbox":[{"x":168.53,"y":251.35,"w":393.78,"h":80.25,"startIndex":0,"endIndex":740}]},{"type":"heading","lvl":2,"value":"eLife Assessment","md":"## eLife Assessment","bBox":{"x":168.53,"y":368.3,"w":98.44,"h":12},"layoutAwareBbox":[{"x":166,"y":370,"w":101,"h":9,"startIndex":0,"endIndex":18}]},{"type":"text","value":"*For correspondence: p.gleeson@ucl.ac.uk (PG); a.silver@ucl.ac.uk (RAS)","md":"*For correspondence: p.gleeson@ucl.ac.uk (PG); a.silver@ucl.ac.uk (RAS)","bBox":{"x":37.01,"y":384.47,"w":95.34,"h":30},"layoutAwareBbox":[{"x":34,"y":384,"w":113,"h":82,"startIndex":0,"endIndex":70}]},{"type":"text","value":"†These authors contributed equally to this work","md":"†These authors contributed equally to this work","bBox":{"x":37.01,"y":421.47,"w":99.58,"h":19},"layoutAwareBbox":[{"x":34,"y":384,"w":113,"h":82,"startIndex":0,"endIndex":46}]},{"type":"text","value":"**Competing interest:** See page 38","md":"**Competing interest:** See page 38","bBox":{"x":37.01,"y":460.47,"w":8.9,"h":8},"layoutAwareBbox":[{"x":34,"y":449,"w":113,"h":18,"startIndex":33,"endIndex":35}]},{"type":"text","value":"**Funding:** See page 38","md":"**Funding:** See page 38","bBox":{"x":37.01,"y":460.47,"w":8.9,"h":8},"layoutAwareBbox":[{"x":35,"y":477,"w":82,"h":8,"startIndex":2,"endIndex":9}]},{"type":"text","value":"**Preprint posted** 11 December 2023\n**Sent for Review** 31 January 2024\n**Reviewed preprint posted** 03 May 2024\n**Reviewed preprint revised** 30 October 2024\n**Version of Record published** 10 January 2025","md":"**Preprint posted** 11 December 2023\n**Sent for Review** 31 January 2024\n**Reviewed preprint posted** 03 May 2024\n**Reviewed preprint revised** 30 October 2024\n**Version of Record published** 10 January 2025","bBox":{"x":37.01,"y":492.47,"w":105.49,"h":107},"layoutAwareBbox":[{"x":34,"y":493,"w":107,"h":106,"startIndex":0,"endIndex":206}]},{"type":"text","value":"**Reviewing Editor:** Eilif B Muller, University of Montreal, Canada","md":"**Reviewing Editor:** Eilif B Muller, University of Montreal, Canada","bBox":{"x":37.01,"y":619.47,"w":111.18,"h":8},"layoutAwareBbox":[{"x":35,"y":608,"w":116,"h":19,"startIndex":0,"endIndex":67}]},{"type":"text","value":"This **important** work presents a consolidated overview of the NeuroML2 open community standard and provides **convincing** evidence for its central role within a broader software ecosystem for the development of neuronal models that are open, shareable, reproducible, and interoperable. A major strength of the work is the continued development over more than two decades to establish, maintain, and adapt this standard to meet the evolving needs of the field. This work is of broad interest to the sub-cellular, cellular, computational, and systems neuroscience communities undertaking studies involving theory, modeling, and simulation.","md":"This **important** work presents a consolidated overview of the NeuroML2 open community standard and provides **convincing** evidence for its central role within a broader software ecosystem for the development of neuronal models that are open, shareable, reproducible, and interoperable. A major strength of the work is the continued development over more than two decades to establish, maintain, and adapt this standard to meet the evolving needs of the field. This work is of broad interest to the sub-cellular, cellular, computational, and systems neuroscience communities undertaking studies involving theory, modeling, and simulation.","bBox":{"x":168.53,"y":410.15,"w":408.26,"h":60.8},"layoutAwareBbox":[{"x":165,"y":384,"w":408,"h":88,"startIndex":0,"endIndex":4}]},{"type":"heading","lvl":2,"value":"Abstract","md":"## Abstract","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":166,"y":502,"w":51,"h":11,"startIndex":3,"endIndex":11}]},{"type":"text","value":"Data-driven models of neurons and circuits are important for understanding how the properties of membrane conductances, synapses, dendrites, and the anatomical connectivity between neurons generate the complex dynamical behaviors of brain circuits in health and disease. However, the inherent complexity of these biological processes makes the construction and reuse of biologically detailed models challenging. A wide range of tools have been developed to aid their construction and simulation, but differences in design and internal representation act as technical barriers to those who wish to use data-driven models in their research workflows. NeuroML, a model description language for computational neuroscience, was developed to address this fragmentation in modeling tools. Since its inception, NeuroML has evolved into a mature community standard that encompasses a wide range of model types and approaches in computational neuroscience. It has enabled the development of a large ecosystem of interoperable open-source software tools for the creation, visualization, validation, and simulation of data-driven models. Here, we describe how the NeuroML ecosystem can be incorporated into research workflows to simplify the construction, testing, and analysis of standardized models of neural systems, and supports the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles, thus promoting open, transparent and reproducible science.","md":"Data-driven models of neurons and circuits are important for understanding how the properties of membrane conductances, synapses, dendrites, and the anatomical connectivity between neurons generate the complex dynamical behaviors of brain circuits in health and disease. However, the inherent complexity of these biological processes makes the construction and reuse of biologically detailed models challenging. A wide range of tools have been developed to aid their construction and simulation, but differences in design and internal representation act as technical barriers to those who wish to use data-driven models in their research workflows. NeuroML, a model description language for computational neuroscience, was developed to address this fragmentation in modeling tools. Since its inception, NeuroML has evolved into a mature community standard that encompasses a wide range of model types and approaches in computational neuroscience. It has enabled the development of a large ecosystem of interoperable open-source software tools for the creation, visualization, validation, and simulation of data-driven models. Here, we describe how the NeuroML ecosystem can be incorporated into research workflows to simplify the construction, testing, and analysis of standardized models of neural systems, and supports the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles, thus promoting open, transparent and reproducible science.","bBox":{"x":168.52,"y":516.85,"w":405.23,"h":190.31},"layoutAwareBbox":[{"x":165,"y":503,"w":405,"h":205,"startIndex":0,"endIndex":4}]},{"type":"text","value":"© Copyright Sinha, Gleeson et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.","md":"© Copyright Sinha, Gleeson et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.","bBox":{"x":37.01,"y":634.47,"w":117.09,"h":85},"layoutAwareBbox":[{"x":34,"y":634,"w":116,"h":85,"startIndex":0,"endIndex":230}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                          1 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                          1 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":133},{"x":549,"y":746,"w":24,"h":7,"startIndex":0,"endIndex":133}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://en.wikipedia.org/wiki/Open_access","unsafeUrl":"https://en.wikipedia.org/wiki/Open_access","text":""},{"url":"https://creativecommons.org/","unsafeUrl":"https://creativecommons.org/","text":""},{"url":"https://elifesciences.org/?utm_source=pdf&utm_medium=article-pdf&utm_campaign=PDF_tracking","unsafeUrl":"https://elifesciences.org/?utm_source=pdf&utm_medium=article-pdf&utm_campaign=PDF_tracking","text":""},{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"mailto:p.gleeson@ucl.ac.uk","unsafeUrl":"mailto:p.gleeson@ucl.ac.uk","text":"p.gleeson@ucl.ac.uk (PG); "},{"url":"mailto:a.silver@ucl.ac.uk","unsafeUrl":"mailto:a.silver@ucl.ac.uk","text":"a.silver@ucl.ac.uk (RAS)"},{"url":"https://doi.org/10.1101/2023.12.07.570537","unsafeUrl":"https://doi.org/10.1101/2023.12.07.570537","text":"11 December 2023"},{"url":"https://doi.org/10.7554/eLife.95135.1","unsafeUrl":"https://doi.org/10.7554/eLife.95135.1","text":"03 May 2024"},{"url":"https://doi.org/10.7554/eLife.95135.2","unsafeUrl":"https://doi.org/10.7554/eLife.95135.2","text":"30 October 2024"},{"url":"http://creativecommons.org/licenses/by/4.0/","unsafeUrl":"http://creativecommons.org/licenses/by/4.0/","text":"under the terms of the Creative "},{"url":"http://creativecommons.org/licenses/by/4.0/","unsafeUrl":"http://creativecommons.org/licenses/by/4.0/","text":"Commons Attribution License, "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\nTOOLS AND RESOURCES\n","pageFooterMarkdown":"\n© Copyright Sinha, Gleeson et al. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                          1 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.961,"layout":[{"image":"page_1_text_1_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.204,"w":0.613,"h":0.045},"isLikelyNoise":false},{"image":"page_1_text_2_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.265,"w":0.655,"h":0.154},"isLikelyNoise":false},{"image":"page_1_doc_title_1_v2.jpg","confidence":0.95,"label":"doc_title","bbox":{"x":0.272,"y":0.133,"w":0.664,"h":0.059},"isLikelyNoise":false},{"image":"page_1_header_1_v2.jpg","confidence":0.94,"label":"header","bbox":{"x":0.059,"y":0.044,"w":0.164,"h":0.042},"isLikelyNoise":false},{"image":"page_1_text_3_v2.jpg","confidence":0.92,"label":"text","bbox":{"x":0.057,"y":0.623,"w":0.175,"h":0.134},"isLikelyNoise":false},{"image":"page_1_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_1_header_2_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.58,"y":0.06,"w":0.156,"h":0.01},"isLikelyNoise":false},{"image":"page_1_paragraph_title_1_v2.jpg","confidence":0.87,"label":"paragraph_title","bbox":{"x":0.271,"y":0.467,"w":0.166,"h":0.012},"isLikelyNoise":false},{"image":"page_1_text_4_v2.jpg","confidence":0.86,"label":"text","bbox":{"x":0.057,"y":0.801,"w":0.191,"h":0.108},"isLikelyNoise":false},{"image":"page_1_text_5_v2.jpg","confidence":0.85,"label":"text","bbox":{"x":0.057,"y":0.768,"w":0.191,"h":0.025},"isLikelyNoise":false},{"image":"page_1_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.897,"y":0.943,"w":0.04,"h":0.01},"isLikelyNoise":false},{"image":"page_1_text_6_v2.jpg","confidence":0.8,"label":"text","bbox":{"x":0.057,"y":0.486,"w":0.185,"h":0.104},"isLikelyNoise":false},{"image":"page_1_paragraph_title_2_v2.jpg","confidence":0.79,"label":"paragraph_title","bbox":{"x":0.272,"y":0.635,"w":0.085,"h":0.014},"isLikelyNoise":false},{"image":"page_1_text_7_v2.jpg","confidence":0.76,"label":"text","bbox":{"x":0.057,"y":0.603,"w":0.134,"h":0.011},"isLikelyNoise":false},{"image":"page_1_abstract_1_v2.jpg","confidence":0.73,"label":"abstract","bbox":{"x":0.27,"y":0.635,"w":0.663,"h":0.259},"isLikelyNoise":false},{"image":"page_1_header_3_v2.jpg","confidence":0.73,"label":"header","bbox":{"x":0.906,"y":0.052,"w":0.033,"h":0.026},"isLikelyNoise":false},{"image":"page_1_header_4_v2.jpg","confidence":0.61,"label":"header","bbox":{"x":0.805,"y":0.041,"w":0.032,"h":0.037},"isLikelyNoise":false},{"image":"page_1_text_8_v2.jpg","confidence":0.6,"label":"text","bbox":{"x":0.27,"y":0.485,"w":0.667,"h":0.112},"isLikelyNoise":false},{"image":"page_1_text_9_v2.jpg","confidence":0.57,"label":"text","bbox":{"x":0.057,"y":0.568,"w":0.185,"h":0.023},"isLikelyNoise":true}]},{"page":2,"text":"Tools  and  resources                                                                                           Neuroscience\n                         Introduction\n                         Development of an in-     depth, mechanistic understanding of brain function in health and disease\n                         requires different scientiﬁc approaches spanning multiple scales, from gene expression to behavior.\n                         Although ‘wet’ experimental approaches are essential for characterizing the properties of neural\n                         systems and testing hypotheses, theory and modeling are critical for exploring how these complex\n                         systems behave across a wider range of conditions, and for generating new experimentally testable,\n                         physically plausible hypotheses. Theory and modeling also provide a way to integrate a panoply of\n                         experimentally measured parameters, functional properties, and responses to perturbations into a\n                         physio-chemically coherent framework that reproduces the properties of the neural system of interest\n                         (Einevoll et  al., 2019;  Yao et  al., 2022; Poirazi and Papoutsi, 2020;  Gurnani and Silver, 2021;\n                         Gleeson et al., 2018; Cayco‐Gajic et al., 2017; Billings et al., 2014; Vervaeke et al., 2010; Kriener\n                         et al., 2022; Billeh et al., 2020; Markram et al., 2015).\n                         Computational models in neuroscience often focus on different levels of description. For example,\n                         a cellular physiologist may construct a complex multi- compartmental model to explain the dynam-\n                         ical behavior of an individual neuron in terms of its morphology, biophysical properties, and ionic\n                         conductances (Hay et al., 2011; De Schutter and Bower, 1994; Migliore et al., 2005). In contrast,\n                         to relate neural population activity to sensory processing and behavior, a systems neurophysiologist\n                         may build a circuit- level model consisting of thousands of much simpler integrate- and-ﬁre neurons\n                         (Lapicque, 1907; Potjans and Diesmann, 2014;  Brunel, 2000). Domain speciﬁc tools have been\n                         developed to aid the construction and simulation of models at varying levels of biological detail\n                         and scales. An ecosystem of diverse tools is powerful and ﬂexible, but it also creates serious chal-\n                         lenges for the research community (Cannon et  al., 2007). Each tool typically has its own design,\n                         features, Application Programming Interface (API) and syntax, a custom set of utility libraries, and\n                         ﬁnally, a distinct machine- readable representation of the model’s physiological components. This\n                         represents a complex landscape for users to navigate. Additionally, models developed in different\n                         simulators cannot be mixed and matched or easily compared, and the translation of a model from\n                         one tool-speciﬁc implementation to another can be non-trivial and error-prone. This fragmentation in\n                         modeling tools and approaches can act as a barrier to neuroscientists who wish to use models in their\n                         research, as well as impede how Findable, Accessible, Interoperable, and Reusable (FAIR) models are\n                         (Wilkinson et al., 2016).\n                         To counter fragmentation and promote cooperation and interoperability within and across ﬁelds,\n                         standardization is required. The International Neuroinformatics Co-ordinating Facility (INCF) (Abrams\n                         et al., 2022) has highlighted the need for standards to ‘make research outputs machine-\n                                                                                                             readable and\n                         computable and are necessary for making research FAIR’ (INCF, 2023). In biology, several community\n                         standards have been developed to describe experimental data (e.g. Brain Imaging Data Structure\n                         [BIDS; Gorgolewski et  al., 2016], Neurodata Without Borders [NWB; Teeters et  al., 2015]) and\n                         computational models (e.g. Systems Biology Markup Language [SBML; Hucka et al., 2003], CellML\n                         [Lloyd et  al., 2004], Scalable Open Network Architecture TemplAte [SONATA; Dai et  al., 2020],\n                         PyNN [Davison et al., 2008] and Neural Open Markup Language [NeuroML; Gleeson et al., 2010]).\n                         These standards have enabled open and interoperable ecosystems of software applications, libraries,\n                         and databases to emerge, facilitating the sharing of research outputs, an endeavor encouraged by a\n                         growing number of funding agencies and scientiﬁc journals.\n                         The initial version of the NeuroML standard, version 1 (NeuroMLv1), was originally conceived as a\n                         model description format (Goddard et al., 2001) and implemented as a three-    layered, declarative,\n                         modular, simulator-independent language (Gleeson et al., 2010). NeuroMLv1 could describe detailed\n                         neuronal morphologies and their biophysical properties as well as speciﬁc instantiations of networks.\n                         It enabled the archiving of models in a standardized format and addressed the issue of simulator frag-\n                         mentation by acting as the common language for model exchange between established simulation\n                         environments—NEURON (Hines and Carnevale, 1997;          Awile et  al., 2022), GENESIS (Bower and\n                         Beeman, 1998), and MOOSE (Ray and Bhalla, 2008). While solving a number of long-\n                                                                                                             standing prob-\n                         lems in computational neuroscience, NeuroMLv1 had several key limitations. The most restrictive of\n                         these was that the dynamical behavior of model elements was not formally described in the standard\n                         itself, making it only partially machine readable. Information on the dynamics of elements (i.e. how the\n                         state variables should evolve in time) was only provided in the form of human- readable documenta-\n                         tion, requiring the developers of each new simulator to re-implement the behavior of these elements\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    2 of 44","md":"\n\neLife Tools and resources                                                                                           Neuroscience\n\n## Introduction\n\nDevelopment of an in-depth, mechanistic understanding of brain function in health and disease requires different scientific approaches spanning multiple scales, from gene expression to behavior. Although 'wet' experimental approaches are essential for characterizing the properties of neural systems and testing hypotheses, theory and modeling are critical for exploring how these complex systems behave across a wider range of conditions, and for generating new experimentally testable, physically plausible hypotheses. Theory and modeling also provide a way to integrate a panoply of experimentally measured parameters, functional properties, and responses to perturbations into a physio-chemically coherent framework that reproduces the properties of the neural system of interest (Einevoll et al., 2019; Yao et al., 2022; Poirazi and Papoutsi, 2020; Gurnani and Silver, 2021; Gleeson et al., 2018; Cayco-Gajic et al., 2017; Billings et al., 2014; Vervaeke et al., 2010; Kriener et al., 2022; Billeh et al., 2020; Markram et al., 2015).\n\nComputational models in neuroscience often focus on different levels of description. For example, a cellular physiologist may construct a complex multi-compartmental model to explain the dynamical behavior of an individual neuron in terms of its morphology, biophysical properties, and ionic conductances (Hay et al., 2011; De Schutter and Bower, 1994; Migliore et al., 2005). In contrast, to relate neural population activity to sensory processing and behavior, a systems neurophysiologist may build a circuit-level model consisting of thousands of much simpler integrate-and-fire neurons (Lapicque, 1907; Potjans and Diesmann, 2014; Brunel, 2000). Domain specific tools have been developed to aid the construction and simulation of models at varying levels of biological detail and scales. An ecosystem of diverse tools is powerful and flexible, but it also creates serious challenges for the research community (Cannon et al., 2007). Each tool typically has its own design, features, Application Programming Interface (API) and syntax, a custom set of utility libraries, and finally, a distinct machine-readable representation of the model's physiological components. This represents a complex landscape for users to navigate. Additionally, models developed in different simulators cannot be mixed and matched or easily compared, and the translation of a model from one tool-specific implementation to another can be non-trivial and error-prone. This fragmentation in modeling tools and approaches can act as a barrier to neuroscientists who wish to use models in their research, as well as impede how Findable, Accessible, Interoperable, and Reusable (FAIR) models are (Wilkinson et al., 2016).\n\nTo counter fragmentation and promote cooperation and interoperability within and across fields, standardization is required. The International Neuroinformatics Co-ordinating Facility (INCF) (Abrams et al., 2022) has highlighted the need for standards to 'make research outputs machine-readable and computable and are necessary for making research FAIR' (INCF, 2023). In biology, several community standards have been developed to describe experimental data (e.g. Brain Imaging Data Structure [BIDS; Gorgolewski et al., 2016], Neurodata Without Borders [NWB; Teeters et al., 2015]) and computational models (e.g. Systems Biology Markup Language [SBML; Hucka et al., 2003], CellML [Lloyd et al., 2004], Scalable Open Network Architecture TemplAte [SONATA; Dai et al., 2020], PyNN [Davison et al., 2008] and Neural Open Markup Language [NeuroML; Gleeson et al., 2010]). These standards have enabled open and interoperable ecosystems of software applications, libraries, and databases to emerge, facilitating the sharing of research outputs, an endeavor encouraged by a growing number of funding agencies and scientific journals.\n\nThe initial version of the NeuroML standard, version 1 (NeuroMLv1), was originally conceived as a model description format (Goddard et al., 2001) and implemented as a three-layered, declarative, modular, simulator-independent language (Gleeson et al., 2010). NeuroMLv1 could describe detailed neuronal morphologies and their biophysical properties as well as specific instantiations of networks. It enabled the archiving of models in a standardized format and addressed the issue of simulator fragmentation by acting as the common language for model exchange between established simulation environments—NEURON (Hines and Carnevale, 1997; Awile et al., 2022), GENESIS (Bower and Beeman, 1998), and MOOSE (Ray and Bhalla, 2008). While solving a number of long-standing problems in computational neuroscience, NeuroMLv1 had several key limitations. The most restrictive of these was that the dynamical behavior of model elements was not formally described in the standard itself, making it only partially machine readable. Information on the dynamics of elements (i.e. how the state variables should evolve in time) was only provided in the form of human-readable documentation, requiring the developers of each new simulator to re-implement the behavior of these elements\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    2 of 44\n","images":[{"name":"page_2.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_2_text_1_v2.jpg","height":170214.613,"width":250310.081,"x":101187.209,"y":160233.471,"original_width":1653,"original_height":869,"rotation":0,"type":"layout_v2_text"},{"name":"page_2_text_2_v2.jpg","height":122581.303,"width":250404.109,"x":101275.698,"y":447840.719,"original_width":1654,"original_height":626,"rotation":0,"type":"layout_v2_text"},{"name":"page_2_text_3_v2.jpg","height":113253.612,"width":250404.579,"x":101172.74,"y":332684.712,"original_width":1654,"original_height":578,"rotation":0,"type":"layout_v2_text"},{"name":"page_2_text_4_v2.jpg","height":103581.221,"width":250368.457,"x":101173.467,"y":54717.806,"original_width":1654,"original_height":529,"rotation":0,"type":"layout_v2_text"},{"name":"page_2_footer_1_v2.jpg","height":6889.162,"width":191859.561,"x":21555.882,"y":591497.21,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_2_paragraph_title_1_v2.jpg","height":8740.186,"width":51203.708,"x":101804.966,"y":42015.634,"original_width":339,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_2_header_1_v2.jpg","height":5701.908,"width":30185.974,"x":320848.778,"y":27650.973,"original_width":200,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_2_number_1_v2.jpg","height":5884.226,"width":15546.68,"x":335565.222,"y":591851.81,"original_width":103,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_2_header_2_v2.jpg","height":5727.13,"width":42920.475,"x":47759.05,"y":27862.68,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_2_header_3_v2.jpg","height":10662.335,"width":24386.805,"x":21850.192,"y":22407.998,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                           Neuroscience","md":"eLife Tools and resources                                                                                           Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":116,"endIndex":128}]},{"type":"heading","lvl":2,"value":"Introduction","md":"## Introduction","bBox":{"x":168.53,"y":50.58,"w":81.38,"h":14},"layoutAwareBbox":[{"x":166,"y":53,"w":83,"h":11,"startIndex":3,"endIndex":15}]},{"type":"text","value":"Development of an in-depth, mechanistic understanding of brain function in health and disease requires different scientific approaches spanning multiple scales, from gene expression to behavior. Although 'wet' experimental approaches are essential for characterizing the properties of neural systems and testing hypotheses, theory and modeling are critical for exploring how these complex systems behave across a wider range of conditions, and for generating new experimentally testable, physically plausible hypotheses. Theory and modeling also provide a way to integrate a panoply of experimentally measured parameters, functional properties, and responses to perturbations into a physio-chemically coherent framework that reproduces the properties of the neural system of interest (Einevoll et al., 2019; Yao et al., 2022; Poirazi and Papoutsi, 2020; Gurnani and Silver, 2021; Gleeson et al., 2018; Cayco-Gajic et al., 2017; Billings et al., 2014; Vervaeke et al., 2010; Kriener et al., 2022; Billeh et al., 2020; Markram et al., 2015).","md":"Development of an in-depth, mechanistic understanding of brain function in health and disease requires different scientific approaches spanning multiple scales, from gene expression to behavior. Although 'wet' experimental approaches are essential for characterizing the properties of neural systems and testing hypotheses, theory and modeling are critical for exploring how these complex systems behave across a wider range of conditions, and for generating new experimentally testable, physically plausible hypotheses. Theory and modeling also provide a way to integrate a panoply of experimentally measured parameters, functional properties, and responses to perturbations into a physio-chemically coherent framework that reproduces the properties of the neural system of interest (Einevoll et al., 2019; Yao et al., 2022; Poirazi and Papoutsi, 2020; Gurnani and Silver, 2021; Gleeson et al., 2018; Cayco-Gajic et al., 2017; Billings et al., 2014; Vervaeke et al., 2010; Kriener et al., 2022; Billeh et al., 2020; Markram et al., 2015).","bBox":{"x":168.53,"y":68.68,"w":411.61,"h":105.77},"layoutAwareBbox":[{"x":165,"y":69,"w":409,"h":130,"startIndex":683,"endIndex":689}]},{"type":"text","value":"Computational models in neuroscience often focus on different levels of description. For example, a cellular physiologist may construct a complex multi-compartmental model to explain the dynamical behavior of an individual neuron in terms of its morphology, biophysical properties, and ionic conductances (Hay et al., 2011; De Schutter and Bower, 1994; Migliore et al., 2005). In contrast, to relate neural population activity to sensory processing and behavior, a systems neurophysiologist may build a circuit-level model consisting of thousands of much simpler integrate-and-fire neurons (Lapicque, 1907; Potjans and Diesmann, 2014; Brunel, 2000). Domain specific tools have been developed to aid the construction and simulation of models at varying levels of biological detail and scales. An ecosystem of diverse tools is powerful and flexible, but it also creates serious challenges for the research community (Cannon et al., 2007). Each tool typically has its own design, features, Application Programming Interface (API) and syntax, a custom set of utility libraries, and finally, a distinct machine-readable representation of the model's physiological components. This represents a complex landscape for users to navigate. Additionally, models developed in different simulators cannot be mixed and matched or easily compared, and the translation of a model from one tool-specific implementation to another can be non-trivial and error-prone. This fragmentation in modeling tools and approaches can act as a barrier to neuroscientists who wish to use models in their research, as well as impede how Findable, Accessible, Interoperable, and Reusable (FAIR) models are (Wilkinson et al., 2016).","md":"Computational models in neuroscience often focus on different levels of description. For example, a cellular physiologist may construct a complex multi-compartmental model to explain the dynamical behavior of an individual neuron in terms of its morphology, biophysical properties, and ionic conductances (Hay et al., 2011; De Schutter and Bower, 1994; Migliore et al., 2005). In contrast, to relate neural population activity to sensory processing and behavior, a systems neurophysiologist may build a circuit-level model consisting of thousands of much simpler integrate-and-fire neurons (Lapicque, 1907; Potjans and Diesmann, 2014; Brunel, 2000). Domain specific tools have been developed to aid the construction and simulation of models at varying levels of biological detail and scales. An ecosystem of diverse tools is powerful and flexible, but it also creates serious challenges for the research community (Cannon et al., 2007). Each tool typically has its own design, features, Application Programming Interface (API) and syntax, a custom set of utility libraries, and finally, a distinct machine-readable representation of the model's physiological components. This represents a complex landscape for users to navigate. Additionally, models developed in different simulators cannot be mixed and matched or easily compared, and the translation of a model from one tool-specific implementation to another can be non-trivial and error-prone. This fragmentation in modeling tools and approaches can act as a barrier to neuroscientists who wish to use models in their research, as well as impede how Findable, Accessible, Interoperable, and Reusable (FAIR) models are (Wilkinson et al., 2016).","bBox":{"x":168.53,"y":201.74,"w":412.08,"h":202.54},"layoutAwareBbox":[{"x":165,"y":202,"w":409,"h":214,"startIndex":0,"endIndex":13}]},{"type":"text","value":"To counter fragmentation and promote cooperation and interoperability within and across fields, standardization is required. The International Neuroinformatics Co-ordinating Facility (INCF) (Abrams et al., 2022) has highlighted the need for standards to 'make research outputs machine-readable and computable and are necessary for making research FAIR' (INCF, 2023). In biology, several community standards have been developed to describe experimental data (e.g. Brain Imaging Data Structure [BIDS; Gorgolewski et al., 2016], Neurodata Without Borders [NWB; Teeters et al., 2015]) and computational models (e.g. Systems Biology Markup Language [SBML; Hucka et al., 2003], CellML [Lloyd et al., 2004], Scalable Open Network Architecture TemplAte [SONATA; Dai et al., 2020], PyNN [Davison et al., 2008] and Neural Open Markup Language [NeuroML; Gleeson et al., 2010]). These standards have enabled open and interoperable ecosystems of software applications, libraries, and databases to emerge, facilitating the sharing of research outputs, an endeavor encouraged by a growing number of funding agencies and scientific journals.","md":"To counter fragmentation and promote cooperation and interoperability within and across fields, standardization is required. The International Neuroinformatics Co-ordinating Facility (INCF) (Abrams et al., 2022) has highlighted the need for standards to 'make research outputs machine-readable and computable and are necessary for making research FAIR' (INCF, 2023). In biology, several community standards have been developed to describe experimental data (e.g. Brain Imaging Data Structure [BIDS; Gorgolewski et al., 2016], Neurodata Without Borders [NWB; Teeters et al., 2015]) and computational models (e.g. Systems Biology Markup Language [SBML; Hucka et al., 2003], CellML [Lloyd et al., 2004], Scalable Open Network Architecture TemplAte [SONATA; Dai et al., 2020], PyNN [Davison et al., 2008] and Neural Open Markup Language [NeuroML; Gleeson et al., 2010]). These standards have enabled open and interoperable ecosystems of software applications, libraries, and databases to emerge, facilitating the sharing of research outputs, an endeavor encouraged by a growing number of funding agencies and scientific journals.","bBox":{"x":168.53,"y":431.56,"w":410.17,"h":117.86},"layoutAwareBbox":[{"x":165,"y":420,"w":409,"h":142,"startIndex":0,"endIndex":2}]},{"type":"text","value":"The initial version of the NeuroML standard, version 1 (NeuroMLv1), was originally conceived as a model description format (Goddard et al., 2001) and implemented as a three-layered, declarative, modular, simulator-independent language (Gleeson et al., 2010). NeuroMLv1 could describe detailed neuronal morphologies and their biophysical properties as well as specific instantiations of networks. It enabled the archiving of models in a standardized format and addressed the issue of simulator fragmentation by acting as the common language for model exchange between established simulation environments—NEURON (Hines and Carnevale, 1997; Awile et al., 2022), GENESIS (Bower and Beeman, 1998), and MOOSE (Ray and Bhalla, 2008). While solving a number of long-standing problems in computational neuroscience, NeuroMLv1 had several key limitations. The most restrictive of these was that the dynamical behavior of model elements was not formally described in the standard itself, making it only partially machine readable. Information on the dynamics of elements (i.e. how the state variables should evolve in time) was only provided in the form of human-readable documentation, requiring the developers of each new simulator to re-implement the behavior of these elements","md":"The initial version of the NeuroML standard, version 1 (NeuroMLv1), was originally conceived as a model description format (Goddard et al., 2001) and implemented as a three-layered, declarative, modular, simulator-independent language (Gleeson et al., 2010). NeuroMLv1 could describe detailed neuronal morphologies and their biophysical properties as well as specific instantiations of networks. It enabled the archiving of models in a standardized format and addressed the issue of simulator fragmentation by acting as the common language for model exchange between established simulation environments—NEURON (Hines and Carnevale, 1997; Awile et al., 2022), GENESIS (Bower and Beeman, 1998), and MOOSE (Ray and Bhalla, 2008). While solving a number of long-standing problems in computational neuroscience, NeuroMLv1 had several key limitations. The most restrictive of these was that the dynamical behavior of model elements was not formally described in the standard itself, making it only partially machine readable. Information on the dynamics of elements (i.e. how the state variables should evolve in time) was only provided in the form of human-readable documentation, requiring the developers of each new simulator to re-implement the behavior of these elements","bBox":{"x":168.53,"y":564.62,"w":414.87,"h":154.15},"layoutAwareBbox":[{"x":165,"y":565,"w":409,"h":154,"startIndex":37,"endIndex":40}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    2 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    2 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                           Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    2 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.982,"layout":[{"image":"page_2_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.255,"w":0.668,"h":0.271},"isLikelyNoise":false},{"image":"page_2_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.714,"w":0.669,"h":0.195},"isLikelyNoise":false},{"image":"page_2_text_3_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.53,"w":0.669,"h":0.181},"isLikelyNoise":false},{"image":"page_2_text_4_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.087,"w":0.668,"h":0.165},"isLikelyNoise":false},{"image":"page_2_footer_1_v2.jpg","confidence":0.88,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_2_paragraph_title_1_v2.jpg","confidence":0.88,"label":"paragraph_title","bbox":{"x":0.272,"y":0.067,"w":0.137,"h":0.014},"isLikelyNoise":false},{"image":"page_2_header_1_v2.jpg","confidence":0.86,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_2_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.042,"h":0.009},"isLikelyNoise":false},{"image":"page_2_header_2_v2.jpg","confidence":0.7,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_2_header_3_v2.jpg","confidence":0.57,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":3,"text":"Tools  and  resources    Neuroscience\n\n\nCreate\n      Validate\n\nReuse\n\n\n\n[WonN]  Visualize\n\n\nShare\n\n     Simulate\n     Fit\n\n\nFigure 1. The NeuroML software ecosystem supports all stages of the model development life cycle.\n\n\nin their native format. Additionally, the introduction of new model components required updates to\nthe standard and all supporting simulators, making extension of the language difﬁcult. Finally, the use\nof Extensible Markup Language (XML) as the primary interface language limited usability—applica-\ntions would generally have to add their own code to read/write XML ﬁles.\nTo address these limitations, NeuroML was redesigned from the ground up in version 2 (NeuroMLv2)\nusing the Low Entropy Modeling Speciﬁcation (LEMS) language (Cannon et  al., 2014). LEMS was\ndesigned to deﬁne a wide range of physio- chemical systems, enabling the creation of fully machine-\nreadable, formal deﬁnitions of the structure and dynamics of any model components. Modeling\nelements in NeuroMLv2 (cells, ion channels, synapses) have their mathematical and structural deﬁ-\nnitions described in LEMS (e.g. the parameters required and how the state variables change with\ntime). Thus, NeuroMLv2 retains all the features of NeuroMLv1—it remains modular, declarative, and\ncontinues to support multiple simulation engines—but unlike version 1, it is extensible, and all speci-\nﬁcations are fully machine-readable. NeuroMLv2 also moved to Python as its main interface language\nand provides a comprehensive set of Python libraries to improve usability (Vella et al., 2014), with\nXML retained as a machine- readable serialization format (i.e. the form in which the model ﬁles are\nsaved/shared).\nSince its release in 2014, the NeuroMLv2 standard, the software ecosystem, and the commu-\nnity have all steadily grown. An open, community- based governance structure was put in place—an\nelected Editorial Board, overseen by an independent Scientiﬁc Committee, maintains the standard\nand core software tools—APIs, reference simulators, and utilities. Although these tools were initially\nfocused on enabling the simulation of models on multiple platforms, they have been expanded to\nsupport all stages of the model life cycle (Figure 1). Modelers can use these tools to easily create,\ninspect and visualize, validate, simulate, ﬁt and optimize, share and disseminate NeuroMLv2 models\nand outputs (Billings et al., 2014;\n              Cayco‐Gajic et al., 2017; Gurnani and Silver, 2021; Kriener et al.,\n2022; Gleeson et al., 2019b). To provide clear, concise, searchable information for both users and\ndevelopers, the NeuroML documentation has been signiﬁcantly expanded and re-    deployed using\nthe latest modern web technologies (https://docs.neuroml.org). Increased community-\n                                                                                wide collabora-\ntions have also extended the software ecosystem well beyond the NeuroMLv2 tools developed by the\nNeuroML team: additional simulators such as Brian (Stimberg et al., 2019), NetPyNE (Dura‐ Bernal\net al., 2019), Arbor (Akar et al., 2019) and EDEN (Panagiotou et al., 2022) all support NeuroMLv2.\nWe have worked to ensure interoperability with other structured formats for model development\nin neuroscience such as PyNN (Davison et  al., 2008) and SONATA (Dai et  al., 2020). Platforms\nfor collaboratively developing, visualizing, and sharing NeuroML models (Open Source Brain (OSB)\nGleeson et al., 2019b) as well as a searchable database of NeuroML model components NeuroML\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    3 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n```mermaid\ngraph TD\n    A[Create] --> B[Validate]\n    B --> C[Visualize]\n    C --> D[Simulate]\n    D --> E[Fit]\n    E --> F[Share]\n    F --> G[Reuse]\n    G --> A\n    H[NeuroML] --> A\n    H --> B\n    H --> C\n    H --> D\n    H --> E\n    H --> F\n    H --> G\n```\n\n**Figure 1.** The NeuroML software ecosystem supports all stages of the model development life cycle.\n\nin their native format. Additionally, the introduction of new model components required updates to the standard and all supporting simulators, making extension of the language difficult. Finally, the use of Extensible Markup Language (XML) as the primary interface language limited usability—applications would generally have to add their own code to read/write XML files.\n\nTo address these limitations, NeuroML was redesigned from the ground up in version 2 (NeuroMLv2) using the Low Entropy Modeling Specification (LEMS) language (Cannon *et al.*, 2014). LEMS was designed to define a wide range of physio-chemical systems, enabling the creation of fully machine-readable, formal definitions of the structure and dynamics of any model components. Modeling elements in NeuroMLv2 (cells, ion channels, synapses) have their mathematical and structural definitions described in LEMS (e.g. the parameters required and how the state variables change with time). Thus, NeuroMLv2 retains all the features of NeuroMLv1—it remains modular, declarative, and continues to support multiple simulation engines—but unlike version 1, it is extensible, and all specifications are fully machine-readable. NeuroMLv2 also moved to Python as its main interface language and provides a comprehensive set of Python libraries to improve usability (Vella *et al.*, 2014), with XML retained as a machine-readable serialization format (i.e. the form in which the model files are saved/shared).\n\nSince its release in 2014, the NeuroMLv2 standard, the software ecosystem, and the community have all steadily grown. An open, community-based governance structure was put in place—an elected Editorial Board, overseen by an independent Scientific Committee, maintains the standard and core software tools—APIs, reference simulators, and utilities. Although these tools were initially focused on enabling the simulation of models on multiple platforms, they have been expanded to support all stages of the model life cycle (Figure 1). Modelers can use these tools to easily create, inspect and visualize, validate, simulate, fit and optimize, share and disseminate NeuroMLv2 models and outputs (Billings *et al.*, 2014; Cayco-Gajic *et al.*, 2017; Gurnani and Silver, 2021; Kriener *et al.*, 2022; Gleeson *et al.*, 2019b). To provide clear, concise, searchable information for both users and developers, the NeuroML documentation has been significantly expanded and re-deployed using the latest modern web technologies (https://docs.neuroml.org). Increased community-wide collaborations have also extended the software ecosystem well beyond the NeuroMLv2 tools developed by the NeuroML team: additional simulators such as Brian (Stimberg *et al.*, 2019), NetPyNE (Dura-Bernal *et al.*, 2019), Arbor (Akar *et al.*, 2019) and EDEN (Panagiotou *et al.*, 2022) all support NeuroMLv2. We have worked to ensure interoperability with other structured formats for model development in neuroscience such as PyNN (Davison *et al.*, 2008) and SONATA (Dai *et al.*, 2020). Platforms for collaboratively developing, visualizing, and sharing NeuroML models (Open Source Brain (OSB) Gleeson *et al.*, 2019b) as well as a searchable database of NeuroML model components NeuroML\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    3 of 44\n","images":[{"name":"img_p2_1.jpg","height":43.191,"width":136.457,"x":299.512,"y":144.457,"original_width":569,"original_height":180,"rotation":180,"ocr":[{"x":12,"y":56,"w":373,"h":88,"confidence":0.495,"text":"[WonN]"}]},{"name":"page_3.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_3_text_1_v2.jpg","height":169235.984,"width":250456.664,"x":101180.721,"y":401698.689,"original_width":1654,"original_height":864,"rotation":0,"type":"layout_v2_text"},{"name":"page_3_text_2_v2.jpg","height":111744.317,"width":250297.532,"x":101191.489,"y":287651.43,"original_width":1653,"original_height":571,"rotation":0,"type":"layout_v2_text"},{"name":"page_3_image_1_v2.jpg","height":174884.631,"width":248130.008,"x":102993.102,"y":42688.433,"original_width":1639,"original_height":893,"rotation":0,"type":"layout_v2_image"},{"name":"page_3_text_3_v2.jpg","height":36208.814,"width":250222.759,"x":101149.779,"y":249393.736,"original_width":1653,"original_height":185,"rotation":0,"type":"layout_v2_text"},{"name":"page_3_figure_title_1_v2.jpg","height":7557.394,"width":219490.462,"x":101636.187,"y":223149.932,"original_width":1450,"original_height":39,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_3_footer_1_v2.jpg","height":6945.184,"width":191907.65,"x":21534.418,"y":591463.103,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_3_header_1_v2.jpg","height":5722.929,"width":30425.846,"x":320789.757,"y":27660.864,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_3_number_1_v2.jpg","height":5854.039,"width":15482.737,"x":335656.473,"y":591807.118,"original_width":103,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_3_header_2_v2.jpg","height":5811.91,"width":42844.601,"x":47759.379,"y":27799.632,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_3_header_3_v2.jpg","height":10796.832,"width":24453.408,"x":21819.995,"y":22367.305,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"```mermaid\ngraph TD\n    A[Create] --> B[Validate]\n    B --> C[Visualize]\n    C --> D[Simulate]\n    D --> E[Fit]\n    E --> F[Share]\n    F --> G[Reuse]\n    G --> A\n    H[NeuroML] --> A\n    H --> B\n    H --> C\n    H --> D\n    H --> E\n    H --> F\n    H --> G\n```","md":"```mermaid\ngraph TD\n    A[Create] --> B[Validate]\n    B --> C[Visualize]\n    C --> D[Simulate]\n    D --> E[Fit]\n    E --> F[Share]\n    F --> G[Reuse]\n    G --> A\n    H[NeuroML] --> A\n    H --> B\n    H --> C\n    H --> D\n    H --> E\n    H --> F\n    H --> G\n```","bBox":{"x":194.83,"y":68.7,"w":365.03,"h":189.07},"layoutAwareBbox":[{"x":194.83,"y":68.7,"w":365.03,"h":189.07,"startIndex":0,"endIndex":257}]},{"type":"text","value":"**Figure 1.** The NeuroML software ecosystem supports all stages of the model development life cycle.","md":"**Figure 1.** The NeuroML software ecosystem supports all stages of the model development life cycle.","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":166,"y":281,"w":358,"h":9,"startIndex":0,"endIndex":100}]},{"type":"text","value":"in their native format. Additionally, the introduction of new model components required updates to the standard and all supporting simulators, making extension of the language difficult. Finally, the use of Extensible Markup Language (XML) as the primary interface language limited usability—applications would generally have to add their own code to read/write XML files.","md":"in their native format. Additionally, the introduction of new model components required updates to the standard and all supporting simulators, making extension of the language difficult. Finally, the use of Extensible Markup Language (XML) as the primary interface language limited usability—applications would generally have to add their own code to read/write XML files.","bBox":{"x":168.53,"y":314.49,"w":403.24,"h":9},"layoutAwareBbox":[{"x":165,"y":314,"w":408,"h":45,"startIndex":0,"endIndex":371}]},{"type":"text","value":"To address these limitations, NeuroML was redesigned from the ground up in version 2 (NeuroMLv2) using the Low Entropy Modeling Specification (LEMS) language (Cannon *et al.*, 2014). LEMS was designed to define a wide range of physio-chemical systems, enabling the creation of fully machine-readable, formal definitions of the structure and dynamics of any model components. Modeling elements in NeuroMLv2 (cells, ion channels, synapses) have their mathematical and structural definitions described in LEMS (e.g. the parameters required and how the state variables change with time). Thus, NeuroMLv2 retains all the features of NeuroMLv1—it remains modular, declarative, and continues to support multiple simulation engines—but unlike version 1, it is extensible, and all specifications are fully machine-readable. NeuroMLv2 also moved to Python as its main interface language and provides a comprehensive set of Python libraries to improve usability (Vella *et al.*, 2014), with XML retained as a machine-readable serialization format (i.e. the form in which the model files are saved/shared).","md":"To address these limitations, NeuroML was redesigned from the ground up in version 2 (NeuroMLv2) using the Low Entropy Modeling Specification (LEMS) language (Cannon *et al.*, 2014). LEMS was designed to define a wide range of physio-chemical systems, enabling the creation of fully machine-readable, formal definitions of the structure and dynamics of any model components. Modeling elements in NeuroMLv2 (cells, ion channels, synapses) have their mathematical and structural definitions described in LEMS (e.g. the parameters required and how the state variables change with time). Thus, NeuroMLv2 retains all the features of NeuroMLv1—it remains modular, declarative, and continues to support multiple simulation engines—but unlike version 1, it is extensible, and all specifications are fully machine-readable. NeuroMLv2 also moved to Python as its main interface language and provides a comprehensive set of Python libraries to improve usability (Vella *et al.*, 2014), with XML retained as a machine-readable serialization format (i.e. the form in which the model files are saved/shared).","bBox":{"x":168.53,"y":362.48,"w":420.4,"h":140.97},"layoutAwareBbox":[{"x":165,"y":363,"w":408,"h":141,"startIndex":24,"endIndex":27}]},{"type":"text","value":"Since its release in 2014, the NeuroMLv2 standard, the software ecosystem, and the community have all steadily grown. An open, community-based governance structure was put in place—an elected Editorial Board, overseen by an independent Scientific Committee, maintains the standard and core software tools—APIs, reference simulators, and utilities. Although these tools were initially focused on enabling the simulation of models on multiple platforms, they have been expanded to support all stages of the model life cycle (Figure 1). Modelers can use these tools to easily create, inspect and visualize, validate, simulate, fit and optimize, share and disseminate NeuroMLv2 models and outputs (Billings *et al.*, 2014; Cayco-Gajic *et al.*, 2017; Gurnani and Silver, 2021; Kriener *et al.*, 2022; Gleeson *et al.*, 2019b). To provide clear, concise, searchable information for both users and developers, the NeuroML documentation has been significantly expanded and re-deployed using the latest modern web technologies (https://docs.neuroml.org). Increased community-wide collaborations have also extended the software ecosystem well beyond the NeuroMLv2 tools developed by the NeuroML team: additional simulators such as Brian (Stimberg *et al.*, 2019), NetPyNE (Dura-Bernal *et al.*, 2019), Arbor (Akar *et al.*, 2019) and EDEN (Panagiotou *et al.*, 2022) all support NeuroMLv2. We have worked to ensure interoperability with other structured formats for model development in neuroscience such as PyNN (Davison *et al.*, 2008) and SONATA (Dai *et al.*, 2020). Platforms for collaboratively developing, visualizing, and sharing NeuroML models (Open Source Brain (OSB) Gleeson *et al.*, 2019b) as well as a searchable database of NeuroML model components NeuroML","md":"Since its release in 2014, the NeuroMLv2 standard, the software ecosystem, and the community have all steadily grown. An open, community-based governance structure was put in place—an elected Editorial Board, overseen by an independent Scientific Committee, maintains the standard and core software tools—APIs, reference simulators, and utilities. Although these tools were initially focused on enabling the simulation of models on multiple platforms, they have been expanded to support all stages of the model life cycle (Figure 1). Modelers can use these tools to easily create, inspect and visualize, validate, simulate, fit and optimize, share and disseminate NeuroMLv2 models and outputs (Billings *et al.*, 2014; Cayco-Gajic *et al.*, 2017; Gurnani and Silver, 2021; Kriener *et al.*, 2022; Gleeson *et al.*, 2019b). To provide clear, concise, searchable information for both users and developers, the NeuroML documentation has been significantly expanded and re-deployed using the latest modern web technologies (https://docs.neuroml.org). Increased community-wide collaborations have also extended the software ecosystem well beyond the NeuroMLv2 tools developed by the NeuroML team: additional simulators such as Brian (Stimberg *et al.*, 2019), NetPyNE (Dura-Bernal *et al.*, 2019), Arbor (Akar *et al.*, 2019) and EDEN (Panagiotou *et al.*, 2022) all support NeuroMLv2. We have worked to ensure interoperability with other structured formats for model development in neuroscience such as PyNN (Davison *et al.*, 2008) and SONATA (Dai *et al.*, 2020). Platforms for collaboratively developing, visualizing, and sharing NeuroML models (Open Source Brain (OSB) Gleeson *et al.*, 2019b) as well as a searchable database of NeuroML model components NeuroML","bBox":{"x":168.53,"y":34.63,"w":414.44,"h":672.76},"layoutAwareBbox":[{"x":165,"y":507,"w":409,"h":213,"startIndex":27,"endIndex":30}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    3 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    3 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/","unsafeUrl":"https://docs.neuroml.org","text":"the latest modern web technologies (https://docs.neuroml.org). Increased community-"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    3 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.919,"layout":[{"image":"page_3_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.64,"w":0.669,"h":0.27},"isLikelyNoise":false},{"image":"page_3_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.459,"w":0.668,"h":0.178},"isLikelyNoise":false},{"image":"page_3_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.068,"w":0.662,"h":0.279},"isLikelyNoise":false},{"image":"page_3_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.398,"w":0.668,"h":0.058},"isLikelyNoise":false},{"image":"page_3_figure_title_1_v2.jpg","confidence":0.9,"label":"figure_title","bbox":{"x":0.271,"y":0.356,"w":0.586,"h":0.012},"isLikelyNoise":false},{"image":"page_3_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_3_header_1_v2.jpg","confidence":0.86,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_3_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.896,"y":0.943,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_3_header_2_v2.jpg","confidence":0.67,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_3_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":4,"text":"Tools  and  resources                                                                                     Neuroscience\n\n                         Database (NeuroML-DB) (Birgiolas et al., 2023) have been developed. These enhancements, driven\n                         by an ever-expanding community, have helped NeuroMLv2 grow into a standard that has been ofﬁ-\n                         cially endorsed by international organizations such as the INCF and COmputational Modeling in\n                         Biology NEtwork (COMBINE) (Hucka et al., 2015), and that is now sufﬁciently mature to be incorpo-\n                         rated into a wide range of research workﬂows.\n                         In this paper, we provide an overview of the current scope of version 2 of the NeuroML standard,\n                         describe the current software ecosystem and community, and outline the extensive resources to assist\n                         researchers in incorporate NeuroML into their modeling work. We demonstrate, with examples, that\n                         NeuroML supports users at all stages of the model development life cycle (Figure 1) and promotes\n                         FAIR principles in computational neuroscience. We highlight the various NeuroML tools and libraries,\n                         additional utilities, supported simulation engines, and the related projects that build upon NeuroML\n                         for automated model validation, advanced analysis, visualization, and sharing/re-\n                                                                      use of models. Finally,\n                         we summarize the organizational aspects of NeuroML, its governance structure and its community.\n\n\nResults\nNeuroML provides a ready-to-use set of curated model elements\nA central aim of the NeuroML initiative is to enable and encourage the use of multi-\n                                                            scale biophysically\ndetailed models of neurons and neuronal circuits in neuroscience research. The initiative takes a range\nof steps to achieve this aim.\nNeuroML provides users with a curated library of model elements that form the NeuroML standard\n(An index of all the model elements included in version 2.3 of NeuroML, with links to further online\ndocumentation, is provided in Tables 1 and 2; Figure 2). The standard is maintained by the NeuroML\nEditorial Board that has identiﬁed a fundamental set of model types to support, to ensure that a\nsigniﬁcant proportion of commonly used neurobiological modeling entities can be described with the\nlanguage. This includes (but is not limited to): active membrane conductances (using Hodgkin-\n                                                                                       Huxley\nstyle [Hodgkin and Huxley, 1952] or kinetic scheme-\n                                              based ionic conductances), multiple synapse and\nplasticity mechanisms, detailed multi-compartmental neuron models with morphologies and biophys-\nical properties, abstract point neuron models, and networks of such cells spatially arranged in popula-\ntions, connected by targeted projections, receiving spiking and currently based inputs.\nThe NeuroMLv2 standard consists of two levels that are designed to enable users to easily create\ntheir models without worrying about simulator-\n                             speciﬁc details. The ﬁrst level deﬁnes a formal ‘schema’\nfor the standard model elements, their attributes/parameters (e.g. an integrate and ﬁre cell model\nand its necessary attributes: a threshold parameter, a reset parameter, etc.), and the relationships\nbetween them (e.g. a network contains populations; a multi-\n                                                            compartmental cell morphology contains\nsegments). This allows the validation of the completeness of the description of individual NeuroML\nmodel elements and models, prior to simulation. The second level deﬁnes the underlying dynamical\nbehavior of the model elements (e.g. how the time- varying membrane potential of a cell model is to\nbe calculated). Most users do not need to interact with this level (which is enabled by LEMS), which,\namong other features, enables the automated translation of simulator‐ independent NeuroML models\ninto simulator‐ speciﬁc code.\nThus, modelers can use the standard NeuroML elements to conveniently build simulator-\nindependent models, while also being able to examine and extend the underlying implementations\nof models. As a simulator- independent language, NeuroML also promotes interoperability between\ndifferent computational modeling tools, and as a result, the standard library is complemented by a\nlarge, well-maintained ecosystem of software tools that support all stages of the model life cycle—\nfrom creation, analysis, simulation, and ﬁtting, to sharing and reuse. Finally, as discussed in later\nsections, for advanced use cases where the existing NeuroML model building blocks are insufﬁcient,\nNeuroML also includes a framework for creating and including new model elements.\n\nNeuroML is a modular, structured language for defining FAIR models\nNeuroMLv2 is a modular, structured, hierarchical, simulator-\n                                                   independent format. All NeuroML elements\nare formally deﬁned, independent, and self- contained with hierarchical relationships between them.\nAn ‘ionic conductance’ model element in NeuroML, for example, can contain zero, one, or more\n‘gates’ and be added into a ‘cell’ model element along with a ‘morphology’ element, which can then\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    4 of 44","md":"\n\neLife Tools and resources                                                                                     Neuroscience\n\nDatabase (NeuroML-DB) (*Birgiolas et al.*, 2023) have been developed. These enhancements, driven by an ever-expanding community, have helped NeuroMLv2 grow into a standard that has been officially endorsed by international organizations such as the INCF and COmputational Modeling in Biology NEtwork (COMBINE) (*Hucka et al.*, 2015), and that is now sufficiently mature to be incorporated into a wide range of research workflows.\n\nIn this paper, we provide an overview of the current scope of version 2 of the NeuroML standard, describe the current software ecosystem and community, and outline the extensive resources to assist researchers in incorporate NeuroML into their modeling work. We demonstrate, with examples, that NeuroML supports users at all stages of the model development life cycle (Figure 1) and promotes FAIR principles in computational neuroscience. We highlight the various NeuroML tools and libraries, additional utilities, supported simulation engines, and the related projects that build upon NeuroML for automated model validation, advanced analysis, visualization, and sharing/re-use of models. Finally, we summarize the organizational aspects of NeuroML, its governance structure and its community.\n\n## Results\n\n### NeuroML provides a ready-to-use set of curated model elements\n\nA central aim of the NeuroML initiative is to enable and encourage the use of multi-scale biophysically detailed models of neurons and neuronal circuits in neuroscience research. The initiative takes a range of steps to achieve this aim.\n\nNeuroML provides users with a curated library of model elements that form the NeuroML standard (An index of all the model elements included in version 2.3 of NeuroML, with links to further online documentation, is provided in Tables 1 and 2; Figure 2). The standard is maintained by the NeuroML Editorial Board that has identified a fundamental set of model types to support, to ensure that a significant proportion of commonly used neurobiological modeling entities can be described with the language. This includes (but is not limited to): active membrane conductances (using Hodgkin-Huxley style [Hodgkin and Huxley, 1952] or kinetic scheme-based ionic conductances), multiple synapse and plasticity mechanisms, detailed multi-compartmental neuron models with morphologies and biophysical properties, abstract point neuron models, and networks of such cells spatially arranged in populations, connected by targeted projections, receiving spiking and currently based inputs.\n\nThe NeuroMLv2 standard consists of two levels that are designed to enable users to easily create their models without worrying about simulator-specific details. The first level defines a formal 'schema' for the standard model elements, their attributes/parameters (e.g. an integrate and fire cell model and its necessary attributes: a threshold parameter, a reset parameter, etc.), and the relationships between them (e.g. a network contains populations; a multi-compartmental cell morphology contains segments). This allows the validation of the completeness of the description of individual NeuroML model elements and models, prior to simulation. The second level defines the underlying dynamical behavior of the model elements (e.g. how the time-varying membrane potential of a cell model is to be calculated). Most users do not need to interact with this level (which is enabled by LEMS), which, among other features, enables the automated translation of simulator-independent NeuroML models into simulator-specific code.\n\nThus, modelers can use the standard NeuroML elements to conveniently build simulator-independent models, while also being able to examine and extend the underlying implementations of models. As a simulator-independent language, NeuroML also promotes interoperability between different computational modeling tools, and as a result, the standard library is complemented by a large, well-maintained ecosystem of software tools that support all stages of the model life cycle—from creation, analysis, simulation, and fitting, to sharing and reuse. Finally, as discussed in later sections, for advanced use cases where the existing NeuroML model building blocks are insufficient, NeuroML also includes a framework for creating and including new model elements.\n\n### NeuroML is a modular, structured language for defining FAIR models\n\nNeuroMLv2 is a modular, structured, hierarchical, simulator-independent format. All NeuroML elements are formally defined, independent, and self-contained with hierarchical relationships between them. An 'ionic conductance' model element in NeuroML, for example, can contain zero, one, or more 'gates' and be added into a 'cell' model element along with a 'morphology' element, which can then\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    4 of 44\n","images":[{"name":"page_4.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_4_text_1_v2.jpg","height":101909.386,"width":250491.74,"x":101011.866,"y":332199.249,"original_width":1654,"original_height":520,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_2_v2.jpg","height":93079.92,"width":250468.28,"x":101016.879,"y":237089.404,"original_width":1654,"original_height":475,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_3_v2.jpg","height":73917.103,"width":250487.802,"x":101040.748,"y":436465.855,"original_width":1654,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_4_v2.jpg","height":74035.405,"width":250171.544,"x":101162.934,"y":89124.625,"original_width":1652,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_5_v2.jpg","height":45335.654,"width":250336.894,"x":101158.488,"y":41435.456,"original_width":1653,"original_height":232,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_6_v2.jpg","height":35939.58,"width":250305.241,"x":101290.222,"y":534903.1,"original_width":1653,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_text_7_v2.jpg","height":26030.848,"width":250245.81,"x":101211.708,"y":208517.843,"original_width":1653,"original_height":133,"rotation":0,"type":"layout_v2_text"},{"name":"page_4_paragraph_title_1_v2.jpg","height":8830.759,"width":240971.628,"x":101347.093,"y":522890.151,"original_width":1592,"original_height":46,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_4_paragraph_title_2_v2.jpg","height":9084.096,"width":226834.296,"x":101398.42,"y":196553.566,"original_width":1498,"original_height":47,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_4_footer_1_v2.jpg","height":6789.191,"width":191905.622,"x":21500.037,"y":591499.915,"original_width":1268,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_4_header_1_v2.jpg","height":5585.364,"width":30346.575,"x":320753.998,"y":27702.567,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_4_number_1_v2.jpg","height":5643.749,"width":15477.602,"x":335632.407,"y":591911.4,"original_width":103,"original_height":29,"rotation":0,"type":"layout_v2_number"},{"name":"page_4_paragraph_title_3_v2.jpg","height":8677.46,"width":30230.965,"x":101869.34,"y":183613.815,"original_width":200,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_4_header_2_v2.jpg","height":5714.872,"width":42932.556,"x":47680.193,"y":27841.369,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_4_header_3_v2.jpg","height":10646.685,"width":24459.567,"x":21794.318,"y":22424.341,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                     Neuroscience","md":"eLife Tools and resources                                                                                     Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":110,"endIndex":122}]},{"type":"text","value":"Database (NeuroML-DB) (*Birgiolas et al.*, 2023) have been developed. These enhancements, driven by an ever-expanding community, have helped NeuroMLv2 grow into a standard that has been officially endorsed by international organizations such as the INCF and COmputational Modeling in Biology NEtwork (COMBINE) (*Hucka et al.*, 2015), and that is now sufficiently mature to be incorporated into a wide range of research workflows.","md":"Database (NeuroML-DB) (*Birgiolas et al.*, 2023) have been developed. These enhancements, driven by an ever-expanding community, have helped NeuroMLv2 grow into a standard that has been officially endorsed by international organizations such as the INCF and COmputational Modeling in Biology NEtwork (COMBINE) (*Hucka et al.*, 2015), and that is now sufficiently mature to be incorporated into a wide range of research workflows.","bBox":{"x":168.53,"y":75.8,"w":389.18,"h":9},"layoutAwareBbox":[{"x":165,"y":52,"w":409,"h":57,"startIndex":18,"endIndex":20}]},{"type":"text","value":"In this paper, we provide an overview of the current scope of version 2 of the NeuroML standard, describe the current software ecosystem and community, and outline the extensive resources to assist researchers in incorporate NeuroML into their modeling work. We demonstrate, with examples, that NeuroML supports users at all stages of the model development life cycle (Figure 1) and promotes FAIR principles in computational neuroscience. We highlight the various NeuroML tools and libraries, additional utilities, supported simulation engines, and the related projects that build upon NeuroML for automated model validation, advanced analysis, visualization, and sharing/re-use of models. Finally, we summarize the organizational aspects of NeuroML, its governance structure and its community.","md":"In this paper, we provide an overview of the current scope of version 2 of the NeuroML standard, describe the current software ecosystem and community, and outline the extensive resources to assist researchers in incorporate NeuroML into their modeling work. We demonstrate, with examples, that NeuroML supports users at all stages of the model development life cycle (Figure 1) and promotes FAIR principles in computational neuroscience. We highlight the various NeuroML tools and libraries, additional utilities, supported simulation engines, and the related projects that build upon NeuroML for automated model validation, advanced analysis, visualization, and sharing/re-use of models. Finally, we summarize the organizational aspects of NeuroML, its governance structure and its community.","bBox":{"x":168.53,"y":111.79,"w":412.74,"h":92.98},"layoutAwareBbox":[{"x":165,"y":112,"w":408,"h":93,"startIndex":41,"endIndex":44}]},{"type":"heading","lvl":2,"value":"Results","md":"## Results","bBox":{"x":168.53,"y":229.53,"w":47.45,"h":14},"layoutAwareBbox":[{"x":166,"y":231,"w":49,"h":10,"startIndex":3,"endIndex":10}]},{"type":"heading","lvl":3,"value":"NeuroML provides a ready-to-use set of curated model elements","md":"### NeuroML provides a ready-to-use set of curated model elements","bBox":{"x":168.53,"y":246.53,"w":367.69,"h":12},"layoutAwareBbox":[{"x":165,"y":248,"w":370,"h":11,"startIndex":0,"endIndex":64}]},{"type":"text","value":"A central aim of the NeuroML initiative is to enable and encourage the use of multi-scale biophysically detailed models of neurons and neuronal circuits in neuroscience research. The initiative takes a range of steps to achieve this aim.","md":"A central aim of the NeuroML initiative is to enable and encourage the use of multi-scale biophysically detailed models of neurons and neuronal circuits in neuroscience research. The initiative takes a range of steps to achieve this aim.","bBox":{"x":168.53,"y":262.53,"w":413.91,"h":32.99},"layoutAwareBbox":[{"x":165,"y":263,"w":408,"h":32,"startIndex":0,"endIndex":236}]},{"type":"text","value":"NeuroML provides users with a curated library of model elements that form the NeuroML standard (An index of all the model elements included in version 2.3 of NeuroML, with links to further online documentation, is provided in Tables 1 and 2; Figure 2). The standard is maintained by the NeuroML Editorial Board that has identified a fundamental set of model types to support, to ensure that a significant proportion of commonly used neurobiological modeling entities can be described with the language. This includes (but is not limited to): active membrane conductances (using Hodgkin-Huxley style [Hodgkin and Huxley, 1952] or kinetic scheme-based ionic conductances), multiple synapse and plasticity mechanisms, detailed multi-compartmental neuron models with morphologies and biophysical properties, abstract point neuron models, and networks of such cells spatially arranged in populations, connected by targeted projections, receiving spiking and currently based inputs.","md":"NeuroML provides users with a curated library of model elements that form the NeuroML standard (An index of all the model elements included in version 2.3 of NeuroML, with links to further online documentation, is provided in Tables 1 and 2; Figure 2). The standard is maintained by the NeuroML Editorial Board that has identified a fundamental set of model types to support, to ensure that a significant proportion of commonly used neurobiological modeling entities can be described with the language. This includes (but is not limited to): active membrane conductances (using Hodgkin-Huxley style [Hodgkin and Huxley, 1952] or kinetic scheme-based ionic conductances), multiple synapse and plasticity mechanisms, detailed multi-compartmental neuron models with morphologies and biophysical properties, abstract point neuron models, and networks of such cells spatially arranged in populations, connected by targeted projections, receiving spiking and currently based inputs.","bBox":{"x":168.53,"y":298.52,"w":413.05,"h":116.97},"layoutAwareBbox":[{"x":165,"y":299,"w":409,"h":117,"startIndex":46,"endIndex":48}]},{"type":"text","value":"The NeuroMLv2 standard consists of two levels that are designed to enable users to easily create their models without worrying about simulator-specific details. The first level defines a formal 'schema' for the standard model elements, their attributes/parameters (e.g. an integrate and fire cell model and its necessary attributes: a threshold parameter, a reset parameter, etc.), and the relationships between them (e.g. a network contains populations; a multi-compartmental cell morphology contains segments). This allows the validation of the completeness of the description of individual NeuroML model elements and models, prior to simulation. The second level defines the underlying dynamical behavior of the model elements (e.g. how the time-varying membrane potential of a cell model is to be calculated). Most users do not need to interact with this level (which is enabled by LEMS), which, among other features, enables the automated translation of simulator-independent NeuroML models into simulator-specific code.","md":"The NeuroMLv2 standard consists of two levels that are designed to enable users to easily create their models without worrying about simulator-specific details. The first level defines a formal 'schema' for the standard model elements, their attributes/parameters (e.g. an integrate and fire cell model and its necessary attributes: a threshold parameter, a reset parameter, etc.), and the relationships between them (e.g. a network contains populations; a multi-compartmental cell morphology contains segments). This allows the validation of the completeness of the description of individual NeuroML model elements and models, prior to simulation. The second level defines the underlying dynamical behavior of the model elements (e.g. how the time-varying membrane potential of a cell model is to be calculated). Most users do not need to interact with this level (which is enabled by LEMS), which, among other features, enables the automated translation of simulator-independent NeuroML models into simulator-specific code.","bBox":{"x":168.53,"y":418.49,"w":409.63,"h":104.98},"layoutAwareBbox":[{"x":165,"y":419,"w":409,"h":128,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Thus, modelers can use the standard NeuroML elements to conveniently build simulator-independent models, while also being able to examine and extend the underlying implementations of models. As a simulator-independent language, NeuroML also promotes interoperability between different computational modeling tools, and as a result, the standard library is complemented by a large, well-maintained ecosystem of software tools that support all stages of the model life cycle—from creation, analysis, simulation, and fitting, to sharing and reuse. Finally, as discussed in later sections, for advanced use cases where the existing NeuroML model building blocks are insufficient, NeuroML also includes a framework for creating and including new model elements.","md":"Thus, modelers can use the standard NeuroML elements to conveniently build simulator-independent models, while also being able to examine and extend the underlying implementations of models. As a simulator-independent language, NeuroML also promotes interoperability between different computational modeling tools, and as a result, the standard library is complemented by a large, well-maintained ecosystem of software tools that support all stages of the model life cycle—from creation, analysis, simulation, and fitting, to sharing and reuse. Finally, as discussed in later sections, for advanced use cases where the existing NeuroML model building blocks are insufficient, NeuroML also includes a framework for creating and including new model elements.","bBox":{"x":168.53,"y":550.46,"w":405.92,"h":92.98},"layoutAwareBbox":[{"x":165,"y":551,"w":409,"h":93,"startIndex":53,"endIndex":55}]},{"type":"heading","lvl":3,"value":"NeuroML is a modular, structured language for defining FAIR models","md":"### NeuroML is a modular, structured language for defining FAIR models","bBox":{"x":168.53,"y":658.48,"w":390.85,"h":12},"layoutAwareBbox":[{"x":165,"y":660,"w":393,"h":11,"startIndex":0,"endIndex":69}]},{"type":"text","value":"NeuroMLv2 is a modular, structured, hierarchical, simulator-independent format. All NeuroML elements are formally defined, independent, and self-contained with hierarchical relationships between them. An 'ionic conductance' model element in NeuroML, for example, can contain zero, one, or more 'gates' and be added into a 'cell' model element along with a 'morphology' element, which can then","md":"NeuroMLv2 is a modular, structured, hierarchical, simulator-independent format. All NeuroML elements are formally defined, independent, and self-contained with hierarchical relationships between them. An 'ionic conductance' model element in NeuroML, for example, can contain zero, one, or more 'gates' and be added into a 'cell' model element along with a 'morphology' element, which can then","bBox":{"x":168.53,"y":674.48,"w":413,"h":9},"layoutAwareBbox":[{"x":165,"y":675,"w":408,"h":45,"startIndex":0,"endIndex":391}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    4 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    4 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                     Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    4 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.975,"layout":[{"image":"page_4_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.53,"w":0.669,"h":0.162},"isLikelyNoise":false},{"image":"page_4_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.378,"w":0.669,"h":0.148},"isLikelyNoise":false},{"image":"page_4_text_3_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.696,"w":0.669,"h":0.118},"isLikelyNoise":false},{"image":"page_4_text_4_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.142,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_4_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.072},"isLikelyNoise":false},{"image":"page_4_text_6_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.853,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_4_text_7_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.332,"w":0.668,"h":0.041},"isLikelyNoise":false},{"image":"page_4_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.834,"w":0.643,"h":0.014},"isLikelyNoise":false},{"image":"page_4_paragraph_title_2_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.313,"w":0.606,"h":0.014},"isLikelyNoise":false},{"image":"page_4_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_4_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_4_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_4_paragraph_title_3_v2.jpg","confidence":0.78,"label":"paragraph_title","bbox":{"x":0.272,"y":0.293,"w":0.081,"h":0.014},"isLikelyNoise":false},{"image":"page_4_header_2_v2.jpg","confidence":0.68,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_4_header_3_v2.jpg","confidence":0.53,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":5,"text":"                 Tools  and  resources                                                                                  Neuroscience\n\nTable 1. Index of standard NeuroMLv2 ComponentTypes.\nCore components\n\nannotation                                            bqbiol_encodes                      bqbiol_hasPart\n\nbqbiol_hasProperty                                    bqbiol_hasTaxon                     bqbiol_hasVersion\n\nbqbiol_is                                             bqbiol_isDescribedBy                bqbiol_isEncodedBy\n\nbqbiol_isHomologTo                                    bqbiol_isPartOf                     bqbiol_isPropertyOf\n\nbqbiol_isVersionOf                                    bqbiol_occursIn                     bqmodel_is\n\nbqmodel_isDerivedFrom                                 bqmodel_isDescribedBy               rdf_Bag\n\nrdf_Description                                       rdf_li                              rdf_RDF\n\nproperty                                              point3DWithDiam                     notes\n\nCore dimensions\n\narea                                                  capacitance                         charge\n\ncharge_per_mole                                       concentration                       conductance\n\nconductance_per_voltage                               conductanceDensity                  current\n\ncurrentDensity                                        idealGasConstantDims                length\n\nper_time                                              per_voltage                         permeability\n\nresistance                                            resistivity                         rho_factor\n\nspecificCapacitance                                   substance                           temperature\n\ntime                                                  voltage                             volume\n\nAbstract cell models\n\nadExIaFCell                                           fitzHughNagumoCell                  hindmarshRose1984Cell\n\niafCell                                               iafRefCell                          iafTauCell\n\niafTauRefCell                                         izhikevich2007Cell                  izhikevichCell\n\npinskyRinzelCA3Cell\n\nComponentTypes related to biophysically detailed cells\n\nbiophysical Properties                                biophysicalProperties2CaPools       cell\n\ncell2CaPools                                          concentration Model                 decayingPoolConcentrationModel\n\ndistal                                                distalProperties                    fixedFactorConcentrationModel\n\nfixedFactorConcentrationModelTraub                    from                                include\n\ninhomogeneousParameter                                inhomogeneousValue                  initMembPotential\n\nintracellular Properties                              intracellularProperties2CaPools     member\n\nmembraneProperties                                    membraneProperties2CaPools          morphology\n\nparent                                                path                                pointCellCondBased\n\npointCellCondBasedCa                                  proximal                            proximalProperties\n\nsegment                                               segment Group                       species\n\nspikeThresh                                           subTree                             to\n\nvariable Parameter                                    channel Density                     channelDensityGHK\n\nchannelDensityGHK2                                    channelDensityNernst                channelDensityNernstCa2\n\nchannelDensityNonUniform                              channelDensityNonUniformGHK         channelDensityNonUniformNernst\n\nchannelDensityVShift                                  channelPopulation                   channelPopulationNernst\n\nComponentTypes related to ion channels\n\nfixedTimeCourse                                       forward Transition                  gate\n\ngateFractional                                        gateHHInstantaneous                 gateHHrates\n\ngateHHratesInf                                        gateHHratesTau                      gateHHratesTauInf\nTable 1 continued on next page\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    5 of 44","md":"\n\neLife Tools and resources                                                                                  Neuroscience\n\n**Table 1.** Index of standard NeuroMLv2 ComponentTypes.\n\n**Core components**\n\n<table>\n<tr>\n<td>annotation</td>\n<td>bqbiol_encodes</td>\n<td>bqbiol_hasPart</td>\n</tr>\n<tr>\n<td>bqbiol_hasProperty</td>\n<td>bqbiol_hasTaxon</td>\n<td>bqbiol_hasVersion</td>\n</tr>\n<tr>\n<td>bqbiol_is</td>\n<td>bqbiol_isDescribedBy</td>\n<td>bqbiol_isEncodedBy</td>\n</tr>\n<tr>\n<td>bqbiol_isHomologTo</td>\n<td>bqbiol_isPartOf</td>\n<td>bqbiol_isPropertyOf</td>\n</tr>\n<tr>\n<td>bqbiol_isVersionOf</td>\n<td>bqbiol_occursIn</td>\n<td>bqmodel_is</td>\n</tr>\n<tr>\n<td>bqmodel_isDerivedFrom</td>\n<td>bqmodel_isDescribedBy</td>\n<td>rdf_Bag</td>\n</tr>\n<tr>\n<td>rdf_Description</td>\n<td>rdf_li</td>\n<td>rdf_RDF</td>\n</tr>\n<tr>\n<td>property</td>\n<td>point3DWithDiam</td>\n<td>notes</td>\n</tr>\n</table>\n\n**Core dimensions**\n\n<table>\n<tr>\n<td>area</td>\n<td>capacitance</td>\n<td>charge</td>\n</tr>\n<tr>\n<td>charge_per_mole</td>\n<td>concentration</td>\n<td>conductance</td>\n</tr>\n<tr>\n<td>conductance_per_voltage</td>\n<td>conductanceDensity</td>\n<td>current</td>\n</tr>\n<tr>\n<td>currentDensity</td>\n<td>idealGasConstantDims</td>\n<td>length</td>\n</tr>\n<tr>\n<td>per_time</td>\n<td>per_voltage</td>\n<td>permeability</td>\n</tr>\n<tr>\n<td>resistance</td>\n<td>resistivity</td>\n<td>rho_factor</td>\n</tr>\n<tr>\n<td>specificCapacitance</td>\n<td>substance</td>\n<td>temperature</td>\n</tr>\n<tr>\n<td>time</td>\n<td>voltage</td>\n<td>volume</td>\n</tr>\n</table>\n\n**Abstract cell models**\n\n<table>\n<tr>\n<td>adExIaFCell</td>\n<td>fitzHughNagumoCell</td>\n<td>hindmarshRose1984Cell</td>\n</tr>\n<tr>\n<td>iafCell</td>\n<td>iafRefCell</td>\n<td>iafTauCell</td>\n</tr>\n<tr>\n<td>iafTauRefCell</td>\n<td>izhikevich2007Cell</td>\n<td>izhikevichCell</td>\n</tr>\n<tr>\n<td>pinskyRinzelCA3Cell</td>\n<td></td>\n<td></td>\n</tr>\n</table>\n\n**ComponentTypes related to biophysically detailed cells**\n\n<table>\n<tr>\n<td>biophysical Properties</td>\n<td>biophysicalProperties2CaPools</td>\n<td>cell</td>\n</tr>\n<tr>\n<td>cell2CaPools</td>\n<td>concentration Model</td>\n<td>decayingPoolConcentrationModel</td>\n</tr>\n<tr>\n<td>distal</td>\n<td>distalProperties</td>\n<td>fixedFactorConcentrationModel</td>\n</tr>\n<tr>\n<td>fixedFactorConcentrationModelTraub</td>\n<td>from</td>\n<td>include</td>\n</tr>\n<tr>\n<td>inhomogeneousParameter</td>\n<td>inhomogeneousValue</td>\n<td>initMembPotential</td>\n</tr>\n<tr>\n<td>intracellular Properties</td>\n<td>intracellularProperties2CaPools</td>\n<td>member</td>\n</tr>\n<tr>\n<td>membraneProperties</td>\n<td>membraneProperties2CaPools</td>\n<td>morphology</td>\n</tr>\n<tr>\n<td>parent</td>\n<td>path</td>\n<td>pointCellCondBased</td>\n</tr>\n<tr>\n<td>pointCellCondBasedCa</td>\n<td>proximal</td>\n<td>proximalProperties</td>\n</tr>\n<tr>\n<td>segment</td>\n<td>segment Group</td>\n<td>species</td>\n</tr>\n<tr>\n<td>spikeThresh</td>\n<td>subTree</td>\n<td>to</td>\n</tr>\n<tr>\n<td>variable Parameter</td>\n<td>channel Density</td>\n<td>channelDensityGHK</td>\n</tr>\n<tr>\n<td>channelDensityGHK2</td>\n<td>channelDensityNernst</td>\n<td>channelDensityNernstCa2</td>\n</tr>\n<tr>\n<td>channelDensityNonUniform</td>\n<td>channelDensityNonUniformGHK</td>\n<td>channelDensityNonUniformNernst</td>\n</tr>\n<tr>\n<td>channelDensityVShift</td>\n<td>channelPopulation</td>\n<td>channelPopulationNernst</td>\n</tr>\n</table>\n\n**ComponentTypes related to ion channels**\n\n<table>\n<tr>\n<td>fixedTimeCourse</td>\n<td>forward Transition</td>\n<td>gate</td>\n</tr>\n<tr>\n<td>gateFractional</td>\n<td>gateHHInstantaneous</td>\n<td>gateHHrates</td>\n</tr>\n<tr>\n<td>gateHHratesInf</td>\n<td>gateHHratesTau</td>\n<td>gateHHratesTauInf</td>\n</tr>\n</table>\n\nTable 1 continued on next page\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    5 of 44\n","images":[{"name":"page_5.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_5_header_1_v2.jpg","height":5623.788,"width":30237.302,"x":320882.279,"y":27746.009,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_5_footer_1_v2.jpg","height":6715.213,"width":192350.742,"x":21445.833,"y":591747.763,"original_width":1271,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_5_table_1_v2.jpg","height":509692.105,"width":331462.192,"x":20904.774,"y":65504.669,"original_width":2189,"original_height":2601,"rotation":0,"type":"layout_v2_table"},{"name":"page_5_number_1_v2.jpg","height":5631.125,"width":15454.263,"x":335724.187,"y":591972.892,"original_width":103,"original_height":29,"rotation":0,"type":"layout_v2_number"},{"name":"page_5_figure_title_1_v2.jpg","height":7252.861,"width":142802.109,"x":21087.546,"y":45988.405,"original_width":943,"original_height":38,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_5_header_2_v2.jpg","height":5694.296,"width":42817.361,"x":47889.925,"y":28052.545,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_5_header_3_v2.jpg","height":10861.768,"width":24570.333,"x":21758.151,"y":22516.437,"original_width":163,"original_height":56,"rotation":0,"type":"layout_v2_header"},{"name":"page_5_figure_title_2_v2.jpg","height":5218.816,"width":34110.906,"x":21404.374,"y":58086.986,"original_width":226,"original_height":27,"rotation":0,"type":"layout_v2_figure_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                  Neuroscience","md":"eLife Tools and resources                                                                                  Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":107,"endIndex":119}]},{"type":"text","value":"**Table 1.** Index of standard NeuroMLv2 ComponentTypes.","md":"**Table 1.** Index of standard NeuroMLv2 ComponentTypes.","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":34,"y":58,"w":233,"h":9,"startIndex":0,"endIndex":55}]},{"type":"text","value":"**Core components**","md":"**Core components**","bBox":{"x":36.5,"y":72.84,"w":54.26,"h":6.5},"layoutAwareBbox":[{"x":34,"y":73,"w":55,"h":6,"startIndex":0,"endIndex":18}]},{"type":"table","rows":[["annotation","bqbiol_encodes","bqbiol_hasPart"],["bqbiol_hasProperty","bqbiol_hasTaxon","bqbiol_hasVersion"],["bqbiol_is","bqbiol_isDescribedBy","bqbiol_isEncodedBy"],["bqbiol_isHomologTo","bqbiol_isPartOf","bqbiol_isPropertyOf"],["bqbiol_isVersionOf","bqbiol_occursIn","bqmodel_is"],["bqmodel_isDerivedFrom","bqmodel_isDescribedBy","rdf_Bag"],["rdf_Description","rdf_li","rdf_RDF"],["property","point3DWithDiam","notes"]],"html":"<table>\n<tr>\n<td>annotation</td>\n<td>bqbiol_encodes</td>\n<td>bqbiol_hasPart</td>\n</tr>\n<tr>\n<td>bqbiol_hasProperty</td>\n<td>bqbiol_hasTaxon</td>\n<td>bqbiol_hasVersion</td>\n</tr>\n<tr>\n<td>bqbiol_is</td>\n<td>bqbiol_isDescribedBy</td>\n<td>bqbiol_isEncodedBy</td>\n</tr>\n<tr>\n<td>bqbiol_isHomologTo</td>\n<td>bqbiol_isPartOf</td>\n<td>bqbiol_isPropertyOf</td>\n</tr>\n<tr>\n<td>bqbiol_isVersionOf</td>\n<td>bqbiol_occursIn</td>\n<td>bqmodel_is</td>\n</tr>\n<tr>\n<td>bqmodel_isDerivedFrom</td>\n<td>bqmodel_isDescribedBy</td>\n<td>rdf_Bag</td>\n</tr>\n<tr>\n<td>rdf_Description</td>\n<td>rdf_li</td>\n<td>rdf_RDF</td>\n</tr>\n<tr>\n<td>property</td>\n<td>point3DWithDiam</td>\n<td>notes</td>\n</tr>\n</table>","md":"| annotation             | bqbiol\\_encodes        | bqbiol\\_hasPart      |\n| ---------------------- | ---------------------- | -------------------- |\n| bqbiol\\_hasProperty    | bqbiol\\_hasTaxon       | bqbiol\\_hasVersion   |\n| bqbiol\\_is             | bqbiol\\_isDescribedBy  | bqbiol\\_isEncodedBy  |\n| bqbiol\\_isHomologTo    | bqbiol\\_isPartOf       | bqbiol\\_isPropertyOf |\n| bqbiol\\_isVersionOf    | bqbiol\\_occursIn       | bqmodel\\_is          |\n| bqmodel\\_isDerivedFrom | bqmodel\\_isDescribedBy | rdf\\_Bag             |\n| rdf\\_Description       | rdf\\_li                | rdf\\_RDF             |\n| property               | point3DWithDiam        | notes                |","isPerfectTable":true,"csv":"\"annotation\",\"bqbiol_encodes\",\"bqbiol_hasPart\"\n\"bqbiol_hasProperty\",\"bqbiol_hasTaxon\",\"bqbiol_hasVersion\"\n\"bqbiol_is\",\"bqbiol_isDescribedBy\",\"bqbiol_isEncodedBy\"\n\"bqbiol_isHomologTo\",\"bqbiol_isPartOf\",\"bqbiol_isPropertyOf\"\n\"bqbiol_isVersionOf\",\"bqbiol_occursIn\",\"bqmodel_is\"\n\"bqmodel_isDerivedFrom\",\"bqmodel_isDescribedBy\",\"rdf_Bag\"\n\"rdf_Description\",\"rdf_li\",\"rdf_RDF\"\n\"property\",\"point3DWithDiam\",\"notes\"","bBox":{"x":36.5,"y":87.75,"w":396.59,"h":110.88},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":2,"endIndex":12}]},{"type":"text","value":"**Core dimensions**","md":"**Core dimensions**","bBox":{"x":36.5,"y":207.04,"w":49.25,"h":6.5},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":0,"endIndex":18}]},{"type":"table","rows":[["area","capacitance","charge"],["charge_per_mole","concentration","conductance"],["conductance_per_voltage","conductanceDensity","current"],["currentDensity","idealGasConstantDims","length"],["per_time","per_voltage","permeability"],["resistance","resistivity","rho_factor"],["specificCapacitance","substance","temperature"],["time","voltage","volume"]],"html":"<table>\n<tr>\n<td>area</td>\n<td>capacitance</td>\n<td>charge</td>\n</tr>\n<tr>\n<td>charge_per_mole</td>\n<td>concentration</td>\n<td>conductance</td>\n</tr>\n<tr>\n<td>conductance_per_voltage</td>\n<td>conductanceDensity</td>\n<td>current</td>\n</tr>\n<tr>\n<td>currentDensity</td>\n<td>idealGasConstantDims</td>\n<td>length</td>\n</tr>\n<tr>\n<td>per_time</td>\n<td>per_voltage</td>\n<td>permeability</td>\n</tr>\n<tr>\n<td>resistance</td>\n<td>resistivity</td>\n<td>rho_factor</td>\n</tr>\n<tr>\n<td>specificCapacitance</td>\n<td>substance</td>\n<td>temperature</td>\n</tr>\n<tr>\n<td>time</td>\n<td>voltage</td>\n<td>volume</td>\n</tr>\n</table>","md":"| area                      | capacitance          | charge       |\n| ------------------------- | -------------------- | ------------ |\n| charge\\_per\\_mole         | concentration        | conductance  |\n| conductance\\_per\\_voltage | conductanceDensity   | current      |\n| currentDensity            | idealGasConstantDims | length       |\n| per\\_time                 | per\\_voltage         | permeability |\n| resistance                | resistivity          | rho\\_factor  |\n| specificCapacitance       | substance            | temperature  |\n| time                      | voltage              | volume       |","isPerfectTable":true,"csv":"\"area\",\"capacitance\",\"charge\"\n\"charge_per_mole\",\"concentration\",\"conductance\"\n\"conductance_per_voltage\",\"conductanceDensity\",\"current\"\n\"currentDensity\",\"idealGasConstantDims\",\"length\"\n\"per_time\",\"per_voltage\",\"permeability\"\n\"resistance\",\"resistivity\",\"rho_factor\"\n\"specificCapacitance\",\"substance\",\"temperature\"\n\"time\",\"voltage\",\"volume\"","bBox":{"x":36.5,"y":221.95,"w":436.35,"h":453.83},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":2,"endIndex":6}]},{"type":"text","value":"**Abstract cell models**","md":"**Abstract cell models**","bBox":{"x":36.5,"y":341.24,"w":60.07,"h":6.5},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":11,"endIndex":15}]},{"type":"table","rows":[["adExIaFCell","fitzHughNagumoCell","hindmarshRose1984Cell"],["iafCell","iafRefCell","iafTauCell"],["iafTauRefCell","izhikevich2007Cell","izhikevichCell"],["pinskyRinzelCA3Cell","",""]],"html":"<table>\n<tr>\n<td>adExIaFCell</td>\n<td>fitzHughNagumoCell</td>\n<td>hindmarshRose1984Cell</td>\n</tr>\n<tr>\n<td>iafCell</td>\n<td>iafRefCell</td>\n<td>iafTauCell</td>\n</tr>\n<tr>\n<td>iafTauRefCell</td>\n<td>izhikevich2007Cell</td>\n<td>izhikevichCell</td>\n</tr>\n<tr>\n<td>pinskyRinzelCA3Cell</td>\n<td></td>\n<td></td>\n</tr>\n</table>","md":"| adExIaFCell         | fitzHughNagumoCell | hindmarshRose1984Cell |\n| ------------------- | ------------------ | --------------------- |\n| iafCell             | iafRefCell         | iafTauCell            |\n| iafTauRefCell       | izhikevich2007Cell | izhikevichCell        |\n| pinskyRinzelCA3Cell |                    |                       |","isPerfectTable":true,"csv":"\"adExIaFCell\",\"fitzHughNagumoCell\",\"hindmarshRose1984Cell\"\n\"iafCell\",\"iafRefCell\",\"iafTauCell\"\n\"iafTauRefCell\",\"izhikevich2007Cell\",\"izhikevichCell\"\n\"pinskyRinzelCA3Cell\",\"\",\"\"","bBox":{"x":36.5,"y":34.63,"w":538.49,"h":720.13},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":2,"endIndex":13}]},{"type":"text","value":"**ComponentTypes related to biophysically detailed cells**","md":"**ComponentTypes related to biophysically detailed cells**","bBox":{"x":36.5,"y":415.8,"w":162.29,"h":6.5},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":25,"endIndex":27}]},{"type":"table","rows":[["biophysical Properties","biophysicalProperties2CaPools","cell"],["cell2CaPools","concentration Model","decayingPoolConcentrationModel"],["distal","distalProperties","fixedFactorConcentrationModel"],["fixedFactorConcentrationModelTraub","from","include"],["inhomogeneousParameter","inhomogeneousValue","initMembPotential"],["intracellular Properties","intracellularProperties2CaPools","member"],["membraneProperties","membraneProperties2CaPools","morphology"],["parent","path","pointCellCondBased"],["pointCellCondBasedCa","proximal","proximalProperties"],["segment","segment Group","species"],["spikeThresh","subTree","to"],["variable Parameter","channel Density","channelDensityGHK"],["channelDensityGHK2","channelDensityNernst","channelDensityNernstCa2"],["channelDensityNonUniform","channelDensityNonUniformGHK","channelDensityNonUniformNernst"],["channelDensityVShift","channelPopulation","channelPopulationNernst"]],"html":"<table>\n<tr>\n<td>biophysical Properties</td>\n<td>biophysicalProperties2CaPools</td>\n<td>cell</td>\n</tr>\n<tr>\n<td>cell2CaPools</td>\n<td>concentration Model</td>\n<td>decayingPoolConcentrationModel</td>\n</tr>\n<tr>\n<td>distal</td>\n<td>distalProperties</td>\n<td>fixedFactorConcentrationModel</td>\n</tr>\n<tr>\n<td>fixedFactorConcentrationModelTraub</td>\n<td>from</td>\n<td>include</td>\n</tr>\n<tr>\n<td>inhomogeneousParameter</td>\n<td>inhomogeneousValue</td>\n<td>initMembPotential</td>\n</tr>\n<tr>\n<td>intracellular Properties</td>\n<td>intracellularProperties2CaPools</td>\n<td>member</td>\n</tr>\n<tr>\n<td>membraneProperties</td>\n<td>membraneProperties2CaPools</td>\n<td>morphology</td>\n</tr>\n<tr>\n<td>parent</td>\n<td>path</td>\n<td>pointCellCondBased</td>\n</tr>\n<tr>\n<td>pointCellCondBasedCa</td>\n<td>proximal</td>\n<td>proximalProperties</td>\n</tr>\n<tr>\n<td>segment</td>\n<td>segment Group</td>\n<td>species</td>\n</tr>\n<tr>\n<td>spikeThresh</td>\n<td>subTree</td>\n<td>to</td>\n</tr>\n<tr>\n<td>variable Parameter</td>\n<td>channel Density</td>\n<td>channelDensityGHK</td>\n</tr>\n<tr>\n<td>channelDensityGHK2</td>\n<td>channelDensityNernst</td>\n<td>channelDensityNernstCa2</td>\n</tr>\n<tr>\n<td>channelDensityNonUniform</td>\n<td>channelDensityNonUniformGHK</td>\n<td>channelDensityNonUniformNernst</td>\n</tr>\n<tr>\n<td>channelDensityVShift</td>\n<td>channelPopulation</td>\n<td>channelPopulationNernst</td>\n</tr>\n</table>","md":"| biophysical Properties             | biophysicalProperties2CaPools   | cell                           |\n| ---------------------------------- | ------------------------------- | ------------------------------ |\n| cell2CaPools                       | concentration Model             | decayingPoolConcentrationModel |\n| distal                             | distalProperties                | fixedFactorConcentrationModel  |\n| fixedFactorConcentrationModelTraub | from                            | include                        |\n| inhomogeneousParameter             | inhomogeneousValue              | initMembPotential              |\n| intracellular Properties           | intracellularProperties2CaPools | member                         |\n| membraneProperties                 | membraneProperties2CaPools      | morphology                     |\n| parent                             | path                            | pointCellCondBased             |\n| pointCellCondBasedCa               | proximal                        | proximalProperties             |\n| segment                            | segment Group                   | species                        |\n| spikeThresh                        | subTree                         | to                             |\n| variable Parameter                 | channel Density                 | channelDensityGHK              |\n| channelDensityGHK2                 | channelDensityNernst            | channelDensityNernstCa2        |\n| channelDensityNonUniform           | channelDensityNonUniformGHK     | channelDensityNonUniformNernst |\n| channelDensityVShift               | channelPopulation               | channelPopulationNernst        |","isPerfectTable":true,"csv":"\"biophysical Properties\",\"biophysicalProperties2CaPools\",\"cell\"\n\"cell2CaPools\",\"concentration Model\",\"decayingPoolConcentrationModel\"\n\"distal\",\"distalProperties\",\"fixedFactorConcentrationModel\"\n\"fixedFactorConcentrationModelTraub\",\"from\",\"include\"\n\"inhomogeneousParameter\",\"inhomogeneousValue\",\"initMembPotential\"\n\"intracellular Properties\",\"intracellularProperties2CaPools\",\"member\"\n\"membraneProperties\",\"membraneProperties2CaPools\",\"morphology\"\n\"parent\",\"path\",\"pointCellCondBased\"\n\"pointCellCondBasedCa\",\"proximal\",\"proximalProperties\"\n\"segment\",\"segment Group\",\"species\"\n\"spikeThresh\",\"subTree\",\"to\"\n\"variable Parameter\",\"channel Density\",\"channelDensityGHK\"\n\"channelDensityGHK2\",\"channelDensityNernst\",\"channelDensityNernstCa2\"\n\"channelDensityNonUniform\",\"channelDensityNonUniformGHK\",\"channelDensityNonUniformNernst\"\n\"channelDensityVShift\",\"channelPopulation\",\"channelPopulationNernst\"","bBox":{"x":36.5,"y":34.79,"w":436.35,"h":626.09},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":39,"endIndex":60}]},{"type":"text","value":"**ComponentTypes related to ion channels**","md":"**ComponentTypes related to ion channels**","bBox":{"x":36.5,"y":654.37,"w":120.55,"h":6.5},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":25,"endIndex":27}]},{"type":"table","rows":[["fixedTimeCourse","forward Transition","gate"],["gateFractional","gateHHInstantaneous","gateHHrates"],["gateHHratesInf","gateHHratesTau","gateHHratesTauInf"]],"html":"<table>\n<tr>\n<td>fixedTimeCourse</td>\n<td>forward Transition</td>\n<td>gate</td>\n</tr>\n<tr>\n<td>gateFractional</td>\n<td>gateHHInstantaneous</td>\n<td>gateHHrates</td>\n</tr>\n<tr>\n<td>gateHHratesInf</td>\n<td>gateHHratesTau</td>\n<td>gateHHratesTauInf</td>\n</tr>\n</table>","md":"| fixedTimeCourse | forward Transition  | gate              |\n| --------------- | ------------------- | ----------------- |\n| gateFractional  | gateHHInstantaneous | gateHHrates       |\n| gateHHratesInf  | gateHHratesTau      | gateHHratesTauInf |","isPerfectTable":true,"csv":"\"fixedTimeCourse\",\"forward Transition\",\"gate\"\n\"gateFractional\",\"gateHHInstantaneous\",\"gateHHrates\"\n\"gateHHratesInf\",\"gateHHratesTau\",\"gateHHratesTauInf\"","bBox":{"x":36.5,"y":669.28,"w":390.82,"h":36.32},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":2,"endIndex":17}]},{"type":"text","value":"Table 1 continued on next page","md":"Table 1 continued on next page","bBox":{"x":36.5,"y":711.86,"w":126.59,"h":9},"layoutAwareBbox":[{"x":34,"y":82,"w":541,"h":643,"startIndex":0,"endIndex":29}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    5 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    5 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":747,"w":314,"h":8,"startIndex":0,"endIndex":95},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":95}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-annotation","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-annotation","text":"annotation"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-encodes","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-encodes","text":"bqbiol_encodes"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-haspart","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-haspart","text":"bqbiol_hasPart"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hasproperty","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hasproperty","text":"bqbiol_hasProperty"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hastaxon","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hastaxon","text":"bqbiol_hasTaxon"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hasversion","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-hasversion","text":"bqbiol_hasVersion"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-is","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-is","text":"bqbiol_is"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isdescribedby","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isdescribedby","text":"bqbiol_isDescribedBy"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isencodedby","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isencodedby","text":"bqbiol_isEncodedBy"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ishomologto","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ishomologto","text":"bqbiol_isHomologTo"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ispartof","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ispartof","text":"bqbiol_isPartOf"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ispropertyof","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-ispropertyof","text":"bqbiol_isPropertyOf"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isversionof","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-isversionof","text":"bqbiol_isVersionOf"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-occursin","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqbiol-occursin","text":"bqbiol_occursIn"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-is","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-is","text":"bqmodel_is"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-isderivedfrom","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-isderivedfrom","text":"bqmodel_isDerivedFrom"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-isdescribedby","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-bqmodel-isdescribedby","text":"bqmodel_isDescribedBy"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-bag","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-bag","text":"rdf_Bag"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-description","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-description","text":"rdf_Description"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-li","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-li","text":"rdf_li"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-rdf","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-rdf-rdf","text":"rdf_RDF"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-property","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-property","text":"property"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-point3dwithdiam","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-point3dwithdiam","text":"point3DWithDiam"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-notes","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreCompTypes.html#schema-notes","text":"notes"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-area","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-area","text":"area"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-capacitance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-capacitance","text":"capacitance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-charge","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-charge","text":"charge"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-charge-per-mole","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-charge-per-mole","text":"charge_per_mole"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-concentration","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-concentration","text":"concentration"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductance","text":"conductance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductance-per-voltage","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductance-per-voltage","text":"conductance_per_voltage"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductancedensity","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-conductancedensity","text":"conductanceDensity"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-current","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-current","text":"current"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-currentdensity","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-currentdensity","text":"currentDensity"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-idealgasconstantdims","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-idealgasconstantdims","text":"idealGasConstantDims"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-length","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-length","text":"length"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-per-time","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-per-time","text":"per_time"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-per-voltage","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-per-voltage","text":"per_voltage"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-permeability","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-permeability","text":"permeability"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-resistance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-resistance","text":"resistance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-resistivity","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-resistivity","text":"resistivity"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-rho-factor","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-rho-factor","text":"rho_factor"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-specificcapacitance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-specificcapacitance","text":"specificCapacitance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-substance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-substance","text":"substance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-temperature","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-temperature","text":"temperature"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-time","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-time","text":"time"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-voltage","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-voltage","text":"voltage"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-volume","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/NeuroMLCoreDimensions.html#schema-dimensions-volume","text":"volume"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-adexiafcell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-adexiafcell","text":"adExIaFCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fitzhughnagumocell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fitzhughnagumocell","text":"fitzHughNagumoCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-hindmarshrose1984cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-hindmarshrose1984cell","text":"hindmarshRose1984Cell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iafcell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iafcell","text":"iafCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iafrefcell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iafrefcell","text":"iafRefCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iaftaucell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iaftaucell","text":"iafTauCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iaftaurefcell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-iaftaurefcell","text":"iafTauRefCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-izhikevich2007cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-izhikevich2007cell","text":"izhikevich2007Cell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-izhikevichcell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-izhikevichcell","text":"izhikevichCell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pinskyrinzelca3cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pinskyrinzelca3cell","text":"pinskyRinzelCA3Cell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-biophysicalproperties","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-biophysicalproperties","text":"biophysical Properties"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-biophysicalproperties2capools","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-biophysicalproperties2capools","text":"biophysicalProperties2CaPools"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-cell","text":"cell"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-cell2capools","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-cell2capools","text":"cell2CaPools"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-concentrationmodel","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-concentrationmodel","text":"concentration Model"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-decayingpoolconcentrationmodel","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-decayingpoolconcentrationmodel","text":"decayingPoolConcentrationModel"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-distal","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-distal","text":"distal"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-distalproperties","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-distalproperties","text":"distalProperties"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fixedfactorconcentrationmodel","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fixedfactorconcentrationmodel","text":"fixedFactorConcentrationModel"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fixedfactorconcentrationmodeltraub","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-fixedfactorconcentrationmodeltraub","text":"fixedFactorConcentrationModelTraub"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-from","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-from","text":"from"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-include","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-include","text":"include"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-inhomogeneousparameter","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-inhomogeneousparameter","text":"inhomogeneousParameter"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-inhomogeneousvalue","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-inhomogeneousvalue","text":"inhomogeneousValue"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-initmembpotential","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-initmembpotential","text":"initMembPotential"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-intracellularproperties","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-intracellularproperties","text":"intracellular Properties"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-intracellularproperties2capools","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-intracellularproperties2capools","text":"intracellularProperties2CaPools"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-member","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-member","text":"member"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-membraneproperties","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-membraneproperties","text":"membraneProperties"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-membraneproperties2capools","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-membraneproperties2capools","text":"membraneProperties2CaPools"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-morphology","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-morphology","text":"morphology"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-parent","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-parent","text":"parent"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-path","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-path","text":"path"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pointcellcondbased","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pointcellcondbased","text":"pointCellCondBased"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pointcellcondbasedca","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-pointcellcondbasedca","text":"pointCellCondBasedCa"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-proximal","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-proximal","text":"proximal"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-proximalproperties","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-proximalproperties","text":"proximalProperties"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-segment","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-segment","text":"segment"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-segmentgroup","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-segmentgroup","text":"segment Group"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-species","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-species","text":"species"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-spikethresh","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-spikethresh","text":"spikeThresh"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-subtree","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-subtree","text":"subTree"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-to","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-to","text":"to"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-variableparameter","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-variableparameter","text":"variable Parameter"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensity","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensity","text":"channel Density"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityghk","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityghk","text":"channelDensityGHK"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityghk2","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityghk2","text":"channelDensityGHK2"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynernst","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynernst","text":"channelDensityNernst"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynernstca2","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynernstca2","text":"channelDensityNernstCa2"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniform","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniform","text":"channelDensityNonUniform"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniformghk","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniformghk","text":"channelDensityNonUniformGHK"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniformnernst","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensitynonuniformnernst","text":"channelDensityNonUniformNernst"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityvshift","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channeldensityvshift","text":"channelDensityVShift"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channelpopulation","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channelpopulation","text":"channelPopulation"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channelpopulationnernst","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#schema-channelpopulationnernst","text":"channelPopulationNernst"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-fixedtimecourse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-fixedtimecourse","text":"fixedTimeCourse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-forwardtransition","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-forwardtransition","text":"forward Transition"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gate","text":"gate"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatefractional","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatefractional","text":"gateFractional"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhinstantaneous","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhinstantaneous","text":"gateHHInstantaneous"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhrates","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhrates","text":"gateHHrates"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratesinf","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratesinf","text":"gateHHratesInf"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratestau","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratestau","text":"gateHHratesTau"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratestauinf","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhratestauinf","text":"gateHHratesTauInf"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                  Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    5 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":1,"layout":[{"image":"page_5_header_1_v2.jpg","confidence":0.91,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_5_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.514,"h":0.011},"isLikelyNoise":false},{"image":"page_5_table_1_v2.jpg","confidence":0.9,"label":"table","bbox":{"x":0.056,"y":0.104,"w":0.885,"h":0.813},"isLikelyNoise":false},{"image":"page_5_number_1_v2.jpg","confidence":0.9,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_5_figure_title_1_v2.jpg","confidence":0.77,"label":"figure_title","bbox":{"x":0.056,"y":0.073,"w":0.381,"h":0.012},"isLikelyNoise":false},{"image":"page_5_header_2_v2.jpg","confidence":0.76,"label":"header","bbox":{"x":0.128,"y":0.045,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_5_header_3_v2.jpg","confidence":0.72,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.017},"isLikelyNoise":false},{"image":"page_5_figure_title_2_v2.jpg","confidence":0.67,"label":"figure_title","bbox":{"x":0.057,"y":0.093,"w":0.091,"h":0.008},"isLikelyNoise":false}]},{"page":6,"text":"                Tools  and  resources                                               Neuroscience\n\nTable 1 continued\nCore components\ngateHHtauInf                             gateKS                    HHExpLinearRate\nHHExpLinearVariable                      HHExpRate                 HHExpVariable\nHHSigmoidRate                            HHSigmoidVariable         ionChannel\nionChannelHH                             ionChannelKS              ionChannelPassive\nionChannelVShift                         KSState                   KSTransition\nopen State                               q10ConductanceScaling     q10ExpTemp\nq10Fixed                                 reverse Transition        sub Gate\ntauInfTransition                         vHalfTransition           closedState\n\n\n\nﬁt into a ‘population’ of a ‘network’ (Figure 2). To support the range of electrical properties found in\nbiological neurons, ionic conductances with distinct ionic selectivities and dynamics can be generated\nin NeuroML through the inclusion of different types of gates (e.g. activation, inactivation), their depen-\ndence on variables such as voltage and [Ca 2+] and their reversal potential. Cell types with different\nfunctional and biophysical properties can then be generated by conferring combinations of ionic\nconductances on their membranes. The conductance density can be adjusted to generate the elec-\ntrophysiological properties found in real neurons. In practice, many examples of ionic conductances\nthat underlie the electrical behavior of neurons are already available in NeuroMLv2 and can simply be\ninserted into a cell membrane (Figure 2). Indeed, a model element, once deﬁned in NeuroML, acts as\na building block that may be reused any number of times within or across models. Elements such as\nionic conductances, cell biophysics, cell morphologies, and cell deﬁnitions that incorporate them can\nbe serialized in separate ﬁles and ‘included’ in other models (e.g. morphologies https://docs.neuroml.\norg/Userdocs/ImportingMorphologyFiles.html#neuroml2). Such reuse of model components speeds\nmodel construction and prototyping irrespective of the simulation engine used.\nThe deﬁned structure of each model element and the relationships between them inform users of\nexactly how model elements are to be created and combined. This encourages the construction of\nwell-structured models, reduces errors and redundancy, and ensures that FAIR principles are ﬁrmly\nembedded in NeuroML models and the ecosystem of tools. As we will see in the following sections,\nNeuroML’s formal structure also enables features such as model validation prior to simulation, trans-\nlation into simulation speciﬁc formats, and the use of NeuroML as a common language of exchange\nbetween different tools.\n\nNeuroML supports a large ecosystem of software tools that cover all\nstages of the model life cycle\nModel building and the generation of scientiﬁc knowledge from simulation and analysis of models is\na multi-step, iterative process requiring an array of software tools. NeuroML supports all stages of the\nmodel development life cycle (Figure 1), by providing a single model description format that interacts\nwith a myriad of tools throughout the process. Researchers typically assemble ad- hoc sets of scripts,\napplications, and processes to help them in their investigations. In the absence of standardization, they\nmust work with the speciﬁc model formats and APIs that each tool they use requires, and somehow\nconvert model descriptions when using multiple applications in a toolchain. NeuroML addresses this\nissue by providing a common language for the use and exchange of models and their components\nbetween different simulation engines and modeling tools. The NeuroML ecosystem includes a large\ncollection of software tools, both developed and maintained by the main NeuroML contributors (the\n‘core NeuroML tools and libraries:’ jNeuroML, pyNeuroML, APIs) and those external applications that\nhave added NeuroML support (Figures 3 and 4a, Tables 3 and 4).\nThe core NeuroML tools and libraries include APIs in several programming languages—Python,\nJava, C++, and MATLAB. These tools provide critical functionality to allow users to interact with\nNeuroML components and build models. Using these, researchers can build models from scratch,\nor read, modify, analyze, visualize, and simulate existing NeuroML models on supported simulation\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    6 of 44","md":"\n\neLife Tools and resources                                                           Neuroscience\n\n**Table 1 continued**\n\n**Core components**\n\n<table>\n<tr>\n<td>gateHHtauInf</td>\n<td>gateKS</td>\n<td>HHExpLinearRate</td>\n</tr>\n<tr>\n<td>HHExpLinearVariable</td>\n<td>HHExpRate</td>\n<td>HHExpVariable</td>\n</tr>\n<tr>\n<td>HHSigmoidRate</td>\n<td>HHSigmoidVariable</td>\n<td>ionChannel</td>\n</tr>\n<tr>\n<td>ionChannelHH</td>\n<td>ionChannelKS</td>\n<td>ionChannelPassive</td>\n</tr>\n<tr>\n<td>ionChannelVShift</td>\n<td>KSState</td>\n<td>KSTransition</td>\n</tr>\n<tr>\n<td>open State</td>\n<td>q10ConductanceScaling</td>\n<td>q10ExpTemp</td>\n</tr>\n<tr>\n<td>q10Fixed</td>\n<td>reverse Transition</td>\n<td>sub Gate</td>\n</tr>\n<tr>\n<td>tauInfTransition</td>\n<td>vHalfTransition</td>\n<td>closedState</td>\n</tr>\n</table>\n\nfit into a 'population' of a 'network' (Figure 2). To support the range of electrical properties found in biological neurons, ionic conductances with distinct ionic selectivities and dynamics can be generated in NeuroML through the inclusion of different types of gates (e.g. activation, inactivation), their dependence on variables such as voltage and [Ca<sup>2+</sup>] and their reversal potential. Cell types with different functional and biophysical properties can then be generated by conferring combinations of ionic conductances on their membranes. The conductance density can be adjusted to generate the electrophysiological properties found in real neurons. In practice, many examples of ionic conductances that underlie the electrical behavior of neurons are already available in NeuroMLv2 and can simply be inserted into a cell membrane (Figure 2). Indeed, a model element, once defined in NeuroML, acts as a building block that may be reused any number of times within or across models. Elements such as ionic conductances, cell biophysics, cell morphologies, and cell definitions that incorporate them can be serialized in separate files and 'included' in other models (e.g. morphologies https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2). Such reuse of model components speeds model construction and prototyping irrespective of the simulation engine used.\n\nThe defined structure of each model element and the relationships between them inform users of exactly how model elements are to be created and combined. This encourages the construction of well-structured models, reduces errors and redundancy, and ensures that FAIR principles are firmly embedded in NeuroML models and the ecosystem of tools. As we will see in the following sections, NeuroML's formal structure also enables features such as model validation prior to simulation, translation into simulation specific formats, and the use of NeuroML as a common language of exchange between different tools.\n\n## NeuroML supports a large ecosystem of software tools that cover all stages of the model life cycle\n\nModel building and the generation of scientific knowledge from simulation and analysis of models is a multi-step, iterative process requiring an array of software tools. NeuroML supports all stages of the model development life cycle (Figure 1), by providing a single model description format that interacts with a myriad of tools throughout the process. Researchers typically assemble ad-hoc sets of scripts, applications, and processes to help them in their investigations. In the absence of standardization, they must work with the specific model formats and APIs that each tool they use requires, and somehow convert model descriptions when using multiple applications in a toolchain. NeuroML addresses this issue by providing a common language for the use and exchange of models and their components between different simulation engines and modeling tools. The NeuroML ecosystem includes a large collection of software tools, both developed and maintained by the main NeuroML contributors (the 'core NeuroML tools and libraries:' jNeuroML, pyNeuroML, APIs) and those external applications that have added NeuroML support (Figures 3 and 4a, Tables 3 and 4).\n\nThe core NeuroML tools and libraries include APIs in several programming languages—Python, Java, C++, and MATLAB. These tools provide critical functionality to allow users to interact with NeuroML components and build models. Using these, researchers can build models from scratch, or read, modify, analyze, visualize, and simulate existing NeuroML models on supported simulation\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    6 of 44\n","images":[{"name":"page_6.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_6_text_1_v2.jpg","height":131066.655,"width":250586.308,"x":100893.233,"y":185107.645,"original_width":1655,"original_height":669,"rotation":0,"type":"layout_v2_text"},{"name":"page_6_text_2_v2.jpg","height":111916.991,"width":250538.91,"x":100953.715,"y":420571.24,"original_width":1655,"original_height":571,"rotation":0,"type":"layout_v2_text"},{"name":"page_6_table_1_v2.jpg","height":95259.447,"width":331104.863,"x":21047.977,"y":63564.953,"original_width":2187,"original_height":486,"rotation":0,"type":"layout_v2_table"},{"name":"page_6_text_3_v2.jpg","height":63809.92,"width":250555.139,"x":101076.158,"y":318353.18,"original_width":1655,"original_height":326,"rotation":0,"type":"layout_v2_text"},{"name":"page_6_text_4_v2.jpg","height":36185.684,"width":250544.476,"x":101029.238,"y":534520.077,"original_width":1655,"original_height":185,"rotation":0,"type":"layout_v2_text"},{"name":"page_6_footer_1_v2.jpg","height":6796.66,"width":191910.393,"x":21454.873,"y":591474.805,"original_width":1268,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_6_paragraph_title_1_v2.jpg","height":20409.778,"width":241647.746,"x":101144.372,"y":397455.228,"original_width":1596,"original_height":105,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_6_header_1_v2.jpg","height":5676.813,"width":30244.738,"x":320776.595,"y":27637.587,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_6_number_1_v2.jpg","height":5702.221,"width":15401.406,"x":335676.692,"y":591865.649,"original_width":102,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_6_header_2_v2.jpg","height":5658.393,"width":42716.656,"x":47905.498,"y":27961.39,"original_width":283,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_6_figure_title_1_v2.jpg","height":5335.521,"width":34095.986,"x":21258.201,"y":54677.328,"original_width":226,"original_height":28,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_6_header_3_v2.jpg","height":11013.581,"width":24683.671,"x":21683.689,"y":22468.161,"original_width":163,"original_height":57,"rotation":0,"type":"layout_v2_header"},{"name":"page_6_figure_title_2_v2.jpg","height":6559.152,"width":44568.709,"x":21587.498,"y":41690.98,"original_width":295,"original_height":34,"rotation":0,"type":"layout_v2_figure_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                           Neuroscience","md":"eLife Tools and resources                                                           Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":84,"endIndex":96}]},{"type":"text","value":"**Table 1 continued**","md":"**Table 1 continued**","bBox":{"x":36.5,"y":51.8,"w":71.21,"h":9},"layoutAwareBbox":[{"x":35,"y":52,"w":72,"h":8,"startIndex":0,"endIndex":20}]},{"type":"text","value":"**Core components**","md":"**Core components**","bBox":{"x":36.5,"y":68.84,"w":54.26,"h":6.5},"layoutAwareBbox":[{"x":34,"y":69,"w":55,"h":6,"startIndex":0,"endIndex":18}]},{"type":"table","rows":[["gateHHtauInf","gateKS","HHExpLinearRate"],["HHExpLinearVariable","HHExpRate","HHExpVariable"],["HHSigmoidRate","HHSigmoidVariable","ionChannel"],["ionChannelHH","ionChannelKS","ionChannelPassive"],["ionChannelVShift","KSState","KSTransition"],["open State","q10ConductanceScaling","q10ExpTemp"],["q10Fixed","reverse Transition","sub Gate"],["tauInfTransition","vHalfTransition","closedState"]],"html":"<table>\n<tr>\n<td>gateHHtauInf</td>\n<td>gateKS</td>\n<td>HHExpLinearRate</td>\n</tr>\n<tr>\n<td>HHExpLinearVariable</td>\n<td>HHExpRate</td>\n<td>HHExpVariable</td>\n</tr>\n<tr>\n<td>HHSigmoidRate</td>\n<td>HHSigmoidVariable</td>\n<td>ionChannel</td>\n</tr>\n<tr>\n<td>ionChannelHH</td>\n<td>ionChannelKS</td>\n<td>ionChannelPassive</td>\n</tr>\n<tr>\n<td>ionChannelVShift</td>\n<td>KSState</td>\n<td>KSTransition</td>\n</tr>\n<tr>\n<td>open State</td>\n<td>q10ConductanceScaling</td>\n<td>q10ExpTemp</td>\n</tr>\n<tr>\n<td>q10Fixed</td>\n<td>reverse Transition</td>\n<td>sub Gate</td>\n</tr>\n<tr>\n<td>tauInfTransition</td>\n<td>vHalfTransition</td>\n<td>closedState</td>\n</tr>\n</table>","md":"| gateHHtauInf        | gateKS                | HHExpLinearRate   |\n| ------------------- | --------------------- | ----------------- |\n| HHExpLinearVariable | HHExpRate             | HHExpVariable     |\n| HHSigmoidRate       | HHSigmoidVariable     | ionChannel        |\n| ionChannelHH        | ionChannelKS          | ionChannelPassive |\n| ionChannelVShift    | KSState               | KSTransition      |\n| open State          | q10ConductanceScaling | q10ExpTemp        |\n| q10Fixed            | reverse Transition    | sub Gate          |\n| tauInfTransition    | vHalfTransition       | closedState       |","isPerfectTable":true,"csv":"\"gateHHtauInf\",\"gateKS\",\"HHExpLinearRate\"\n\"HHExpLinearVariable\",\"HHExpRate\",\"HHExpVariable\"\n\"HHSigmoidRate\",\"HHSigmoidVariable\",\"ionChannel\"\n\"ionChannelHH\",\"ionChannelKS\",\"ionChannelPassive\"\n\"ionChannelVShift\",\"KSState\",\"KSTransition\"\n\"open State\",\"q10ConductanceScaling\",\"q10ExpTemp\"\n\"q10Fixed\",\"reverse Transition\",\"sub Gate\"\n\"tauInfTransition\",\"vHalfTransition\",\"closedState\"","bBox":{"x":36.5,"y":83.75,"w":390.83,"h":110.88},"layoutAwareBbox":[{"x":34,"y":80,"w":541,"h":120,"startIndex":2,"endIndex":14}]},{"type":"text","value":"fit into a 'population' of a 'network' (Figure 2). To support the range of electrical properties found in biological neurons, ionic conductances with distinct ionic selectivities and dynamics can be generated in NeuroML through the inclusion of different types of gates (e.g. activation, inactivation), their dependence on variables such as voltage and [Ca<sup>2+</sup>] and their reversal potential. Cell types with different functional and biophysical properties can then be generated by conferring combinations of ionic conductances on their membranes. The conductance density can be adjusted to generate the electrophysiological properties found in real neurons. In practice, many examples of ionic conductances that underlie the electrical behavior of neurons are already available in NeuroMLv2 and can simply be inserted into a cell membrane (Figure 2). Indeed, a model element, once defined in NeuroML, acts as a building block that may be reused any number of times within or across models. Elements such as ionic conductances, cell biophysics, cell morphologies, and cell definitions that incorporate them can be serialized in separate files and 'included' in other models (e.g. morphologies https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2). Such reuse of model components speeds model construction and prototyping irrespective of the simulation engine used.","md":"fit into a 'population' of a 'network' (Figure 2). To support the range of electrical properties found in biological neurons, ionic conductances with distinct ionic selectivities and dynamics can be generated in NeuroML through the inclusion of different types of gates (e.g. activation, inactivation), their dependence on variables such as voltage and [Ca<sup>2+</sup>] and their reversal potential. Cell types with different functional and biophysical properties can then be generated by conferring combinations of ionic conductances on their membranes. The conductance density can be adjusted to generate the electrophysiological properties found in real neurons. In practice, many examples of ionic conductances that underlie the electrical behavior of neurons are already available in NeuroMLv2 and can simply be inserted into a cell membrane (Figure 2). Indeed, a model element, once defined in NeuroML, acts as a building block that may be reused any number of times within or across models. Elements such as ionic conductances, cell biophysics, cell morphologies, and cell definitions that incorporate them can be serialized in separate files and 'included' in other models (e.g. morphologies https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2). Such reuse of model components speeds model construction and prototyping irrespective of the simulation engine used.","bBox":{"x":168.53,"y":245.37,"w":412.02,"h":152.97},"layoutAwareBbox":[{"x":164,"y":233,"w":409,"h":165,"startIndex":4,"endIndex":6}]},{"type":"text","value":"The defined structure of each model element and the relationships between them inform users of exactly how model elements are to be created and combined. This encourages the construction of well-structured models, reduces errors and redundancy, and ensures that FAIR principles are firmly embedded in NeuroML models and the ecosystem of tools. As we will see in the following sections, NeuroML's formal structure also enables features such as model validation prior to simulation, translation into simulation specific formats, and the use of NeuroML as a common language of exchange between different tools.","md":"The defined structure of each model element and the relationships between them inform users of exactly how model elements are to be created and combined. This encourages the construction of well-structured models, reduces errors and redundancy, and ensures that FAIR principles are firmly embedded in NeuroML models and the ecosystem of tools. As we will see in the following sections, NeuroML's formal structure also enables features such as model validation prior to simulation, translation into simulation specific formats, and the use of NeuroML as a common language of exchange between different tools.","bBox":{"x":168.53,"y":413.34,"w":404.8,"h":68.99},"layoutAwareBbox":[{"x":165,"y":401,"w":409,"h":80,"startIndex":0,"endIndex":3}]},{"type":"heading","lvl":2,"value":"NeuroML supports a large ecosystem of software tools that cover all stages of the model life cycle","md":"## NeuroML supports a large ecosystem of software tools that cover all stages of the model life cycle","bBox":{"x":168.53,"y":500.35,"w":395.41,"h":26},"layoutAwareBbox":[{"x":165,"y":501,"w":394,"h":25,"startIndex":0,"endIndex":100}]},{"type":"text","value":"Model building and the generation of scientific knowledge from simulation and analysis of models is a multi-step, iterative process requiring an array of software tools. NeuroML supports all stages of the model development life cycle (Figure 1), by providing a single model description format that interacts with a myriad of tools throughout the process. Researchers typically assemble ad-hoc sets of scripts, applications, and processes to help them in their investigations. In the absence of standardization, they must work with the specific model formats and APIs that each tool they use requires, and somehow convert model descriptions when using multiple applications in a toolchain. NeuroML addresses this issue by providing a common language for the use and exchange of models and their components between different simulation engines and modeling tools. The NeuroML ecosystem includes a large collection of software tools, both developed and maintained by the main NeuroML contributors (the 'core NeuroML tools and libraries:' jNeuroML, pyNeuroML, APIs) and those external applications that have added NeuroML support (Figures 3 and 4a, Tables 3 and 4).","md":"Model building and the generation of scientific knowledge from simulation and analysis of models is a multi-step, iterative process requiring an array of software tools. NeuroML supports all stages of the model development life cycle (Figure 1), by providing a single model description format that interacts with a myriad of tools throughout the process. Researchers typically assemble ad-hoc sets of scripts, applications, and processes to help them in their investigations. In the absence of standardization, they must work with the specific model formats and APIs that each tool they use requires, and somehow convert model descriptions when using multiple applications in a toolchain. NeuroML addresses this issue by providing a common language for the use and exchange of models and their components between different simulation engines and modeling tools. The NeuroML ecosystem includes a large collection of software tools, both developed and maintained by the main NeuroML contributors (the 'core NeuroML tools and libraries:' jNeuroML, pyNeuroML, APIs) and those external applications that have added NeuroML support (Figures 3 and 4a, Tables 3 and 4).","bBox":{"x":168.53,"y":542.35,"w":417.89,"h":104.98},"layoutAwareBbox":[{"x":164,"y":531,"w":409,"h":141,"startIndex":0,"endIndex":5}]},{"type":"text","value":"The core NeuroML tools and libraries include APIs in several programming languages—Python, Java, C++, and MATLAB. These tools provide critical functionality to allow users to interact with NeuroML components and build models. Using these, researchers can build models from scratch, or read, modify, analyze, visualize, and simulate existing NeuroML models on supported simulation","md":"The core NeuroML tools and libraries include APIs in several programming languages—Python, Java, C++, and MATLAB. These tools provide critical functionality to allow users to interact with NeuroML components and build models. Using these, researchers can build models from scratch, or read, modify, analyze, visualize, and simulate existing NeuroML models on supported simulation","bBox":{"x":168.53,"y":674.32,"w":400.83,"h":44.99},"layoutAwareBbox":[{"x":165,"y":674,"w":409,"h":45,"startIndex":0,"endIndex":378}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    6 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    6 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2","unsafeUrl":"https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2","text":"be serialized in separate ﬁles and ‘included’ in other models (e.g. morphologies https://docs.neuroml."},{"url":"https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2","unsafeUrl":"https://docs.neuroml.org/Userdocs/ImportingMorphologyFiles.html#neuroml2","text":"org/Userdocs/ImportingMorphologyFiles.html#neuroml2). Such reuse of model components speeds "},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhtauinf","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gatehhtauinf","text":"gateHHtauInf"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gateks","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-gateks","text":"gateKS"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexplinearrate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexplinearrate","text":"HHExpLinearRate"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexplinearvariable","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexplinearvariable","text":"HHExpLinearVariable"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexprate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexprate","text":"HHExpRate"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexpvariable","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhexpvariable","text":"HHExpVariable"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhsigmoidrate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhsigmoidrate","text":"HHSigmoidRate"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhsigmoidvariable","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-hhsigmoidvariable","text":"HHSigmoidVariable"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannel","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannel","text":"ionChannel"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelhh","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelhh","text":"ionChannelHH"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelks","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelks","text":"ionChannelKS"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelpassive","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelpassive","text":"ionChannelPassive"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelvshift","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ionchannelvshift","text":"ionChannelVShift"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ksstate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-ksstate","text":"KSState"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-kstransition","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-kstransition","text":"KSTransition"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-openstate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-openstate","text":"open State"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10conductancescaling","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10conductancescaling","text":"q10ConductanceScaling"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10exptemp","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10exptemp","text":"q10ExpTemp"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10fixed","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-q10fixed","text":"q10Fixed"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-reversetransition","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-reversetransition","text":"reverse Transition"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-subgate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-subgate","text":"sub Gate"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-tauinftransition","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-tauinftransition","text":"tauInfTransition"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-vhalftransition","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-vhalftransition","text":"vHalfTransition"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-closedstate","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Channels.html#schema-closedstate","text":"closedState"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                           Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    6 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.978,"layout":[{"image":"page_6_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.269,"y":0.295,"w":0.669,"h":0.209},"isLikelyNoise":false},{"image":"page_6_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.67,"w":0.669,"h":0.178},"isLikelyNoise":false},{"image":"page_6_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.056,"y":0.101,"w":0.884,"h":0.152},"isLikelyNoise":false},{"image":"page_6_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.508,"w":0.669,"h":0.102},"isLikelyNoise":false},{"image":"page_6_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.852,"w":0.669,"h":0.058},"isLikelyNoise":false},{"image":"page_6_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_6_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.27,"y":0.634,"w":0.645,"h":0.033},"isLikelyNoise":false},{"image":"page_6_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_6_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_6_header_2_v2.jpg","confidence":0.71,"label":"header","bbox":{"x":0.128,"y":0.045,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_6_figure_title_1_v2.jpg","confidence":0.7,"label":"figure_title","bbox":{"x":0.057,"y":0.087,"w":0.091,"h":0.009},"isLikelyNoise":false},{"image":"page_6_header_3_v2.jpg","confidence":0.64,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":false},{"image":"page_6_figure_title_2_v2.jpg","confidence":0.6,"label":"figure_title","bbox":{"x":0.058,"y":0.066,"w":0.119,"h":0.01},"isLikelyNoise":false}]},{"page":7,"text":"              Tools  and  resources                                                                      Neuroscience\n\nTable 2. Index of standard NeuroMLv2 ComponentTypes (continued).\nComponentTypes related to synapses\n\nalphaCurrentSynapse                       alphaSynapse                      blockingPlasticSynapse\n\ndoubleSynapse                             expOneSynapse                     expThreeSynapse\n\nexpTwoSynapse                             gap Junction                      gradedSynapse\n\nlinearGradedSynapse                       silentSynapse                     stdpSynapse\n\ntsodyksMarkramDepFacMechanism             tsodyksMarkramDepMechanism        voltageConcDepBlockMechanism\n\nComponentTypes related to inputs\n\ncompoundInput                             compoundInputDL                   poissonFiringSynapse\n\npulseGenerator                            pulseGeneratorDL                  rampGenerator\n\nrampGeneratorDL                           sineGenerator                     sineGeneratorDL\n\nspike                                     spikeArray                        spike Generator\n\nspikeGeneratorPoisson                     spikeGeneratorRandom              spikeGeneratorRefPoisson\n\ntimedSynapticInput                        transientPoissonFiringSynapse     voltage Clamp\n\nvoltageClampTriple\n\nComponentTypes related to networks\n\nconnection                                connectionWD                      continuous Connection\n\ncontinuousConnectionInstance              continuousConnectionInstanceW     continuous Projection\n\nelectrical Connection                     electricalConnectionInstance      electricalConnectionInstanceW\n\nelectrical Projection                     explicit Connection               explicitInput\n\ninput                                     inputList                         inputW\n\ninstance                                  location                          network\n\nnetworkWithTemperature                    population                        population List\n\nprojection                                rectangularExtent                 region\n\nsynaptic Connection                       synapticConnectionWD\n\nComponentTypes related to model simulation\n\nDisplay                                   EventOutputFile                   EventSelection\n\nLine                                      OutputColumn                      OutputFile\n\nSimulation\n\nComponentTypes related to PyNN\n\nalphaCondSynapse                          alphaCurrSynapse                  EIF_cond_alpha_isfa_ista\n\nEIF_cond_exp_isfa_ista                    expCondSynapse                    expCurrSynapse\n\nHH_cond_exp                               IF_cond_alpha                     IF_cond_exp\n\nIF_curr_alpha                             IF_curr_exp                       SpikeSourcePoisson\n\n\n\n\n\nplatforms. Furthermore, developers can also use the core tools, libraries, and APIs to support NeuroML\nin their own applications.\nThe simulation platforms e.g. EDEN (Panagiotou et  al., 2022), NEURON (Hines and Carne‐\nvale, 1997), along with other independently developed tools, form the next layer of the software\necosystem—providing extra functionality such as interactive model construction (e.g. neuroConstruct\nGleeson et al., 2007), NetPyNE (Dura‐\n                          Bernal et al., 2019), additional visualization (e.g. OSB Gleeson\net al., 2019b), analysis (e.g. NeuroML-DB Birgiolas et al., 2023), data-driven validation (e.g. SciUnit\nGerkin et al., 2019), and archival/sharing (e.g. OSB, NeuroML- DB). Indeed, OSB and NeuroML- DB\nare prime examples of how advanced neuroinformatics resources can be built on top of standards\nsuch as NeuroML.\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    7 of 44","md":"\n\neLife Tools and resources                                                                      Neuroscience\n\n## Table 2. Index of standard NeuroMLv2 ComponentTypes (continued).\n\n<table>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to synapses</strong></td></tr>\n<tr>\n<td>alphaCurrentSynapse</td>\n<td>alphaSynapse</td>\n<td>blockingPlasticSynapse</td>\n</tr>\n<tr>\n<td>doubleSynapse</td>\n<td>expOneSynapse</td>\n<td>expThreeSynapse</td>\n</tr>\n<tr>\n<td>expTwoSynapse</td>\n<td>gap Junction</td>\n<td>gradedSynapse</td>\n</tr>\n<tr>\n<td>linearGradedSynapse</td>\n<td>silentSynapse</td>\n<td>stdpSynapse</td>\n</tr>\n<tr>\n<td>tsodyksMarkramDepFacMechanism</td>\n<td>tsodyksMarkramDepMechanism</td>\n<td>voltageConcDepBlockMechanism</td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to inputs</strong></td></tr>\n<tr>\n<td>compoundInput</td>\n<td>compoundInputDL</td>\n<td>poissonFiringSynapse</td>\n</tr>\n<tr>\n<td>pulseGenerator</td>\n<td>pulseGeneratorDL</td>\n<td>rampGenerator</td>\n</tr>\n<tr>\n<td>rampGeneratorDL</td>\n<td>sineGenerator</td>\n<td>sineGeneratorDL</td>\n</tr>\n<tr>\n<td>spike</td>\n<td>spikeArray</td>\n<td>spike Generator</td>\n</tr>\n<tr>\n<td>spikeGeneratorPoisson</td>\n<td>spikeGeneratorRandom</td>\n<td>spikeGeneratorRefPoisson</td>\n</tr>\n<tr>\n<td>timedSynapticInput</td>\n<td>transientPoissonFiringSynapse</td>\n<td>voltage Clamp</td>\n</tr>\n<tr>\n<td>voltageClampTriple</td>\n<td></td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to networks</strong></td></tr>\n<tr>\n<td>connection</td>\n<td>connectionWD</td>\n<td>continuous Connection</td>\n</tr>\n<tr>\n<td>continuousConnectionInstance</td>\n<td>continuousConnectionInstanceW</td>\n<td>continuous Projection</td>\n</tr>\n<tr>\n<td>electrical Connection</td>\n<td>electricalConnectionInstance</td>\n<td>electricalConnectionInstanceW</td>\n</tr>\n<tr>\n<td>electrical Projection</td>\n<td>explicit Connection</td>\n<td>explicitInput</td>\n</tr>\n<tr>\n<td>input</td>\n<td>inputList</td>\n<td>inputW</td>\n</tr>\n<tr>\n<td>instance</td>\n<td>location</td>\n<td>network</td>\n</tr>\n<tr>\n<td>networkWithTemperature</td>\n<td>population</td>\n<td>population List</td>\n</tr>\n<tr>\n<td>projection</td>\n<td>rectangularExtent</td>\n<td>region</td>\n</tr>\n<tr>\n<td>synaptic Connection</td>\n<td>synapticConnectionWD</td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to model simulation</strong></td></tr>\n<tr>\n<td>Display</td>\n<td>EventOutputFile</td>\n<td>EventSelection</td>\n</tr>\n<tr>\n<td>Line</td>\n<td>OutputColumn</td>\n<td>OutputFile</td>\n</tr>\n<tr>\n<td>Simulation</td>\n<td></td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to PyNN</strong></td></tr>\n<tr>\n<td>alphaCondSynapse</td>\n<td>alphaCurrSynapse</td>\n<td>EIF_cond_alpha_isfa_ista</td>\n</tr>\n<tr>\n<td>EIF_cond_exp_isfa_ista</td>\n<td>expCondSynapse</td>\n<td>expCurrSynapse</td>\n</tr>\n<tr>\n<td>HH_cond_exp</td>\n<td>IF_cond_alpha</td>\n<td>IF_cond_exp</td>\n</tr>\n<tr>\n<td>IF_curr_alpha</td>\n<td>IF_curr_exp</td>\n<td>SpikeSourcePoisson</td>\n</tr>\n</table>\n\nplatforms. Furthermore, developers can also use the core tools, libraries, and APIs to support NeuroML in their own applications.\n\nThe simulation platforms e.g. EDEN (Panagiotou et al., 2022), NEURON (Hines and Carnevale, 1997), along with other independently developed tools, form the next layer of the software ecosystem—providing extra functionality such as interactive model construction (e.g. neuroConstruct Gleeson et al., 2007), NetPyNE (Dura-Bernal et al., 2019), additional visualization (e.g. OSB Gleeson et al., 2019b), analysis (e.g. NeuroML-DB Birgiolas et al., 2023), data-driven validation (e.g. SciUnit Gerkin et al., 2019), and archival/sharing (e.g. OSB, NeuroML-DB). Indeed, OSB and NeuroML-DB are prime examples of how advanced neuroinformatics resources can be built on top of standards such as NeuroML.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    7 of 44\n","images":[{"name":"page_7.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_7_text_1_v2.jpg","height":73721.749,"width":250125.835,"x":101262.742,"y":496463.343,"original_width":1652,"original_height":377,"rotation":0,"type":"layout_v2_text"},{"name":"page_7_table_1_v2.jpg","height":387990.716,"width":331281.364,"x":20978.1,"y":63131.553,"original_width":2188,"original_height":1980,"rotation":0,"type":"layout_v2_table"},{"name":"page_7_text_2_v2.jpg","height":16622.79,"width":250180.614,"x":101132.115,"y":477433.27,"original_width":1652,"original_height":85,"rotation":0,"type":"layout_v2_text"},{"name":"page_7_footer_1_v2.jpg","height":6808.48,"width":191847.814,"x":21535.188,"y":591554.095,"original_width":1267,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_7_header_1_v2.jpg","height":5646.209,"width":30278.77,"x":320795.27,"y":27700.84,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_7_number_1_v2.jpg","height":5783.511,"width":15520.373,"x":335600.011,"y":591870.099,"original_width":103,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_7_figure_title_1_v2.jpg","height":6393.021,"width":77121.476,"x":21386.473,"y":53514.969,"original_width":510,"original_height":33,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_7_header_2_v2.jpg","height":5707.447,"width":42939.087,"x":47839.352,"y":28016.693,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_7_header_3_v2.jpg","height":11044.319,"width":24682.099,"x":21671.427,"y":22461.29,"original_width":163,"original_height":57,"rotation":0,"type":"layout_v2_header"},{"name":"page_7_figure_title_2_v2.jpg","height":7684.062,"width":172297.088,"x":21075.48,"y":41415.991,"original_width":1138,"original_height":40,"rotation":0,"type":"layout_v2_figure_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                      Neuroscience","md":"eLife Tools and resources                                                                      Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":95,"endIndex":107}]},{"type":"heading","lvl":2,"value":"Table 2. Index of standard NeuroMLv2 ComponentTypes (continued).","md":"## Table 2. Index of standard NeuroMLv2 ComponentTypes (continued).","bBox":{"x":36.5,"y":51.84,"w":280.6,"h":9},"layoutAwareBbox":[{"x":34,"y":52,"w":281,"h":9,"startIndex":0,"endIndex":66}]},{"type":"table","rows":[["ComponentTypes related to synapses","",""],["alphaCurrentSynapse","alphaSynapse","blockingPlasticSynapse"],["doubleSynapse","expOneSynapse","expThreeSynapse"],["expTwoSynapse","gap Junction","gradedSynapse"],["linearGradedSynapse","silentSynapse","stdpSynapse"],["tsodyksMarkramDepFacMechanism","tsodyksMarkramDepMechanism","voltageConcDepBlockMechanism"],["ComponentTypes related to inputs","",""],["compoundInput","compoundInputDL","poissonFiringSynapse"],["pulseGenerator","pulseGeneratorDL","rampGenerator"],["rampGeneratorDL","sineGenerator","sineGeneratorDL"],["spike","spikeArray","spike Generator"],["spikeGeneratorPoisson","spikeGeneratorRandom","spikeGeneratorRefPoisson"],["timedSynapticInput","transientPoissonFiringSynapse","voltage Clamp"],["voltageClampTriple","",""],["ComponentTypes related to networks","",""],["connection","connectionWD","continuous Connection"],["continuousConnectionInstance","continuousConnectionInstanceW","continuous Projection"],["electrical Connection","electricalConnectionInstance","electricalConnectionInstanceW"],["electrical Projection","explicit Connection","explicitInput"],["input","inputList","inputW"],["instance","location","network"],["networkWithTemperature","population","population List"],["projection","rectangularExtent","region"],["synaptic Connection","synapticConnectionWD",""],["ComponentTypes related to model simulation","",""],["Display","EventOutputFile","EventSelection"],["Line","OutputColumn","OutputFile"],["Simulation","",""],["ComponentTypes related to PyNN","",""],["alphaCondSynapse","alphaCurrSynapse","EIF_cond_alpha_isfa_ista"],["EIF_cond_exp_isfa_ista","expCondSynapse","expCurrSynapse"],["HH_cond_exp","IF_cond_alpha","IF_cond_exp"],["IF_curr_alpha","IF_curr_exp","SpikeSourcePoisson"]],"html":"<table>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to synapses</strong></td></tr>\n<tr>\n<td>alphaCurrentSynapse</td>\n<td>alphaSynapse</td>\n<td>blockingPlasticSynapse</td>\n</tr>\n<tr>\n<td>doubleSynapse</td>\n<td>expOneSynapse</td>\n<td>expThreeSynapse</td>\n</tr>\n<tr>\n<td>expTwoSynapse</td>\n<td>gap Junction</td>\n<td>gradedSynapse</td>\n</tr>\n<tr>\n<td>linearGradedSynapse</td>\n<td>silentSynapse</td>\n<td>stdpSynapse</td>\n</tr>\n<tr>\n<td>tsodyksMarkramDepFacMechanism</td>\n<td>tsodyksMarkramDepMechanism</td>\n<td>voltageConcDepBlockMechanism</td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to inputs</strong></td></tr>\n<tr>\n<td>compoundInput</td>\n<td>compoundInputDL</td>\n<td>poissonFiringSynapse</td>\n</tr>\n<tr>\n<td>pulseGenerator</td>\n<td>pulseGeneratorDL</td>\n<td>rampGenerator</td>\n</tr>\n<tr>\n<td>rampGeneratorDL</td>\n<td>sineGenerator</td>\n<td>sineGeneratorDL</td>\n</tr>\n<tr>\n<td>spike</td>\n<td>spikeArray</td>\n<td>spike Generator</td>\n</tr>\n<tr>\n<td>spikeGeneratorPoisson</td>\n<td>spikeGeneratorRandom</td>\n<td>spikeGeneratorRefPoisson</td>\n</tr>\n<tr>\n<td>timedSynapticInput</td>\n<td>transientPoissonFiringSynapse</td>\n<td>voltage Clamp</td>\n</tr>\n<tr>\n<td>voltageClampTriple</td>\n<td></td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to networks</strong></td></tr>\n<tr>\n<td>connection</td>\n<td>connectionWD</td>\n<td>continuous Connection</td>\n</tr>\n<tr>\n<td>continuousConnectionInstance</td>\n<td>continuousConnectionInstanceW</td>\n<td>continuous Projection</td>\n</tr>\n<tr>\n<td>electrical Connection</td>\n<td>electricalConnectionInstance</td>\n<td>electricalConnectionInstanceW</td>\n</tr>\n<tr>\n<td>electrical Projection</td>\n<td>explicit Connection</td>\n<td>explicitInput</td>\n</tr>\n<tr>\n<td>input</td>\n<td>inputList</td>\n<td>inputW</td>\n</tr>\n<tr>\n<td>instance</td>\n<td>location</td>\n<td>network</td>\n</tr>\n<tr>\n<td>networkWithTemperature</td>\n<td>population</td>\n<td>population List</td>\n</tr>\n<tr>\n<td>projection</td>\n<td>rectangularExtent</td>\n<td>region</td>\n</tr>\n<tr>\n<td>synaptic Connection</td>\n<td>synapticConnectionWD</td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to model simulation</strong></td></tr>\n<tr>\n<td>Display</td>\n<td>EventOutputFile</td>\n<td>EventSelection</td>\n</tr>\n<tr>\n<td>Line</td>\n<td>OutputColumn</td>\n<td>OutputFile</td>\n</tr>\n<tr>\n<td>Simulation</td>\n<td></td>\n<td></td>\n</tr>\n<tr><td colspan=\"3\"><strong>ComponentTypes related to PyNN</strong></td></tr>\n<tr>\n<td>alphaCondSynapse</td>\n<td>alphaCurrSynapse</td>\n<td>EIF_cond_alpha_isfa_ista</td>\n</tr>\n<tr>\n<td>EIF_cond_exp_isfa_ista</td>\n<td>expCondSynapse</td>\n<td>expCurrSynapse</td>\n</tr>\n<tr>\n<td>HH_cond_exp</td>\n<td>IF_cond_alpha</td>\n<td>IF_cond_exp</td>\n</tr>\n<tr>\n<td>IF_curr_alpha</td>\n<td>IF_curr_exp</td>\n<td>SpikeSourcePoisson</td>\n</tr>\n</table>","md":"| **ComponentTypes related to synapses**         |                               |                               |\n| ---------------------------------------------- | ----------------------------- | ----------------------------- |\n| alphaCurrentSynapse                            | alphaSynapse                  | blockingPlasticSynapse        |\n| doubleSynapse                                  | expOneSynapse                 | expThreeSynapse               |\n| expTwoSynapse                                  | gap Junction                  | gradedSynapse                 |\n| linearGradedSynapse                            | silentSynapse                 | stdpSynapse                   |\n| tsodyksMarkramDepFacMechanism                  | tsodyksMarkramDepMechanism    | voltageConcDepBlockMechanism  |\n| **ComponentTypes related to inputs**           |                               |                               |\n| compoundInput                                  | compoundInputDL               | poissonFiringSynapse          |\n| pulseGenerator                                 | pulseGeneratorDL              | rampGenerator                 |\n| rampGeneratorDL                                | sineGenerator                 | sineGeneratorDL               |\n| spike                                          | spikeArray                    | spike Generator               |\n| spikeGeneratorPoisson                          | spikeGeneratorRandom          | spikeGeneratorRefPoisson      |\n| timedSynapticInput                             | transientPoissonFiringSynapse | voltage Clamp                 |\n| voltageClampTriple                             |                               |                               |\n| **ComponentTypes related to networks**         |                               |                               |\n| connection                                     | connectionWD                  | continuous Connection         |\n| continuousConnectionInstance                   | continuousConnectionInstanceW | continuous Projection         |\n| electrical Connection                          | electricalConnectionInstance  | electricalConnectionInstanceW |\n| electrical Projection                          | explicit Connection           | explicitInput                 |\n| input                                          | inputList                     | inputW                        |\n| instance                                       | location                      | network                       |\n| networkWithTemperature                         | population                    | population List               |\n| projection                                     | rectangularExtent             | region                        |\n| synaptic Connection                            | synapticConnectionWD          |                               |\n| **ComponentTypes related to model simulation** |                               |                               |\n| Display                                        | EventOutputFile               | EventSelection                |\n| Line                                           | OutputColumn                  | OutputFile                    |\n| Simulation                                     |                               |                               |\n| **ComponentTypes related to PyNN**             |                               |                               |\n| alphaCondSynapse                               | alphaCurrSynapse              | EIF\\_cond\\_alpha\\_isfa\\_ista  |\n| EIF\\_cond\\_exp\\_isfa\\_ista                     | expCondSynapse                | expCurrSynapse                |\n| HH\\_cond\\_exp                                  | IF\\_cond\\_alpha               | IF\\_cond\\_exp                 |\n| IF\\_curr\\_alpha                                | IF\\_curr\\_exp                 | SpikeSourcePoisson            |","isPerfectTable":true,"csv":"\"ComponentTypes related to synapses\",\"\",\"\"\n\"alphaCurrentSynapse\",\"alphaSynapse\",\"blockingPlasticSynapse\"\n\"doubleSynapse\",\"expOneSynapse\",\"expThreeSynapse\"\n\"expTwoSynapse\",\"gap Junction\",\"gradedSynapse\"\n\"linearGradedSynapse\",\"silentSynapse\",\"stdpSynapse\"\n\"tsodyksMarkramDepFacMechanism\",\"tsodyksMarkramDepMechanism\",\"voltageConcDepBlockMechanism\"\n\"ComponentTypes related to inputs\",\"\",\"\"\n\"compoundInput\",\"compoundInputDL\",\"poissonFiringSynapse\"\n\"pulseGenerator\",\"pulseGeneratorDL\",\"rampGenerator\"\n\"rampGeneratorDL\",\"sineGenerator\",\"sineGeneratorDL\"\n\"spike\",\"spikeArray\",\"spike Generator\"\n\"spikeGeneratorPoisson\",\"spikeGeneratorRandom\",\"spikeGeneratorRefPoisson\"\n\"timedSynapticInput\",\"transientPoissonFiringSynapse\",\"voltage Clamp\"\n\"voltageClampTriple\",\"\",\"\"\n\"ComponentTypes related to networks\",\"\",\"\"\n\"connection\",\"connectionWD\",\"continuous Connection\"\n\"continuousConnectionInstance\",\"continuousConnectionInstanceW\",\"continuous Projection\"\n\"electrical Connection\",\"electricalConnectionInstance\",\"electricalConnectionInstanceW\"\n\"electrical Projection\",\"explicit Connection\",\"explicitInput\"\n\"input\",\"inputList\",\"inputW\"\n\"instance\",\"location\",\"network\"\n\"networkWithTemperature\",\"population\",\"population List\"\n\"projection\",\"rectangularExtent\",\"region\"\n\"synaptic Connection\",\"synapticConnectionWD\",\"\"\n\"ComponentTypes related to model simulation\",\"\",\"\"\n\"Display\",\"EventOutputFile\",\"EventSelection\"\n\"Line\",\"OutputColumn\",\"OutputFile\"\n\"Simulation\",\"\",\"\"\n\"ComponentTypes related to PyNN\",\"\",\"\"\n\"alphaCondSynapse\",\"alphaCurrSynapse\",\"EIF_cond_alpha_isfa_ista\"\n\"EIF_cond_exp_isfa_ista\",\"expCondSynapse\",\"expCurrSynapse\"\n\"HH_cond_exp\",\"IF_cond_alpha\",\"IF_cond_exp\"\n\"IF_curr_alpha\",\"IF_curr_exp\",\"SpikeSourcePoisson\"","bBox":{"x":36.5,"y":34.63,"w":550.81,"h":720.13},"layoutAwareBbox":[{"x":34,"y":79,"w":541,"h":489,"startIndex":232,"endIndex":251}]},{"type":"text","value":"platforms. Furthermore, developers can also use the core tools, libraries, and APIs to support NeuroML in their own applications.","md":"platforms. Furthermore, developers can also use the core tools, libraries, and APIs to support NeuroML in their own applications.","bBox":{"x":168.53,"y":602.28,"w":418.78,"h":21.02},"layoutAwareBbox":[{"x":165,"y":602,"w":408,"h":20,"startIndex":0,"endIndex":128}]},{"type":"text","value":"The simulation platforms e.g. EDEN (Panagiotou et al., 2022), NEURON (Hines and Carnevale, 1997), along with other independently developed tools, form the next layer of the software ecosystem—providing extra functionality such as interactive model construction (e.g. neuroConstruct Gleeson et al., 2007), NetPyNE (Dura-Bernal et al., 2019), additional visualization (e.g. OSB Gleeson et al., 2019b), analysis (e.g. NeuroML-DB Birgiolas et al., 2023), data-driven validation (e.g. SciUnit Gerkin et al., 2019), and archival/sharing (e.g. OSB, NeuroML-DB). Indeed, OSB and NeuroML-DB are prime examples of how advanced neuroinformatics resources can be built on top of standards such as NeuroML.","md":"The simulation platforms e.g. EDEN (Panagiotou et al., 2022), NEURON (Hines and Carnevale, 1997), along with other independently developed tools, form the next layer of the software ecosystem—providing extra functionality such as interactive model construction (e.g. neuroConstruct Gleeson et al., 2007), NetPyNE (Dura-Bernal et al., 2019), additional visualization (e.g. OSB Gleeson et al., 2019b), analysis (e.g. NeuroML-DB Birgiolas et al., 2023), data-driven validation (e.g. SciUnit Gerkin et al., 2019), and archival/sharing (e.g. OSB, NeuroML-DB). Indeed, OSB and NeuroML-DB are prime examples of how advanced neuroinformatics resources can be built on top of standards such as NeuroML.","bBox":{"x":36.65,"y":480.19,"w":541.97,"h":239.31},"layoutAwareBbox":[{"x":165,"y":626,"w":408,"h":93,"startIndex":62,"endIndex":68}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    7 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    7 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":95},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":95}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-alphacurrentsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-alphacurrentsynapse","text":"alphaCurrentSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-alphasynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-alphasynapse","text":"alphaSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-blockingplasticsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-blockingplasticsynapse","text":"blockingPlasticSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-doublesynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-doublesynapse","text":"doubleSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-exponesynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-exponesynapse","text":"expOneSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-expthreesynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-expthreesynapse","text":"expThreeSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-exptwosynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-exptwosynapse","text":"expTwoSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-gapjunction","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-gapjunction","text":"gap Junction"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-gradedsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-gradedsynapse","text":"gradedSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-lineargradedsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-lineargradedsynapse","text":"linearGradedSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-silentsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-silentsynapse","text":"silentSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-stdpsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-stdpsynapse","text":"stdpSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-tsodyksmarkramdepfacmechanism","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-tsodyksmarkramdepfacmechanism","text":"tsodyksMarkramDepFacMechanism"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-tsodyksmarkramdepmechanism","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-tsodyksmarkramdepmechanism","text":"tsodyksMarkramDepMechanism"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-voltageconcdepblockmechanism","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Synapses.html#schema-voltageconcdepblockmechanism","text":"voltageConcDepBlockMechanism"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-compoundinput","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-compoundinput","text":"compoundInput"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-compoundinputdl","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-compoundinputdl","text":"compoundInputDL"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-poissonfiringsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-poissonfiringsynapse","text":"poissonFiringSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-pulsegenerator","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-pulsegenerator","text":"pulseGenerator"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-pulsegeneratordl","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-pulsegeneratordl","text":"pulseGeneratorDL"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-rampgenerator","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-rampgenerator","text":"rampGenerator"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-rampgeneratordl","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-rampgeneratordl","text":"rampGeneratorDL"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-sinegenerator","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-sinegenerator","text":"sineGenerator"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-sinegeneratordl","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-sinegeneratordl","text":"sineGeneratorDL"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spike","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spike","text":"spike"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikearray","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikearray","text":"spikeArray"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegenerator","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegenerator","text":"spike Generator"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorpoisson","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorpoisson","text":"spikeGeneratorPoisson"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorrandom","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorrandom","text":"spikeGeneratorRandom"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorrefpoisson","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-spikegeneratorrefpoisson","text":"spikeGeneratorRefPoisson"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-timedsynapticinput","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-timedsynapticinput","text":"timedSynapticInput"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-transientpoissonfiringsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-transientpoissonfiringsynapse","text":"transientPoissonFiringSynapse"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-voltageclamp","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-voltageclamp","text":"voltage Clamp"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-voltageclamptriple","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Inputs.html#schema-voltageclamptriple","text":"voltageClampTriple"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-connection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-connection","text":"connection"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-connectionwd","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-connectionwd","text":"connectionWD"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnection","text":"continuous Connection"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnectioninstance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnectioninstance","text":"continuousConnectionInstance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnectioninstancew","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousconnectioninstancew","text":"continuousConnectionInstanceW"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousprojection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-continuousprojection","text":"continuous Projection"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnection","text":"electrical Connection"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnectioninstance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnectioninstance","text":"electricalConnectionInstance"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnectioninstancew","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalconnectioninstancew","text":"electricalConnectionInstanceW"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalprojection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-electricalprojection","text":"electrical Projection"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-explicitconnection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-explicitconnection","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-explicitinput","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-explicitinput","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-input","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-input","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-inputlist","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-inputlist","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-inputw","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-inputw","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-instance","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-instance","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-location","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-location","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-network","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-network","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-networkwithtemperature","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-networkwithtemperature","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-population","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-population","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-populationlist","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-populationlist","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-projection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-projection","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-rectangularextent","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-rectangularextent","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-region","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-region","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-synapticconnection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-synapticconnection","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-synapticconnectionwd","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Networks.html#schema-synapticconnectionwd","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-display","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-display","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-eventoutputfile","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-eventoutputfile","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-eventselection","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-eventselection","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-line","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-line","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-outputcolumn","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-outputcolumn","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-outputfile","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#schema-outputfile","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#id1","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Simulation.html#id1","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-alphacondsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-alphacondsynapse","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-alphacurrsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-alphacurrsynapse","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-eif-cond-alpha-isfa-ista","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-eif-cond-alpha-isfa-ista","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-eif-cond-exp-isfa-ista","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-eif-cond-exp-isfa-ista","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-expcondsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-expcondsynapse","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.htm#schema-expcurrsynapse","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.htm#schema-expcurrsynapse","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-hh-cond-exp","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-hh-cond-exp","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-cond-alpha","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-cond-alpha","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-cond-exp","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-cond-exp","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-curr-alpha","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-curr-alpha","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-curr-exp","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-if-curr-exp","text":""},{"url":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-spikesourcepoisson","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/PyNN.html#schema-spikesourcepoisson","text":""}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                      Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    7 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.997,"layout":[{"image":"page_7_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.791,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_7_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.056,"y":0.101,"w":0.884,"h":0.619},"isLikelyNoise":false},{"image":"page_7_text_2_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.761,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_7_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_7_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_7_number_1_v2.jpg","confidence":0.88,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_7_figure_title_1_v2.jpg","confidence":0.7,"label":"figure_title","bbox":{"x":0.057,"y":0.085,"w":0.206,"h":0.01},"isLikelyNoise":false},{"image":"page_7_header_2_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.128,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_7_header_3_v2.jpg","confidence":0.61,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":false},{"image":"page_7_figure_title_2_v2.jpg","confidence":0.53,"label":"figure_title","bbox":{"x":0.056,"y":0.066,"w":0.46,"h":0.012},"isLikelyNoise":true}]},{"page":8,"text":"    Tools  and  resources    Neuroscience\n\n                             a.    b.    C.\n\n\n\n\n\n\n\n\n    Conductances    Cells    Networks\n\n\n\n  ale  pop\n  gate2  morphz2  projection\n\n  Igate 1  gatel  pop2\n\n  d.  spike\n  Generator\n  pulse\n  Generator  spike\n\n  conductance  Array\n\n  gateKs  voltage  Inputs\n  Clamp  population\n\nKinetic\n Scheme\n  Ion Channels  inputList\n\n  conductance  Networks\n\n  Hodgkin-  NeuroML  projection\n  gateHh  Huxley\n  Rates  iaf\n  Cell  intracellular\n  Synapses  Properties   channel\n  expOne  Densities\n  Synapse  biophysical  membrane\n  Cells  cell  Properties specific\n  gap  alpha  Capacitances\n  Junction  Synapse  morphology\n  izhikevich  segment\n\n  HindmarshRose  Cell  Group\n  Cell  segment\n\n\n    Figure 2. NeuroML is a modular, hierarchical format that supports multi-scale modeling. Elements in NeuroML\n    are formally defined, independent, self-contained building blocks with hierarchical relationships between them.\n    (a) Models of ionic conductances can be defined as a composition of gates, each with specific voltage (and\n    potentially [Ca²⁺]) dependence that controls the conductance. (b) Morphologically detailed neuronal models\n    specify the 3D structure of the cells, along with passive electrical properties, and reference ion channels that\n    confer membrane conductances. (c) Network models contain populations of these cells connected via synaptic\n    projections. (d) A truncated illustration of the main categories of the NeuroMLv2 standard elements and their\n    hierarchies. The standard includes commonly used model elements/building blocks that have been pre-defined\n    for users: Cells: neuronal models ranging from simple spiking point neurons to biophysically detailed cells with\n    multi-compartmental morphologies and active membrane conductances; Synapses and ionic conductance\n    models: commonly used chemical and electrical synapse models (gap junctions), and multiple representations for\n    Figure 2 continued on next page\n\n\n    Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    8 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n**a.**                           **b.**                           **c.**\n\nConductances                     Cells                            Networks\n\n[Diagram showing gate connections with labels: gate3, gate2, gate1, morphz, pop1, pop2, projection]\n\n**d.**\n\n[Hierarchical diagram with NeuroML at center, connected to various elements:]\n\nspike Generator, pulse Generator, spike Array, voltage Clamp, Inputs, population, inputList, Networks, projection\n\ngateKS, conductance, Kinetic Scheme, Ion Channels, conductance, Hodgkin Huxley, gateHH Rates\n\nSynapses, expOne Synapse, gap Junction, alpha Synapse\n\niaf Cell, Cells, intracellular Properties, channel Densities, biophysical cell, membrane Properties, specific Capacitances, morphology, izhikevich Cell, HindmarshRose Cell, segment Group, segment\n\n**Figure 2.** NeuroML is a modular, hierarchical format that supports multi-scale modeling. Elements in NeuroML are formally defined, independent, self-contained building blocks with hierarchical relationships between them. **(a)** Models of ionic conductances can be defined as a composition of gates, each with specific voltage (and potentially [Ca<sup>2+</sup>]) dependence that controls the conductance. **(b)** Morphologically detailed neuronal models specify the 3D structure of the cells, along with passive electrical properties, and reference ion channels that confer membrane conductances. **(c)** Network models contain populations of these cells connected via synaptic projections. **(d)** A truncated illustration of the main categories of the NeuroMLv2 standard elements and their hierarchies. The standard includes commonly used model elements/building blocks that have been pre-defined for users: **Cells:** neuronal models ranging from simple spiking point neurons to biophysically detailed cells with multi-compartmental morphologies and active membrane conductances; **Synapses and ionic conductance models:** commonly used chemical and electrical synapse models (gap junctions), and multiple representations for\n\n*Figure 2 continued on next page*\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    8 of 44\n","images":[{"name":"img_p7_1.png","height":514.704,"width":388.824,"x":174.639,"y":60.073,"original_width":1620,"original_height":2144,"rotation":0,"ocr":[{"x":1307,"y":2064,"w":106,"h":24,"confidence":1,"text":"segment"},{"x":924,"y":2049,"w":54,"h":35,"confidence":1,"text":"Cell"},{"x":878,"y":2023,"w":183,"h":23,"confidence":1,"text":"HindmarshRose"},{"x":1397,"y":2000,"w":83,"h":40,"confidence":1,"text":"Group"},{"x":1101,"y":1985,"w":54,"h":39,"confidence":1,"text":"Cell"},{"x":1400,"y":1976,"w":106,"h":25,"confidence":1,"text":"segment"},{"x":1072,"y":1963,"w":114,"h":22,"confidence":1,"text":"izhikevich"},{"x":1265,"y":1911,"w":148,"h":37,"confidence":1,"text":"morphology"},{"x":511,"y":1916,"w":99,"h":31,"confidence":1,"text":"Synapse"},{"x":321,"y":1905,"w":99,"h":25,"confidence":0.999,"text":"Junction"},{"x":524,"y":1883,"w":72,"h":31,"confidence":1,"text":"alpha"},{"x":1455,"y":1878,"w":152,"h":25,"confidence":0.985,"text":"Capacitances"},{"x":348,"y":1874,"w":48,"h":27,"confidence":1,"text":"gap"},{"x":1455,"y":1842,"w":92,"h":32,"confidence":0.971,"text":"specific"},{"x":949,"y":1820,"w":61,"h":34,"confidence":1,"text":"Cells"},{"x":1321,"y":1816,"w":123,"h":24,"confidence":1,"text":"Properties"},{"x":1167,"y":1816,"w":46,"h":26,"confidence":1,"text":"cell"},{"x":1125,"y":1784,"w":130,"h":25,"confidence":1,"text":"biophysical"},{"x":1318,"y":1782,"w":133,"h":25,"confidence":1,"text":"membrane"},{"x":634,"y":1776,"w":101,"h":31,"confidence":1,"text":"Synapse"},{"x":638,"y":1744,"w":91,"h":25,"confidence":0.998,"text":"expOne"},{"x":1442,"y":1731,"w":110,"h":24,"confidence":1,"text":"Densities"},{"x":425,"y":1704,"w":108,"h":25,"confidence":1,"text":"Synapses"},{"x":1439,"y":1692,"w":98,"h":37,"confidence":0.999,"text":"channel"},{"x":1268,"y":1693,"w":123,"h":24,"confidence":0.962,"text":"Properties"},{"x":1270,"y":1662,"w":145,"h":24,"confidence":1,"text":"intracellular"},{"x":1061,"y":1659,"w":48,"h":27,"confidence":1,"text":"Cell"},{"x":1065,"y":1626,"w":40,"h":29,"confidence":1,"text":"iaf"},{"x":121,"y":1621,"w":75,"h":32,"confidence":1,"text":"Rates"},{"x":114,"y":1585,"w":96,"h":39,"confidence":0.946,"text":"gateHh"},{"x":321,"y":1566,"w":86,"h":31,"confidence":1,"text":"Huxley"},{"x":1248,"y":1536,"w":126,"h":37,"confidence":0.991,"text":"projection"},{"x":310,"y":1532,"w":110,"h":31,"confidence":1,"text":"Hodgkin-"},{"x":687,"y":1523,"w":198,"h":40,"confidence":1,"text":"NeuroML"},{"x":141,"y":1449,"w":150,"h":23,"confidence":1,"text":"conductance"},{"x":1072,"y":1436,"w":112,"h":25,"confidence":1,"text":"Networks"},{"x":1281,"y":1382,"w":106,"h":25,"confidence":1,"text":"inputList"},{"x":401,"y":1367,"w":145,"h":24,"confidence":0.978,"text":"Ion Channels"},{"x":220,"y":1331,"w":90,"h":25,"confidence":1,"text":"Scheme"},{"x":219,"y":1290,"w":92,"h":37,"confidence":1,"text":"Kinetic"},{"x":1166,"y":1246,"w":133,"h":36,"confidence":1,"text":"population"},{"x":607,"y":1221,"w":80,"h":35,"confidence":1,"text":"Clamp"},{"x":34,"y":1196,"w":92,"h":42,"confidence":0.972,"text":"gateKs"},{"x":600,"y":1188,"w":94,"h":36,"confidence":1,"text":"voltage"},{"x":816,"y":1172,"w":85,"h":37,"confidence":1,"text":"Inputs"},{"x":172,"y":1112,"w":147,"h":23,"confidence":1,"text":"conductance"},{"x":1003,"y":1087,"w":76,"h":37,"confidence":1,"text":"Array"},{"x":1008,"y":1056,"w":71,"h":32,"confidence":1,"text":"spike"},{"x":649,"y":1052,"w":119,"h":24,"confidence":1,"text":"Generator"},{"x":674,"y":1016,"w":72,"h":31,"confidence":1,"text":"pulse"},{"x":830,"y":992,"w":116,"h":22,"confidence":1,"text":"Generator"},{"x":849,"y":951,"w":74,"h":37,"confidence":1,"text":"spike"},{"x":26,"y":927,"w":44,"h":40,"confidence":1,"text":"d."},{"x":71,"y":759,"w":110,"h":97,"confidence":0.852,"text":"Igate 1"},{"x":1315,"y":743,"w":133,"h":114,"confidence":0.964,"text":"pop2"},{"x":328,"y":739,"w":123,"h":107,"confidence":0.852,"text":"gatel"},{"x":700,"y":674,"w":156,"h":117,"confidence":0.943,"text":"morphz2"},{"x":1141,"y":605,"w":243,"h":188,"confidence":0.855,"text":"projection"},{"x":252,"y":604,"w":124,"h":113,"confidence":0.91,"text":"gate2"},{"x":1096,"y":545,"w":119,"h":101,"confidence":0.98,"text":"pop"},{"x":183,"y":522,"w":98,"h":113,"confidence":0.492,"text":"ale"},{"x":145,"y":360,"w":264,"h":38,"confidence":1,"text":"Conductances"},{"x":1215,"y":357,"w":185,"h":41,"confidence":0.999,"text":"Networks"},{"x":742,"y":353,"w":101,"h":49,"confidence":0.999,"text":"Cells"},{"x":15,"y":11,"w":47,"h":38,"confidence":0.999,"text":"a."},{"x":1050,"y":9,"w":40,"h":38,"confidence":0.926,"text":"C."},{"x":533,"y":4,"w":46,"h":43,"confidence":1,"text":"b."}]},{"name":"page_8.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_8_image_1_v2.jpg","height":414358.078,"width":244920.122,"x":102835.757,"y":44032.829,"original_width":1618,"original_height":2114,"rotation":0,"type":"layout_v2_image"},{"name":"page_8_figure_title_1_v2.jpg","height":104751.578,"width":245065.986,"x":101475.904,"y":465238.258,"original_width":1619,"original_height":535,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_8_footer_1_v2.jpg","height":6975.724,"width":191859.132,"x":21601.671,"y":591452.126,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_8_header_1_v2.jpg","height":5596.937,"width":30282.601,"x":321048.484,"y":27708.493,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_8_number_1_v2.jpg","height":5706.063,"width":15422.579,"x":335700.47,"y":591826.837,"original_width":102,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_8_header_2_v2.jpg","height":5829.272,"width":42950.885,"x":47744.255,"y":27748.548,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_8_text_1_v2.jpg","height":7056.425,"width":72817.342,"x":102092.888,"y":564035.298,"original_width":481,"original_height":36,"rotation":0,"type":"layout_v2_text"},{"name":"page_8_header_3_v2.jpg","height":10731.23,"width":24448.676,"x":21835.326,"y":22369.157,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"**a.**                           **b.**                           **c.**","md":"**a.**                           **b.**                           **c.**","bBox":{"x":178.24,"y":61.03,"w":258.02,"h":10.8},"layoutAwareBbox":[{"x":168,"y":55,"w":400,"h":523,"startIndex":0,"endIndex":71}]},{"type":"text","value":"Conductances                     Cells                            Networks","md":"Conductances                     Cells                            Networks","bBox":{"x":209.44,"y":144.82,"w":301.22,"h":11.76},"layoutAwareBbox":[{"x":168,"y":55,"w":400,"h":523,"startIndex":0,"endIndex":12}]},{"type":"text","value":"[Diagram showing gate connections with labels: gate3, gate2, gate1, morphz, pop1, pop2, projection]","md":"[Diagram showing gate connections with labels: gate3, gate2, gate1, morphz, pop1, pop2, projection]","bBox":{"x":235.12,"y":190.91,"w":287.06,"h":74.9},"layoutAwareBbox":[{"x":235.12,"y":190.91,"w":287.06,"h":74.9,"startIndex":0,"endIndex":98}]},{"type":"text","value":"**d.**","md":"**d.**","bBox":{"x":180.88,"y":282.62,"w":10.56,"h":9.6},"layoutAwareBbox":[{"x":168,"y":55,"w":400,"h":523,"startIndex":0,"endIndex":5}]},{"type":"text","value":"[Hierarchical diagram with NeuroML at center, connected to various elements:]","md":"[Hierarchical diagram with NeuroML at center, connected to various elements:]","bBox":{"x":339.53,"y":425.7,"w":47.52,"h":9.6},"layoutAwareBbox":[{"x":339.53,"y":425.7,"w":47.52,"h":9.6,"startIndex":0,"endIndex":76}]},{"type":"text","value":"spike Generator, pulse Generator, spike Array, voltage Clamp, Inputs, population, inputList, Networks, projection","md":"spike Generator, pulse Generator, spike Array, voltage Clamp, Inputs, population, inputList, Networks, projection","bBox":{"x":318.65,"y":145.78,"w":192.01,"h":252.07},"layoutAwareBbox":[{"x":168,"y":55,"w":400,"h":523,"startIndex":0,"endIndex":5}]},{"type":"text","value":"gateKS, conductance, Kinetic Scheme, Ion Channels, conductance, Hodgkin Huxley, gateHH Rates","md":"gateKS, conductance, Kinetic Scheme, Ion Channels, conductance, Hodgkin Huxley, gateHH Rates","bBox":{"x":182.8,"y":327.03,"w":122.89,"h":129.88},"layoutAwareBbox":[{"x":182.8,"y":327.03,"w":122.89,"h":129.88,"startIndex":0,"endIndex":91}]},{"type":"text","value":"Synapses, expOne Synapse, gap Junction, alpha Synapse","md":"Synapses, expOne Synapse, gap Junction, alpha Synapse","bBox":{"x":251.68,"y":469.15,"w":97.93,"h":54.26},"layoutAwareBbox":[{"x":251.68,"y":469.15,"w":97.93,"h":54.26,"startIndex":0,"endIndex":52}]},{"type":"text","value":"iaf Cell, Cells, intracellular Properties, channel Densities, biophysical cell, membrane Properties, specific Capacitances, morphology, izhikevich Cell, HindmarshRose Cell, segment Group, segment","md":"iaf Cell, Cells, intracellular Properties, channel Densities, biophysical cell, membrane Properties, specific Capacitances, morphology, izhikevich Cell, HindmarshRose Cell, segment Group, segment","bBox":{"x":352.73,"y":144.82,"w":207.61,"h":406.43},"layoutAwareBbox":[{"x":352.73,"y":144.82,"w":207.61,"h":406.43,"startIndex":0,"endIndex":194}]},{"type":"text","value":"**Figure 2.** NeuroML is a modular, hierarchical format that supports multi-scale modeling. Elements in NeuroML are formally defined, independent, self-contained building blocks with hierarchical relationships between them. **(a)** Models of ionic conductances can be defined as a composition of gates, each with specific voltage (and potentially [Ca<sup>2+</sup>]) dependence that controls the conductance. **(b)** Morphologically detailed neuronal models specify the 3D structure of the cells, along with passive electrical properties, and reference ion channels that confer membrane conductances. **(c)** Network models contain populations of these cells connected via synaptic projections. **(d)** A truncated illustration of the main categories of the NeuroMLv2 standard elements and their hierarchies. The standard includes commonly used model elements/building blocks that have been pre-defined for users: **Cells:** neuronal models ranging from simple spiking point neurons to biophysically detailed cells with multi-compartmental morphologies and active membrane conductances; **Synapses and ionic conductance models:** commonly used chemical and electrical synapse models (gap junctions), and multiple representations for","md":"**Figure 2.** NeuroML is a modular, hierarchical format that supports multi-scale modeling. Elements in NeuroML are formally defined, independent, self-contained building blocks with hierarchical relationships between them. **(a)** Models of ionic conductances can be defined as a composition of gates, each with specific voltage (and potentially [Ca<sup>2+</sup>]) dependence that controls the conductance. **(b)** Morphologically detailed neuronal models specify the 3D structure of the cells, along with passive electrical properties, and reference ion channels that confer membrane conductances. **(c)** Network models contain populations of these cells connected via synaptic projections. **(d)** A truncated illustration of the main categories of the NeuroMLv2 standard elements and their hierarchies. The standard includes commonly used model elements/building blocks that have been pre-defined for users: **Cells:** neuronal models ranging from simple spiking point neurons to biophysically detailed cells with multi-compartmental morphologies and active membrane conductances; **Synapses and ionic conductance models:** commonly used chemical and electrical synapse models (gap junctions), and multiple representations for","bBox":{"x":168.52,"y":146.5,"w":396.6,"h":525.75},"layoutAwareBbox":[{"x":165,"y":587,"w":400,"h":132,"startIndex":70,"endIndex":75}]},{"type":"text","value":"*Figure 2 continued on next page*","md":"*Figure 2 continued on next page*","bBox":{"x":168.52,"y":711.3,"w":117.06,"h":8},"layoutAwareBbox":[{"x":166,"y":712,"w":118,"h":8,"startIndex":0,"endIndex":32}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    8 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    8 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    8 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.943,"layout":[{"image":"page_8_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.07,"w":0.654,"h":0.661},"isLikelyNoise":false},{"image":"page_8_figure_title_1_v2.jpg","confidence":0.94,"label":"figure_title","bbox":{"x":0.271,"y":0.742,"w":0.654,"h":0.167},"isLikelyNoise":false},{"image":"page_8_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_8_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_8_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.896,"y":0.944,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_8_header_2_v2.jpg","confidence":0.74,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_8_text_1_v2.jpg","confidence":0.67,"label":"text","bbox":{"x":0.273,"y":0.899,"w":0.194,"h":0.011},"isLikelyNoise":false},{"image":"page_8_header_3_v2.jpg","confidence":0.63,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false}]},{"page":9,"text":"Tools  and  resources    Neuroscience\n\n\n                   NetPyNE  N2A PyNN\n                   neuroConstruct  NEURON     SciUnit\n\n     Neuro          pyNeuroML      MATLAB/           OMV\n     Morpho.Org     libNeuroML     C++ APIs jNeuroML\nOSB  pyNeuroML              Create            pyNeuroML\n                                      Validate          NetPyNE\nNeuroML-DB         Reuse                            pyNeuroML OSB\n\n\n\nOSB    Share [NwonN]                Visualize  NeuroML-DB\n       pyNeuroML                    Fit  Simulate  jLEMS neuroConstruct\n\nNeuroML-DB                          pyNeuroML    jNeuroML  NEURON\n                                                 pyNeuroML  Arbor\n            NeuroTune                            MOOSE  PyNN NEST\n            BluePyOpt               SciUnit      EDEN Brian2\n                                    NetPyNE      NetPyNE\n\nFigure 3. NeuroML compliant tools and their relation to the model life cycle. The inner circle shows the core\nNeuroML tools and libraries that are maintained by the NeuroML developers. These provide the functionality to\nread, modify, or create new NeuroML models, as well as to validate, analyze, visualize and simulate the models.\nThe outermost layer shows NeuroML-compliant tools that have been developed independently to allow various\ninteractions with NeuroML models. These complement the core tools by facilitating model creation, validation,\nvisualization, simulation, fitting/optimization, sharing, and reuse. Further information on each of the tools shown\nhere can be found in Tables 3 and 4.\n\n\nTable 5 lists interactive, step-\n                  by-step guides in the NeuroML documentation, which can be followed\nto learn the fundamental NeuroML concepts, as well as illustrate how NeuroML- compliant tools can\nbe used to achieve speciﬁc tasks across the model development life cycle. In the following sections,\nwe discuss the speciﬁc functionality available at each stage of model development.\n\nCreating NeuroML models\nThe structured declarative elements of NeuroMLv2, when combined with a procedural scripting\nlanguage such as Python, provide a powerful and yet intuitive ‘building block’ approach to model\nconstruction. For this reason, Python is now the recommended language for interacting with NeuroML\n(Figure 4), although XML remains the primary serialization language for the format (i.e. for saving to\ndisk and depositing in model repositories (Figure  5)). Python has emerged as a key programming\nlanguage in science, including many areas of neuroscience (Muller et  al., 2015). A Python-  based\nNeuroML ecosystem ensures that users can take advantage of Python’s features, and also use pack-\nages from the wider Python ecosystem in their work (e.g. Numpy (Harris et  al., 2020), Matplotlib\nHunter, 2007). pyNeuroML, the Python interface for working with NeuroML, is built on top of the\nPython NeuroML API, libNeuroML (Vella et al., 2014; Sinha, 2023; Figure 4).\nAs illustrated in Figure  5, Python can be used to combine different NeuroML components into\na model. NeuroML supports several pathways for the creation of new models. Modelers may use\n\nFigure 2 continued\nionic conductances; Inputs: to drive cell and network activity, e.g., current or voltage clamp, spiking background\ninputs; Networks: of populations (containing any of the aforementioned cell types), and projections. The full list of\nstandard NeuroML elements can be found in Tables 1 and 2.\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    9 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n**Figure 3.** NeuroML compliant tools and their relation to the model life cycle. The inner circle shows the core NeuroML tools and libraries that are maintained by the NeuroML developers. These provide the functionality to read, modify, or create new NeuroML models, as well as to validate, analyze, visualize and simulate the models. The outermost layer shows NeuroML-compliant tools that have been developed independently to allow various interactions with NeuroML models. These complement the core tools by facilitating model creation, validation, visualization, simulation, fitting/optimization, sharing, and reuse. Further information on each of the tools shown here can be found in *Tables 3 and 4*.\n\n<table>\n<thead>\n<tr>\n<th>Lifecycle Stage</th>\n<th>Core Tools</th>\n<th>External Tools</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Create</td>\n<td>pyNeuroML, libNeuroML</td>\n<td>NetPyNE, neuroConstruct, N2A, PyNN, NEURON, MATLAB/C++ APIs, jNeuroML, pyNeuroML</td>\n</tr>\n<tr>\n<td>Validate</td>\n<td>jNeuroML, pyNeuroML</td>\n<td>SciUnit, OMV, NetPyNE, pyNeuroML, OSB</td>\n</tr>\n<tr>\n<td>Visualize</td>\n<td>pyNeuroML</td>\n<td>NeuroML-DB, neuroConstruct</td>\n</tr>\n<tr>\n<td>Simulate</td>\n<td>jNeuroML, pyNeuroML</td>\n<td>jLEMS, NEURON, Arbor, NEST, PyNN, Brian2, MOOSE, EDEN, NetPyNE</td>\n</tr>\n<tr>\n<td>Fit</td>\n<td>pyNeuroML</td>\n<td>NeuroTune, BluePyOpt, SciUnit, NetPyNE</td>\n</tr>\n<tr>\n<td>Share</td>\n<td>pyNeuroML</td>\n<td>OSB, NeuroML-DB</td>\n</tr>\n<tr>\n<td>Reuse</td>\n<td>pyNeuroML</td>\n<td>NeuroML-DB, OSB, Neuro Morpho.Org</td>\n</tr>\n</tbody>\n</table>\n\n*Table 5* lists interactive, step-by-step guides in the NeuroML documentation, which can be followed to learn the fundamental NeuroML concepts, as well as illustrate how NeuroML-compliant tools can be used to achieve specific tasks across the model development life cycle. In the following sections, we discuss the specific functionality available at each stage of model development.\n\n## Creating NeuroML models\n\nThe structured declarative elements of NeuroMLv2, when combined with a procedural scripting language such as Python, provide a powerful and yet intuitive 'building block' approach to model construction. For this reason, Python is now the recommended language for interacting with NeuroML (*Figure 4*), although XML remains the primary serialization language for the format (i.e. for saving to disk and depositing in model repositories (*Figure 5*)). Python has emerged as a key programming language in science, including many areas of neuroscience (Muller *et al.*, 2015). A Python-based NeuroML ecosystem ensures that users can take advantage of Python's features, and also use packages from the wider Python ecosystem in their work (e.g. Numpy (Harris *et al.*, 2020), Matplotlib Hunter, 2007). pyNeuroML, the Python interface for working with NeuroML, is built on top of the Python NeuroML API, libNeuroML (Vella *et al.*, 2014; Sinha, 2023; *Figure 4*).\n\nAs illustrated in *Figure 5*, Python can be used to combine different NeuroML components into a model. NeuroML supports several pathways for the creation of new models. Modelers may use\n\n**Figure 2 continued**\nionic conductances; **Inputs**: to drive cell and network activity, e.g., current or voltage clamp, spiking background inputs; **Networks**: of populations (containing any of the aforementioned cell types), and projections. The full list of standard NeuroML elements can be found in *Tables 1 and 2*.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    9 of 44\n","images":[{"name":"img_p8_1.jpg","height":27.572,"width":87.034,"x":325.668,"y":169.023,"original_width":363,"original_height":115,"rotation":180,"ocr":[{"x":9,"y":36,"w":229,"h":57,"confidence":0.41,"text":"[NwonN]"}]},{"name":"page_9.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_9_text_1_v2.jpg","height":93198.336,"width":250441.935,"x":101023.157,"y":389103.032,"original_width":1654,"original_height":476,"rotation":0,"type":"layout_v2_text"},{"name":"page_9_image_1_v2.jpg","height":203915.06,"width":247899.178,"x":103007.657,"y":42524.89,"original_width":1637,"original_height":1041,"rotation":0,"type":"layout_v2_image"},{"name":"page_9_text_2_v2.jpg","height":36540.441,"width":250294.578,"x":101085.457,"y":331051.885,"original_width":1653,"original_height":187,"rotation":0,"type":"layout_v2_text"},{"name":"page_9_figure_title_1_v2.jpg","height":58905.95,"width":243487.692,"x":101307.154,"y":252245.749,"original_width":1608,"original_height":301,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_9_text_3_v2.jpg","height":24463.55,"width":248627.244,"x":101280.968,"y":527218.332,"original_width":1642,"original_height":125,"rotation":0,"type":"layout_v2_text"},{"name":"page_9_text_4_v2.jpg","height":17087.435,"width":250054.131,"x":101288.041,"y":484240.516,"original_width":1652,"original_height":88,"rotation":0,"type":"layout_v2_text"},{"name":"page_9_footer_1_v2.jpg","height":6888.397,"width":191861.242,"x":21525.667,"y":591421.546,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_9_paragraph_title_1_v2.jpg","height":8837.071,"width":93618.952,"x":101558.864,"y":377366.432,"original_width":619,"original_height":46,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_9_header_1_v2.jpg","height":5699.481,"width":30437.356,"x":320728.009,"y":27646.033,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_9_number_1_v2.jpg","height":5826.106,"width":15530.369,"x":335567.252,"y":591767.326,"original_width":103,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_9_paragraph_title_2_v2.jpg","height":6960.199,"width":43407.704,"x":101713.837,"y":516084.905,"original_width":287,"original_height":36,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_9_header_2_v2.jpg","height":5871.536,"width":42848.063,"x":47780.279,"y":27758.641,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_9_header_3_v2.jpg","height":10830.25,"width":24455.004,"x":21820.02,"y":22350.114,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"**Figure 3.** NeuroML compliant tools and their relation to the model life cycle. The inner circle shows the core NeuroML tools and libraries that are maintained by the NeuroML developers. These provide the functionality to read, modify, or create new NeuroML models, as well as to validate, analyze, visualize and simulate the models. The outermost layer shows NeuroML-compliant tools that have been developed independently to allow various interactions with NeuroML models. These complement the core tools by facilitating model creation, validation, visualization, simulation, fitting/optimization, sharing, and reuse. Further information on each of the tools shown here can be found in *Tables 3 and 4*.","md":"**Figure 3.** NeuroML compliant tools and their relation to the model life cycle. The inner circle shows the core NeuroML tools and libraries that are maintained by the NeuroML developers. These provide the functionality to read, modify, or create new NeuroML models, as well as to validate, analyze, visualize and simulate the models. The outermost layer shows NeuroML-compliant tools that have been developed independently to allow various interactions with NeuroML models. These complement the core tools by facilitating model creation, validation, visualization, simulation, fitting/optimization, sharing, and reuse. Further information on each of the tools shown here can be found in *Tables 3 and 4*.","bBox":{"x":168.53,"y":105.83,"w":397.12,"h":275.41},"layoutAwareBbox":[{"x":165,"y":318,"w":397,"h":74,"startIndex":0,"endIndex":705}]},{"type":"table","rows":[["Lifecycle Stage","Core Tools","External Tools"],["Create","pyNeuroML, libNeuroML","NetPyNE, neuroConstruct, N2A, PyNN, NEURON, MATLAB/C++ APIs, jNeuroML, pyNeuroML"],["Validate","jNeuroML, pyNeuroML","SciUnit, OMV, NetPyNE, pyNeuroML, OSB"],["Visualize","pyNeuroML","NeuroML-DB, neuroConstruct"],["Simulate","jNeuroML, pyNeuroML","jLEMS, NEURON, Arbor, NEST, PyNN, Brian2, MOOSE, EDEN, NetPyNE"],["Fit","pyNeuroML","NeuroTune, BluePyOpt, SciUnit, NetPyNE"],["Share","pyNeuroML","OSB, NeuroML-DB"],["Reuse","pyNeuroML","NeuroML-DB, OSB, Neuro Morpho.Org"]],"html":"<table>\n<thead>\n<tr>\n<th>Lifecycle Stage</th>\n<th>Core Tools</th>\n<th>External Tools</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Create</td>\n<td>pyNeuroML, libNeuroML</td>\n<td>NetPyNE, neuroConstruct, N2A, PyNN, NEURON, MATLAB/C++ APIs, jNeuroML, pyNeuroML</td>\n</tr>\n<tr>\n<td>Validate</td>\n<td>jNeuroML, pyNeuroML</td>\n<td>SciUnit, OMV, NetPyNE, pyNeuroML, OSB</td>\n</tr>\n<tr>\n<td>Visualize</td>\n<td>pyNeuroML</td>\n<td>NeuroML-DB, neuroConstruct</td>\n</tr>\n<tr>\n<td>Simulate</td>\n<td>jNeuroML, pyNeuroML</td>\n<td>jLEMS, NEURON, Arbor, NEST, PyNN, Brian2, MOOSE, EDEN, NetPyNE</td>\n</tr>\n<tr>\n<td>Fit</td>\n<td>pyNeuroML</td>\n<td>NeuroTune, BluePyOpt, SciUnit, NetPyNE</td>\n</tr>\n<tr>\n<td>Share</td>\n<td>pyNeuroML</td>\n<td>OSB, NeuroML-DB</td>\n</tr>\n<tr>\n<td>Reuse</td>\n<td>pyNeuroML</td>\n<td>NeuroML-DB, OSB, Neuro Morpho.Org</td>\n</tr>\n</tbody>\n</table>","md":"| Lifecycle Stage | Core Tools            | External Tools                                                                   |\n| --------------- | --------------------- | -------------------------------------------------------------------------------- |\n| Create          | pyNeuroML, libNeuroML | NetPyNE, neuroConstruct, N2A, PyNN, NEURON, MATLAB/C++ APIs, jNeuroML, pyNeuroML |\n| Validate        | jNeuroML, pyNeuroML   | SciUnit, OMV, NetPyNE, pyNeuroML, OSB                                            |\n| Visualize       | pyNeuroML             | NeuroML-DB, neuroConstruct                                                       |\n| Simulate        | jNeuroML, pyNeuroML   | jLEMS, NEURON, Arbor, NEST, PyNN, Brian2, MOOSE, EDEN, NetPyNE                   |\n| Fit             | pyNeuroML             | NeuroTune, BluePyOpt, SciUnit, NetPyNE                                           |\n| Share           | pyNeuroML             | OSB, NeuroML-DB                                                                  |\n| Reuse           | pyNeuroML             | NeuroML-DB, OSB, Neuro Morpho.Org                                                |","isPerfectTable":true,"csv":"\"Lifecycle Stage\",\"Core Tools\",\"External Tools\"\n\"Create\",\"pyNeuroML, libNeuroML\",\"NetPyNE, neuroConstruct, N2A, PyNN, NEURON, MATLAB/C++ APIs, jNeuroML, pyNeuroML\"\n\"Validate\",\"jNeuroML, pyNeuroML\",\"SciUnit, OMV, NetPyNE, pyNeuroML, OSB\"\n\"Visualize\",\"pyNeuroML\",\"NeuroML-DB, neuroConstruct\"\n\"Simulate\",\"jNeuroML, pyNeuroML\",\"jLEMS, NEURON, Arbor, NEST, PyNN, Brian2, MOOSE, EDEN, NetPyNE\"\n\"Fit\",\"pyNeuroML\",\"NeuroTune, BluePyOpt, SciUnit, NetPyNE\"\n\"Share\",\"pyNeuroML\",\"OSB, NeuroML-DB\"\n\"Reuse\",\"pyNeuroML\",\"NeuroML-DB, OSB, Neuro Morpho.Org\"","bBox":{"x":168.53,"y":101.51,"w":397.12,"h":494.28},"layoutAwareBbox":[{"x":168.53,"y":101.51,"w":397.12,"h":494.28,"startIndex":0,"endIndex":1141}]},{"type":"text","value":"*Table 5* lists interactive, step-by-step guides in the NeuroML documentation, which can be followed to learn the fundamental NeuroML concepts, as well as illustrate how NeuroML-compliant tools can be used to achieve specific tasks across the model development life cycle. In the following sections, we discuss the specific functionality available at each stage of model development.","md":"*Table 5* lists interactive, step-by-step guides in the NeuroML documentation, which can be followed to learn the fundamental NeuroML concepts, as well as illustrate how NeuroML-compliant tools can be used to achieve specific tasks across the model development life cycle. In the following sections, we discuss the specific functionality available at each stage of model development.","bBox":{"x":168.53,"y":417.81,"w":414.8,"h":21},"layoutAwareBbox":[{"x":165,"y":417,"w":408,"h":46,"startIndex":34,"endIndex":36}]},{"type":"heading","lvl":2,"value":"Creating NeuroML models","md":"## Creating NeuroML models","bBox":{"x":168.53,"y":474.81,"w":149.97,"h":12},"layoutAwareBbox":[{"x":165,"y":476,"w":152,"h":11,"startIndex":0,"endIndex":25}]},{"type":"text","value":"The structured declarative elements of NeuroMLv2, when combined with a procedural scripting language such as Python, provide a powerful and yet intuitive 'building block' approach to model construction. For this reason, Python is now the recommended language for interacting with NeuroML (*Figure 4*), although XML remains the primary serialization language for the format (i.e. for saving to disk and depositing in model repositories (*Figure 5*)). Python has emerged as a key programming language in science, including many areas of neuroscience (Muller *et al.*, 2015). A Python-based NeuroML ecosystem ensures that users can take advantage of Python's features, and also use packages from the wider Python ecosystem in their work (e.g. Numpy (Harris *et al.*, 2020), Matplotlib Hunter, 2007). pyNeuroML, the Python interface for working with NeuroML, is built on top of the Python NeuroML API, libNeuroML (Vella *et al.*, 2014; Sinha, 2023; *Figure 4*).","md":"The structured declarative elements of NeuroMLv2, when combined with a procedural scripting language such as Python, provide a powerful and yet intuitive 'building block' approach to model construction. For this reason, Python is now the recommended language for interacting with NeuroML (*Figure 4*), although XML remains the primary serialization language for the format (i.e. for saving to disk and depositing in model repositories (*Figure 5*)). Python has emerged as a key programming language in science, including many areas of neuroscience (Muller *et al.*, 2015). A Python-based NeuroML ecosystem ensures that users can take advantage of Python's features, and also use packages from the wider Python ecosystem in their work (e.g. Numpy (Harris *et al.*, 2020), Matplotlib Hunter, 2007). pyNeuroML, the Python interface for working with NeuroML, is built on top of the Python NeuroML API, libNeuroML (Vella *et al.*, 2014; Sinha, 2023; *Figure 4*).","bBox":{"x":168.53,"y":34.63,"w":415.07,"h":561.15},"layoutAwareBbox":[{"x":165,"y":491,"w":409,"h":117,"startIndex":0,"endIndex":3}]},{"type":"text","value":"As illustrated in *Figure 5*, Python can be used to combine different NeuroML components into a model. NeuroML supports several pathways for the creation of new models. Modelers may use","md":"As illustrated in *Figure 5*, Python can be used to combine different NeuroML components into a model. NeuroML supports several pathways for the creation of new models. Modelers may use","bBox":{"x":168.53,"y":105.83,"w":392.58,"h":525.95},"layoutAwareBbox":[{"x":165,"y":611,"w":408,"h":21,"startIndex":19,"endIndex":25}]},{"type":"text","value":"**Figure 2 continued**\nionic conductances; **Inputs**: to drive cell and network activity, e.g., current or voltage clamp, spiking background inputs; **Networks**: of populations (containing any of the aforementioned cell types), and projections. The full list of standard NeuroML elements can be found in *Tables 1 and 2*.","md":"**Figure 2 continued**\nionic conductances; **Inputs**: to drive cell and network activity, e.g., current or voltage clamp, spiking background inputs; **Networks**: of populations (containing any of the aforementioned cell types), and projections. The full list of standard NeuroML elements can be found in *Tables 1 and 2*.","bBox":{"x":168.53,"y":105.83,"w":86.95,"h":553.82},"layoutAwareBbox":[{"x":165,"y":665,"w":406,"h":30,"startIndex":45,"endIndex":51},{"x":166,"y":651,"w":70,"h":8,"startIndex":0,"endIndex":322}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    9 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    9 of 44","bBox":{"x":549.78,"y":746.76,"w":25.21,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":111},{"x":548,"y":747,"w":25,"h":7,"startIndex":0,"endIndex":111}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    9 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.983,"layout":[{"image":"page_9_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.62,"w":0.669,"h":0.149},"isLikelyNoise":false},{"image":"page_9_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.068,"w":0.662,"h":0.325},"isLikelyNoise":false},{"image":"page_9_text_2_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.528,"w":0.668,"h":0.058},"isLikelyNoise":false},{"image":"page_9_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.27,"y":0.402,"w":0.65,"h":0.094},"isLikelyNoise":false},{"image":"page_9_text_3_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.841,"w":0.664,"h":0.039},"isLikelyNoise":false},{"image":"page_9_text_4_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.27,"y":0.772,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_9_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_9_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.602,"w":0.25,"h":0.014},"isLikelyNoise":false},{"image":"page_9_header_1_v2.jpg","confidence":0.86,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_9_number_1_v2.jpg","confidence":0.86,"label":"number","bbox":{"x":0.896,"y":0.943,"w":0.041,"h":0.009},"isLikelyNoise":false},{"image":"page_9_paragraph_title_2_v2.jpg","confidence":0.83,"label":"paragraph_title","bbox":{"x":0.272,"y":0.823,"w":0.116,"h":0.011},"isLikelyNoise":false},{"image":"page_9_header_2_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_9_header_3_v2.jpg","confidence":0.52,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":10,"text":"    Tools  and  resources    Neuroscience\n\n\n                                  pyNeuroML\nPython interface to NeuroML. Gives access to all jNeuroML functionality, adds\n                                  and analyzing NeuroML\n    helper methods for summarising, visualizing\n\n    libNeuroML                                 pyLEMS\n     API for reading, writing    Python implementation of\n    Python\n    and validatingNeuroML        LEMS parser & simulator\n\n                  jNeuroML\nCan validate & simulate NeuroML models & convert to other formats, e.g.\n                                 NEURON\n\n       NeuroML2 LEMS                      jLEMS\n        Definitions             Can load and simulate LEMS\nDefine structure/behavior of    models - not neuroscience\n NeuroML core types in LEMS              specific\n\n\n\n\n\n\n\n\n\n\n    Figure 4. The core NeuroML software stack, and an example NeuroML model created using the Python NeuroML\n    tools. (a) The core NeuroML software stack consists of Java (blue) and Python (orange) based applications/libraries,\n    and the LEMS model ComponentType definitions (green), wrapped up in a single package, pyNeuroML. Each of\n    these modules can be used independently or the whole stack can be obtained by installing pyNeuroML with the\n    default Python package manager, Pip: pip install pyneuroml. (b) An example of how to create a simple NeuroML\n    model is shown, using the NeuroMLv2 Python API (libNeuroML) to describe a model consisting of a population\n    of 10 integrate and fire point neurons (IafTauCell) in a network. The IafTauCell, Network, Population, and\n    NeuroMLDocument model ComponentTypes are provided by the NeuroMLv2 standard. The underlying dynamics\n    of the model are hidden from the user, being specified in the LEMS ComponentType definitions of the elements\n    (see Methods). The simulator-independent NeuroML model description can be simulated on any of the supported\n    simulation engines. (c) Extensible Markup Language (XML) serialization of the NeuroMLv2 model description\n    shows the correspondence between the Python object model and the XML serialization.\n\n\n\n\n\n\n\n\n\n\n    Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    10 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n**a.**\n\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"2\"><strong>pyNeuroML</strong><br>Python interface to NeuroML. Gives access to all jNeuroML functionality, adds helper methods for summarising, visualizing and analyzing NeuroML.</td>\n</tr>\n<tr>\n<td><strong>libNeuroML</strong><br>Python API for reading, writing and validating NeuroML</td>\n<td><strong>pyLEMS</strong><br>Python implementation of LEMS parser & simulator</td>\n</tr>\n<tr>\n<td colspan=\"2\"><strong>jNeuroML</strong><br>Can validate & simulate NeuroML models & convert to other formats, e.g. NEURON</td>\n</tr>\n<tr>\n<td><strong>NeuroML2 LEMS Definitions</strong><br>Define structure/behavior of NeuroML core types in LEMS</td>\n<td><strong>jLEMS</strong><br>Can load and simulate LEMS models - not neuroscience specific</td>\n</tr>\n</tbody>\n</table>\n\n**b. Example Python usage**\n\n```python\nfrom neuroml import * # NeuroML API libNeuroML\n\nnewdoc = NeuroMLDocument(id=\"new_doc\")\nnewcell = IafTauCell(id=\"cell_0\",\n                     leak_reversal=\"-60mV\", thresh=\"0mV\",\n                     tau=\"6ms\", reset=\"-70mV\")\nnewdoc.add(newcell)\n\nnetwork = newdoc.add(Network, id=\"new_net\",\n                     validate=False)\npopulation = network.add(Population,\n                        id=\"new_pop\", size=10,\n                        component=newcell.id)\n\n# Helper method to ensure all parameters\n# present and appropriate\nnewdoc.validate(recursive=True)\n```\n\n**c. XML serialization**\n\n```xml\n<neuroml id=\"new_doc\">\n\n    <iafTauCell id=\"cell_0\"\n                leakReversal=\"-60mV\" thresh=\"0mV\"\n                reset=\"-70mV\" tau=\"6ms\"/>\n\n    <network id=\"new_net\">\n\n        <population id=\"new_pop\"\n                    component=\"cell_0\" size=\"10\"/>\n\n    </network>\n\n</neuroml>\n```\n\n**Figure 4.** The core NeuroML software stack, and an example NeuroML model created using the Python NeuroML tools. (a) The core NeuroML software stack consists of Java (blue) and Python (orange) based applications/libraries, and the LEMS model ComponentType definitions (green), wrapped up in a single package, pyNeuroML. Each of these modules can be used independently or the whole stack can be obtained by installing pyNeuroML with the default Python package manager, Pip: pip install pyneuroml. (b) An example of how to create a simple NeuroML model is shown, using the NeuroMLv2 Python API (libNeuroML) to describe a model consisting of a population of 10 integrate and fire point neurons (IafTauCell) in a network. The IafTauCell, Network, Population, and NeuroMLDocument model ComponentTypes are provided by the NeuroMLv2 standard. The underlying dynamics of the model are hidden from the user, being specified in the LEMS ComponentType definitions of the elements (see Methods). The simulator-independent NeuroML model description can be simulated on any of the supported simulation engines. (c) Extensible Markup Language (XML) serialization of the NeuroMLv2 model description shows the correspondence between the Python object model and the XML serialization.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    10 of 44\n","images":[{"name":"img_p9_1.png","height":243.817,"width":319.125,"x":194.514,"y":62.257,"original_width":1330,"original_height":1016,"rotation":0,"ocr":[{"x":193,"y":809,"w":408,"h":33,"confidence":0.999,"text":"NeuroML core types in LEMS"},{"x":872,"y":799,"w":118,"h":45,"confidence":0.999,"text":"specific"},{"x":204,"y":772,"w":390,"h":31,"confidence":0.999,"text":"Define structure/behavior of"},{"x":747,"y":768,"w":370,"h":31,"confidence":0.999,"text":"models - not neuroscience"},{"x":729,"y":729,"w":407,"h":32,"confidence":0.992,"text":"Can load and simulate LEMS"},{"x":264,"y":715,"w":264,"h":51,"confidence":0.99,"text":"Definitions"},{"x":848,"y":657,"w":165,"h":59,"confidence":0.999,"text":"jLEMS"},{"x":198,"y":657,"w":398,"h":47,"confidence":0.999,"text":"NeuroML2 LEMS"},{"x":590,"y":576,"w":142,"h":33,"confidence":1,"text":"NEURON"},{"x":154,"y":534,"w":1013,"h":43,"confidence":0.985,"text":"Can validate & simulate NeuroML models & convert to other formats, e.g."},{"x":536,"y":468,"w":244,"h":60,"confidence":1,"text":"jNeuroML"},{"x":218,"y":352,"w":202,"h":37,"confidence":0.985,"text":"and validating"},{"x":763,"y":349,"w":358,"h":40,"confidence":0.959,"text":"LEMS parser & simulator"},{"x":418,"y":352,"w":135,"h":33,"confidence":1,"text":"NeuroML"},{"x":266,"y":315,"w":332,"h":37,"confidence":0.966,"text":" API for reading, writing"},{"x":179,"y":318,"w":102,"h":30,"confidence":1,"text":"Python"},{"x":762,"y":312,"w":363,"h":40,"confidence":1,"text":"Python implementation of"},{"x":251,"y":250,"w":273,"h":43,"confidence":0.987,"text":"libNeuroML"},{"x":837,"y":241,"w":207,"h":66,"confidence":0.967,"text":"pyLEMS"},{"x":791,"y":132,"w":347,"h":41,"confidence":0.962,"text":" and analyzing NeuroML"},{"x":187,"y":134,"w":623,"h":37,"confidence":0.981,"text":"helper methods for summarising, visualizing"},{"x":129,"y":97,"w":1071,"h":33,"confidence":0.996,"text":"Python interface to NeuroML. Gives access to all jNeuroML functionality, adds"},{"x":522,"y":24,"w":282,"h":65,"confidence":1,"text":"pyNeuroML"}]},{"name":"page_10.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_10_footer_1_v2.jpg","height":6850.938,"width":191696.067,"x":21782.956,"y":591474.315,"original_width":1266,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_10_header_1_v2.jpg","height":5646.291,"width":30355.647,"x":320810.036,"y":27693.215,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_10_number_1_v2.jpg","height":5782.648,"width":17725.169,"x":333424.657,"y":591838.501,"original_width":118,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_10_image_1_v2.jpg","height":199441.313,"width":226378.128,"x":103244.187,"y":44038.108,"original_width":1495,"original_height":1018,"rotation":0,"type":"layout_v2_image"},{"name":"page_10_header_2_v2.jpg","height":5701.553,"width":43130.878,"x":47774.136,"y":27899.506,"original_width":285,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_10_text_1_v2.jpg","height":103187.613,"width":249376.082,"x":101238.781,"y":422037.92,"original_width":1647,"original_height":527,"rotation":0,"type":"layout_v2_text"},{"name":"page_10_image_2_v2.jpg","height":371105.622,"width":227225.318,"x":102881.012,"y":43859.327,"original_width":1501,"original_height":1894,"rotation":0,"type":"layout_v2_image"},{"name":"page_10_algorithm_1_v2.jpg","height":155541.811,"width":108220.331,"x":104403.511,"y":257552.246,"original_width":715,"original_height":794,"rotation":0,"type":"layout_v2_algorithm"},{"name":"page_10_header_3_v2.jpg","height":10708.622,"width":24445.965,"x":21854.695,"y":22428.881,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"**a.**","md":"**a.**","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":55,"w":369,"h":251,"startIndex":0,"endIndex":5}]},{"type":"table","rows":[["Component","Description"],["pyNeuroML<br/>Python interface to NeuroML. Gives access to all jNeuroML functionality, adds helper methods for summarising, visualizing and analyzing NeuroML.",""],["libNeuroML<br/>Python API for reading, writing and validating NeuroML","pyLEMS<br/>Python implementation of LEMS parser & simulator"],["jNeuroML<br/>Can validate & simulate NeuroML models & convert to other formats, e.g. NEURON",""],["NeuroML2 LEMS Definitions<br/>Define structure/behavior of NeuroML core types in LEMS","jLEMS<br/>Can load and simulate LEMS models - not neuroscience specific"]],"html":"<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"2\"><strong>pyNeuroML</strong><br />Python interface to NeuroML. Gives access to all jNeuroML functionality, adds helper methods for summarising, visualizing and analyzing NeuroML.</td>\n</tr>\n<tr>\n<td><strong>libNeuroML</strong><br />Python API for reading, writing and validating NeuroML</td>\n<td><strong>pyLEMS</strong><br />Python implementation of LEMS parser &#x26; simulator</td>\n</tr>\n<tr>\n<td colspan=\"2\"><strong>jNeuroML</strong><br />Can validate &#x26; simulate NeuroML models &#x26; convert to other formats, e.g. NEURON</td>\n</tr>\n<tr>\n<td><strong>NeuroML2 LEMS Definitions</strong><br />Define structure/behavior of NeuroML core types in LEMS</td>\n<td><strong>jLEMS</strong><br />Can load and simulate LEMS models - not neuroscience specific</td>\n</tr>\n</tbody>\n</table>","md":"| Component                                                                                                                                                          | Description                                                                 |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------- |\n| **pyNeuroML**<br/>Python interface to NeuroML. Gives access to all jNeuroML functionality, adds helper methods for summarising, visualizing and analyzing NeuroML. |                                                                             |\n| **libNeuroML**<br/>Python API for reading, writing and validating NeuroML                                                                                          | **pyLEMS**<br/>Python implementation of LEMS parser & simulator             |\n| **jNeuroML**<br/>Can validate & simulate NeuroML models & convert to other formats, e.g. NEURON                                                                    |                                                                             |\n| **NeuroML2 LEMS Definitions**<br/>Define structure/behavior of NeuroML core types in LEMS                                                                          | **jLEMS**<br/>Can load and simulate LEMS models - not neuroscience specific |","isPerfectTable":false,"csv":"\"Component\",\"Description\"\n\"pyNeuroML<br/>Python interface to NeuroML. Gives access to all jNeuroML functionality, adds helper methods for summarising, visualizing and analyzing NeuroML.\",\"\"\n\"libNeuroML<br/>Python API for reading, writing and validating NeuroML\",\"pyLEMS<br/>Python implementation of LEMS parser & simulator\"\n\"jNeuroML<br/>Can validate & simulate NeuroML models & convert to other formats, e.g. NEURON\",\"\"\n\"NeuroML2 LEMS Definitions<br/>Define structure/behavior of NeuroML core types in LEMS\",\"jLEMS<br/>Can load and simulate LEMS models - not neuroscience specific\"","bBox":{"x":37.01,"y":34.63,"w":539.33,"h":720.13},"layoutAwareBbox":[{"x":168,"y":55,"w":369,"h":251,"startIndex":494,"endIndex":503}]},{"type":"text","value":"**b. Example Python usage**","md":"**b. Example Python usage**","bBox":{"x":237.46,"y":138.57,"w":24.47,"h":7.2},"layoutAwareBbox":[{"x":237.46,"y":138.57,"w":24.47,"h":7.2,"startIndex":0,"endIndex":26}]},{"type":"text","value":"```python\nfrom neuroml import * # NeuroML API libNeuroML","md":"```python\nfrom neuroml import * # NeuroML API libNeuroML","bBox":{"x":237.46,"y":122.25,"w":82.78,"h":23.52},"layoutAwareBbox":[{"x":237.46,"y":122.25,"w":82.78,"h":23.52,"startIndex":0,"endIndex":55}]},{"type":"text","value":"newdoc = NeuroMLDocument(id=\"new_doc\")\nnewcell = IafTauCell(id=\"cell_0\",\n                     leak_reversal=\"-60mV\", thresh=\"0mV\",\n                     tau=\"6ms\", reset=\"-70mV\")\nnewdoc.add(newcell)","md":"newdoc = NeuroMLDocument(id=\"new_doc\")\nnewcell = IafTauCell(id=\"cell_0\",\n                     leak_reversal=\"-60mV\", thresh=\"0mV\",\n                     tau=\"6ms\", reset=\"-70mV\")\nnewdoc.add(newcell)","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":196}]},{"type":"text","value":"network = newdoc.add(Network, id=\"new_net\",\n                     validate=False)\npopulation = network.add(Population,\n                        id=\"new_pop\", size=10,\n                        component=newcell.id)","md":"network = newdoc.add(Network, id=\"new_net\",\n                     validate=False)\npopulation = network.add(Population,\n                        id=\"new_pop\", size=10,\n                        component=newcell.id)","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":209}]},{"type":"heading","lvl":1,"value":"Helper method to ensure all parameters","md":"# Helper method to ensure all parameters","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":39}]},{"type":"heading","lvl":1,"value":"present and appropriate","md":"# present and appropriate","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":24}]},{"type":"text","value":"newdoc.validate(recursive=True)\n```","md":"newdoc.validate(recursive=True)\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":34}]},{"type":"text","value":"**c. XML serialization**","md":"**c. XML serialization**","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":23}]},{"type":"text","value":"```xml\n<neuroml id=\"new_doc\">","md":"```xml\n<neuroml id=\"new_doc\">","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":28}]},{"type":"text","value":"<iafTauCell id=\"cell_0\"\n                leakReversal=\"-60mV\" thresh=\"0mV\"\n                reset=\"-70mV\" tau=\"6ms\"/>","md":"<iafTauCell id=\"cell_0\"\n                leakReversal=\"-60mV\" thresh=\"0mV\"\n                reset=\"-70mV\" tau=\"6ms\"/>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":114}]},{"type":"text","value":"<network id=\"new_net\">","md":"<network id=\"new_net\">","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":21}]},{"type":"text","value":"<population id=\"new_pop\"\n                    component=\"cell_0\" size=\"10\"/>","md":"<population id=\"new_pop\"\n                    component=\"cell_0\" size=\"10\"/>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":74}]},{"type":"text","value":"</network>","md":"</network>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":9}]},{"type":"text","value":"</neuroml>\n```","md":"</neuroml>\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":55,"w":369,"h":251,"startIndex":2,"endIndex":9}]},{"type":"text","value":"**Figure 4.** The core NeuroML software stack, and an example NeuroML model created using the Python NeuroML tools. (a) The core NeuroML software stack consists of Java (blue) and Python (orange) based applications/libraries, and the LEMS model ComponentType definitions (green), wrapped up in a single package, pyNeuroML. Each of these modules can be used independently or the whole stack can be obtained by installing pyNeuroML with the default Python package manager, Pip: pip install pyneuroml. (b) An example of how to create a simple NeuroML model is shown, using the NeuroMLv2 Python API (libNeuroML) to describe a model consisting of a population of 10 integrate and fire point neurons (IafTauCell) in a network. The IafTauCell, Network, Population, and NeuroMLDocument model ComponentTypes are provided by the NeuroMLv2 standard. The underlying dynamics of the model are hidden from the user, being specified in the LEMS ComponentType definitions of the elements (see Methods). The simulator-independent NeuroML model description can be simulated on any of the supported simulation engines. (c) Extensible Markup Language (XML) serialization of the NeuroMLv2 model description shows the correspondence between the Python object model and the XML serialization.","md":"**Figure 4.** The core NeuroML software stack, and an example NeuroML model created using the Python NeuroML tools. (a) The core NeuroML software stack consists of Java (blue) and Python (orange) based applications/libraries, and the LEMS model ComponentType definitions (green), wrapped up in a single package, pyNeuroML. Each of these modules can be used independently or the whole stack can be obtained by installing pyNeuroML with the default Python package manager, Pip: pip install pyneuroml. (b) An example of how to create a simple NeuroML model is shown, using the NeuroMLv2 Python API (libNeuroML) to describe a model consisting of a population of 10 integrate and fire point neurons (IafTauCell) in a network. The IafTauCell, Network, Population, and NeuroMLDocument model ComponentTypes are provided by the NeuroMLv2 standard. The underlying dynamics of the model are hidden from the user, being specified in the LEMS ComponentType definitions of the elements (see Methods). The simulator-independent NeuroML model description can be simulated on any of the supported simulation engines. (c) Extensible Markup Language (XML) serialization of the NeuroMLv2 model description shows the correspondence between the Python object model and the XML serialization.","bBox":{"x":168.53,"y":138.57,"w":405.71,"h":523.13},"layoutAwareBbox":[{"x":165,"y":532,"w":407,"h":130,"startIndex":109,"endIndex":114}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    10 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    10 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":28,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    10 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.845,"layout":[{"image":"page_10_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_10_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_10_number_1_v2.jpg","confidence":0.88,"label":"number","bbox":{"x":0.89,"y":0.944,"w":0.047,"h":0.009},"isLikelyNoise":false},{"image":"page_10_image_1_v2.jpg","confidence":0.8,"label":"image","bbox":{"x":0.276,"y":0.07,"w":0.604,"h":0.318},"isLikelyNoise":false},{"image":"page_10_header_2_v2.jpg","confidence":0.73,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_10_text_1_v2.jpg","confidence":0.68,"label":"text","bbox":{"x":0.27,"y":0.673,"w":0.666,"h":0.165},"isLikelyNoise":false},{"image":"page_10_image_2_v2.jpg","confidence":0.68,"label":"image","bbox":{"x":0.275,"y":0.07,"w":0.607,"h":0.592},"isLikelyNoise":false},{"image":"page_10_algorithm_1_v2.jpg","confidence":0.64,"label":"algorithm","bbox":{"x":0.279,"y":0.411,"w":0.289,"h":0.248},"isLikelyNoise":false},{"image":"page_10_header_3_v2.jpg","confidence":0.62,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false}]},{"page":11,"text":"            Tools  and  resources                                                                                          Neuroscience\n\nTable 3. NeuroML software core tools and libraries, with a description of their scope, the main programming language they use (or\nother interaction means, e.g. Command Line Interface (CLI)), and links for more information.\nTool                   Language/interface     Description                                                URL\n\n                                                                                                         https://docs.neuroml.org/\n                                              Recommended Python library for NeuroML; provides           Userdocs/Software/pyNeuroML.\npyNeuroML              Python/CLI             pynml, primary command line tool for NeuroML               html\n\n                                                                                                         https://docs.neuroml.org/\n                                                                                                         Userdocs/Software/libNeuroML.\nlibNeuroML             Python                 Python API for NeuroML                                     html\n\n                                                                                                         https://docs.neuroml.org/\n                                              High level library for creating NeuroML network models     Userdocs/Software/NeuroMLlite.\nNeuroMLlite            Python                 (beta)                                                     html\n\n                                                                                                         https://docs.neuroml.org/\nPyLEMS                 Python/CLI             Python API and simulator for LEMS                          Userdocs/Software/pyLEMS.html\n\n                                                                                                         https://docs.neuroml.org/\njLEMS                  Java/CLI               Java API for LEMS and reference simulator                  Userdocs/Software/jLEMS.html\n\n                                                                                                         https://github.com/NeuroML/\norg.neuroml.model      Java                   Java API for NeuroML, DOI:10.5281/zenodo.5783290           org.neuroml.model/\n\n                                              Java API for translating NeuroML into different formats such https://github.com/NeuroML/\norg.neuroml.export     Java                   as NEURON, DOI:10.5281/zenodo.1346272                      org.neuroml.export\n\n                                              Java API for importing formats into LEMS and NeuroML,      https://github.com/NeuroML/\norg.neuroml.import     Java                   DOI:10.5281/zenodo.5783295                                 org.neuroml.import\n\n                                                                                                         https://docs.neuroml.org/\n                                              Wraps jLEMS and all export/import packages and provides    Userdocs/Software/jNeuroML.\njNeuroML               Java/CLI               the jnml tool, DOI:10.5281/zenodo.593108                   html\n\n                                                                                                         https://docs.neuroml.org/\n                                                                                                         Userdocs/Software/NeuroML_\nNeuroML- C++           C++                    C++ API for NeuroML                                        API.html\n\n                                                                                                         https://docs.neuroml.org/\nNeuroML Toolbox        MATLAB                 MATLAB NeuroML Toolbox                                     Userdocs/Software/MatLab.html\n\n\n\n\nelements included in the NeuroML standard, re-\n                                    use user-deﬁned NeuroML model elements from other\nmodels, or deﬁne completely new model elements using LEMS (Figure 5) (see section on extending\nNeuroML below). It is common for models to use a combination of these strategies, e.g., Gurnani\nand Silver, 2021; Kriener et al., 2022; Cayco‐Gajic et al., 2017, highlighting the ﬂexibility provided\nby the modular design of NeuroML. NeuroML APIs support all of these workﬂows. The Python tools\nalso include many additional higher- level utilities to speed up model construction, such as factory\nfunctions, type hints, and convenience functions for building complex multi-   compartmental neuron\nmodels (Figure 6).\nFor the construction of complex 3D circuit models, or for users who are not experienced with\nPython, a range of NeuroML- compliant online and standalone applications with graphical user inter -\nfaces are available. These include NetPyNE’s interactive web interface (Dura‐  Bernal et  al., 2019)\n(which is available on the latest version of OSB (https://v2.opensourcebrain.org)) and neuroConstruct\n(Gleeson et al., 2007) which can export models directly into NeuroML and LEMS. These applications\ncan be used to build and simulate new NeuroML models without requiring programming. Thus, users\ncan take advantage of the individual features provided by these applications to generate NeuroML-\ncompliant models and model elements.\n\nValidating NeuroML models\nEnsuring a model is ‘valid’ can have different meanings at different stages of the life cycle—from\nchecking whether the source ﬁles are in the correct format, to ensuring the model reproduces a signif-\nicant feature of its biological counterpart. NeuroML’s hierarchical, well- deﬁned structure allows users\nto check their model descriptions for correctness at multiple levels (Figure 7), in a manner similar to\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    11 of 44","md":"\n\neLife Tools and resources                                                                                          Neuroscience\n\n**Table 3.** NeuroML software core tools and libraries, with a description of their scope, the main programming language they use (or other interaction means, e.g. Command Line Interface (CLI)), and links for more information.\n\n<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Language/interface</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pyNeuroML</td>\n<td>Python/CLI</td>\n<td>Recommended Python library for NeuroML; provides pynml, primary command line tool for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html</td>\n</tr>\n<tr>\n<td>libNeuroML</td>\n<td>Python</td>\n<td>Python API for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/libNeuroML.html</td>\n</tr>\n<tr>\n<td>NeuroMLlite</td>\n<td>Python</td>\n<td>High level library for creating NeuroML network models (beta)</td>\n<td>https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html</td>\n</tr>\n<tr>\n<td>PyLEMS</td>\n<td>Python/CLI</td>\n<td>Python API and simulator for LEMS</td>\n<td>https://docs.neuroml.org/Userdocs/Software/pyLEMS.html</td>\n</tr>\n<tr>\n<td>jLEMS</td>\n<td>Java/CLI</td>\n<td>Java API for LEMS and reference simulator</td>\n<td>https://docs.neuroml.org/Userdocs/Software/jLEMS.html</td>\n</tr>\n<tr>\n<td>org.neuroml.model</td>\n<td>Java</td>\n<td>Java API for NeuroML, DOI:10.5281/zenodo.5783290</td>\n<td>https://github.com/NeuroML/org.neuroml.model/</td>\n</tr>\n<tr>\n<td>org.neuroml.export</td>\n<td>Java</td>\n<td>Java API for translating NeuroML into different formats such as NEURON, DOI:10.5281/zenodo.1346272</td>\n<td>https://github.com/NeuroML/org.neuroml.export</td>\n</tr>\n<tr>\n<td>org.neuroml.import</td>\n<td>Java</td>\n<td>Java API for importing formats into LEMS and NeuroML, DOI:10.5281/zenodo.5783295</td>\n<td>https://github.com/NeuroML/org.neuroml.import</td>\n</tr>\n<tr>\n<td>jNeuroML</td>\n<td>Java/CLI</td>\n<td>Wraps jLEMS and all export/import packages and provides the jnml tool, DOI:10.5281/zenodo.593108</td>\n<td>https://docs.neuroml.org/Userdocs/Software/jNeuroML.html</td>\n</tr>\n<tr>\n<td>NeuroML-C++</td>\n<td>C++</td>\n<td>C++ API for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html</td>\n</tr>\n<tr>\n<td>NeuroML Toolbox</td>\n<td>MATLAB</td>\n<td>MATLAB NeuroML Toolbox</td>\n<td>https://docs.neuroml.org/Userdocs/Software/MatLab.html</td>\n</tr>\n</tbody>\n</table>\n\nelements included in the NeuroML standard, re-use user-defined NeuroML model elements from other models, or define completely new model elements using LEMS (Figure 5) (see section on extending NeuroML below). It is common for models to use a combination of these strategies, e.g., Gurnani and Silver, 2021; Kriener et al., 2022; Cayco-Gajic et al., 2017, highlighting the flexibility provided by the modular design of NeuroML. NeuroML APIs support all of these workflows. The Python tools also include many additional higher-level utilities to speed up model construction, such as factory functions, type hints, and convenience functions for building complex multi-compartmental neuron models (Figure 6).\n\nFor the construction of complex 3D circuit models, or for users who are not experienced with Python, a range of NeuroML-compliant online and standalone applications with graphical user interfaces are available. These include NetPyNE's interactive web interface (Dura-Bernal et al., 2019) (which is available on the latest version of OSB (https://v2.opensourcebrain.org)) and neuroConstruct (Gleeson et al., 2007) which can export models directly into NeuroML and LEMS. These applications can be used to build and simulate new NeuroML models without requiring programming. Thus, users can take advantage of the individual features provided by these applications to generate NeuroML-compliant models and model elements.\n\n## Validating NeuroML models\n\nEnsuring a model is 'valid' can have different meanings at different stages of the life cycle—from checking whether the source files are in the correct format, to ensuring the model reproduces a significant feature of its biological counterpart. NeuroML's hierarchical, well-defined structure allows users to check their model descriptions for correctness at multiple levels (Figure 7), in a manner similar to\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    11 of 44\n","images":[{"name":"page_11.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_11_table_1_v2.jpg","height":265111.824,"width":331195.311,"x":20574.004,"y":61765.443,"original_width":2187,"original_height":1353,"rotation":0,"type":"layout_v2_table"},{"name":"page_11_text_1_v2.jpg","height":75477.697,"width":250388.192,"x":100925.704,"y":431605.264,"original_width":1654,"original_height":386,"rotation":0,"type":"layout_v2_text"},{"name":"page_11_text_2_v2.jpg","height":75613.46,"width":250662.239,"x":100879.034,"y":353683.59,"original_width":1656,"original_height":386,"rotation":0,"type":"layout_v2_text"},{"name":"page_11_text_3_v2.jpg","height":36891.258,"width":250254.322,"x":101019.151,"y":533697.126,"original_width":1653,"original_height":189,"rotation":0,"type":"layout_v2_text"},{"name":"page_11_paragraph_title_1_v2.jpg","height":8658.379,"width":98767.245,"x":101376.664,"y":521753.118,"original_width":653,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_11_footer_1_v2.jpg","height":6794.837,"width":191815.841,"x":21452.586,"y":591466.435,"original_width":1267,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_11_header_1_v2.jpg","height":5527.213,"width":30341.199,"x":320702.807,"y":27712.543,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_11_number_1_v2.jpg","height":6036.141,"width":17896.705,"x":333166.156,"y":591714.557,"original_width":119,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_11_figure_title_1_v2.jpg","height":16809.642,"width":324942.505,"x":20571.078,"y":41447.684,"original_width":2146,"original_height":86,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_11_header_2_v2.jpg","height":5840.756,"width":42893.58,"x":47712.733,"y":27830.962,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_11_header_3_v2.jpg","height":11066.61,"width":24781.589,"x":21503.532,"y":22368.485,"original_width":164,"original_height":57,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                          Neuroscience","md":"eLife Tools and resources                                                                                          Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":6,"startIndex":115,"endIndex":127}]},{"type":"text","value":"**Table 3.** NeuroML software core tools and libraries, with a description of their scope, the main programming language they use (or other interaction means, e.g. Command Line Interface (CLI)), and links for more information.","md":"**Table 3.** NeuroML software core tools and libraries, with a description of their scope, the main programming language they use (or other interaction means, e.g. Command Line Interface (CLI)), and links for more information.","bBox":{"x":36.5,"y":63.79,"w":370.91,"h":23.19},"layoutAwareBbox":[{"x":33,"y":52,"w":530,"h":21,"startIndex":0,"endIndex":225}]},{"type":"table","rows":[["Tool","Language/interface","Description","URL"],["pyNeuroML","Python/CLI","Recommended Python library for NeuroML; provides pynml, primary command line tool for NeuroML","https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html"],["libNeuroML","Python","Python API for NeuroML","https://docs.neuroml.org/Userdocs/Software/libNeuroML.html"],["NeuroMLlite","Python","High level library for creating NeuroML network models (beta)","https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html"],["PyLEMS","Python/CLI","Python API and simulator for LEMS","https://docs.neuroml.org/Userdocs/Software/pyLEMS.html"],["jLEMS","Java/CLI","Java API for LEMS and reference simulator","https://docs.neuroml.org/Userdocs/Software/jLEMS.html"],["org.neuroml.model","Java","Java API for NeuroML, DOI:10.5281/zenodo.5783290","https://github.com/NeuroML/org.neuroml.model/"],["org.neuroml.export","Java","Java API for translating NeuroML into different formats such as NEURON, DOI:10.5281/zenodo.1346272","https://github.com/NeuroML/org.neuroml.export"],["org.neuroml.import","Java","Java API for importing formats into LEMS and NeuroML, DOI:10.5281/zenodo.5783295","https://github.com/NeuroML/org.neuroml.import"],["jNeuroML","Java/CLI","Wraps jLEMS and all export/import packages and provides the jnml tool, DOI:10.5281/zenodo.593108","https://docs.neuroml.org/Userdocs/Software/jNeuroML.html"],["NeuroML-C++","C++","C++ API for NeuroML","https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html"],["NeuroML Toolbox","MATLAB","MATLAB NeuroML Toolbox","https://docs.neuroml.org/Userdocs/Software/MatLab.html"]],"html":"<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Language/interface</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pyNeuroML</td>\n<td>Python/CLI</td>\n<td>Recommended Python library for NeuroML; provides pynml, primary command line tool for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html</td>\n</tr>\n<tr>\n<td>libNeuroML</td>\n<td>Python</td>\n<td>Python API for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/libNeuroML.html</td>\n</tr>\n<tr>\n<td>NeuroMLlite</td>\n<td>Python</td>\n<td>High level library for creating NeuroML network models (beta)</td>\n<td>https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html</td>\n</tr>\n<tr>\n<td>PyLEMS</td>\n<td>Python/CLI</td>\n<td>Python API and simulator for LEMS</td>\n<td>https://docs.neuroml.org/Userdocs/Software/pyLEMS.html</td>\n</tr>\n<tr>\n<td>jLEMS</td>\n<td>Java/CLI</td>\n<td>Java API for LEMS and reference simulator</td>\n<td>https://docs.neuroml.org/Userdocs/Software/jLEMS.html</td>\n</tr>\n<tr>\n<td>org.neuroml.model</td>\n<td>Java</td>\n<td>Java API for NeuroML, DOI:10.5281/zenodo.5783290</td>\n<td>https://github.com/NeuroML/org.neuroml.model/</td>\n</tr>\n<tr>\n<td>org.neuroml.export</td>\n<td>Java</td>\n<td>Java API for translating NeuroML into different formats such as NEURON, DOI:10.5281/zenodo.1346272</td>\n<td>https://github.com/NeuroML/org.neuroml.export</td>\n</tr>\n<tr>\n<td>org.neuroml.import</td>\n<td>Java</td>\n<td>Java API for importing formats into LEMS and NeuroML, DOI:10.5281/zenodo.5783295</td>\n<td>https://github.com/NeuroML/org.neuroml.import</td>\n</tr>\n<tr>\n<td>jNeuroML</td>\n<td>Java/CLI</td>\n<td>Wraps jLEMS and all export/import packages and provides the jnml tool, DOI:10.5281/zenodo.593108</td>\n<td>https://docs.neuroml.org/Userdocs/Software/jNeuroML.html</td>\n</tr>\n<tr>\n<td>NeuroML-C++</td>\n<td>C++</td>\n<td>C++ API for NeuroML</td>\n<td>https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html</td>\n</tr>\n<tr>\n<td>NeuroML Toolbox</td>\n<td>MATLAB</td>\n<td>MATLAB NeuroML Toolbox</td>\n<td>https://docs.neuroml.org/Userdocs/Software/MatLab.html</td>\n</tr>\n</tbody>\n</table>","md":"| Tool               | Language/interface | Description                                                                                        | URL                                                           |\n| ------------------ | ------------------ | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- |\n| pyNeuroML          | Python/CLI         | Recommended Python library for NeuroML; provides pynml, primary command line tool for NeuroML      | <https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html>   |\n| libNeuroML         | Python             | Python API for NeuroML                                                                             | <https://docs.neuroml.org/Userdocs/Software/libNeuroML.html>  |\n| NeuroMLlite        | Python             | High level library for creating NeuroML network models (beta)                                      | <https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html> |\n| PyLEMS             | Python/CLI         | Python API and simulator for LEMS                                                                  | <https://docs.neuroml.org/Userdocs/Software/pyLEMS.html>      |\n| jLEMS              | Java/CLI           | Java API for LEMS and reference simulator                                                          | <https://docs.neuroml.org/Userdocs/Software/jLEMS.html>       |\n| org.neuroml.model  | Java               | Java API for NeuroML, DOI:10.5281/zenodo.5783290                                                   | <https://github.com/NeuroML/org.neuroml.model/>               |\n| org.neuroml.export | Java               | Java API for translating NeuroML into different formats such as NEURON, DOI:10.5281/zenodo.1346272 | <https://github.com/NeuroML/org.neuroml.export>               |\n| org.neuroml.import | Java               | Java API for importing formats into LEMS and NeuroML, DOI:10.5281/zenodo.5783295                   | <https://github.com/NeuroML/org.neuroml.import>               |\n| jNeuroML           | Java/CLI           | Wraps jLEMS and all export/import packages and provides the jnml tool, DOI:10.5281/zenodo.593108   | <https://docs.neuroml.org/Userdocs/Software/jNeuroML.html>    |\n| NeuroML-C++        | C++                | C++ API for NeuroML                                                                                | <https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html> |\n| NeuroML Toolbox    | MATLAB             | MATLAB NeuroML Toolbox                                                                             | <https://docs.neuroml.org/Userdocs/Software/MatLab.html>      |","isPerfectTable":false,"csv":"\"Tool\",\"Language/interface\",\"Description\",\"URL\"\n\"pyNeuroML\",\"Python/CLI\",\"Recommended Python library for NeuroML; provides pynml, primary command line tool for NeuroML\",\"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html\"\n\"libNeuroML\",\"Python\",\"Python API for NeuroML\",\"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html\"\n\"NeuroMLlite\",\"Python\",\"High level library for creating NeuroML network models (beta)\",\"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html\"\n\"PyLEMS\",\"Python/CLI\",\"Python API and simulator for LEMS\",\"https://docs.neuroml.org/Userdocs/Software/pyLEMS.html\"\n\"jLEMS\",\"Java/CLI\",\"Java API for LEMS and reference simulator\",\"https://docs.neuroml.org/Userdocs/Software/jLEMS.html\"\n\"org.neuroml.model\",\"Java\",\"Java API for NeuroML, DOI:10.5281/zenodo.5783290\",\"https://github.com/NeuroML/org.neuroml.model/\"\n\"org.neuroml.export\",\"Java\",\"Java API for translating NeuroML into different formats such as NEURON, DOI:10.5281/zenodo.1346272\",\"https://github.com/NeuroML/org.neuroml.export\"\n\"org.neuroml.import\",\"Java\",\"Java API for importing formats into LEMS and NeuroML, DOI:10.5281/zenodo.5783295\",\"https://github.com/NeuroML/org.neuroml.import\"\n\"jNeuroML\",\"Java/CLI\",\"Wraps jLEMS and all export/import packages and provides the jnml tool, DOI:10.5281/zenodo.593108\",\"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html\"\n\"NeuroML-C++\",\"C++\",\"C++ API for NeuroML\",\"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html\"\n\"NeuroML Toolbox\",\"MATLAB\",\"MATLAB NeuroML Toolbox\",\"https://docs.neuroml.org/Userdocs/Software/MatLab.html\"","bBox":{"x":36.5,"y":34.79,"w":538.5,"h":684.54},"layoutAwareBbox":[{"x":33,"y":77,"w":541,"h":334,"startIndex":2,"endIndex":6}]},{"type":"text","value":"elements included in the NeuroML standard, re-use user-defined NeuroML model elements from other models, or define completely new model elements using LEMS (Figure 5) (see section on extending NeuroML below). It is common for models to use a combination of these strategies, e.g., Gurnani and Silver, 2021; Kriener et al., 2022; Cayco-Gajic et al., 2017, highlighting the flexibility provided by the modular design of NeuroML. NeuroML APIs support all of these workflows. The Python tools also include many additional higher-level utilities to speed up model construction, such as factory functions, type hints, and convenience functions for building complex multi-compartmental neuron models (Figure 6).","md":"elements included in the NeuroML standard, re-use user-defined NeuroML model elements from other models, or define completely new model elements using LEMS (Figure 5) (see section on extending NeuroML below). It is common for models to use a combination of these strategies, e.g., Gurnani and Silver, 2021; Kriener et al., 2022; Cayco-Gajic et al., 2017, highlighting the flexibility provided by the modular design of NeuroML. NeuroML APIs support all of these workflows. The Python tools also include many additional higher-level utilities to speed up model construction, such as factory functions, type hints, and convenience functions for building complex multi-compartmental neuron models (Figure 6).","bBox":{"x":36.5,"y":78.98,"w":540.17,"h":449.85},"layoutAwareBbox":[{"x":164,"y":446,"w":409,"h":95,"startIndex":97,"endIndex":103}]},{"type":"text","value":"For the construction of complex 3D circuit models, or for users who are not experienced with Python, a range of NeuroML-compliant online and standalone applications with graphical user interfaces are available. These include NetPyNE's interactive web interface (Dura-Bernal et al., 2019) (which is available on the latest version of OSB (https://v2.opensourcebrain.org)) and neuroConstruct (Gleeson et al., 2007) which can export models directly into NeuroML and LEMS. These applications can be used to build and simulate new NeuroML models without requiring programming. Thus, users can take advantage of the individual features provided by these applications to generate NeuroML-compliant models and model elements.","md":"For the construction of complex 3D circuit models, or for users who are not experienced with Python, a range of NeuroML-compliant online and standalone applications with graphical user interfaces are available. These include NetPyNE's interactive web interface (Dura-Bernal et al., 2019) (which is available on the latest version of OSB (https://v2.opensourcebrain.org)) and neuroConstruct (Gleeson et al., 2007) which can export models directly into NeuroML and LEMS. These applications can be used to build and simulate new NeuroML models without requiring programming. Thus, users can take advantage of the individual features provided by these applications to generate NeuroML-compliant models and model elements.","bBox":{"x":136,"y":147.07,"w":442.87,"h":492.16},"layoutAwareBbox":[{"x":164,"y":544,"w":409,"h":95,"startIndex":8,"endIndex":20}]},{"type":"heading","lvl":2,"value":"Validating NeuroML models","md":"## Validating NeuroML models","bBox":{"x":168.53,"y":657.25,"w":158.23,"h":12},"layoutAwareBbox":[{"x":165,"y":658,"w":161,"h":10,"startIndex":0,"endIndex":27}]},{"type":"text","value":"Ensuring a model is 'valid' can have different meanings at different stages of the life cycle—from checking whether the source files are in the correct format, to ensuring the model reproduces a significant feature of its biological counterpart. NeuroML's hierarchical, well-defined structure allows users to check their model descriptions for correctness at multiple levels (Figure 7), in a manner similar to","md":"Ensuring a model is 'valid' can have different meanings at different stages of the life cycle—from checking whether the source files are in the correct format, to ensuring the model reproduces a significant feature of its biological counterpart. NeuroML's hierarchical, well-defined structure allows users to check their model descriptions for correctness at multiple levels (Figure 7), in a manner similar to","bBox":{"x":238,"y":78.98,"w":43.41,"h":8},"layoutAwareBbox":[{"x":165,"y":673,"w":408,"h":46,"startIndex":327,"endIndex":339}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    11 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    11 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://v2.opensourcebrain.org/","unsafeUrl":"https://v2.opensourcebrain.org","text":"(which is available on the latest version of OSB (https://v2.opensourcebrain.org)) and neuroConstruct "},{"url":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","text":"https://docs.neuroml.org/ Userdocs/Software/pyNeuroML."},{"url":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","text":"Userdocs/Software/pyNeuroML. html"},{"url":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/pyNeuroML.html","text":"html"},{"url":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","text":"https://docs.neuroml.org/ Userdocs/Software/libNeuroML."},{"url":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","text":"Userdocs/Software/libNeuroML. html"},{"url":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/libNeuroML.html","text":"html"},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","text":"https://docs.neuroml.org/ Userdocs/Software/NeuroMLlite."},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","text":"Userdocs/Software/NeuroMLlite. html"},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroMLlite.html","text":"html"},{"url":"https://docs.neuroml.org/Userdocs/Software/pyLEMS.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/pyLEMS.html","text":"https://docs.neuroml.org/ Userdocs/Software/pyLEMS.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/pyLEMS.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/pyLEMS.html","text":"Userdocs/Software/pyLEMS.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/jLEMS.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/jLEMS.html","text":"https://docs.neuroml.org/ Userdocs/Software/jLEMS.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/jLEMS.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/jLEMS.html","text":"Userdocs/Software/jLEMS.html"},{"url":"https://doi.org/10.5281/zenodo.5783290","unsafeUrl":"https://doi.org/10.5281/zenodo.5783290","text":"Java API for NeuroML, DOI:10.5281/zenodo.5783290"},{"url":"https://github.com/NeuroML/org.neuroml.model/","unsafeUrl":"https://github.com/NeuroML/org.neuroml.model/","text":"https://github.com/NeuroML/ org.neuroml.model/"},{"url":"https://github.com/NeuroML/org.neuroml.model/","unsafeUrl":"https://github.com/NeuroML/org.neuroml.model/","text":"org.neuroml.model/"},{"url":"https://doi.org/10.5281/zenodo.1346272","unsafeUrl":"https://doi.org/10.5281/zenodo.1346272","text":"as NEURON, DOI:10.5281/zenodo.1346272"},{"url":"https://github.com/NeuroML/org.neuroml.export","unsafeUrl":"https://github.com/NeuroML/org.neuroml.export","text":"https://github.com/NeuroML/ org.neuroml.export"},{"url":"https://github.com/NeuroML/org.neuroml.export","unsafeUrl":"https://github.com/NeuroML/org.neuroml.export","text":"org.neuroml.export"},{"url":"https://doi.org/10.5281/zenodo.5783295","unsafeUrl":"https://doi.org/10.5281/zenodo.5783295","text":"DOI:10.5281/zenodo.5783295"},{"url":"https://github.com/NeuroML/org.neuroml.import","unsafeUrl":"https://github.com/NeuroML/org.neuroml.import","text":"https://github.com/NeuroML/ org.neuroml.import"},{"url":"https://github.com/NeuroML/org.neuroml.import","unsafeUrl":"https://github.com/NeuroML/org.neuroml.import","text":"org.neuroml.import"},{"url":"https://doi.org/10.5281/zenodo.593108","unsafeUrl":"https://doi.org/10.5281/zenodo.593108","text":"the jnml tool, DOI:10.5281/zenodo.593108"},{"url":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","text":"https://docs.neuroml.org/ Userdocs/Software/jNeuroML."},{"url":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","text":"Userdocs/Software/jNeuroML. html"},{"url":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/jNeuroML.html","text":"html"},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","text":"https://docs.neuroml.org/ Userdocs/Software/NeuroML_"},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","text":"Userdocs/Software/NeuroML_ API.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/NeuroML_API.html","text":"API.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/MatLab.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/MatLab.html","text":"https://docs.neuroml.org/ Userdocs/Software/MatLab.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/MatLab.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/MatLab.html","text":"Userdocs/Software/MatLab.html"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                          Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    11 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.986,"layout":[{"image":"page_11_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.055,"y":0.098,"w":0.884,"h":0.423},"isLikelyNoise":false},{"image":"page_11_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.269,"y":0.688,"w":0.669,"h":0.12},"isLikelyNoise":false},{"image":"page_11_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.269,"y":0.564,"w":0.669,"h":0.121},"isLikelyNoise":false},{"image":"page_11_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.851,"w":0.668,"h":0.059},"isLikelyNoise":false},{"image":"page_11_paragraph_title_1_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.271,"y":0.832,"w":0.264,"h":0.014},"isLikelyNoise":false},{"image":"page_11_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_11_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_11_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.048,"h":0.01},"isLikelyNoise":false},{"image":"page_11_figure_title_1_v2.jpg","confidence":0.87,"label":"figure_title","bbox":{"x":0.055,"y":0.066,"w":0.868,"h":0.027},"isLikelyNoise":false},{"image":"page_11_header_2_v2.jpg","confidence":0.61,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_11_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.057,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":true}]},{"page":12,"text":"             Tools  and  resources                                                                                          Neuroscience\n\nTable 4. Tools in the wi main programming language they use (or other interaction means, e.g. through a web browser, Graphical\nUser Interface (GUI) or Command Line Interface (CLI)), and links for more information.\nTool                                  Language/interface     Description                             URL\n\nSimulation engines\n\n                                                             Empirically-based simulations of        https://docs.neuroml.org/Userdocs/\nNEURON                                Python/Hoc/CLI/GUI     neurons and networks of neurons         Software/Tools/NEURON.html\n\n                                                             Package to facilitate the\n                                                             development, parallel simulation,\n                                                             analysis, and optimization of\n                                                             biological neuronal networks using\n                                                             the NEURON simulator. Also has a        https://docs.neuroml.org/Userdocs/\nNetPyNE                               Python/web             graphical web interface, NetPyNE-UI     Software/Tools/NetPyNE.html\n\n                                                                                                     https://docs.neuroml.org/Userdocs/\nEDEN                                  NeuroML                NeuroML-based neural simulator          Software/Tools/EDEN.html\n\n                                                             The Multiscale Object-Oriented\n                                                             Simulation Environment is the\n                                                             base and numerical core for large,\n                                                             detailed multi-scale simulations that\n                                                             span computational neuroscience\n                                                             and systems biology. Based on a\n                                                             reimplementation of the GENESIS         https://docs.neuroml.org/Userdocs/\nMOOSE                                 Python                 2 core.                                 Software/Tools/MOOSE.html\n\n                                                             A simulator-independent language\n                                                             for building neuronal network           https://docs.neuroml.org/Userdocs/\nPyNN                                  Python                 models                                  Software/Tools/PyNN.html\n\n                                                             Simulator for spiking neural network\n                                                             models focusing on dynamics, size,      https://docs.neuroml.org/Userdocs/\nNEST                                  Python/SLI             and structure of neural systems         Software/Tools/NEST.html\n\n                                                             Easy to learn and use simulator for     https://docs.neuroml.org/Userdocs/\nBrian2                                Python                 spiking neural networks                 Software/Tools/Brian.html\n\n                                                             A multi-compartment neuron              https://docs.neuroml.org/Userdocs/\nArbor                                 Python                 simulation library                      Software/Tools/Arbor.html\n\n                                                             Language and IDE for writing and        https://docs.neuroml.org/Userdocs/\nN2A                                   Java/GUI               simulating models                       Software/Tools/N2A.html\n\nDatabases\n\n                                                             Resource for sharing and\n                                                             collaboratively developing\n                                                             computational models of neural\nOSB                                   Web                    systems                                 https://www.opensourcebrain.org/\n\n                                                             NeuroML database of cell and\nNeuroML- DB                           Web                    channel models                          https://neuroml-db.org/\n\nOther tools\n\n                                                                                                     https://github.com/\n                                                             Open Source Brain Model Validation OpenSourceBrain/osb-model-\nOMV                                   Python                 framework                               validation\n\nSciUnit                               Python                 Data driven unit testing framework      https://github.com/scidash/sciunit\n\n                                                             Blue Brain Python Optimization\nBluePyOpt                             Python                 Library                                 https://bluepyopt.readthedocs.io/\n\n                                                             Package for fitting/optimization        https://github.com/NeuralEnsemble/\nNeuroTune                             Python                 of NeuroML models                       neurotune\n\n                                                                                                     https://github.com/NeuralEnsemble/\nPyElectro                             Python                 Electrophysiology analysis package      pyelectro\n\n\n\n\n\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    12 of 44","md":"\n\neLife Tools and resources                                                                                          Neuroscience\n\n**Table 4.** Tools in the wi main programming language they use (or other interaction means, e.g. through a web browser, Graphical User Interface (GUI) or Command Line Interface (CLI)), and links for more information.\n\n<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Language/interface</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"4\"><strong>Simulation engines</strong></td>\n</tr>\n<tr>\n<td>NEURON</td>\n<td>Python/Hoc/CLI/GUI</td>\n<td>Empirically-based simulations of neurons and networks of neurons</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html</td>\n</tr>\n<tr>\n<td>NetPyNE</td>\n<td>Python/web</td>\n<td>Package to facilitate the development, parallel simulation, analysis, and optimization of biological neuronal networks using the NEURON simulator. Also has a graphical web interface, NetPyNE-UI</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html</td>\n</tr>\n<tr>\n<td>EDEN</td>\n<td>NeuroML</td>\n<td>NeuroML-based neural simulator</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html</td>\n</tr>\n<tr>\n<td>MOOSE</td>\n<td>Python</td>\n<td>The Multiscale Object-Oriented Simulation Environment is the base and numerical core for large, detailed multi-scale simulations that span computational neuroscience and systems biology. Based on a reimplementation of the GENESIS 2 core.</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html</td>\n</tr>\n<tr>\n<td>PyNN</td>\n<td>Python</td>\n<td>A simulator-independent language for building neuronal network models</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html</td>\n</tr>\n<tr>\n<td>NEST</td>\n<td>Python/SLI</td>\n<td>Simulator for spiking neural network models focusing on dynamics, size, and structure of neural systems</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html</td>\n</tr>\n<tr>\n<td>Brian2</td>\n<td>Python</td>\n<td>Easy to learn and use simulator for spiking neural networks</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html</td>\n</tr>\n<tr>\n<td>Arbor</td>\n<td>Python</td>\n<td>A multi-compartment neuron simulation library</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html</td>\n</tr>\n<tr>\n<td>N2A</td>\n<td>Java/GUI</td>\n<td>Language and IDE for writing and simulating models</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html</td>\n</tr>\n<tr>\n<td colspan=\"4\"><strong>Databases</strong></td>\n</tr>\n<tr>\n<td>OSB</td>\n<td>Web</td>\n<td>Resource for sharing and collaboratively developing computational models of neural systems</td>\n<td>https://www.opensourcebrain.org/</td>\n</tr>\n<tr>\n<td>NeuroML-DB</td>\n<td>Web</td>\n<td>NeuroML database of cell and channel models</td>\n<td>https://neuroml-db.org/</td>\n</tr>\n<tr>\n<td colspan=\"4\"><strong>Other tools</strong></td>\n</tr>\n<tr>\n<td>OMV</td>\n<td>Python</td>\n<td>Open Source Brain Model Validation framework</td>\n<td>https://github.com/OpenSourceBrain/osb-model-validation</td>\n</tr>\n<tr>\n<td>SciUnit</td>\n<td>Python</td>\n<td>Data driven unit testing framework</td>\n<td>https://github.com/scidash/sciunit</td>\n</tr>\n<tr>\n<td>BluePyOpt</td>\n<td>Python</td>\n<td>Blue Brain Python Optimization Library</td>\n<td>https://bluepyopt.readthedocs.io/</td>\n</tr>\n<tr>\n<td>NeuroTune</td>\n<td>Python</td>\n<td>Package for fitting/optimization of NeuroML models</td>\n<td>https://github.com/NeuralEnsemble/neurotune</td>\n</tr>\n<tr>\n<td>PyElectro</td>\n<td>Python</td>\n<td>Electrophysiology analysis package</td>\n<td>https://github.com/NeuralEnsemble/pyelectro</td>\n</tr>\n</tbody>\n</table>\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    12 of 44\n","images":[{"name":"page_12.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_12_table_1_v2.jpg","height":467931.965,"width":331681.008,"x":20631.222,"y":60828.867,"original_width":2190,"original_height":2388,"rotation":0,"type":"layout_v2_table"},{"name":"page_12_footer_1_v2.jpg","height":6875.46,"width":192038.235,"x":21544.776,"y":591487.605,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_12_header_1_v2.jpg","height":5570.647,"width":30456.545,"x":320851.913,"y":27734.013,"original_width":202,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_12_number_1_v2.jpg","height":5983,"width":17805.606,"x":333360.456,"y":591762.425,"original_width":118,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_12_figure_title_1_v2.jpg","height":16695.542,"width":320281.869,"x":20674.999,"y":41461.16,"original_width":2115,"original_height":86,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_12_header_2_v2.jpg","height":5834.09,"width":43025.527,"x":47787.17,"y":27813.109,"original_width":285,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_12_header_3_v2.jpg","height":11074.785,"width":24691.161,"x":21620.126,"y":22392.177,"original_width":164,"original_height":57,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                          Neuroscience","md":"eLife Tools and resources                                                                                          Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":115,"endIndex":127}]},{"type":"text","value":"**Table 4.** Tools in the wi main programming language they use (or other interaction means, e.g. through a web browser, Graphical User Interface (GUI) or Command Line Interface (CLI)), and links for more information.","md":"**Table 4.** Tools in the wi main programming language they use (or other interaction means, e.g. through a web browser, Graphical User Interface (GUI) or Command Line Interface (CLI)), and links for more information.","bBox":{"x":36.5,"y":63.8,"w":344.91,"h":431.75},"layoutAwareBbox":[{"x":33,"y":52,"w":523,"h":21,"startIndex":0,"endIndex":216}]},{"type":"table","rows":[["Tool","Language/interface","Description","URL"],["Simulation engines","","",""],["NEURON","Python/Hoc/CLI/GUI","Empirically-based simulations of neurons and networks of neurons","https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html"],["NetPyNE","Python/web","Package to facilitate the development, parallel simulation, analysis, and optimization of biological neuronal networks using the NEURON simulator. Also has a graphical web interface, NetPyNE-UI","https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html"],["EDEN","NeuroML","NeuroML-based neural simulator","https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html"],["MOOSE","Python","The Multiscale Object-Oriented Simulation Environment is the base and numerical core for large, detailed multi-scale simulations that span computational neuroscience and systems biology. Based on a reimplementation of the GENESIS 2 core.","https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html"],["PyNN","Python","A simulator-independent language for building neuronal network models","https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html"],["NEST","Python/SLI","Simulator for spiking neural network models focusing on dynamics, size, and structure of neural systems","https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html"],["Brian2","Python","Easy to learn and use simulator for spiking neural networks","https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html"],["Arbor","Python","A multi-compartment neuron simulation library","https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html"],["N2A","Java/GUI","Language and IDE for writing and simulating models","https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html"],["Databases","","",""],["OSB","Web","Resource for sharing and collaboratively developing computational models of neural systems","https://www.opensourcebrain.org/"],["NeuroML-DB","Web","NeuroML database of cell and channel models","https://neuroml-db.org/"],["Other tools","","",""],["OMV","Python","Open Source Brain Model Validation framework","https://github.com/OpenSourceBrain/osb-model-validation"],["SciUnit","Python","Data driven unit testing framework","https://github.com/scidash/sciunit"],["BluePyOpt","Python","Blue Brain Python Optimization Library","https://bluepyopt.readthedocs.io/"],["NeuroTune","Python","Package for fitting/optimization of NeuroML models","https://github.com/NeuralEnsemble/neurotune"],["PyElectro","Python","Electrophysiology analysis package","https://github.com/NeuralEnsemble/pyelectro"]],"html":"<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Language/interface</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"4\"><strong>Simulation engines</strong></td>\n</tr>\n<tr>\n<td>NEURON</td>\n<td>Python/Hoc/CLI/GUI</td>\n<td>Empirically-based simulations of neurons and networks of neurons</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html</td>\n</tr>\n<tr>\n<td>NetPyNE</td>\n<td>Python/web</td>\n<td>Package to facilitate the development, parallel simulation, analysis, and optimization of biological neuronal networks using the NEURON simulator. Also has a graphical web interface, NetPyNE-UI</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html</td>\n</tr>\n<tr>\n<td>EDEN</td>\n<td>NeuroML</td>\n<td>NeuroML-based neural simulator</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html</td>\n</tr>\n<tr>\n<td>MOOSE</td>\n<td>Python</td>\n<td>The Multiscale Object-Oriented Simulation Environment is the base and numerical core for large, detailed multi-scale simulations that span computational neuroscience and systems biology. Based on a reimplementation of the GENESIS 2 core.</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html</td>\n</tr>\n<tr>\n<td>PyNN</td>\n<td>Python</td>\n<td>A simulator-independent language for building neuronal network models</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html</td>\n</tr>\n<tr>\n<td>NEST</td>\n<td>Python/SLI</td>\n<td>Simulator for spiking neural network models focusing on dynamics, size, and structure of neural systems</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html</td>\n</tr>\n<tr>\n<td>Brian2</td>\n<td>Python</td>\n<td>Easy to learn and use simulator for spiking neural networks</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html</td>\n</tr>\n<tr>\n<td>Arbor</td>\n<td>Python</td>\n<td>A multi-compartment neuron simulation library</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html</td>\n</tr>\n<tr>\n<td>N2A</td>\n<td>Java/GUI</td>\n<td>Language and IDE for writing and simulating models</td>\n<td>https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html</td>\n</tr>\n<tr>\n<td colspan=\"4\"><strong>Databases</strong></td>\n</tr>\n<tr>\n<td>OSB</td>\n<td>Web</td>\n<td>Resource for sharing and collaboratively developing computational models of neural systems</td>\n<td>https://www.opensourcebrain.org/</td>\n</tr>\n<tr>\n<td>NeuroML-DB</td>\n<td>Web</td>\n<td>NeuroML database of cell and channel models</td>\n<td>https://neuroml-db.org/</td>\n</tr>\n<tr>\n<td colspan=\"4\"><strong>Other tools</strong></td>\n</tr>\n<tr>\n<td>OMV</td>\n<td>Python</td>\n<td>Open Source Brain Model Validation framework</td>\n<td>https://github.com/OpenSourceBrain/osb-model-validation</td>\n</tr>\n<tr>\n<td>SciUnit</td>\n<td>Python</td>\n<td>Data driven unit testing framework</td>\n<td>https://github.com/scidash/sciunit</td>\n</tr>\n<tr>\n<td>BluePyOpt</td>\n<td>Python</td>\n<td>Blue Brain Python Optimization Library</td>\n<td>https://bluepyopt.readthedocs.io/</td>\n</tr>\n<tr>\n<td>NeuroTune</td>\n<td>Python</td>\n<td>Package for fitting/optimization of NeuroML models</td>\n<td>https://github.com/NeuralEnsemble/neurotune</td>\n</tr>\n<tr>\n<td>PyElectro</td>\n<td>Python</td>\n<td>Electrophysiology analysis package</td>\n<td>https://github.com/NeuralEnsemble/pyelectro</td>\n</tr>\n</tbody>\n</table>","md":"| Tool                   | Language/interface | Description                                                                                                                                                                                                                                   | URL                                                             |\n| ---------------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |\n| **Simulation engines** |                    |                                                                                                                                                                                                                                               |                                                                 |\n| NEURON                 | Python/Hoc/CLI/GUI | Empirically-based simulations of neurons and networks of neurons                                                                                                                                                                              | <https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html>  |\n| NetPyNE                | Python/web         | Package to facilitate the development, parallel simulation, analysis, and optimization of biological neuronal networks using the NEURON simulator. Also has a graphical web interface, NetPyNE-UI                                             | <https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html> |\n| EDEN                   | NeuroML            | NeuroML-based neural simulator                                                                                                                                                                                                                | <https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html>    |\n| MOOSE                  | Python             | The Multiscale Object-Oriented Simulation Environment is the base and numerical core for large, detailed multi-scale simulations that span computational neuroscience and systems biology. Based on a reimplementation of the GENESIS 2 core. | <https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html>   |\n| PyNN                   | Python             | A simulator-independent language for building neuronal network models                                                                                                                                                                         | <https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html>    |\n| NEST                   | Python/SLI         | Simulator for spiking neural network models focusing on dynamics, size, and structure of neural systems                                                                                                                                       | <https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html>    |\n| Brian2                 | Python             | Easy to learn and use simulator for spiking neural networks                                                                                                                                                                                   | <https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html>   |\n| Arbor                  | Python             | A multi-compartment neuron simulation library                                                                                                                                                                                                 | <https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html>   |\n| N2A                    | Java/GUI           | Language and IDE for writing and simulating models                                                                                                                                                                                            | <https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html>     |\n| **Databases**          |                    |                                                                                                                                                                                                                                               |                                                                 |\n| OSB                    | Web                | Resource for sharing and collaboratively developing computational models of neural systems                                                                                                                                                    | <https://www.opensourcebrain.org/>                              |\n| NeuroML-DB             | Web                | NeuroML database of cell and channel models                                                                                                                                                                                                   | <https://neuroml-db.org/>                                       |\n| **Other tools**        |                    |                                                                                                                                                                                                                                               |                                                                 |\n| OMV                    | Python             | Open Source Brain Model Validation framework                                                                                                                                                                                                  | <https://github.com/OpenSourceBrain/osb-model-validation>       |\n| SciUnit                | Python             | Data driven unit testing framework                                                                                                                                                                                                            | <https://github.com/scidash/sciunit>                            |\n| BluePyOpt              | Python             | Blue Brain Python Optimization Library                                                                                                                                                                                                        | <https://bluepyopt.readthedocs.io/>                             |\n| NeuroTune              | Python             | Package for fitting/optimization of NeuroML models                                                                                                                                                                                            | <https://github.com/NeuralEnsemble/neurotune>                   |\n| PyElectro              | Python             | Electrophysiology analysis package                                                                                                                                                                                                            | <https://github.com/NeuralEnsemble/pyelectro>                   |","isPerfectTable":false,"csv":"\"Tool\",\"Language/interface\",\"Description\",\"URL\"\n\"Simulation engines\",\"\",\"\",\"\"\n\"NEURON\",\"Python/Hoc/CLI/GUI\",\"Empirically-based simulations of neurons and networks of neurons\",\"https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html\"\n\"NetPyNE\",\"Python/web\",\"Package to facilitate the development, parallel simulation, analysis, and optimization of biological neuronal networks using the NEURON simulator. Also has a graphical web interface, NetPyNE-UI\",\"https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html\"\n\"EDEN\",\"NeuroML\",\"NeuroML-based neural simulator\",\"https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html\"\n\"MOOSE\",\"Python\",\"The Multiscale Object-Oriented Simulation Environment is the base and numerical core for large, detailed multi-scale simulations that span computational neuroscience and systems biology. Based on a reimplementation of the GENESIS 2 core.\",\"https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html\"\n\"PyNN\",\"Python\",\"A simulator-independent language for building neuronal network models\",\"https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html\"\n\"NEST\",\"Python/SLI\",\"Simulator for spiking neural network models focusing on dynamics, size, and structure of neural systems\",\"https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html\"\n\"Brian2\",\"Python\",\"Easy to learn and use simulator for spiking neural networks\",\"https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html\"\n\"Arbor\",\"Python\",\"A multi-compartment neuron simulation library\",\"https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html\"\n\"N2A\",\"Java/GUI\",\"Language and IDE for writing and simulating models\",\"https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html\"\n\"Databases\",\"\",\"\",\"\"\n\"OSB\",\"Web\",\"Resource for sharing and collaboratively developing computational models of neural systems\",\"https://www.opensourcebrain.org/\"\n\"NeuroML-DB\",\"Web\",\"NeuroML database of cell and channel models\",\"https://neuroml-db.org/\"\n\"Other tools\",\"\",\"\",\"\"\n\"OMV\",\"Python\",\"Open Source Brain Model Validation framework\",\"https://github.com/OpenSourceBrain/osb-model-validation\"\n\"SciUnit\",\"Python\",\"Data driven unit testing framework\",\"https://github.com/scidash/sciunit\"\n\"BluePyOpt\",\"Python\",\"Blue Brain Python Optimization Library\",\"https://bluepyopt.readthedocs.io/\"\n\"NeuroTune\",\"Python\",\"Package for fitting/optimization of NeuroML models\",\"https://github.com/NeuralEnsemble/neurotune\"\n\"PyElectro\",\"Python\",\"Electrophysiology analysis package\",\"https://github.com/NeuralEnsemble/pyelectro\"","bBox":{"x":36.5,"y":34.63,"w":538.49,"h":720.13},"layoutAwareBbox":[{"x":33,"y":76,"w":541,"h":590,"startIndex":2,"endIndex":6}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    12 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    12 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/NEURON.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NEURON.html","text":"Software/Tools/NEURON.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/NetPyNE.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NetPyNE.html","text":"Software/Tools/NetPyNE.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/EDEN.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/EDEN.html","text":"Software/Tools/EDEN.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/MOOSE.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/MOOSE.html","text":"Software/Tools/MOOSE.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/PyNN.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/PyNN.html","text":"Software/Tools/PyNN.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/NEST.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/NEST.html","text":"Software/Tools/NEST.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/Brian.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/Brian.html","text":"Software/Tools/Brian.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/Arbor.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/Arbor.html","text":"Software/Tools/Arbor.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html","text":"https://docs.neuroml.org/Userdocs/ Software/Tools/N2A.html"},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/N2A.html","text":"Software/Tools/N2A.html"},{"url":"https://www.opensourcebrain.org/","unsafeUrl":"https://www.opensourcebrain.org/","text":"https://www.opensourcebrain.org/"},{"url":"https://neuroml-db.org/","unsafeUrl":"https://neuroml-db.org/","text":"https://neuroml-db.org/"},{"url":"https://github.com/OpenSourceBrain/osb-model-validation","unsafeUrl":"https://github.com/OpenSourceBrain/osb-model-validation","text":"https://github.com/ OpenSourceBrain/osb-model-"},{"url":"https://github.com/OpenSourceBrain/osb-model-validation","unsafeUrl":"https://github.com/OpenSourceBrain/osb-model-validation","text":"OpenSourceBrain/osb-model- validation"},{"url":"https://github.com/OpenSourceBrain/osb-model-validation","unsafeUrl":"https://github.com/OpenSourceBrain/osb-model-validation","text":"validation"},{"url":"https://github.com/scidash/sciunit","unsafeUrl":"https://github.com/scidash/sciunit","text":"https://github.com/scidash/sciunit"},{"url":"https://bluepyopt.readthedocs.io/","unsafeUrl":"https://bluepyopt.readthedocs.io/","text":"https://bluepyopt.readthedocs.io/"},{"url":"https://github.com/NeuralEnsemble/neurotune","unsafeUrl":"https://github.com/NeuralEnsemble/neurotune","text":"https://github.com/NeuralEnsemble/ neurotune"},{"url":"https://github.com/NeuralEnsemble/neurotune","unsafeUrl":"https://github.com/NeuralEnsemble/neurotune","text":"neurotune"},{"url":"https://github.com/NeuralEnsemble/pyelectro","unsafeUrl":"https://github.com/NeuralEnsemble/pyelectro","text":"https://github.com/NeuralEnsemble/ pyelectro"},{"url":"https://github.com/NeuralEnsemble/pyelectro","unsafeUrl":"https://github.com/NeuralEnsemble/pyelectro","text":"pyelectro"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                          Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    12 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":1,"layout":[{"image":"page_12_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.055,"y":0.097,"w":0.886,"h":0.746},"isLikelyNoise":false},{"image":"page_12_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_12_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_12_number_1_v2.jpg","confidence":0.88,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.048,"h":0.01},"isLikelyNoise":false},{"image":"page_12_figure_title_1_v2.jpg","confidence":0.86,"label":"figure_title","bbox":{"x":0.055,"y":0.066,"w":0.855,"h":0.027},"isLikelyNoise":false},{"image":"page_12_header_2_v2.jpg","confidence":0.7,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_12_header_3_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":false}]},{"page":13,"text":"Tools  and  resources                                                                                                               Neuroscience\n                         Table 5. Step-by-step guides for using NeuroML illustrating the various stages of the model\n                         development life cycle.\n                         These include Introductory guides aimed at teaching the fundamental NeuroML concepts,\n                         Advanced guides illustrating speciﬁc modeling workﬂows, and Walkthrough guides discussing the\n                         steps required for converting models to NeuroML. An updated list is available at http://neuroml.org/\n                         gettingstarted.\n                         Link           Description                                                       Model life cycle stages\n                         Introductory guides\n                                        Create and simulate a simple regular spiking Izhikevich neuron in\n                         Guide 1        NeuroML                                                           Create, Validate, Simulate\n                                        Create a network of two synaptically connected populations of\n                         Guide 2        Izhikevich neurons                                                Create, Validate, Visualize, Simulate\n                         Guide 3        Build and simulate a single compartment Hodgkin-Huxley neuron     Create, Validate, Visualize, Simulate\n                         Guide 4        Create and simulate a multi compartment hippocampal OLM neuron Create, Validate, Visualize, Simulate\n                         Advanced guides\n                         Guide 5        Create novel NeuroML models from components on NeuroML-DB         Reuse, Create, Validate, Simulate\n                         Guide 6        Optimize/fit NeuroML models to experimental data                  Create, Validate, Simulate, Fit\n                         Guide 7        Extend NeuroML by creating a novel model type in LEMS             Create, Simulate\n                         Walkthroughs\n                                        Guide to converting cell models to NeuroML and sharing them on\n                         Guide 8        Open Source Brain                                                 Create, Validate, Simulate, Share\n                                                                                                          Create, Validate, Visualize, Simulate,\n                         Guide 9        Conversion of Ray et al., 2020                                    Share\n\n\n\nmulti-level testing in software development. Importantly, most of the validation tests in NeuroML are\nrun on the models’ NeuroML descriptions prior to simulation.\nA ﬁrst level of validation checks the structure of individual model elements against their formal\nspeciﬁcations contained in the NeuroML standard. The standard includes information on the param-\neters of each model element, restrictions on parameter values, their allowed units, their cardinality,\nand the location of the model element in the model hierarchy—i.e., parent/children relationships. A\nsecond level of validation includes a suite of semantic and logical checks. For example, at this level,\na model of a multi- compartmental cell can be checked to ensure that all segments referenced in\nsegment groups (e.g. the group of dendritic segments) have been deﬁned, and only deﬁned once\nwith unique identiﬁers. A list of validation tests currently included in the NeuroML core tools can be\nfound in Table 6. These can be run against NeuroML ﬁles at the command line or programmatically\nin Python (Figure 6).\nA key advantage of using the NeuroML2/LEMS framework is that dimensions and units are inbuilt\ninto LEMS descriptions. This enables automated conversions of units, unit checking, together with the\nvalidation of equations. Any expressions in models which are dimensionally inconsistent will be high-\nlighted at this stage. Note that LEMS handles unit conversions internally—modelers have ﬂexibility in\nhow they enter the units of parameter values (e.g. specifying conductance density in   2    2\n                                                            S/m                             or mS/cm ) in\nthe NeuroML ﬁles, with the underlying LEMS deﬁnitions ensuring that a consistent set of dimensions\nare used in model equations (Cannon et al., 2014). LEMS then takes care of mapping the entered\nunits to the target simulator’s preferred units. This makes model deﬁnition, inspection, use, extension,\nand translation easier and less error-prone.\nOnce the set of NeuroML ﬁles are validated, the model can be simulated, and checks can be made\nto test whether execution produces consistent results (e.g. ﬁring rate of neurons in a given popula-\ntion) across multiple simulators (or versions of the same simulator). For this, the OSB Model Validation\n(OMV) framework has been developed (Gleeson et  al., 2019b). This framework can automatically\ncheck that the output (e.g. spike times) of a NeuroML model running on a given simulator is within an\nallowed tolerance of the expected value. OMV has been applied to NeuroML models that have been\nshared on OSB, to test consistent behavior of models as the models themselves, and all supported\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    13 of 44","md":"\n\neLife Tools and resources                                                                                                               Neuroscience\n\n**Table 5.** Step-by-step guides for using NeuroML illustrating the various stages of the model development life cycle.\n\nThese include Introductory guides aimed at teaching the fundamental NeuroML concepts, Advanced guides illustrating specific modeling workflows, and Walkthrough guides discussing the steps required for converting models to NeuroML. An updated list is available at http://neuroml.org/gettingstarted.\n\n<table>\n<thead>\n<tr>\n<th>Link</th>\n<th>Description</th>\n<th>Model life cycle stages</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"3\"><strong>Introductory guides</strong></td>\n</tr>\n<tr>\n<td>Guide 1</td>\n<td>Create and simulate a simple regular spiking Izhikevich neuron in NeuroML</td>\n<td>Create, Validate, Simulate</td>\n</tr>\n<tr>\n<td>Guide 2</td>\n<td>Create a network of two synaptically connected populations of Izhikevich neurons</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td>Guide 3</td>\n<td>Build and simulate a single compartment Hodgkin-Huxley neuron</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td>Guide 4</td>\n<td>Create and simulate a multi compartment hippocampal OLM neuron</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Advanced guides</strong></td>\n</tr>\n<tr>\n<td>Guide 5</td>\n<td>Create novel NeuroML models from components on NeuroML-DB</td>\n<td>Reuse, Create, Validate, Simulate</td>\n</tr>\n<tr>\n<td>Guide 6</td>\n<td>Optimize/fit NeuroML models to experimental data</td>\n<td>Create, Validate, Simulate, Fit</td>\n</tr>\n<tr>\n<td>Guide 7</td>\n<td>Extend NeuroML by creating a novel model type in LEMS</td>\n<td>Create, Simulate</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Walkthroughs</strong></td>\n</tr>\n<tr>\n<td>Guide 8</td>\n<td>Guide to converting cell models to NeuroML and sharing them on Open Source Brain</td>\n<td>Create, Validate, Simulate, Share</td>\n</tr>\n<tr>\n<td>Guide 9</td>\n<td>Conversion of Ray et al., 2020</td>\n<td>Create, Validate, Visualize, Simulate, Share</td>\n</tr>\n</tbody>\n</table>\n\nmulti-level testing in software development. Importantly, most of the validation tests in NeuroML are run on the models' NeuroML descriptions *prior to simulation*.\n\nA first level of validation checks the structure of individual model elements against their formal specifications contained in the NeuroML standard. The standard includes information on the parameters of each model element, restrictions on parameter values, their allowed units, their cardinality, and the location of the model element in the model hierarchy—i.e., parent/children relationships. A second level of validation includes a suite of semantic and logical checks. For example, at this level, a model of a multi-compartmental cell can be checked to ensure that all segments referenced in segment groups (e.g. the group of dendritic segments) have been defined, and only defined once with unique identifiers. A list of validation tests currently included in the NeuroML core tools can be found in Table 6. These can be run against NeuroML files at the command line or programmatically in Python (Figure 6).\n\nA key advantage of using the NeuroML2/LEMS framework is that dimensions and units are inbuilt into LEMS descriptions. This enables automated conversions of units, unit checking, together with the validation of equations. Any expressions in models which are dimensionally inconsistent will be highlighted at this stage. Note that LEMS handles unit conversions internally—modelers have flexibility in how they enter the units of parameter values (e.g. specifying conductance density in S/m<sup>2</sup> or mS/cm<sup>2</sup>) in the NeuroML files, with the underlying LEMS definitions ensuring that a consistent set of *dimensions* are used in model equations (Cannon et al., 2014). LEMS then takes care of mapping the entered units to the target simulator's preferred units. This makes model definition, inspection, use, extension, and translation easier and less error-prone.\n\nOnce the set of NeuroML files are validated, the model can be simulated, and checks can be made to test whether execution produces consistent results (e.g. firing rate of neurons in a given population) across multiple simulators (or versions of the same simulator). For this, the OSB Model Validation (OMV) framework has been developed (Gleeson et al., 2019b). This framework can automatically check that the output (e.g. spike times) of a NeuroML model running on a given simulator is within an allowed tolerance of the expected value. OMV has been applied to NeuroML models that have been shared on OSB, to test consistent behavior of models as the models themselves, and all supported\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    13 of 44\n","images":[{"name":"page_13.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_13_text_1_v2.jpg","height":92965.013,"width":250559.667,"x":101025.073,"y":325642.635,"original_width":1655,"original_height":475,"rotation":0,"type":"layout_v2_text"},{"name":"page_13_text_2_v2.jpg","height":83424.014,"width":250481.447,"x":100916.444,"y":420635.201,"original_width":1654,"original_height":426,"rotation":0,"type":"layout_v2_text"},{"name":"page_13_text_3_v2.jpg","height":64868.898,"width":250505.825,"x":101015.713,"y":505969.372,"original_width":1655,"original_height":331,"rotation":0,"type":"layout_v2_text"},{"name":"page_13_table_1_v2.jpg","height":182328.506,"width":250770.964,"x":101460.739,"y":99291.937,"original_width":1656,"original_height":931,"rotation":0,"type":"layout_v2_table"},{"name":"page_13_text_4_v2.jpg","height":16912.507,"width":250290.459,"x":101119.898,"y":306523.961,"original_width":1653,"original_height":87,"rotation":0,"type":"layout_v2_text"},{"name":"page_13_footer_1_v2.jpg","height":6911.665,"width":191869.966,"x":21543.024,"y":591454.36,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_13_header_1_v2.jpg","height":5635.492,"width":30283.707,"x":320817.685,"y":27678.529,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_13_number_1_v2.jpg","height":5985.882,"width":17747.721,"x":333358.911,"y":591743.215,"original_width":118,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_13_header_2_v2.jpg","height":5722.17,"width":42816.043,"x":47755.95,"y":27856.153,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_13_text_5_v2.jpg","height":36062.54,"width":250099.915,"x":101229.171,"y":60395.977,"original_width":1652,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_13_header_3_v2.jpg","height":10734.019,"width":24406.365,"x":21820.894,"y":22383.809,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_13_text_6_v2.jpg","height":16843.394,"width":228294.821,"x":101181.584,"y":41425.692,"original_width":1508,"original_height":86,"rotation":0,"type":"layout_v2_text"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                                               Neuroscience","md":"eLife Tools and resources                                                                                                               Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":136,"endIndex":148}]},{"type":"text","value":"**Table 5.** Step-by-step guides for using NeuroML illustrating the various stages of the model development life cycle.","md":"**Table 5.** Step-by-step guides for using NeuroML illustrating the various stages of the model development life cycle.","bBox":{"x":168.52,"y":63.77,"w":93.54,"h":109.44},"layoutAwareBbox":[{"x":165,"y":52,"w":373,"h":21,"startIndex":13,"endIndex":17}]},{"type":"text","value":"These include Introductory guides aimed at teaching the fundamental NeuroML concepts, Advanced guides illustrating specific modeling workflows, and Walkthrough guides discussing the steps required for converting models to NeuroML. An updated list is available at http://neuroml.org/gettingstarted.","md":"These include Introductory guides aimed at teaching the fundamental NeuroML concepts, Advanced guides illustrating specific modeling workflows, and Walkthrough guides discussing the steps required for converting models to NeuroML. An updated list is available at http://neuroml.org/gettingstarted.","bBox":{"x":168.52,"y":75.76,"w":406.02,"h":167.03},"layoutAwareBbox":[{"x":165,"y":76,"w":408,"h":45,"startIndex":282,"endIndex":296}]},{"type":"table","rows":[["Link","Description","Model life cycle stages"],["Introductory guides","",""],["Guide 1","Create and simulate a simple regular spiking Izhikevich neuron in NeuroML","Create, Validate, Simulate"],["Guide 2","Create a network of two synaptically connected populations of Izhikevich neurons","Create, Validate, Visualize, Simulate"],["Guide 3","Build and simulate a single compartment Hodgkin-Huxley neuron","Create, Validate, Visualize, Simulate"],["Guide 4","Create and simulate a multi compartment hippocampal OLM neuron","Create, Validate, Visualize, Simulate"],["Advanced guides","",""],["Guide 5","Create novel NeuroML models from components on NeuroML-DB","Reuse, Create, Validate, Simulate"],["Guide 6","Optimize/fit NeuroML models to experimental data","Create, Validate, Simulate, Fit"],["Guide 7","Extend NeuroML by creating a novel model type in LEMS","Create, Simulate"],["Walkthroughs","",""],["Guide 8","Guide to converting cell models to NeuroML and sharing them on Open Source Brain","Create, Validate, Simulate, Share"],["Guide 9","Conversion of Ray et al., 2020","Create, Validate, Visualize, Simulate, Share"]],"html":"<table>\n<thead>\n<tr>\n<th>Link</th>\n<th>Description</th>\n<th>Model life cycle stages</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"3\"><strong>Introductory guides</strong></td>\n</tr>\n<tr>\n<td>Guide 1</td>\n<td>Create and simulate a simple regular spiking Izhikevich neuron in NeuroML</td>\n<td>Create, Validate, Simulate</td>\n</tr>\n<tr>\n<td>Guide 2</td>\n<td>Create a network of two synaptically connected populations of Izhikevich neurons</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td>Guide 3</td>\n<td>Build and simulate a single compartment Hodgkin-Huxley neuron</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td>Guide 4</td>\n<td>Create and simulate a multi compartment hippocampal OLM neuron</td>\n<td>Create, Validate, Visualize, Simulate</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Advanced guides</strong></td>\n</tr>\n<tr>\n<td>Guide 5</td>\n<td>Create novel NeuroML models from components on NeuroML-DB</td>\n<td>Reuse, Create, Validate, Simulate</td>\n</tr>\n<tr>\n<td>Guide 6</td>\n<td>Optimize/fit NeuroML models to experimental data</td>\n<td>Create, Validate, Simulate, Fit</td>\n</tr>\n<tr>\n<td>Guide 7</td>\n<td>Extend NeuroML by creating a novel model type in LEMS</td>\n<td>Create, Simulate</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Walkthroughs</strong></td>\n</tr>\n<tr>\n<td>Guide 8</td>\n<td>Guide to converting cell models to NeuroML and sharing them on Open Source Brain</td>\n<td>Create, Validate, Simulate, Share</td>\n</tr>\n<tr>\n<td>Guide 9</td>\n<td>Conversion of Ray et al., 2020</td>\n<td>Create, Validate, Visualize, Simulate, Share</td>\n</tr>\n</tbody>\n</table>","md":"| Link                    | Description                                                                      | Model life cycle stages                      |\n| ----------------------- | -------------------------------------------------------------------------------- | -------------------------------------------- |\n| **Introductory guides** |                                                                                  |                                              |\n| Guide 1                 | Create and simulate a simple regular spiking Izhikevich neuron in NeuroML        | Create, Validate, Simulate                   |\n| Guide 2                 | Create a network of two synaptically connected populations of Izhikevich neurons | Create, Validate, Visualize, Simulate        |\n| Guide 3                 | Build and simulate a single compartment Hodgkin-Huxley neuron                    | Create, Validate, Visualize, Simulate        |\n| Guide 4                 | Create and simulate a multi compartment hippocampal OLM neuron                   | Create, Validate, Visualize, Simulate        |\n| **Advanced guides**     |                                                                                  |                                              |\n| Guide 5                 | Create novel NeuroML models from components on NeuroML-DB                        | Reuse, Create, Validate, Simulate            |\n| Guide 6                 | Optimize/fit NeuroML models to experimental data                                 | Create, Validate, Simulate, Fit              |\n| Guide 7                 | Extend NeuroML by creating a novel model type in LEMS                            | Create, Simulate                             |\n| **Walkthroughs**        |                                                                                  |                                              |\n| Guide 8                 | Guide to converting cell models to NeuroML and sharing them on Open Source Brain | Create, Validate, Simulate, Share            |\n| Guide 9                 | Conversion of Ray et al., 2020                                                   | Create, Validate, Visualize, Simulate, Share |","isPerfectTable":true,"csv":"\"Link\",\"Description\",\"Model life cycle stages\"\n\"Introductory guides\",\"\",\"\"\n\"Guide 1\",\"Create and simulate a simple regular spiking Izhikevich neuron in NeuroML\",\"Create, Validate, Simulate\"\n\"Guide 2\",\"Create a network of two synaptically connected populations of Izhikevich neurons\",\"Create, Validate, Visualize, Simulate\"\n\"Guide 3\",\"Build and simulate a single compartment Hodgkin-Huxley neuron\",\"Create, Validate, Visualize, Simulate\"\n\"Guide 4\",\"Create and simulate a multi compartment hippocampal OLM neuron\",\"Create, Validate, Visualize, Simulate\"\n\"Advanced guides\",\"\",\"\"\n\"Guide 5\",\"Create novel NeuroML models from components on NeuroML-DB\",\"Reuse, Create, Validate, Simulate\"\n\"Guide 6\",\"Optimize/fit NeuroML models to experimental data\",\"Create, Validate, Simulate, Fit\"\n\"Guide 7\",\"Extend NeuroML by creating a novel model type in LEMS\",\"Create, Simulate\"\n\"Walkthroughs\",\"\",\"\"\n\"Guide 8\",\"Guide to converting cell models to NeuroML and sharing them on Open Source Brain\",\"Create, Validate, Simulate, Share\"\n\"Guide 9\",\"Conversion of Ray et al., 2020\",\"Create, Validate, Visualize, Simulate, Share\"","bBox":{"x":37.01,"y":34.63,"w":544.73,"h":720.13},"layoutAwareBbox":[{"x":165,"y":125,"w":409,"h":230,"startIndex":2,"endIndex":6}]},{"type":"text","value":"multi-level testing in software development. Importantly, most of the validation tests in NeuroML are run on the models' NeuroML descriptions *prior to simulation*.","md":"multi-level testing in software development. Importantly, most of the validation tests in NeuroML are run on the models' NeuroML descriptions *prior to simulation*.","bBox":{"x":168.53,"y":127.22,"w":408.37,"h":268.27},"layoutAwareBbox":[{"x":165,"y":387,"w":408,"h":21,"startIndex":0,"endIndex":5}]},{"type":"text","value":"A first level of validation checks the structure of individual model elements against their formal specifications contained in the NeuroML standard. The standard includes information on the parameters of each model element, restrictions on parameter values, their allowed units, their cardinality, and the location of the model element in the model hierarchy—i.e., parent/children relationships. A second level of validation includes a suite of semantic and logical checks. For example, at this level, a model of a multi-compartmental cell can be checked to ensure that all segments referenced in segment groups (e.g. the group of dendritic segments) have been defined, and only defined once with unique identifiers. A list of validation tests currently included in the NeuroML core tools can be found in Table 6. These can be run against NeuroML files at the command line or programmatically in Python (Figure 6).","md":"A first level of validation checks the structure of individual model elements against their formal specifications contained in the NeuroML standard. The standard includes information on the parameters of each model element, restrictions on parameter values, their allowed units, their cardinality, and the location of the model element in the model hierarchy—i.e., parent/children relationships. A second level of validation includes a suite of semantic and logical checks. For example, at this level, a model of a multi-compartmental cell can be checked to ensure that all segments referenced in segment groups (e.g. the group of dendritic segments) have been defined, and only defined once with unique identifiers. A list of validation tests currently included in the NeuroML core tools can be found in Table 6. These can be run against NeuroML files at the command line or programmatically in Python (Figure 6).","bBox":{"x":168.53,"y":166.21,"w":403.48,"h":313.26},"layoutAwareBbox":[{"x":165,"y":411,"w":409,"h":117,"startIndex":14,"endIndex":16}]},{"type":"text","value":"A key advantage of using the NeuroML2/LEMS framework is that dimensions and units are inbuilt into LEMS descriptions. This enables automated conversions of units, unit checking, together with the validation of equations. Any expressions in models which are dimensionally inconsistent will be highlighted at this stage. Note that LEMS handles unit conversions internally—modelers have flexibility in how they enter the units of parameter values (e.g. specifying conductance density in S/m<sup>2</sup> or mS/cm<sup>2</sup>) in the NeuroML files, with the underlying LEMS definitions ensuring that a consistent set of *dimensions* are used in model equations (Cannon et al., 2014). LEMS then takes care of mapping the entered units to the target simulator's preferred units. This makes model definition, inspection, use, extension, and translation easier and less error-prone.","md":"A key advantage of using the NeuroML2/LEMS framework is that dimensions and units are inbuilt into LEMS descriptions. This enables automated conversions of units, unit checking, together with the validation of equations. Any expressions in models which are dimensionally inconsistent will be highlighted at this stage. Note that LEMS handles unit conversions internally—modelers have flexibility in how they enter the units of parameter values (e.g. specifying conductance density in S/m<sup>2</sup> or mS/cm<sup>2</sup>) in the NeuroML files, with the underlying LEMS definitions ensuring that a consistent set of *dimensions* are used in model equations (Cannon et al., 2014). LEMS then takes care of mapping the entered units to the target simulator's preferred units. This makes model definition, inspection, use, extension, and translation easier and less error-prone.","bBox":{"x":168.52,"y":530.46,"w":413.22,"h":105.02},"layoutAwareBbox":[{"x":164,"y":531,"w":409,"h":105,"startIndex":16,"endIndex":18}]},{"type":"text","value":"Once the set of NeuroML files are validated, the model can be simulated, and checks can be made to test whether execution produces consistent results (e.g. firing rate of neurons in a given population) across multiple simulators (or versions of the same simulator). For this, the OSB Model Validation (OMV) framework has been developed (Gleeson et al., 2019b). This framework can automatically check that the output (e.g. spike times) of a NeuroML model running on a given simulator is within an allowed tolerance of the expected value. OMV has been applied to NeuroML models that have been shared on OSB, to test consistent behavior of models as the models themselves, and all supported","md":"Once the set of NeuroML files are validated, the model can be simulated, and checks can be made to test whether execution produces consistent results (e.g. firing rate of neurons in a given population) across multiple simulators (or versions of the same simulator). For this, the OSB Model Validation (OMV) framework has been developed (Gleeson et al., 2019b). This framework can automatically check that the output (e.g. spike times) of a NeuroML model running on a given simulator is within an allowed tolerance of the expected value. OMV has been applied to NeuroML models that have been shared on OSB, to test consistent behavior of models as the models themselves, and all supported","bBox":{"x":168.52,"y":166.21,"w":413.05,"h":553.25},"layoutAwareBbox":[{"x":165,"y":638,"w":409,"h":81,"startIndex":0,"endIndex":2}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    13 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    13 of 44","bBox":{"x":518.89,"y":576.17,"w":56.1,"h":178.59},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":28,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"http://neuroml.org/gettingstarted","unsafeUrl":"http://neuroml.org/gettingstarted","text":"steps required for converting models to NeuroML. An updated list is available at http://neuroml.org/"},{"url":"http://neuroml.org/gettingstarted","unsafeUrl":"http://neuroml.org/gettingstarted","text":"gettingstarted."},{"url":"https://docs.neuroml.org/Userdocs/NML2_examples/SingleNeuron.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/NML2_examples/SingleNeuron.html","text":"Guide 1"},{"url":"https://docs.neuroml.org/Userdocs/IzhikevichNetworkExample.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/IzhikevichNetworkExample.html","text":"Guide 2"},{"url":"https://docs.neuroml.org/Userdocs/SingleCompartmentHHExample.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/SingleCompartmentHHExample.html","text":"Guide 3"},{"url":"https://docs.neuroml.org/Userdocs/MultiCompartmentOLMexample.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/MultiCompartmentOLMexample.html","text":"Guide 4"},{"url":"https://docs.neuroml.org/Userdocs/NML2_examples/NeuroML-DB.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/NML2_examples/NeuroML-DB.html","text":"Guide 5"},{"url":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","text":"Guide 6"},{"url":"https://docs.neuroml.org/Userdocs/ExtendingNeuroMLv2.html#example-lorenz-model-for-cellular-convection","unsafeUrl":"https://docs.neuroml.org/Userdocs/ExtendingNeuroMLv2.html#example-lorenz-model-for-cellular-convection","text":"Guide 7"},{"url":"https://docs.neuroml.org/Userdocs/CreatingNeuroMLModels.html#converting-cell-models-to-neuroml-and-sharing-them-on-open-source-brain","unsafeUrl":"https://docs.neuroml.org/Userdocs/CreatingNeuroMLModels.html#converting-cell-models-to-neuroml-and-sharing-them-on-open-source-brain","text":"Guide 8"},{"url":"https://docs.neuroml.org/Userdocs/Walkthroughs/RayEtAl2020/RayEtAl2020.html#userdocs-walkthroughs-rayetal2020","unsafeUrl":"https://docs.neuroml.org/Userdocs/Walkthroughs/RayEtAl2020/RayEtAl2020.html#userdocs-walkthroughs-rayetal2020","text":"Guide 9"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                                               Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    13 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.968,"layout":[{"image":"page_13_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.519,"w":0.669,"h":0.148},"isLikelyNoise":false},{"image":"page_13_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.269,"y":0.671,"w":0.669,"h":0.133},"isLikelyNoise":false},{"image":"page_13_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.807,"w":0.669,"h":0.103},"isLikelyNoise":false},{"image":"page_13_table_1_v2.jpg","confidence":0.98,"label":"table","bbox":{"x":0.271,"y":0.158,"w":0.67,"h":0.291},"isLikelyNoise":false},{"image":"page_13_text_4_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.489,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_13_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_13_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_13_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.047,"h":0.01},"isLikelyNoise":false},{"image":"page_13_header_2_v2.jpg","confidence":0.72,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_13_text_5_v2.jpg","confidence":0.62,"label":"text","bbox":{"x":0.27,"y":0.096,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_13_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true},{"image":"page_13_text_6_v2.jpg","confidence":0.52,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.61,"h":0.027},"isLikelyNoise":true}]},{"page":14,"text":"    Tools  and  resources    Neuroscience\n\n\n    5) Other standardized formats\n\n\nNeuroML core software             PyNN  SONATA  SBML\n        tools\n    pyNeuroML    Simulator specific    4) Generated simulator scripts\n                    export modules\n                                  NEURON        Brian2\n Build NeuroML    Expanded LEMS\ncore Components    description    3) Simulators import NeuroML\n\n\nReuse existing    Generate helper    NetPyNE  MOOSE\n  Components    scripts\n\n\n   User defined    Execute in native    2) Native NeuroML simulators\nComponents in LEMS    simulators        EDEN\n\n\n\n    NeuroML/LEMS serialization (XML)    1) NeuroML reference simulators\n\n                                        jNeuroML  PyLEMS\n\n\n    Figure 5. Workflow showing how to create and simulate NeuroML models using Python. The Python API can be\n    used to create models which may include elements built from scratch from the NeuroML standard, re-use elements\n    from previously created models, or create new components based on novel model definitions expressed in LEMS\n    (red). The generated model elements are saved in the default XML-based serialization (blue). The NeuroML core\n    tools and libraries (orange) include modules to import model descriptions expressed in the XML serialization,\n    and support multiple options for how simulators can execute these models (green). These include: (1) execution\n    of the NeuroML models by reference simulators; (2) execution by other independently developed simulators that\n    natively support NeuroML, such as EDEN; (3) generation of Python ‘import scripts’ which allow NeuroML models\n    to be imported (and converted to internal formats) by simulators which support this; (4) fully expanding the LEMS\n    description of the models, which can be mapped to generated simulator specific scripts for target simulators; (5)\n    mapping to other standardized formats in neuroscience and systems biology.\n\n\n    simulators, are updated. This has proven to be a valuable process for ensuring uniform usage and\n    interpretation of NeuroML across the ecosystem of supporting tools.\n    A ﬁnal level of validation concerns checking whether the model elements have emergent features\n    that are in line with experimentally observed behavior of the biological equivalents. NeuronUnit\n    (Gerkin et al., 2019), a SciUnit (Omar et al., 2014) package for data-\n                                                              driven unit testing and validation\n    of neuronal and ion channel models, is also fully NeuroML compliant, and also supports automated\n    validation of NeuroML models shared on NeuroML-DB and OSB.\n\n    Visualizing/analyzing NeuroML models\n    Multiple visualization, inspection, and analysis tools are available in the NeuroML software ecosystem.\n    Since NeuroML models have a ﬁxed, well-\n    deﬁned structure, NeuroML libraries can extract all informa-\n    tion from their descriptions. This information can be used by modelers and their programs/tools to run\n    automated programmatic analyses on models.\n    pyNeuroML includes a range of ready-\n    made inspection utilities for users (Figure 6) that can be used\n    via Python scripts, interactive Jupyter Notebooks, and command line tools. Examining the structure of\n    cell and network models with 2D and 3D views is important for manual validation and to compare them\n    to their biological counterparts. Graphical views of cell model morphology and the 3-  dimensional\n    network layout (Figure 8), population and connectivity matrices/graphs at different levels (Figure 9),\n    and model summaries can all be generated (Figure 10). In addition to these inspection functions, a\n\n\n    Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    14 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n<table>\n<thead>\n<tr>\n<th colspan=\"3\">NeuroML Workflow</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"4\" style=\"background-color: #ffb3b3;\">\n<strong>python pyNeuroML</strong><br><br>\nBuild NeuroML core Components<br><br>\nReuse existing Components<br><br>\nUser defined Components in LEMS\n</td>\n<td style=\"background-color: #ffcc99;\">\nNeuroML core software tools<br><br>\nSimulator specific export modules<br><br>\nExpanded LEMS description<br><br>\nGenerate helper scripts<br><br>\nExecute in native simulators\n</td>\n<td style=\"background-color: #ccffcc;\">\n5) Other standardized formats<br>\nPyNN | SONATA | SBML<br><br>\n4) Generated simulator scripts<br>\nNEURON | Brian2<br><br>\n3) Simulators import NeuroML<br>\nNetPyNE | MOOSE<br><br>\n2) Native NeuroML simulators<br>\nEDEN\n</td>\n</tr>\n<tr>\n<td colspan=\"2\" style=\"background-color: #b3d9ff; text-align: center;\">\nNeuroML/LEMS serialization (XML)\n</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"background-color: #ccffcc;\">\n1) NeuroML reference simulators<br>\njNeuroML | PyLEMS\n</td>\n</tr>\n</tbody>\n</table>\n\n**Figure 5.** Workflow showing how to create and simulate NeuroML models using Python. The Python API can be used to create models which may include elements built from scratch from the NeuroML standard, re-use elements from previously created models, or create new components based on novel model definitions expressed in LEMS (red). The generated model elements are saved in the default XML-based serialization (blue). The NeuroML core tools and libraries (orange) include modules to import model descriptions expressed in the XML serialization, and support multiple options for how simulators can execute these models (green). These include: (1) execution of the NeuroML models by reference simulators; (2) execution by other independently developed simulators that natively support NeuroML, such as EDEN; (3) generation of Python 'import scripts' which allow NeuroML models to be imported (and converted to internal formats) by simulators which support this; (4) fully expanding the LEMS description of the models, which can be mapped to generated simulator specific scripts for target simulators; (5) mapping to other standardized formats in neuroscience and systems biology.\n\nsimulators, are updated. This has proven to be a valuable process for ensuring uniform usage and interpretation of NeuroML across the ecosystem of supporting tools.\n\nA final level of validation concerns checking whether the model elements have emergent features that are in line with experimentally observed behavior of the biological equivalents. NeuronUnit (**Gerkin et al., 2019**), a SciUnit (**Omar et al., 2014**) package for data-driven unit testing and validation of neuronal and ion channel models, is also fully NeuroML compliant, and also supports automated validation of NeuroML models shared on NeuroML-DB and OSB.\n\n## Visualizing/analyzing NeuroML models\n\nMultiple visualization, inspection, and analysis tools are available in the NeuroML software ecosystem. Since NeuroML models have a fixed, well-defined structure, NeuroML libraries can extract all information from their descriptions. This information can be used by modelers and their programs/tools to run automated programmatic analyses on models.\n\npyNeuroML includes a range of ready-made inspection utilities for users (**Figure 6**) that can be used via Python scripts, interactive Jupyter Notebooks, and command line tools. Examining the structure of cell and network models with 2D and 3D views is important for manual validation and to compare them to their biological counterparts. Graphical views of cell model morphology and the 3-dimensional network layout (**Figure 8**), population and connectivity matrices/graphs at different levels (**Figure 9**), and model summaries can all be generated (**Figure 10**). In addition to these inspection functions, a\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    14 of 44\n","images":[{"name":"page_14.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_14_image_1_v2.jpg","height":231926.165,"width":247966.514,"x":102859.702,"y":42796.805,"original_width":1638,"original_height":1184,"rotation":0,"type":"layout_v2_image"},{"name":"page_14_text_1_v2.jpg","height":55091.224,"width":250347.007,"x":101254.847,"y":516191.423,"original_width":1653,"original_height":282,"rotation":0,"type":"layout_v2_text"},{"name":"page_14_text_2_v2.jpg","height":45335.995,"width":250402.292,"x":101175.678,"y":410637.436,"original_width":1654,"original_height":232,"rotation":0,"type":"layout_v2_text"},{"name":"page_14_text_3_v2.jpg","height":35956.027,"width":250300.712,"x":101075.401,"y":478293.249,"original_width":1653,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_14_figure_title_1_v2.jpg","height":94469.643,"width":249953.377,"x":101225.211,"y":280803.844,"original_width":1651,"original_height":482,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_14_text_4_v2.jpg","height":17089.16,"width":250401.162,"x":101145.639,"y":391692.593,"original_width":1654,"original_height":88,"rotation":0,"type":"layout_v2_text"},{"name":"page_14_paragraph_title_1_v2.jpg","height":9535.255,"width":136324.156,"x":101322.709,"y":466091.141,"original_width":901,"original_height":49,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_14_footer_1_v2.jpg","height":6988.622,"width":191874.276,"x":21531.126,"y":591439.62,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_14_header_1_v2.jpg","height":5714.065,"width":30395.919,"x":320919.628,"y":27686.38,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_14_number_1_v2.jpg","height":5992.154,"width":17765.108,"x":333377.585,"y":591792.377,"original_width":118,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_14_header_2_v2.jpg","height":5712.499,"width":42875.784,"x":47791.42,"y":27883.464,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_14_header_3_v2.jpg","height":10771.237,"width":24468.661,"x":21783.93,"y":22369.485,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"table","rows":[["NeuroML Workflow","NeuroML Workflow","NeuroML Workflow"],["python pyNeuroML<br/><br/>Build NeuroML core Components<br/><br/>Reuse existing Components<br/><br/>User defined Components in LEMS","NeuroML core software tools<br/><br/>Simulator specific export modules<br/><br/>Expanded LEMS description<br/><br/>Generate helper scripts<br/><br/>Execute in native simulators","5) Other standardized formats<br/>PyNN | SONATA | SBML<br/><br/>4) Generated simulator scripts<br/>NEURON | Brian2<br/><br/>3) Simulators import NeuroML<br/>NetPyNE | MOOSE<br/><br/>2) Native NeuroML simulators<br/>EDEN"],["","NeuroML/LEMS serialization (XML)",""],["","","1) NeuroML reference simulators<br/>jNeuroML | PyLEMS"]],"html":"<table>\n<thead>\n<tr>\n<th colspan=\"3\">NeuroML Workflow</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"4\" style=\"background-color: #ffb3b3;\">\n<strong>python pyNeuroML</strong><br /><br />\nBuild NeuroML core Components<br /><br />\nReuse existing Components<br /><br />\nUser defined Components in LEMS\n</td>\n<td style=\"background-color: #ffcc99;\">\nNeuroML core software tools<br /><br />\nSimulator specific export modules<br /><br />\nExpanded LEMS description<br /><br />\nGenerate helper scripts<br /><br />\nExecute in native simulators\n</td>\n<td style=\"background-color: #ccffcc;\">\n5) Other standardized formats<br />\nPyNN | SONATA | SBML<br /><br />\n4) Generated simulator scripts<br />\nNEURON | Brian2<br /><br />\n3) Simulators import NeuroML<br />\nNetPyNE | MOOSE<br /><br />\n2) Native NeuroML simulators<br />\nEDEN\n</td>\n</tr>\n<tr>\n<td colspan=\"2\" style=\"background-color: #b3d9ff; text-align: center;\">\nNeuroML/LEMS serialization (XML)\n</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"background-color: #ccffcc;\">\n1) NeuroML reference simulators<br />\njNeuroML | PyLEMS\n</td>\n</tr>\n</tbody>\n</table>","md":"| NeuroML Workflow                                                                                                                        | NeuroML Workflow                                                                                                                                                                 | NeuroML Workflow                                                                                                                                                                                                                |\n| --------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **python pyNeuroML**<br/><br/>Build NeuroML core Components<br/><br/>Reuse existing Components<br/><br/>User defined Components in LEMS | NeuroML core software tools<br/><br/>Simulator specific export modules<br/><br/>Expanded LEMS description<br/><br/>Generate helper scripts<br/><br/>Execute in native simulators | 5) Other standardized formats<br/>PyNN \\| SONATA \\| SBML<br/><br/>4) Generated simulator scripts<br/>NEURON \\| Brian2<br/><br/>3) Simulators import NeuroML<br/>NetPyNE \\| MOOSE<br/><br/>2) Native NeuroML simulators<br/>EDEN |\n|                                                                                                                                         | NeuroML/LEMS serialization (XML)                                                                                                                                                 |                                                                                                                                                                                                                                 |\n|                                                                                                                                         |                                                                                                                                                                                  | 1) NeuroML reference simulators<br/>jNeuroML \\| PyLEMS                                                                                                                                                                          |","isPerfectTable":false,"csv":"\"NeuroML Workflow\",\"NeuroML Workflow\",\"NeuroML Workflow\"\n\"python pyNeuroML<br/><br/>Build NeuroML core Components<br/><br/>Reuse existing Components<br/><br/>User defined Components in LEMS\",\"NeuroML core software tools<br/><br/>Simulator specific export modules<br/><br/>Expanded LEMS description<br/><br/>Generate helper scripts<br/><br/>Execute in native simulators\",\"5) Other standardized formats<br/>PyNN | SONATA | SBML<br/><br/>4) Generated simulator scripts<br/>NEURON | Brian2<br/><br/>3) Simulators import NeuroML<br/>NetPyNE | MOOSE<br/><br/>2) Native NeuroML simulators<br/>EDEN\"\n\"\",\"NeuroML/LEMS serialization (XML)\",\"\"\n\"\",\"\",\"1) NeuroML reference simulators<br/>jNeuroML | PyLEMS\"","bBox":{"x":37.01,"y":34.63,"w":550.9,"h":720.13},"layoutAwareBbox":[{"x":37.01,"y":34.63,"w":550.9,"h":720.13,"startIndex":0,"endIndex":2723}]},{"type":"text","value":"**Figure 5.** Workflow showing how to create and simulate NeuroML models using Python. The Python API can be used to create models which may include elements built from scratch from the NeuroML standard, re-use elements from previously created models, or create new components based on novel model definitions expressed in LEMS (red). The generated model elements are saved in the default XML-based serialization (blue). The NeuroML core tools and libraries (orange) include modules to import model descriptions expressed in the XML serialization, and support multiple options for how simulators can execute these models (green). These include: (1) execution of the NeuroML models by reference simulators; (2) execution by other independently developed simulators that natively support NeuroML, such as EDEN; (3) generation of Python 'import scripts' which allow NeuroML models to be imported (and converted to internal formats) by simulators which support this; (4) fully expanding the LEMS description of the models, which can be mapped to generated simulator specific scripts for target simulators; (5) mapping to other standardized formats in neuroscience and systems biology.","md":"**Figure 5.** Workflow showing how to create and simulate NeuroML models using Python. The Python API can be used to create models which may include elements built from scratch from the NeuroML standard, re-use elements from previously created models, or create new components based on novel model definitions expressed in LEMS (red). The generated model elements are saved in the default XML-based serialization (blue). The NeuroML core tools and libraries (orange) include modules to import model descriptions expressed in the XML serialization, and support multiple options for how simulators can execute these models (green). These include: (1) execution of the NeuroML models by reference simulators; (2) execution by other independently developed simulators that natively support NeuroML, such as EDEN; (3) generation of Python 'import scripts' which allow NeuroML models to be imported (and converted to internal formats) by simulators which support this; (4) fully expanding the LEMS description of the models, which can be mapped to generated simulator specific scripts for target simulators; (5) mapping to other standardized formats in neuroscience and systems biology.","bBox":{"x":168.53,"y":213.29,"w":408.35,"h":258.96},"layoutAwareBbox":[{"x":165,"y":354,"w":408,"h":119,"startIndex":0,"endIndex":1179}]},{"type":"text","value":"simulators, are updated. This has proven to be a valuable process for ensuring uniform usage and interpretation of NeuroML across the ecosystem of supporting tools.","md":"simulators, are updated. This has proven to be a valuable process for ensuring uniform usage and interpretation of NeuroML across the ecosystem of supporting tools.","bBox":{"x":168.53,"y":494.05,"w":395.39,"h":21},"layoutAwareBbox":[{"x":165,"y":494,"w":409,"h":21,"startIndex":0,"endIndex":10}]},{"type":"text","value":"A final level of validation concerns checking whether the model elements have emergent features that are in line with experimentally observed behavior of the biological equivalents. NeuronUnit (**Gerkin et al., 2019**), a SciUnit (**Omar et al., 2014**) package for data-driven unit testing and validation of neuronal and ion channel models, is also fully NeuroML compliant, and also supports automated validation of NeuroML models shared on NeuroML-DB and OSB.","md":"A final level of validation concerns checking whether the model elements have emergent features that are in line with experimentally observed behavior of the biological equivalents. NeuronUnit (**Gerkin et al., 2019**), a SciUnit (**Omar et al., 2014**) package for data-driven unit testing and validation of neuronal and ion channel models, is also fully NeuroML compliant, and also supports automated validation of NeuroML models shared on NeuroML-DB and OSB.","bBox":{"x":168.53,"y":530.05,"w":410.58,"h":44.99},"layoutAwareBbox":[{"x":165,"y":518,"w":409,"h":57,"startIndex":254,"endIndex":261}]},{"type":"heading","lvl":2,"value":"Visualizing/analyzing NeuroML models","md":"## Visualizing/analyzing NeuroML models","bBox":{"x":168.53,"y":587.05,"w":219.71,"h":12},"layoutAwareBbox":[{"x":165,"y":588,"w":222,"h":12,"startIndex":0,"endIndex":38}]},{"type":"text","value":"Multiple visualization, inspection, and analysis tools are available in the NeuroML software ecosystem. Since NeuroML models have a fixed, well-defined structure, NeuroML libraries can extract all information from their descriptions. This information can be used by modelers and their programs/tools to run automated programmatic analyses on models.","md":"Multiple visualization, inspection, and analysis tools are available in the NeuroML software ecosystem. Since NeuroML models have a fixed, well-defined structure, NeuroML libraries can extract all information from their descriptions. This information can be used by modelers and their programs/tools to run automated programmatic analyses on models.","bBox":{"x":168.53,"y":603.05,"w":415.9,"h":44.99},"layoutAwareBbox":[{"x":165,"y":603,"w":408,"h":45,"startIndex":0,"endIndex":348}]},{"type":"text","value":"pyNeuroML includes a range of ready-made inspection utilities for users (**Figure 6**) that can be used via Python scripts, interactive Jupyter Notebooks, and command line tools. Examining the structure of cell and network models with 2D and 3D views is important for manual validation and to compare them to their biological counterparts. Graphical views of cell model morphology and the 3-dimensional network layout (**Figure 8**), population and connectivity matrices/graphs at different levels (**Figure 9**), and model summaries can all be generated (**Figure 10**). In addition to these inspection functions, a","md":"pyNeuroML includes a range of ready-made inspection utilities for users (**Figure 6**) that can be used via Python scripts, interactive Jupyter Notebooks, and command line tools. Examining the structure of cell and network models with 2D and 3D views is important for manual validation and to compare them to their biological counterparts. Graphical views of cell model morphology and the 3-dimensional network layout (**Figure 8**), population and connectivity matrices/graphs at different levels (**Figure 9**), and model summaries can all be generated (**Figure 10**). In addition to these inspection functions, a","bBox":{"x":168.53,"y":651.04,"w":419.38,"h":44.99},"layoutAwareBbox":[{"x":165,"y":651,"w":409,"h":69,"startIndex":391,"endIndex":402}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    14 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    14 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    14 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.994,"layout":[{"image":"page_14_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.068,"w":0.662,"h":0.37},"isLikelyNoise":false},{"image":"page_14_text_1_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.823,"w":0.668,"h":0.088},"isLikelyNoise":false},{"image":"page_14_text_2_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.655,"w":0.669,"h":0.072},"isLikelyNoise":false},{"image":"page_14_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.763,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_14_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.27,"y":0.448,"w":0.667,"h":0.151},"isLikelyNoise":false},{"image":"page_14_text_4_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.27,"y":0.624,"w":0.669,"h":0.027},"isLikelyNoise":false},{"image":"page_14_paragraph_title_1_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.743,"w":0.364,"h":0.015},"isLikelyNoise":false},{"image":"page_14_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_14_header_1_v2.jpg","confidence":0.85,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_14_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.047,"h":0.01},"isLikelyNoise":false},{"image":"page_14_header_2_v2.jpg","confidence":0.73,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_14_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":15,"text":"Tools  and  resources                                                                                          Neuroscience\n\n                         Create (using Python API)\n\n                         ƒrom neuroml import *\n\n                         # Create a container document\n                         doc = NeuroMLDocument(id=\"network0\")\n\n                         # Add single exponential synapse model\n                         syn0 = doc.add(\"ΕxpOneSynapse\", id=\"syn0\", gbase=\"65nS\", erev=\"0mV\", tau_decay=\"3ms\")\n\n                         # Reuse existing ion channel model\n                         doc.add(\"ΙncludeType\", hreƒ=\"Na_chan.channel.nml\")\n\n                         # Create a cell with 3D morphology using the Cell ComponentType\n                         cell = doc.add(\"Cell\", id=\"olm\", neuro_lex_id=\"NLΧCΕLL:091206\") # Hippocampal CA1 OLM cell\n                         cell.set_init_memb_potential(\"–67mV\")\n                         cell.set_resistivity(\"0.15 kohm_cm\")\n                         cell.add_channel_density(doc, cd_id=\"na_all\", cond_density=\"10 mS_per_cm2\",\n                                              ion_channel=\"Na_chan\", ion_chan_deƒ_ƒile=\"Na.channel.nml\",\n                                              erev=\"50mV\", ion=\"na\")\n                         cell.add_unbranched_segment_group(\"soma_group\")\n                         soma_0 = cell.add_segment(prox=[0, 0, 0, 10], dist=[0, 10, 0, 10], name=\"Seg0_soma_0\",\n                                              group_id=\"soma_group\", seg_type=\"soma\")\n\n\n API examples                                  Command line usage examples\n\n Validate\n validate_neuroml2(\"ƒile.nml\")                 > pynml \"ƒile.nml\" –validate\n doc.validate(recursive=True)\n\n Inspect and visualize\n element.inƒo()\n summary(doc)                                  >  pynml–summary \"ƒile.nml\"\n nml2_to_png(doc)                              >  pynml –png \"ƒile.nml\"\n nml2_to_svg(doc)                              >  pynml –svg \"ƒile.nml\"\n generate_nmlgraph(doc)                        >  pynml \"ƒile.nml\" –graph\n                                               > pynml \"ƒile.nml\" –matrix 1\n plot_2D(cell)                                 >  pynml–plotmorph \"cell.nml\"\n plot_interactive_3d(cell)                     > pynml–plotmorph –interactive3d \"cell.nml\"\n plot_interactive_3d(network)                  > pynml–plotmorph –interactive3d \"net.nml\"\n                                               > pynml–channelanalysis \"channel.nml\"\n plot_channel_densities(cell)                  > pynml–plotchan \"cell.nml\"\n\n Simulate\n run_lems_with_jneuroml(\"sim.xml\")             > pynml \"sim.xml\"\n run_lems_with_jneuroml_neuron(\"sim.xml\")      > pynml \"sim.xml\" –neuron –run\n run_lems_with_jneuroml_netpyne(\"sim.xml\")     > pynml \"sim.xml\" –netpyne –run\n run_on_nsg(\"jneuroml_neuron\", \"sim.xml\")\n . . .\n\n Share and archive\n create_combine_archive(\"sim.xml\")             > pynml–archive \"neuron.cell.nml\"\n\nFigure 6. PyNeuroML provides Python functions and command line utilities supporting all stages of the model life\ncycle.\n\n\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    15 of 44","md":"\n\neLife Tools and resources                                                                                          Neuroscience\n\n## Create (using Python API)\n\n```python\nfrom neuroml import *\n\n# Create a container document\ndoc = NeuroMLDocument(id=\"network0\")\n\n# Add single exponential synapse model\nsyn0 = doc.add(\"ExpOneSynapse\", id=\"syn0\", gbase=\"65nS\", erev=\"0mV\", tau_decay=\"3ms\")\n\n# Reuse existing ion channel model\ndoc.add(\"IncludeType\", href=\"Na_chan.channel.nml\")\n\n# Create a cell with 3D morphology using the Cell ComponentType\ncell = doc.add(\"Cell\", id=\"olm\", neuro_lex_id=\"NLXCELL:091206\") # Hippocampal CA1 OLM cell\ncell.set_init_memb_potential(\"-67mV\")\ncell.set_resistivity(\"0.15 kohm_cm\")\ncell.add_channel_density(doc, cd_id=\"na_all\", cond_density=\"10 mS_per_cm2\",\n                     ion_channel=\"Na_chan\", ion_chan_def_file=\"Na.channel.nml\",\n                     erev=\"50mV\", ion=\"na\")\ncell.add_unbranched_segment_group(\"soma_group\")\nsoma_0 = cell.add_segment(prox=[0, 0, 0, 10], dist=[0, 10, 0, 10], name=\"Seg0_soma_0\",\n                     group_id=\"soma_group\", seg_type=\"soma\")\n```\n\n## API examples\n\n### Validate\n```python\nvalidate_neuroml2(\"file.nml\")\ndoc.validate(recursive=True)\n```\n\n### Inspect and visualize\n```python\nelement.info()\nsummary(doc)\nnml2_to_png(doc)\nnml2_to_svg(doc)\ngenerate_nmlgraph(doc)\n\nplot_2D(cell)\nplot_interactive_3d(cell)\nplot_interactive_3d(network)\n\nplot_channel_densities(cell)\n```\n\n### Simulate\n```python\nrun_lems_with_jneuroml(\"sim.xml\")\nrun_lems_with_jneuroml_neuron(\"sim.xml\")\nrun_lems_with_jneuroml_netpyne(\"sim.xml\")\nrun_on_nsg(\"jneuroml_neuron\", \"sim.xml\")\n...\n```\n\n### Share and archive\n```python\ncreate_combine_archive(\"sim.xml\")\n```\n\n## Command line usage examples\n\n### Validate\n```bash\n> pynml \"file.nml\" --validate\n```\n\n### Inspect and visualize\n```bash\n> pynml-summary \"file.nml\"\n> pynml -png \"file.nml\"\n> pynml -svg \"file.nml\"\n> pynml \"file.nml\" -graph\n> pynml \"file.nml\" -matrix 1\n> pynml-plotmorph \"cell.nml\"\n> pynml-plotmorph -interactive3d \"cell.nml\"\n> pynml-plotmorph -interactive3d \"net.nml\"\n> pynml-channelanalysis \"channel.nml\"\n> pynml-plotchan \"cell.nml\"\n```\n\n### Simulate\n```bash\n> pynml \"sim.xml\"\n> pynml \"sim.xml\" -neuron -run\n> pynml \"sim.xml\" -netpyne -run\n```\n\n### Share and archive\n```bash\n> pynml-archive \"neuron.cell.nml\"\n```\n\n**Figure 6.** PyNeuroML provides Python functions and command line utilities supporting all stages of the model life cycle.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    15 of 44\n","images":[{"name":"page_15.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_15_footer_1_v2.jpg","height":6741.539,"width":191882.886,"x":21633.516,"y":591575.618,"original_width":1267,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_15_number_1_v2.jpg","height":5771.495,"width":17794.883,"x":333405.422,"y":591877.94,"original_width":118,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_15_header_1_v2.jpg","height":5649.429,"width":30411.17,"x":320787.803,"y":27740.601,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_15_text_1_v2.jpg","height":16246.216,"width":248124.964,"x":101701.206,"y":526963.114,"original_width":1639,"original_height":83,"rotation":0,"type":"layout_v2_text"},{"name":"page_15_header_2_v2.jpg","height":5774.919,"width":43112.258,"x":47664.863,"y":27925.477,"original_width":285,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_15_paragraph_title_1_v2.jpg","height":9317.673,"width":48471.733,"x":106521.51,"y":498348.251,"original_width":321,"original_height":48,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_15_header_3_v2.jpg","height":10934.867,"width":24556.579,"x":21784.528,"y":22423.515,"original_width":163,"original_height":56,"rotation":0,"type":"layout_v2_header"},{"name":"page_15_paragraph_title_2_v2.jpg","height":9738.573,"width":67475.139,"x":105811.951,"y":46248.07,"original_width":446,"original_height":50,"rotation":0,"type":"layout_v2_paragraph_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                          Neuroscience","md":"eLife Tools and resources                                                                                          Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":115,"endIndex":127}]},{"type":"heading","lvl":2,"value":"Create (using Python API)","md":"## Create (using Python API)","bBox":{"x":175.05,"y":58.91,"w":107.28,"h":8.47},"layoutAwareBbox":[{"x":172,"y":58,"w":110,"h":12,"startIndex":3,"endIndex":9}]},{"type":"text","value":"```python\nfrom neuroml import *","md":"```python\nfrom neuroml import *","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":30}]},{"type":"heading","lvl":1,"value":"Create a container document","md":"# Create a container document","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":28}]},{"type":"text","value":"doc = NeuroMLDocument(id=\"network0\")","md":"doc = NeuroMLDocument(id=\"network0\")","bBox":{"x":174.65,"y":106.18,"w":144.05,"h":7.53},"layoutAwareBbox":[{"x":174.65,"y":106.18,"w":144.05,"h":7.53,"startIndex":0,"endIndex":35}]},{"type":"heading","lvl":1,"value":"Add single exponential synapse model","md":"# Add single exponential synapse model","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":37}]},{"type":"text","value":"syn0 = doc.add(\"ExpOneSynapse\", id=\"syn0\", gbase=\"65nS\", erev=\"0mV\", tau_decay=\"3ms\")","md":"syn0 = doc.add(\"ExpOneSynapse\", id=\"syn0\", gbase=\"65nS\", erev=\"0mV\", tau_decay=\"3ms\")","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":84}]},{"type":"heading","lvl":1,"value":"Reuse existing ion channel model","md":"# Reuse existing ion channel model","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":33}]},{"type":"text","value":"doc.add(\"IncludeType\", href=\"Na_chan.channel.nml\")","md":"doc.add(\"IncludeType\", href=\"Na_chan.channel.nml\")","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":49}]},{"type":"heading","lvl":1,"value":"Create a cell with 3D morphology using the Cell ComponentType","md":"# Create a cell with 3D morphology using the Cell ComponentType","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":62}]},{"type":"text","value":"cell = doc.add(\"Cell\", id=\"olm\", neuro_lex_id=\"NLXCELL:091206\") # Hippocampal CA1 OLM cell\ncell.set_init_memb_potential(\"-67mV\")\ncell.set_resistivity(\"0.15 kohm_cm\")\ncell.add_channel_density(doc, cd_id=\"na_all\", cond_density=\"10 mS_per_cm2\",\n                     ion_channel=\"Na_chan\", ion_chan_def_file=\"Na.channel.nml\",\n                     erev=\"50mV\", ion=\"na\")\ncell.add_unbranched_segment_group(\"soma_group\")\nsoma_0 = cell.add_segment(prox=[0, 0, 0, 10], dist=[0, 10, 0, 10], name=\"Seg0_soma_0\",\n                     group_id=\"soma_group\", seg_type=\"soma\")\n```","md":"cell = doc.add(\"Cell\", id=\"olm\", neuro_lex_id=\"NLXCELL:091206\") # Hippocampal CA1 OLM cell\ncell.set_init_memb_potential(\"-67mV\")\ncell.set_resistivity(\"0.15 kohm_cm\")\ncell.add_channel_density(doc, cd_id=\"na_all\", cond_density=\"10 mS_per_cm2\",\n                     ion_channel=\"Na_chan\", ion_chan_def_file=\"Na.channel.nml\",\n                     erev=\"50mV\", ion=\"na\")\ncell.add_unbranched_segment_group(\"soma_group\")\nsoma_0 = cell.add_segment(prox=[0, 0, 0, 10], dist=[0, 10, 0, 10], name=\"Seg0_soma_0\",\n                     group_id=\"soma_group\", seg_type=\"soma\")\n```","bBox":{"x":174.64,"y":197.69,"w":358.91,"h":88.88},"layoutAwareBbox":[{"x":174.64,"y":197.69,"w":358.91,"h":88.88,"startIndex":0,"endIndex":564}]},{"type":"heading","lvl":2,"value":"API examples","md":"## API examples","bBox":{"x":176.3,"y":307.39,"w":52.89,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":307.39,"w":52.89,"h":8.47,"startIndex":0,"endIndex":14}]},{"type":"heading","lvl":3,"value":"Validate","md":"### Validate","bBox":{"x":176.03,"y":333.26,"w":34.96,"h":8.47},"layoutAwareBbox":[{"x":176.03,"y":333.26,"w":34.96,"h":8.47,"startIndex":0,"endIndex":11}]},{"type":"text","value":"```python\nvalidate_neuroml2(\"file.nml\")\ndoc.validate(recursive=True)\n```","md":"```python\nvalidate_neuroml2(\"file.nml\")\ndoc.validate(recursive=True)\n```","bBox":{"x":176.03,"y":333.26,"w":112.12,"h":33.21},"layoutAwareBbox":[{"x":176.03,"y":333.26,"w":112.12,"h":33.21,"startIndex":0,"endIndex":71}]},{"type":"heading","lvl":3,"value":"Inspect and visualize","md":"### Inspect and visualize","bBox":{"x":176.3,"y":382.75,"w":88.06,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":382.75,"w":88.06,"h":8.47,"startIndex":0,"endIndex":24}]},{"type":"text","value":"```python\nelement.info()\nsummary(doc)\nnml2_to_png(doc)\nnml2_to_svg(doc)\ngenerate_nmlgraph(doc)","md":"```python\nelement.info()\nsummary(doc)\nnml2_to_png(doc)\nnml2_to_svg(doc)\ngenerate_nmlgraph(doc)","bBox":{"x":176.32,"y":408.43,"w":88.11,"h":44.65},"layoutAwareBbox":[{"x":176.32,"y":408.43,"w":88.11,"h":44.65,"startIndex":0,"endIndex":93}]},{"type":"text","value":"plot_2D(cell)\nplot_interactive_3d(cell)\nplot_interactive_3d(network)","md":"plot_2D(cell)\nplot_interactive_3d(cell)\nplot_interactive_3d(network)","bBox":{"x":176.48,"y":470.3,"w":111.99,"h":32.27},"layoutAwareBbox":[{"x":176.48,"y":470.3,"w":111.99,"h":32.27,"startIndex":0,"endIndex":67}]},{"type":"text","value":"plot_channel_densities(cell)\n```","md":"plot_channel_densities(cell)\n```","bBox":{"x":176.47,"y":519.8,"w":111.99,"h":7.53},"layoutAwareBbox":[{"x":176.47,"y":519.8,"w":111.99,"h":7.53,"startIndex":0,"endIndex":31}]},{"type":"heading","lvl":3,"value":"Simulate","md":"### Simulate","bBox":{"x":176.3,"y":543.57,"w":37.53,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":543.57,"w":37.53,"h":8.47,"startIndex":0,"endIndex":11}]},{"type":"text","value":"```python\nrun_lems_with_jneuroml(\"sim.xml\")\nrun_lems_with_jneuroml_neuron(\"sim.xml\")\nrun_lems_with_jneuroml_netpyne(\"sim.xml\")\nrun_on_nsg(\"jneuroml_neuron\", \"sim.xml\")\n...\n```","md":"```python\nrun_lems_with_jneuroml(\"sim.xml\")\nrun_lems_with_jneuroml_neuron(\"sim.xml\")\nrun_lems_with_jneuroml_netpyne(\"sim.xml\")\nrun_on_nsg(\"jneuroml_neuron\", \"sim.xml\")\n...\n```","bBox":{"x":176.3,"y":556.89,"w":164.07,"h":57.02},"layoutAwareBbox":[{"x":176.3,"y":556.89,"w":164.07,"h":57.02,"startIndex":0,"endIndex":174}]},{"type":"heading","lvl":3,"value":"Share and archive","md":"### Share and archive","bBox":{"x":176.3,"y":630.17,"w":75.95,"h":8.47},"layoutAwareBbox":[{"x":174,"y":629,"w":79,"h":11,"startIndex":4,"endIndex":9}]},{"type":"text","value":"```python\ncreate_combine_archive(\"sim.xml\")\n```","md":"```python\ncreate_combine_archive(\"sim.xml\")\n```","bBox":{"x":176.3,"y":643.49,"w":132.04,"h":7.53},"layoutAwareBbox":[{"x":176.3,"y":643.49,"w":132.04,"h":7.53,"startIndex":0,"endIndex":46}]},{"type":"heading","lvl":2,"value":"Command line usage examples","md":"## Command line usage examples","bBox":{"x":351.65,"y":307.39,"w":123.21,"h":8.47},"layoutAwareBbox":[{"x":351.65,"y":307.39,"w":123.21,"h":8.47,"startIndex":0,"endIndex":29}]},{"type":"heading","lvl":3,"value":"Validate","md":"### Validate","bBox":{"x":176.03,"y":333.26,"w":34.96,"h":8.47},"layoutAwareBbox":[{"x":176.03,"y":333.26,"w":34.96,"h":8.47,"startIndex":0,"endIndex":11}]},{"type":"text","value":"```bash\n> pynml \"file.nml\" --validate\n```","md":"```bash\n> pynml \"file.nml\" --validate\n```","bBox":{"x":176.03,"y":333.26,"w":179.22,"h":82.71},"layoutAwareBbox":[{"x":176.03,"y":333.26,"w":179.22,"h":82.71,"startIndex":0,"endIndex":40}]},{"type":"heading","lvl":3,"value":"Inspect and visualize","md":"### Inspect and visualize","bBox":{"x":176.3,"y":382.75,"w":88.06,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":382.75,"w":88.06,"h":8.47,"startIndex":0,"endIndex":24}]},{"type":"text","value":"```bash\n> pynml-summary \"file.nml\"\n> pynml -png \"file.nml\"\n> pynml -svg \"file.nml\"\n> pynml \"file.nml\" -graph\n> pynml \"file.nml\" -matrix 1\n> pynml-plotmorph \"cell.nml\"\n> pynml-plotmorph -interactive3d \"cell.nml\"\n> pynml-plotmorph -interactive3d \"net.nml\"\n> pynml-channelanalysis \"channel.nml\"\n> pynml-plotchan \"cell.nml\"\n```","md":"```bash\n> pynml-summary \"file.nml\"\n> pynml -png \"file.nml\"\n> pynml -svg \"file.nml\"\n> pynml \"file.nml\" -graph\n> pynml \"file.nml\" -matrix 1\n> pynml-plotmorph \"cell.nml\"\n> pynml-plotmorph -interactive3d \"cell.nml\"\n> pynml-plotmorph -interactive3d \"net.nml\"\n> pynml-channelanalysis \"channel.nml\"\n> pynml-plotchan \"cell.nml\"\n```","bBox":{"x":351.25,"y":408.43,"w":4,"h":7.53},"layoutAwareBbox":[{"x":351.25,"y":408.43,"w":4,"h":7.53,"startIndex":0,"endIndex":322}]},{"type":"heading","lvl":3,"value":"Simulate","md":"### Simulate","bBox":{"x":176.3,"y":543.57,"w":37.53,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":543.57,"w":37.53,"h":8.47,"startIndex":0,"endIndex":11}]},{"type":"text","value":"```bash\n> pynml \"sim.xml\"\n> pynml \"sim.xml\" -neuron -run\n> pynml \"sim.xml\" -netpyne -run\n```","md":"```bash\n> pynml \"sim.xml\"\n> pynml \"sim.xml\" -neuron -run\n> pynml \"sim.xml\" -netpyne -run\n```","bBox":{"x":351.25,"y":556.89,"w":68.01,"h":7.53},"layoutAwareBbox":[{"x":351.25,"y":556.89,"w":68.01,"h":7.53,"startIndex":0,"endIndex":91}]},{"type":"heading","lvl":3,"value":"Share and archive","md":"### Share and archive","bBox":{"x":176.3,"y":630.17,"w":75.95,"h":8.47},"layoutAwareBbox":[{"x":176.3,"y":630.17,"w":75.95,"h":8.47,"startIndex":0,"endIndex":20}]},{"type":"text","value":"```bash\n> pynml-archive \"neuron.cell.nml\"\n```","md":"```bash\n> pynml-archive \"neuron.cell.nml\"\n```","bBox":{"x":351.25,"y":408.43,"w":4,"h":7.53},"layoutAwareBbox":[{"x":351.25,"y":408.43,"w":4,"h":7.53,"startIndex":0,"endIndex":44}]},{"type":"text","value":"**Figure 6.** PyNeuroML provides Python functions and command line utilities supporting all stages of the model life cycle.","md":"**Figure 6.** PyNeuroML provides Python functions and command line utilities supporting all stages of the model life cycle.","bBox":{"x":168.53,"y":676.55,"w":19.85,"h":8},"layoutAwareBbox":[{"x":166,"y":665,"w":405,"h":20,"startIndex":117,"endIndex":122}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    15 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    15 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                          Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    15 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.925,"layout":[{"image":"page_15_footer_1_v2.jpg","confidence":0.94,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_15_number_1_v2.jpg","confidence":0.92,"label":"number","bbox":{"x":0.89,"y":0.944,"w":0.048,"h":0.009},"isLikelyNoise":false},{"image":"page_15_header_1_v2.jpg","confidence":0.92,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_15_text_1_v2.jpg","confidence":0.72,"label":"text","bbox":{"x":0.272,"y":0.84,"w":0.662,"h":0.026},"isLikelyNoise":false},{"image":"page_15_header_2_v2.jpg","confidence":0.71,"label":"header","bbox":{"x":0.127,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_15_paragraph_title_1_v2.jpg","confidence":0.59,"label":"paragraph_title","bbox":{"x":0.284,"y":0.794,"w":0.129,"h":0.015},"isLikelyNoise":true},{"image":"page_15_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.017},"isLikelyNoise":true},{"image":"page_15_paragraph_title_2_v2.jpg","confidence":0.53,"label":"paragraph_title","bbox":{"x":0.283,"y":0.074,"w":0.18,"h":0.016},"isLikelyNoise":true}]},{"page":16,"text":"Tools  and  resources    Neuroscience\n\n\nModel description\n\nNeuroML validity checks\n Does the model include all required model elements?\n Are all model elements correctly ordered?\n Are all necessary model element attributes/parameters set?\n Do all parameters use correct physiological units?\n\n Additional/logical checks\n  Do model elements correctly reference each other?\n  Are synapses/connections/projections correctly defined?\n  Are multi-compartmental cell morphologies valid?\n\n  LEMS checks\n                 Are all model elements mappable to simulation back-ends?\n                 Are all of the units and dimensions consistent?\n\n                 Model simulation\n\n                 OMV checks\n                 Does the model produce the same results on all simulators?\n\n                       Behavioral checks (SciUnit)\n                       Do the simulation results match experimental data?\n\nFigure 7. NeuroML model development incorporates multi-level validation of models. Checks are performed on\nthe model descriptions (blue) before simulation using validation at both the NeuroML and LEMS levels (green).\nAfter the models are simulated (yellow), further checks can be run to ensure the output is in line with expected\nbehavior (brown). The OSB Model Validation (OMV) framework can be used to ensure consistent behavior across\nsimulators, and comparisons can be made of model activity to their biological equivalents using SciUnit.\n\n\nvariety of utilities for the inspection of NeuroML descriptions of electrophysiological properties of\nmembrane conductances and their spatial distribution over the neuronal membrane are also provided\n(Figure 10).\n The graphical applications included in the NeuroML ecosystem (e.g. neuroConstruct, NeuroML-\n                                                                                          DB,\nOSB (v1 [https://v1.opensourcebrain.org] and v2), NetPyNE, and Arbor- GUI) also provide many of\ntheir own analysis and visualization functions. OSBv1, for example, supports automated 3D visual-\nization of networks and cell morphologies, network connectivity graphs and metrics, and advanced\nmodel inspection features (Gleeson et  al., 2019b;   Figure  8b). On OSBv2, NetPyNE provides\nadvanced graphical plotting and analysis facilities (Figure 8c). A complete JupyterLab (https://jupyter.\norg/) interface is also included in OSBv2 for Python scripting, allowing interactive notebooks to be\ncreated and shared, mixing scripting and graphical elements, including those generated by pyNeu-\nroML. NeuroML-DB also provides information on electrophysiology, morphology, and the simulation\naspects of neuronal models (Birgiolas et al., 2023; Figure 10a). In general, any NeuroML- compliant\napplication can be used to inspect and analyze elements of NeuroML models, each having their own\ndistinct advantages.\n\nSimulating NeuroML models\nUsers can simulate NeuroML models using a number of simulation engines without making any\nchanges to their models. This is because the NeuroML/LEMS descriptions of the models are simulator\nindependent and can be translated to simulator speciﬁc formats. pyNeuroML facilitates access to all\navailable simulation options, both from the command line and using function calls in Python scripts\nwhen using the Python API (Figure 6).\n Simulation engines can be classiﬁed into ﬁve broad categories (Figure 5):\n 1. reference NeuroML/LEMS simulators.\n 2. independently developed simulators that natively support NeuroML.\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    16 of 44","md":"\n\neLife Tools and resources                                                                                                                                    Neuroscience\n\n```mermaid\nflowchart TD\n    A[Model description] --> B[NeuroML validity checks]\n    B --> C[Additional/logical checks]\n    C --> D[LEMS checks]\n    D --> E[Model simulation]\n    E --> F[OMV checks]\n    E --> G[Behavioral checks SciUnit]\n    \n    B1[\"Does the model include all required model elements?<br/>Are all model elements correctly ordered?<br/>Are all necessary model element attributes/parameters set?<br/>Do all parameters use correct physiological units?\"]\n    \n    C1[\"Do model elements correctly reference each other?<br/>Are synapses/connections/projections correctly defined?<br/>Are multi-compartmental cell morphologies valid?\"]\n    \n    D1[\"Are all model elements mappable to simulation back-ends?<br/>Are all of the units and dimensions consistent?\"]\n    \n    F1[\"Does the model produce the same results on all simulators?\"]\n    \n    G1[\"Do the simulation results match experimental data?\"]\n    \n    B -.-> B1\n    C -.-> C1\n    D -.-> D1\n    F -.-> F1\n    G -.-> G1\n```\n\n**Figure 7.** NeuroML model development incorporates multi-level validation of models. Checks are performed on the model descriptions (blue) before simulation using validation at both the NeuroML and LEMS levels (green). After the models are simulated (yellow), further checks can be run to ensure the output is in line with expected behavior (brown). The OSB Model Validation (OMV) framework can be used to ensure consistent behavior across simulators, and comparisons can be made of model activity to their biological equivalents using SciUnit.\n\nvariety of utilities for the inspection of NeuroML descriptions of electrophysiological properties of membrane conductances and their spatial distribution over the neuronal membrane are also provided (**Figure 10**).\n\nThe graphical applications included in the NeuroML ecosystem (e.g. neuroConstruct, NeuroML-DB, OSB (v1 [https://v1.opensourcebrain.org] and v2), NetPyNE, and Arbor-GUI) also provide many of their own analysis and visualization functions. OSBv1, for example, supports automated 3D visualization of networks and cell morphologies, network connectivity graphs and metrics, and advanced model inspection features (**Gleeson et al., 2019b; Figure 8b**). On OSBv2, NetPyNE provides advanced graphical plotting and analysis facilities (**Figure 8c**). A complete JupyterLab (https://jupyter.org/) interface is also included in OSBv2 for Python scripting, allowing interactive notebooks to be created and shared, mixing scripting and graphical elements, including those generated by pyNeuroML. NeuroML-DB also provides information on electrophysiology, morphology, and the simulation aspects of neuronal models (**Birgiolas et al., 2023; Figure 10a**). In general, any NeuroML-compliant application can be used to inspect and analyze elements of NeuroML models, each having their own distinct advantages.\n\n## Simulating NeuroML models\n\nUsers can simulate NeuroML models using a number of simulation engines without making any changes to their models. This is because the NeuroML/LEMS descriptions of the models are simulator independent and can be translated to simulator specific formats. pyNeuroML facilitates access to all available simulation options, both from the command line and using function calls in Python scripts when using the Python API (**Figure 6**).\n\nSimulation engines can be classified into five broad categories (**Figure 5**):\n\n1. reference NeuroML/LEMS simulators.\n2. independently developed simulators that natively support NeuroML.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    16 of 44\n","images":[{"name":"page_16.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_16_text_1_v2.jpg","height":111838.426,"width":250272.375,"x":101102.783,"y":359720.359,"original_width":1653,"original_height":571,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_image_1_v2.jpg","height":219675.736,"width":241015.156,"x":102960.676,"y":42444.245,"original_width":1592,"original_height":1121,"rotation":0,"type":"layout_v2_image"},{"name":"page_16_text_2_v2.jpg","height":45726.016,"width":250160.133,"x":101224.082,"y":493304.245,"original_width":1652,"original_height":234,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_text_3_v2.jpg","height":26475.147,"width":250447.561,"x":101116.611,"y":330909.222,"original_width":1654,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_figure_title_1_v2.jpg","height":42323.756,"width":245388.521,"x":101337.551,"y":267874.894,"original_width":1621,"original_height":216,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_16_paragraph_title_1_v2.jpg","height":8693.781,"width":100075.179,"x":101657.505,"y":481581.328,"original_width":661,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_16_footer_1_v2.jpg","height":6936.363,"width":191851.861,"x":21549.754,"y":591467.376,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_16_text_4_v2.jpg","height":7663.597,"width":177194.54,"x":109003.965,"y":563248.376,"original_width":1170,"original_height":40,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_text_5_v2.jpg","height":7594.638,"width":182633.394,"x":109025.881,"y":541013.279,"original_width":1206,"original_height":39,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_header_1_v2.jpg","height":5657.178,"width":30316.481,"x":320782.85,"y":27664.061,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_16_number_1_v2.jpg","height":5877.679,"width":17671.191,"x":333434.002,"y":591817.585,"original_width":117,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_16_text_6_v2.jpg","height":7035.745,"width":101238.91,"x":109166.157,"y":554460.76,"original_width":669,"original_height":36,"rotation":0,"type":"layout_v2_text"},{"name":"page_16_header_2_v2.jpg","height":5715.498,"width":42858.358,"x":47805.168,"y":27890.548,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_16_header_3_v2.jpg","height":10645.533,"width":24394.989,"x":21847.013,"y":22412.788,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                                                                    Neuroscience","md":"eLife Tools and resources                                                                                                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":157,"endIndex":169}]},{"type":"text","value":"```mermaid\nflowchart TD\n    A[Model description] --> B[NeuroML validity checks]\n    B --> C[Additional/logical checks]\n    C --> D[LEMS checks]\n    D --> E[Model simulation]\n    E --> F[OMV checks]\n    E --> G[Behavioral checks SciUnit]\n    \n    B1[\"Does the model include all required model elements?<br/>Are all model elements correctly ordered?<br/>Are all necessary model element attributes/parameters set?<br/>Do all parameters use correct physiological units?\"]\n    \n    C1[\"Do model elements correctly reference each other?<br/>Are synapses/connections/projections correctly defined?<br/>Are multi-compartmental cell morphologies valid?\"]\n    \n    D1[\"Are all model elements mappable to simulation back-ends?<br/>Are all of the units and dimensions consistent?\"]\n    \n    F1[\"Does the model produce the same results on all simulators?\"]\n    \n    G1[\"Do the simulation results match experimental data?\"]\n    \n    B -.-> B1\n    C -.-> C1\n    D -.-> D1\n    F -.-> F1\n    G -.-> G1\n```","md":"```mermaid\nflowchart TD\n    A[Model description] --> B[NeuroML validity checks]\n    B --> C[Additional/logical checks]\n    C --> D[LEMS checks]\n    D --> E[Model simulation]\n    E --> F[OMV checks]\n    E --> G[Behavioral checks SciUnit]\n    \n    B1[\"Does the model include all required model elements?<br/>Are all model elements correctly ordered?<br/>Are all necessary model element attributes/parameters set?<br/>Do all parameters use correct physiological units?\"]\n    \n    C1[\"Do model elements correctly reference each other?<br/>Are synapses/connections/projections correctly defined?<br/>Are multi-compartmental cell morphologies valid?\"]\n    \n    D1[\"Are all model elements mappable to simulation back-ends?<br/>Are all of the units and dimensions consistent?\"]\n    \n    F1[\"Does the model produce the same results on all simulators?\"]\n    \n    G1[\"Do the simulation results match experimental data?\"]\n    \n    B -.-> B1\n    C -.-> C1\n    D -.-> D1\n    F -.-> F1\n    G -.-> G1\n```","bBox":{"x":187.72,"y":66.91,"w":323.82,"h":250.88},"layoutAwareBbox":[{"x":187.72,"y":66.91,"w":323.82,"h":250.88,"startIndex":0,"endIndex":987}]},{"type":"text","value":"**Figure 7.** NeuroML model development incorporates multi-level validation of models. Checks are performed on the model descriptions (blue) before simulation using validation at both the NeuroML and LEMS levels (green). After the models are simulated (yellow), further checks can be run to ensure the output is in line with expected behavior (brown). The OSB Model Validation (OMV) framework can be used to ensure consistent behavior across simulators, and comparisons can be made of model activity to their biological equivalents using SciUnit.","md":"**Figure 7.** NeuroML model development incorporates multi-level validation of models. Checks are performed on the model descriptions (blue) before simulation using validation at both the NeuroML and LEMS levels (green). After the models are simulated (yellow), further checks can be run to ensure the output is in line with expected behavior (brown). The OSB Model Validation (OMV) framework can be used to ensure consistent behavior across simulators, and comparisons can be made of model activity to their biological equivalents using SciUnit.","bBox":{"x":168.53,"y":349.25,"w":399.84,"h":41},"layoutAwareBbox":[{"x":165,"y":338,"w":400,"h":53,"startIndex":0,"endIndex":545}]},{"type":"text","value":"variety of utilities for the inspection of NeuroML descriptions of electrophysiological properties of membrane conductances and their spatial distribution over the neuronal membrane are also provided (**Figure 10**).","md":"variety of utilities for the inspection of NeuroML descriptions of electrophysiological properties of membrane conductances and their spatial distribution over the neuronal membrane are also provided (**Figure 10**).","bBox":{"x":168.53,"y":417.49,"w":412.73,"h":21},"layoutAwareBbox":[{"x":165,"y":417,"w":409,"h":33,"startIndex":0,"endIndex":215}]},{"type":"text","value":"The graphical applications included in the NeuroML ecosystem (e.g. neuroConstruct, NeuroML-DB, OSB (v1 [https://v1.opensourcebrain.org] and v2), NetPyNE, and Arbor-GUI) also provide many of their own analysis and visualization functions. OSBv1, for example, supports automated 3D visualization of networks and cell morphologies, network connectivity graphs and metrics, and advanced model inspection features (**Gleeson et al., 2019b; Figure 8b**). On OSBv2, NetPyNE provides advanced graphical plotting and analysis facilities (**Figure 8c**). A complete JupyterLab (https://jupyter.org/) interface is also included in OSBv2 for Python scripting, allowing interactive notebooks to be created and shared, mixing scripting and graphical elements, including those generated by pyNeuroML. NeuroML-DB also provides information on electrophysiology, morphology, and the simulation aspects of neuronal models (**Birgiolas et al., 2023; Figure 10a**). In general, any NeuroML-compliant application can be used to inspect and analyze elements of NeuroML models, each having their own distinct advantages.","md":"The graphical applications included in the NeuroML ecosystem (e.g. neuroConstruct, NeuroML-DB, OSB (v1 [https://v1.opensourcebrain.org] and v2), NetPyNE, and Arbor-GUI) also provide many of their own analysis and visualization functions. OSBv1, for example, supports automated 3D visualization of networks and cell morphologies, network connectivity graphs and metrics, and advanced model inspection features (**Gleeson et al., 2019b; Figure 8b**). On OSBv2, NetPyNE provides advanced graphical plotting and analysis facilities (**Figure 8c**). A complete JupyterLab (https://jupyter.org/) interface is also included in OSBv2 for Python scripting, allowing interactive notebooks to be created and shared, mixing scripting and graphical elements, including those generated by pyNeuroML. NeuroML-DB also provides information on electrophysiology, morphology, and the simulation aspects of neuronal models (**Birgiolas et al., 2023; Figure 10a**). In general, any NeuroML-compliant application can be used to inspect and analyze elements of NeuroML models, each having their own distinct advantages.","bBox":{"x":168.52,"y":453.48,"w":408.98,"h":140.97},"layoutAwareBbox":[{"x":165,"y":454,"w":408,"h":141,"startIndex":14,"endIndex":26}]},{"type":"heading","lvl":2,"value":"Simulating NeuroML models","md":"## Simulating NeuroML models","bBox":{"x":168.53,"y":606.49,"w":160.65,"h":12},"layoutAwareBbox":[{"x":166,"y":608,"w":163,"h":10,"startIndex":0,"endIndex":27}]},{"type":"text","value":"Users can simulate NeuroML models using a number of simulation engines without making any changes to their models. This is because the NeuroML/LEMS descriptions of the models are simulator independent and can be translated to simulator specific formats. pyNeuroML facilitates access to all available simulation options, both from the command line and using function calls in Python scripts when using the Python API (**Figure 6**).","md":"Users can simulate NeuroML models using a number of simulation engines without making any changes to their models. This is because the NeuroML/LEMS descriptions of the models are simulator independent and can be translated to simulator specific formats. pyNeuroML facilitates access to all available simulation options, both from the command line and using function calls in Python scripts when using the Python API (**Figure 6**).","bBox":{"x":168.53,"y":622.49,"w":412.7,"h":44.99},"layoutAwareBbox":[{"x":165,"y":622,"w":408,"h":57,"startIndex":0,"endIndex":430}]},{"type":"text","value":"Simulation engines can be classified into five broad categories (**Figure 5**):","md":"Simulation engines can be classified into five broad categories (**Figure 5**):","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":178,"y":683,"w":298,"h":9,"startIndex":0,"endIndex":78}]},{"type":"text","value":"1. reference NeuroML/LEMS simulators.\n2. independently developed simulators that natively support NeuroML.","md":"1. reference NeuroML/LEMS simulators.\n2. independently developed simulators that natively support NeuroML.","bBox":{"x":180.52,"y":699.48,"w":288.62,"h":20},"layoutAwareBbox":[{"x":178,"y":711,"w":289,"h":9,"startIndex":0,"endIndex":105},{"x":178,"y":700,"w":165,"h":8,"startIndex":0,"endIndex":105}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    16 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    16 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":160},{"x":544,"y":747,"w":28,"h":7,"startIndex":0,"endIndex":160}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://v1.opensourcebrain.org/","unsafeUrl":"https://v1.opensourcebrain.org","text":"OSB (v1 [https://v1.opensourcebrain.org] and v2), NetPyNE, and Arbor-"},{"url":"https://jupyter.org/","unsafeUrl":"https://jupyter.org/","text":"). A complete JupyterLab (https://jupyter."},{"url":"https://jupyter.org/","unsafeUrl":"https://jupyter.org/","text":"org/) "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    16 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.933,"layout":[{"image":"page_16_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.573,"w":0.668,"h":0.178},"isLikelyNoise":false},{"image":"page_16_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.068,"w":0.643,"h":0.35},"isLikelyNoise":false},{"image":"page_16_text_2_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.786,"w":0.668,"h":0.073},"isLikelyNoise":false},{"image":"page_16_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.528,"w":0.669,"h":0.042},"isLikelyNoise":false},{"image":"page_16_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.271,"y":0.427,"w":0.655,"h":0.067},"isLikelyNoise":false},{"image":"page_16_paragraph_title_1_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.768,"w":0.267,"h":0.014},"isLikelyNoise":false},{"image":"page_16_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_16_text_4_v2.jpg","confidence":0.89,"label":"text","bbox":{"x":0.291,"y":0.898,"w":0.473,"h":0.012},"isLikelyNoise":false},{"image":"page_16_text_5_v2.jpg","confidence":0.88,"label":"text","bbox":{"x":0.291,"y":0.862,"w":0.488,"h":0.012},"isLikelyNoise":false},{"image":"page_16_header_1_v2.jpg","confidence":0.86,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_16_number_1_v2.jpg","confidence":0.86,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.047,"h":0.009},"isLikelyNoise":false},{"image":"page_16_text_6_v2.jpg","confidence":0.72,"label":"text","bbox":{"x":0.291,"y":0.884,"w":0.27,"h":0.011},"isLikelyNoise":false},{"image":"page_16_header_2_v2.jpg","confidence":0.69,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_16_header_3_v2.jpg","confidence":0.53,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":17,"text":"        Tools  and  resources                                                                                   Neuroscience\n\nTable 6. Listing of validation tests run by NeuroML.\nTest                                                Description\n\nSchema tests\n\n                                                    Check that names of all elements, attributes, parameters match those\nCheck names                                         provided in the schema\n\nCheck types                                         Check that the types of all included elements\n\nCheck values                                        Check that values follow given restrictions\n\nCheck inclusion                                     Check that required elements are included\n\nCheck cardinality                                   Check the number of elements\n\n                                                    Check that child/children elements are included in the correct parent\nCheck hierarchy                                     elements\n\nCheck sequence order                                Check that child/children elements are included in the correct order\n\nAdditional tests\n\nCheck top level ids                                 Check that top level (root) elements have unique ids\n\nCheck Network level ids                             Check that child/children of the Network element have unique ids\n\nCheck Cell Segment ids                              Check that all Segments in a Cell have unique ids\n\nCheck single Segment without parent                 Check that only one Segment is without parents (the soma Segment)\n\nCheck SegmentGroup ids                              Check that all SegmentGroups in a Cell have unique ids\n\nCheck Member segment ids exist                      Check that Segments referred to in SegmentGroup Members exist\n\nCheck SegmentGroup definition                       Check that SegmentGroups being referenced are defined\n\nCheck SegmentGroup definition order                 Check that SegmentGroups are defined before being referenced\n\n                                                    Check that SegmentGroups referenced by Include elements of other\nCheck included SegmentGroups                        SegmentGroups exist\n\n                                                    Check that SegmentGroups define numberInternalDivisions (used by\n                                                    simulators to discretize un-branched branches into compartments for\nCheck numberInternalDivisions                       simulation)\n\nCheck included model files                          Check that model files included by other files exist\n\nCheck Population component                          Check that a component id provided to a Population exists\n\nCheck ion channel exists                            Check that an ion channel used to define a ChannelDensity element exists\n\nCheck concentration model species                   Check that the species used in ConcentrationModel elements are defined\n\n                                                    Check that the size attribute of a PopulationList matches the number of\nCheck Population size                               defined Instances\n\nCheck Projection component                          Check that Populations used in the Projection elements exist\n\nCheck Connection Segment                            Check that the Segment used in Connection elements exist\n\n                                                    Check that the pre- and post-synaptic cells used in Connection elements\nCheck Connection pre/post cells                     exist and are correctly specified\n\nCheck Synapse                                       Check that the Synapse component used in a Projection element exists\n\nCheck root id                                       Check that the root Segment in a Cell morphology has id 0\n\n\n\n 3. simulators that import/translate NeuroML to their own internal formats.\n 4. simulators that are supported through generation of simulator-  specific scripts by the core\n NeuroML tools.\n 5. export to other standardized formats which may allow simulation/analysis in other packages.\n\n Each simulation engine supports a different set of features that NeuroML users can take advan-\ntage of (Table 7). For example, the reference NeuroML and LEMS simulators, jNeuroML, jLEMS, and\nPyLEMS, can simulate all LEMS models and most NeuroML models. They cannot, however, simulate\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    17 of 44","md":"\n\neLife Tools and resources                                                                                   Neuroscience\n\n**Table 6.** Listing of validation tests run by NeuroML.\n\n<table>\n<thead>\n<tr>\n<th>Test</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"2\"><strong>Schema tests</strong></td>\n</tr>\n<tr>\n<td>Check names</td>\n<td>Check that names of all elements, attributes, parameters match those provided in the schema</td>\n</tr>\n<tr>\n<td>Check types</td>\n<td>Check that the types of all included elements</td>\n</tr>\n<tr>\n<td>Check values</td>\n<td>Check that values follow given restrictions</td>\n</tr>\n<tr>\n<td>Check inclusion</td>\n<td>Check that required elements are included</td>\n</tr>\n<tr>\n<td>Check cardinality</td>\n<td>Check the number of elements</td>\n</tr>\n<tr>\n<td>Check hierarchy</td>\n<td>Check that child/children elements are included in the correct parent elements</td>\n</tr>\n<tr>\n<td>Check sequence order</td>\n<td>Check that child/children elements are included in the correct order</td>\n</tr>\n<tr>\n<td colspan=\"2\"><strong>Additional tests</strong></td>\n</tr>\n<tr>\n<td>Check top level ids</td>\n<td>Check that top level (root) elements have unique ids</td>\n</tr>\n<tr>\n<td>Check Network level ids</td>\n<td>Check that child/children of the Network element have unique ids</td>\n</tr>\n<tr>\n<td>Check Cell Segment ids</td>\n<td>Check that all Segments in a Cell have unique ids</td>\n</tr>\n<tr>\n<td>Check single Segment without parent</td>\n<td>Check that only one Segment is without parents (the soma Segment)</td>\n</tr>\n<tr>\n<td>Check SegmentGroup ids</td>\n<td>Check that all SegmentGroups in a Cell have unique ids</td>\n</tr>\n<tr>\n<td>Check Member segment ids exist</td>\n<td>Check that Segments referred to in SegmentGroup Members exist</td>\n</tr>\n<tr>\n<td>Check SegmentGroup definition</td>\n<td>Check that SegmentGroups being referenced are defined</td>\n</tr>\n<tr>\n<td>Check SegmentGroup definition order</td>\n<td>Check that SegmentGroups are defined before being referenced</td>\n</tr>\n<tr>\n<td>Check included SegmentGroups</td>\n<td>Check that SegmentGroups referenced by Include elements of other SegmentGroups exist</td>\n</tr>\n<tr>\n<td>Check numberInternalDivisions</td>\n<td>Check that SegmentGroups define numberInternalDivisions (used by simulators to discretize un-branched branches into compartments for simulation)</td>\n</tr>\n<tr>\n<td>Check included model files</td>\n<td>Check that model files included by other files exist</td>\n</tr>\n<tr>\n<td>Check Population component</td>\n<td>Check that a component id provided to a Population exists</td>\n</tr>\n<tr>\n<td>Check ion channel exists</td>\n<td>Check that an ion channel used to define a ChannelDensity element exists</td>\n</tr>\n<tr>\n<td>Check concentration model species</td>\n<td>Check that the species used in ConcentrationModel elements are defined</td>\n</tr>\n<tr>\n<td>Check Population size</td>\n<td>Check that the size attribute of a PopulationList matches the number of defined Instances</td>\n</tr>\n<tr>\n<td>Check Projection component</td>\n<td>Check that Populations used in the Projection elements exist</td>\n</tr>\n<tr>\n<td>Check Connection Segment</td>\n<td>Check that the Segment used in Connection elements exist</td>\n</tr>\n<tr>\n<td>Check Connection pre/post cells</td>\n<td>Check that the pre- and post-synaptic cells used in Connection elements exist and are correctly specified</td>\n</tr>\n<tr>\n<td>Check Synapse</td>\n<td>Check that the Synapse component used in a Projection element exists</td>\n</tr>\n<tr>\n<td>Check root id</td>\n<td>Check that the root Segment in a Cell morphology has id 0</td>\n</tr>\n</tbody>\n</table>\n\n3. simulators that import/translate NeuroML to their own internal formats.\n4. simulators that are supported through generation of simulator-specific scripts by the core NeuroML tools.\n5. export to other standardized formats which may allow simulation/analysis in other packages.\n\nEach simulation engine supports a different set of features that NeuroML users can take advantage of (Table 7). For example, the reference NeuroML and LEMS simulators, jNeuroML, jLEMS, and PyLEMS, can simulate all LEMS models and most NeuroML models. They cannot, however, simulate\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    17 of 44\n","images":[{"name":"page_17.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_17_table_1_v2.jpg","height":427967.094,"width":331777.926,"x":20370.28,"y":53991.141,"original_width":2191,"original_height":2184,"rotation":0,"type":"layout_v2_table"},{"name":"page_17_text_1_v2.jpg","height":26644.743,"width":250371.835,"x":101311.592,"y":544084.755,"original_width":1654,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_17_text_2_v2.jpg","height":15161.735,"width":242760.701,"x":108691.472,"y":512544.627,"original_width":1603,"original_height":78,"rotation":0,"type":"layout_v2_text"},{"name":"page_17_footer_1_v2.jpg","height":6861.66,"width":191987.054,"x":21438.612,"y":591425.075,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_17_text_3_v2.jpg","height":7554.414,"width":236646.289,"x":108868.354,"y":529777.177,"original_width":1563,"original_height":39,"rotation":0,"type":"layout_v2_text"},{"name":"page_17_header_1_v2.jpg","height":5730.723,"width":30225.534,"x":320814.277,"y":27601.754,"original_width":200,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_17_number_1_v2.jpg","height":6027.536,"width":17819.903,"x":333309.068,"y":591713.891,"original_width":118,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_17_text_4_v2.jpg","height":7257.424,"width":185070.217,"x":108778.391,"y":503631.324,"original_width":1222,"original_height":38,"rotation":0,"type":"layout_v2_text"},{"name":"page_17_figure_title_1_v2.jpg","height":7509.573,"width":126863.751,"x":21120.816,"y":41386.098,"original_width":838,"original_height":39,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_17_header_2_v2.jpg","height":11199.951,"width":24784.594,"x":21579.369,"y":22368.073,"original_width":164,"original_height":58,"rotation":0,"type":"layout_v2_header"},{"name":"page_17_header_3_v2.jpg","height":6253.726,"width":43118.473,"x":47685.218,"y":27495.901,"original_width":285,"original_height":32,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                   Neuroscience","md":"eLife Tools and resources                                                                                   Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":34,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":108,"endIndex":120}]},{"type":"text","value":"**Table 6.** Listing of validation tests run by NeuroML.","md":"**Table 6.** Listing of validation tests run by NeuroML.","bBox":{"x":36.5,"y":66.98,"w":15.26,"h":8},"layoutAwareBbox":[{"x":34,"y":52,"w":207,"h":9,"startIndex":0,"endIndex":55}]},{"type":"table","rows":[["Test","Description"],["Schema tests",""],["Check names","Check that names of all elements, attributes, parameters match those provided in the schema"],["Check types","Check that the types of all included elements"],["Check values","Check that values follow given restrictions"],["Check inclusion","Check that required elements are included"],["Check cardinality","Check the number of elements"],["Check hierarchy","Check that child/children elements are included in the correct parent elements"],["Check sequence order","Check that child/children elements are included in the correct order"],["Additional tests",""],["Check top level ids","Check that top level (root) elements have unique ids"],["Check Network level ids","Check that child/children of the Network element have unique ids"],["Check Cell Segment ids","Check that all Segments in a Cell have unique ids"],["Check single Segment without parent","Check that only one Segment is without parents (the soma Segment)"],["Check SegmentGroup ids","Check that all SegmentGroups in a Cell have unique ids"],["Check Member segment ids exist","Check that Segments referred to in SegmentGroup Members exist"],["Check SegmentGroup definition","Check that SegmentGroups being referenced are defined"],["Check SegmentGroup definition order","Check that SegmentGroups are defined before being referenced"],["Check included SegmentGroups","Check that SegmentGroups referenced by Include elements of other SegmentGroups exist"],["Check numberInternalDivisions","Check that SegmentGroups define numberInternalDivisions (used by simulators to discretize un-branched branches into compartments for simulation)"],["Check included model files","Check that model files included by other files exist"],["Check Population component","Check that a component id provided to a Population exists"],["Check ion channel exists","Check that an ion channel used to define a ChannelDensity element exists"],["Check concentration model species","Check that the species used in ConcentrationModel elements are defined"],["Check Population size","Check that the size attribute of a PopulationList matches the number of defined Instances"],["Check Projection component","Check that Populations used in the Projection elements exist"],["Check Connection Segment","Check that the Segment used in Connection elements exist"],["Check Connection pre/post cells","Check that the pre- and post-synaptic cells used in Connection elements exist and are correctly specified"],["Check Synapse","Check that the Synapse component used in a Projection element exists"],["Check root id","Check that the root Segment in a Cell morphology has id 0"]],"html":"<table>\n<thead>\n<tr>\n<th>Test</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"2\"><strong>Schema tests</strong></td>\n</tr>\n<tr>\n<td>Check names</td>\n<td>Check that names of all elements, attributes, parameters match those provided in the schema</td>\n</tr>\n<tr>\n<td>Check types</td>\n<td>Check that the types of all included elements</td>\n</tr>\n<tr>\n<td>Check values</td>\n<td>Check that values follow given restrictions</td>\n</tr>\n<tr>\n<td>Check inclusion</td>\n<td>Check that required elements are included</td>\n</tr>\n<tr>\n<td>Check cardinality</td>\n<td>Check the number of elements</td>\n</tr>\n<tr>\n<td>Check hierarchy</td>\n<td>Check that child/children elements are included in the correct parent elements</td>\n</tr>\n<tr>\n<td>Check sequence order</td>\n<td>Check that child/children elements are included in the correct order</td>\n</tr>\n<tr>\n<td colspan=\"2\"><strong>Additional tests</strong></td>\n</tr>\n<tr>\n<td>Check top level ids</td>\n<td>Check that top level (root) elements have unique ids</td>\n</tr>\n<tr>\n<td>Check Network level ids</td>\n<td>Check that child/children of the Network element have unique ids</td>\n</tr>\n<tr>\n<td>Check Cell Segment ids</td>\n<td>Check that all Segments in a Cell have unique ids</td>\n</tr>\n<tr>\n<td>Check single Segment without parent</td>\n<td>Check that only one Segment is without parents (the soma Segment)</td>\n</tr>\n<tr>\n<td>Check SegmentGroup ids</td>\n<td>Check that all SegmentGroups in a Cell have unique ids</td>\n</tr>\n<tr>\n<td>Check Member segment ids exist</td>\n<td>Check that Segments referred to in SegmentGroup Members exist</td>\n</tr>\n<tr>\n<td>Check SegmentGroup definition</td>\n<td>Check that SegmentGroups being referenced are defined</td>\n</tr>\n<tr>\n<td>Check SegmentGroup definition order</td>\n<td>Check that SegmentGroups are defined before being referenced</td>\n</tr>\n<tr>\n<td>Check included SegmentGroups</td>\n<td>Check that SegmentGroups referenced by Include elements of other SegmentGroups exist</td>\n</tr>\n<tr>\n<td>Check numberInternalDivisions</td>\n<td>Check that SegmentGroups define numberInternalDivisions (used by simulators to discretize un-branched branches into compartments for simulation)</td>\n</tr>\n<tr>\n<td>Check included model files</td>\n<td>Check that model files included by other files exist</td>\n</tr>\n<tr>\n<td>Check Population component</td>\n<td>Check that a component id provided to a Population exists</td>\n</tr>\n<tr>\n<td>Check ion channel exists</td>\n<td>Check that an ion channel used to define a ChannelDensity element exists</td>\n</tr>\n<tr>\n<td>Check concentration model species</td>\n<td>Check that the species used in ConcentrationModel elements are defined</td>\n</tr>\n<tr>\n<td>Check Population size</td>\n<td>Check that the size attribute of a PopulationList matches the number of defined Instances</td>\n</tr>\n<tr>\n<td>Check Projection component</td>\n<td>Check that Populations used in the Projection elements exist</td>\n</tr>\n<tr>\n<td>Check Connection Segment</td>\n<td>Check that the Segment used in Connection elements exist</td>\n</tr>\n<tr>\n<td>Check Connection pre/post cells</td>\n<td>Check that the pre- and post-synaptic cells used in Connection elements exist and are correctly specified</td>\n</tr>\n<tr>\n<td>Check Synapse</td>\n<td>Check that the Synapse component used in a Projection element exists</td>\n</tr>\n<tr>\n<td>Check root id</td>\n<td>Check that the root Segment in a Cell morphology has id 0</td>\n</tr>\n</tbody>\n</table>","md":"| Test                                | Description                                                                                                                                      |\n| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **Schema tests**                    |                                                                                                                                                  |\n| Check names                         | Check that names of all elements, attributes, parameters match those provided in the schema                                                      |\n| Check types                         | Check that the types of all included elements                                                                                                    |\n| Check values                        | Check that values follow given restrictions                                                                                                      |\n| Check inclusion                     | Check that required elements are included                                                                                                        |\n| Check cardinality                   | Check the number of elements                                                                                                                     |\n| Check hierarchy                     | Check that child/children elements are included in the correct parent elements                                                                   |\n| Check sequence order                | Check that child/children elements are included in the correct order                                                                             |\n| **Additional tests**                |                                                                                                                                                  |\n| Check top level ids                 | Check that top level (root) elements have unique ids                                                                                             |\n| Check Network level ids             | Check that child/children of the Network element have unique ids                                                                                 |\n| Check Cell Segment ids              | Check that all Segments in a Cell have unique ids                                                                                                |\n| Check single Segment without parent | Check that only one Segment is without parents (the soma Segment)                                                                                |\n| Check SegmentGroup ids              | Check that all SegmentGroups in a Cell have unique ids                                                                                           |\n| Check Member segment ids exist      | Check that Segments referred to in SegmentGroup Members exist                                                                                    |\n| Check SegmentGroup definition       | Check that SegmentGroups being referenced are defined                                                                                            |\n| Check SegmentGroup definition order | Check that SegmentGroups are defined before being referenced                                                                                     |\n| Check included SegmentGroups        | Check that SegmentGroups referenced by Include elements of other SegmentGroups exist                                                             |\n| Check numberInternalDivisions       | Check that SegmentGroups define numberInternalDivisions (used by simulators to discretize un-branched branches into compartments for simulation) |\n| Check included model files          | Check that model files included by other files exist                                                                                             |\n| Check Population component          | Check that a component id provided to a Population exists                                                                                        |\n| Check ion channel exists            | Check that an ion channel used to define a ChannelDensity element exists                                                                         |\n| Check concentration model species   | Check that the species used in ConcentrationModel elements are defined                                                                           |\n| Check Population size               | Check that the size attribute of a PopulationList matches the number of defined Instances                                                        |\n| Check Projection component          | Check that Populations used in the Projection elements exist                                                                                     |\n| Check Connection Segment            | Check that the Segment used in Connection elements exist                                                                                         |\n| Check Connection pre/post cells     | Check that the pre- and post-synaptic cells used in Connection elements exist and are correctly specified                                        |\n| Check Synapse                       | Check that the Synapse component used in a Projection element exists                                                                             |\n| Check root id                       | Check that the root Segment in a Cell morphology has id 0                                                                                        |","isPerfectTable":true,"csv":"\"Test\",\"Description\"\n\"Schema tests\",\"\"\n\"Check names\",\"Check that names of all elements, attributes, parameters match those provided in the schema\"\n\"Check types\",\"Check that the types of all included elements\"\n\"Check values\",\"Check that values follow given restrictions\"\n\"Check inclusion\",\"Check that required elements are included\"\n\"Check cardinality\",\"Check the number of elements\"\n\"Check hierarchy\",\"Check that child/children elements are included in the correct parent elements\"\n\"Check sequence order\",\"Check that child/children elements are included in the correct order\"\n\"Additional tests\",\"\"\n\"Check top level ids\",\"Check that top level (root) elements have unique ids\"\n\"Check Network level ids\",\"Check that child/children of the Network element have unique ids\"\n\"Check Cell Segment ids\",\"Check that all Segments in a Cell have unique ids\"\n\"Check single Segment without parent\",\"Check that only one Segment is without parents (the soma Segment)\"\n\"Check SegmentGroup ids\",\"Check that all SegmentGroups in a Cell have unique ids\"\n\"Check Member segment ids exist\",\"Check that Segments referred to in SegmentGroup Members exist\"\n\"Check SegmentGroup definition\",\"Check that SegmentGroups being referenced are defined\"\n\"Check SegmentGroup definition order\",\"Check that SegmentGroups are defined before being referenced\"\n\"Check included SegmentGroups\",\"Check that SegmentGroups referenced by Include elements of other SegmentGroups exist\"\n\"Check numberInternalDivisions\",\"Check that SegmentGroups define numberInternalDivisions (used by simulators to discretize un-branched branches into compartments for simulation)\"\n\"Check included model files\",\"Check that model files included by other files exist\"\n\"Check Population component\",\"Check that a component id provided to a Population exists\"\n\"Check ion channel exists\",\"Check that an ion channel used to define a ChannelDensity element exists\"\n\"Check concentration model species\",\"Check that the species used in ConcentrationModel elements are defined\"\n\"Check Population size\",\"Check that the size attribute of a PopulationList matches the number of defined Instances\"\n\"Check Projection component\",\"Check that Populations used in the Projection elements exist\"\n\"Check Connection Segment\",\"Check that the Segment used in Connection elements exist\"\n\"Check Connection pre/post cells\",\"Check that the pre- and post-synaptic cells used in Connection elements exist and are correctly specified\"\n\"Check Synapse\",\"Check that the Synapse component used in a Projection element exists\"\n\"Check root id\",\"Check that the root Segment in a Cell morphology has id 0\"","bBox":{"x":36.5,"y":34.63,"w":538.69,"h":720.13},"layoutAwareBbox":[{"x":33,"y":68,"w":542,"h":540,"startIndex":2,"endIndex":6}]},{"type":"text","value":"3. simulators that import/translate NeuroML to their own internal formats.\n4. simulators that are supported through generation of simulator-specific scripts by the core NeuroML tools.\n5. export to other standardized formats which may allow simulation/analysis in other packages.","md":"3. simulators that import/translate NeuroML to their own internal formats.\n4. simulators that are supported through generation of simulator-specific scripts by the core NeuroML tools.\n5. export to other standardized formats which may allow simulation/analysis in other packages.","bBox":{"x":180.53,"y":635.5,"w":388.81,"h":41.99},"layoutAwareBbox":[{"x":177,"y":647,"w":396,"h":19,"startIndex":3,"endIndex":13},{"x":177,"y":668,"w":386,"h":9,"startIndex":0,"endIndex":277},{"x":177,"y":635,"w":302,"h":9,"startIndex":0,"endIndex":277}]},{"type":"text","value":"Each simulation engine supports a different set of features that NeuroML users can take advantage of (Table 7). For example, the reference NeuroML and LEMS simulators, jNeuroML, jLEMS, and PyLEMS, can simulate all LEMS models and most NeuroML models. They cannot, however, simulate","md":"Each simulation engine supports a different set of features that NeuroML users can take advantage of (Table 7). For example, the reference NeuroML and LEMS simulators, jNeuroML, jLEMS, and PyLEMS, can simulate all LEMS models and most NeuroML models. They cannot, however, simulate","bBox":{"x":168.53,"y":710.49,"w":404.05,"h":9},"layoutAwareBbox":[{"x":165,"y":686,"w":409,"h":33,"startIndex":0,"endIndex":280}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    17 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    17 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                   Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    17 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.998,"layout":[{"image":"page_17_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.054,"y":0.086,"w":0.886,"h":0.682},"isLikelyNoise":false},{"image":"page_17_text_1_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.867,"w":0.668,"h":0.042},"isLikelyNoise":false},{"image":"page_17_text_2_v2.jpg","confidence":0.94,"label":"text","bbox":{"x":0.29,"y":0.817,"w":0.648,"h":0.024},"isLikelyNoise":false},{"image":"page_17_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_17_text_3_v2.jpg","confidence":0.91,"label":"text","bbox":{"x":0.291,"y":0.845,"w":0.632,"h":0.012},"isLikelyNoise":false},{"image":"page_17_header_1_v2.jpg","confidence":0.91,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_17_number_1_v2.jpg","confidence":0.89,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.048,"h":0.01},"isLikelyNoise":false},{"image":"page_17_text_4_v2.jpg","confidence":0.88,"label":"text","bbox":{"x":0.29,"y":0.803,"w":0.494,"h":0.012},"isLikelyNoise":false},{"image":"page_17_figure_title_1_v2.jpg","confidence":0.83,"label":"figure_title","bbox":{"x":0.056,"y":0.066,"w":0.339,"h":0.012},"isLikelyNoise":false},{"image":"page_17_header_2_v2.jpg","confidence":0.58,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":true},{"image":"page_17_header_3_v2.jpg","confidence":0.58,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.01},"isLikelyNoise":true}]},{"page":18,"text":"Tools  and  resources    Neuroscience\n\n\na.\n\n\n\n\n\n\n\n\n\n\nOPEN SOURCE BRAIN  search projects    My Projects  Explore OSB  Help Admin  sanjay_ankur\nMultiscaleISN                         Return to project         Troubleshoot 3D explorer\n\nConnectivity                          Results  Run Play IPause       Stop Help\n\n\n\n\n\n\n\n\n\n\n>_ Console   Experiments\nC.  Open Source Brain v2.0    padraig\n    NetPyNE  File             View  Model  Examples  Help    BACK TO EDIT  SIMULATE\n                                                             n\n\n\n\n          G\n lah\n  -       0\n ulpp     O\n LFS\nPSD D\nLFP C\n  M\n RxD       2\n  *\n  4\n\n  B\n\n            -50    100    200\n  >                Time (ms)\n\nFigure 8. Visualization of detailed neuronal morphology of neurons and networks together with their functional\nproperties (results from model simulation) enabled by NeuroML. (a) Interactive 3-D (VisPy (Campagnola, 2023)\nbased) visualization of an olfactory bulb network with detailed mitral and granule cells (Migliore et al., 2014),\ngenerated using pyNeuroML. (b) Visualization of an inhibition stabilized network based on Sadeh et al., 2017\nusing Open Source Brain (OSB) version 1 (Gleeson et al., 2019b). (c) Visualization of 3D network of simplified\nmulti-compartmental cortical neurons (from Traub et al., 2005, imported as NeuroML Gleeson, 2019a) and\nsimulated spiking activity using NetPyNE’s GUI (Dura‐Bernal et al., 2019), which is embedded in OSB version 2.\n\n\n\n\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    18 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n**a.**\n\n[Interactive 3-D visualization showing a complex spherical network structure with multiple colored connections and nodes extending outward in various directions, representing an olfactory bulb network with detailed mitral and granule cells]\n\n**b.**\n\n[Screenshot of Open Source Brain (OSB) interface showing MultiscaleISN project with a network visualization displaying red and blue nodes connected by green lines against a dark background, with various control panels and options visible]\n\n**c.**\n\n[Screenshot of Open Source Brain v2.0 interface showing NetPyNE GUI with a network visualization of white neuronal structures against a dark background, along with control panels on the right side showing various parameters and a time-series plot displaying neural activity data over 200ms]\n\n**Figure 8.** Visualization of detailed neuronal morphology of neurons and networks together with their functional properties (results from model simulation) enabled by NeuroML. **(a)** Interactive 3-D (VisPy (*Campagnola, 2023*) based) visualization of an olfactory bulb network with detailed mitral and granule cells (*Migliore et al., 2014*), generated using pyNeuroML. **(b)** Visualization of an inhibition stabilized network based on *Sadeh et al., 2017* using Open Source Brain (OSB) version 1 (*Gleeson et al., 2019b*). **(c)** Visualization of 3D network of simplified multi-compartmental cortical neurons (from *Traub et al., 2005*, imported as NeuroML *Gleeson, 2019a*) and simulated spiking activity using NetPyNE's GUI (*Dura-Bernal et al., 2019*), which is embedded in OSB version 2.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    18 of 44\n","images":[{"name":"img_p17_1.jpg","height":527.12,"width":358.823,"x":174.64,"y":60.078,"original_width":1664,"original_height":2444,"rotation":0,"ocr":[{"x":1370,"y":2396,"w":78,"h":25,"confidence":0.943,"text":"Time (ms)"},{"x":114,"y":2401,"w":13,"h":18,"confidence":0.976,"text":">"},{"x":1518,"y":2383,"w":24,"h":15,"confidence":1,"text":"200"},{"x":1401,"y":2383,"w":24,"h":15,"confidence":1,"text":"100"},{"x":1225,"y":2383,"w":18,"h":13,"confidence":0.979,"text":"-50"},{"x":107,"y":2220,"w":28,"h":104,"confidence":0.298,"text":"B"},{"x":109,"y":2151,"w":26,"h":28,"confidence":0.674,"text":"4"},{"x":109,"y":2077,"w":26,"h":74,"confidence":0.433,"text":"*"},{"x":107,"y":2046,"w":26,"h":25,"confidence":0.731,"text":"RxD"},{"x":1170,"y":2044,"w":18,"h":145,"confidence":0.182,"text":"2"},{"x":112,"y":2011,"w":21,"h":26,"confidence":0.83,"text":"M"},{"x":109,"y":1973,"w":24,"h":25,"confidence":0.636,"text":"LFP C"},{"x":109,"y":1937,"w":24,"h":26,"confidence":0.763,"text":"PSD D"},{"x":109,"y":1902,"w":24,"h":23,"confidence":0.826,"text":"LFS"},{"x":109,"y":1869,"w":24,"h":23,"confidence":0.422,"text":"ulpp"},{"x":200,"y":1858,"w":13,"h":16,"confidence":0.423,"text":"O"},{"x":109,"y":1833,"w":24,"h":20,"confidence":0.892,"text":"-"},{"x":200,"y":1830,"w":13,"h":16,"confidence":0.165,"text":"0"},{"x":107,"y":1792,"w":28,"h":26,"confidence":0.543,"text":"lah"},{"x":198,"y":1739,"w":23,"h":23,"confidence":0.965,"text":"G"},{"x":1141,"y":1596,"w":13,"h":13,"confidence":0.407,"text":"n"},{"x":1399,"y":1558,"w":96,"h":18,"confidence":0.999,"text":"BACK TO EDIT"},{"x":598,"y":1558,"w":36,"h":20,"confidence":1,"text":"Help"},{"x":481,"y":1558,"w":65,"h":23,"confidence":1,"text":"Examples"},{"x":290,"y":1555,"w":39,"h":27,"confidence":1,"text":"View"},{"x":211,"y":1558,"w":28,"h":20,"confidence":1,"text":"File"},{"x":94,"y":1558,"w":62,"h":18,"confidence":0.999,"text":"NetPyNE"},{"x":1516,"y":1553,"w":75,"h":25,"confidence":0.999,"text":"SIMULATE"},{"x":382,"y":1556,"w":44,"h":20,"confidence":1,"text":"Model"},{"x":101,"y":1520,"w":177,"h":18,"confidence":0.973,"text":"Open Source Brain v2.0"},{"x":3,"y":1517,"w":36,"h":33,"confidence":0.752,"text":"C."},{"x":1551,"y":1512,"w":90,"h":34,"confidence":1,"text":"padraig"},{"x":83,"y":1469,"w":78,"h":25,"confidence":0.966,"text":">_ Console"},{"x":220,"y":1463,"w":116,"h":32,"confidence":0.961,"text":" Experiments"},{"x":166,"y":806,"w":128,"h":35,"confidence":0.935,"text":"Connectivity"},{"x":1144,"y":799,"w":83,"h":26,"confidence":0.976,"text":"Results"},{"x":1577,"y":791,"w":62,"h":35,"confidence":1,"text":"Help"},{"x":1497,"y":791,"w":67,"h":35,"confidence":1,"text":"Stop"},{"x":1409,"y":797,"w":70,"h":25,"confidence":0.934,"text":"IPause"},{"x":1336,"y":797,"w":58,"h":28,"confidence":1,"text":"Play"},{"x":1250,"y":791,"w":69,"h":35,"confidence":0.874,"text":" Run"},{"x":1399,"y":743,"w":218,"h":26,"confidence":0.999,"text":"Troubleshoot 3D explorer"},{"x":1196,"y":743,"w":169,"h":28,"confidence":0.999,"text":"Return to project"},{"x":70,"y":741,"w":164,"h":28,"confidence":0.986,"text":"MultiscaleISN"},{"x":1529,"y":680,"w":114,"h":28,"confidence":0.999,"text":"sanjay_ankur"},{"x":1459,"y":682,"w":49,"h":21,"confidence":1,"text":"Admin"},{"x":1396,"y":682,"w":42,"h":21,"confidence":1,"text":"Help"},{"x":1279,"y":680,"w":96,"h":25,"confidence":0.992,"text":"Explore OSB"},{"x":1156,"y":674,"w":103,"h":34,"confidence":0.997,"text":"My Projects"},{"x":377,"y":677,"w":112,"h":28,"confidence":0.969,"text":"search projects"},{"x":73,"y":675,"w":231,"h":35,"confidence":0.999,"text":"OPEN SOURCE BRAIN"},{"x":3,"y":8,"w":44,"h":35,"confidence":1,"text":"a."}]},{"name":"page_18.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_18_image_1_v2.jpg","height":423300.828,"width":226164.252,"x":103179.299,"y":43246.001,"original_width":1494,"original_height":2160,"rotation":0,"type":"layout_v2_image"},{"name":"page_18_figure_title_1_v2.jpg","height":59771.947,"width":243310.128,"x":101505.861,"y":475045.649,"original_width":1607,"original_height":305,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_18_footer_1_v2.jpg","height":6926.17,"width":191747.073,"x":21738.72,"y":591406.884,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_18_header_1_v2.jpg","height":5584.978,"width":30302.018,"x":320850.292,"y":27667.952,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_18_number_1_v2.jpg","height":5784.981,"width":17663.316,"x":333449.238,"y":591784.85,"original_width":117,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_18_header_2_v2.jpg","height":5721.167,"width":43005.834,"x":47804.077,"y":27832.84,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_18_header_3_v2.jpg","height":10706.986,"width":24451.353,"x":21854.275,"y":22375.99,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"**a.**","md":"**a.**","bBox":{"x":175.29,"y":61.8,"w":28.46,"h":462.2},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":534,"startIndex":0,"endIndex":5}]},{"type":"text","value":"[Interactive 3-D visualization showing a complex spherical network structure with multiple colored connections and nodes extending outward in various directions, representing an olfactory bulb network with detailed mitral and granule cells]","md":"[Interactive 3-D visualization showing a complex spherical network structure with multiple colored connections and nodes extending outward in various directions, representing an olfactory bulb network with detailed mitral and granule cells]","bBox":{"x":197.71,"y":404.3,"w":225.77,"h":157.01},"layoutAwareBbox":[{"x":197.71,"y":404.3,"w":225.77,"h":157.01,"startIndex":0,"endIndex":239}]},{"type":"text","value":"**b.**","md":"**b.**","bBox":{"x":197.71,"y":508.04,"w":6.04,"h":53.27},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":534,"startIndex":0,"endIndex":5}]},{"type":"text","value":"[Screenshot of Open Source Brain (OSB) interface showing MultiscaleISN project with a network visualization displaying red and blue nodes connected by green lines against a dark background, with various control panels and options visible]","md":"[Screenshot of Open Source Brain (OSB) interface showing MultiscaleISN project with a network visualization displaying red and blue nodes connected by green lines against a dark background, with various control panels and options visible]","bBox":{"x":189.73,"y":205.66,"w":233.75,"h":258.6},"layoutAwareBbox":[{"x":189.73,"y":205.66,"w":233.75,"h":258.6,"startIndex":0,"endIndex":237}]},{"type":"text","value":"**c.**","md":"**c.**","bBox":{"x":175.29,"y":387.26,"w":28.46,"h":136.74},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":534,"startIndex":0,"endIndex":5}]},{"type":"text","value":"[Screenshot of Open Source Brain v2.0 interface showing NetPyNE GUI with a network visualization of white neuronal structures against a dark background, along with control panels on the right side showing various parameters and a time-series plot displaying neural activity data over 200ms]","md":"[Screenshot of Open Source Brain v2.0 interface showing NetPyNE GUI with a network visualization of white neuronal structures against a dark background, along with control panels on the right side showing various parameters and a time-series plot displaying neural activity data over 200ms]","bBox":{"x":194.91,"y":387.91,"w":312.25,"h":189.37},"layoutAwareBbox":[{"x":194.91,"y":387.91,"w":312.25,"h":189.37,"startIndex":0,"endIndex":289}]},{"type":"text","value":"**Figure 8.** Visualization of detailed neuronal morphology of neurons and networks together with their functional properties (results from model simulation) enabled by NeuroML. **(a)** Interactive 3-D (VisPy (*Campagnola, 2023*) based) visualization of an olfactory bulb network with detailed mitral and granule cells (*Migliore et al., 2014*), generated using pyNeuroML. **(b)** Visualization of an inhibition stabilized network based on *Sadeh et al., 2017* using Open Source Brain (OSB) version 1 (*Gleeson et al., 2019b*). **(c)** Visualization of 3D network of simplified multi-compartmental cortical neurons (from *Traub et al., 2005*, imported as NeuroML *Gleeson, 2019a*) and simulated spiking activity using NetPyNE's GUI (*Dura-Bernal et al., 2019*), which is embedded in OSB version 2.","md":"**Figure 8.** Visualization of detailed neuronal morphology of neurons and networks together with their functional properties (results from model simulation) enabled by NeuroML. **(a)** Interactive 3-D (VisPy (*Campagnola, 2023*) based) visualization of an olfactory bulb network with detailed mitral and granule cells (*Migliore et al., 2014*), generated using pyNeuroML. **(b)** Visualization of an inhibition stabilized network based on *Sadeh et al., 2017* using Open Source Brain (OSB) version 1 (*Gleeson et al., 2019b*). **(c)** Visualization of 3D network of simplified multi-compartmental cortical neurons (from *Traub et al., 2005*, imported as NeuroML *Gleeson, 2019a*) and simulated spiking activity using NetPyNE's GUI (*Dura-Bernal et al., 2019*), which is embedded in OSB version 2.","bBox":{"x":190.38,"y":205.66,"w":327.34,"h":371.62},"layoutAwareBbox":[{"x":165,"y":599,"w":397,"h":75,"startIndex":71,"endIndex":74}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    18 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    18 of 44","bBox":{"x":198.14,"y":404.3,"w":376.85,"h":350.46},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":28,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    18 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.784,"layout":[{"image":"page_18_image_1_v2.jpg","confidence":0.98,"label":"image","bbox":{"x":0.275,"y":0.069,"w":0.604,"h":0.675},"isLikelyNoise":false},{"image":"page_18_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.271,"y":0.757,"w":0.65,"h":0.095},"isLikelyNoise":false},{"image":"page_18_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_18_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_18_number_1_v2.jpg","confidence":0.86,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.047,"h":0.009},"isLikelyNoise":false},{"image":"page_18_header_2_v2.jpg","confidence":0.69,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_18_header_3_v2.jpg","confidence":0.57,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":19,"text":"Tools  and  resources    Neuroscience\n\n\n\na.    L23    b.      Chemical conns (number of conns)                           70000\n\nHL23PYR pop          HL23PV_pop                                                 60000\n 400 cells\n                                                                                50000\n                   20\nHL23SST_pop    HL23PYR_pop                                                      4000020\n  25 cells\n\n               HL23SST_pop                                                      30000\n\nHL23VIP_ pop                                                            -20000\n  40 celIs\n               HL23VIP_pop                                                      10000\n\n HL23PV_pop                        H.23BR Dp\n                     H.23V Pp  H.23ST op\n  35 cells                                                              HL23V Pp\n                              postsynaptic\n\nFigure 9. Analysis and visualization of network connectivity from NeuroML model descriptions prior to simulation.\nNetwork connectivity schematic (a) and connectivity matrix (b) for a half scale implementation of the human layer\n2/3 cortical network model (Yao et al., 2022) generated using pyNeuroML.\n\n\nmulti-compartmental models, and users should opt for a simulator that does, e.g., NEURON (Hines\nand Carnevale, 1997) or EDEN (Panagiotou et al., 2022).\nAnother criteria that is relevant when choosing a simulation engine is the efﬁciency of simulation.\nSimulation engines implement different computing techniques—e.g., NetPyNE, Arbor, and EDEN\nsupport parallel execution on clusters and super computers via MPI—to enable simulation of large-\nscale models. Thus, for efﬁcient large-  scale simulation, users may prefer one of these simulation\nengines.\nThe preferred programming language for working with NeuroML is Python (Muller et al., 2015).\nA Python- based ecosystem ensures that automated simulation of models can easily be carried out\neither using scripts, or the command line tools. Utilities to enable the execution of simulations on\ndedicated supercomputing resources, such as the Neuroscience Gateway (NSG) (Sivagnanam, 2013;\n\n\nTable 7. Features supported by NeuroML in different simulation engines.\nNote: the simulators themselves may support more features, but these have not been mapped onto by the NeuroML tools.\nAbstract cell models: abstract cell models included in the NeuroML standard (see Table 1). Single compartmental cells: neuronal\nmodels that include a single compartment (these engines do not support multi-compartmental cells). Multiple compartmental cells:\nneuronal models that include multiple compartments. Conductance-based models: models that support ionic conductances. Parallel\nexecution: engines that support parallel execution using MPI/GPUs. Y: full support; N: no support; L: limited support in NeuroML\ntoolchain.\n                       Abstract cell     Single compartment     Multiple compartment     Conductance- based     Parallel\nTool                   models            cells                  cells                    models                 execution\n\njNeuroML/pyNeuroML     Y                 Y                      N                        Y                      N\n\nNEURON                 Y                 Y                      Y                        Y                      N\n\nNetPyNE                Y                 Y                      Y                        Y                      Y\n\nEDEN                   Y                 Y                      Y                        Y                      Y\n\nMOOSE                  Y                 Y                      L                        Y                      N\n\nPyNN                   Y                 Y                      L                        L                      Y\n\nNEST                   Y                 Y                      N                        N                      Y\n\nBrian2                 Y                 Y                      Y                        Y                      L\n\nArbor                  L                 Y                      Y                        L                      Y\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    19 of 44","md":"\n\n**Figure 9.** Analysis and visualization of network connectivity from NeuroML model descriptions prior to simulation. Network connectivity schematic (a) and connectivity matrix (b) for a half scale implementation of the human layer 2/3 cortical network model (Yao et al., 2022) generated using pyNeuroML.\n\n<table>\n<thead>\n<tr>\n<th>Network Schematic (a)</th>\n<th>Connectivity Matrix (b)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\nNetwork nodes:<br>\n• HL23PYR_pop (400 cells) - Red<br>\n• HL23SST_pop (25 cells) - Green<br>\n• HL23VIP_pop (40 cells) - Gray<br>\n• HL23PV_pop (35 cells) - Blue<br>\n<br>\nConnections shown with arrows between populations\n</td>\n<td>\n\n<table>\n<thead>\n<tr>\n<th>presynaptic \\ postsynaptic</th>\n<th>HL23PV_pop</th>\n<th>HL23PYR_pop</th>\n<th>HL23SST_pop</th>\n<th>HL23VIP_pop</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>HL23PV_pop</td>\n<td>~10000</td>\n<td>~25000</td>\n<td>~15000</td>\n<td>~5000</td>\n</tr>\n<tr>\n<td>HL23PYR_pop</td>\n<td>~70000</td>\n<td>~20000</td>\n<td>~25000</td>\n<td>~15000</td>\n</tr>\n<tr>\n<td>HL23SST_pop</td>\n<td>~15000</td>\n<td>~5000</td>\n<td>~5000</td>\n<td>~10000</td>\n</tr>\n<tr>\n<td>HL23VIP_pop</td>\n<td>~0</td>\n<td>~5000</td>\n<td>~15000</td>\n<td>~5000</td>\n</tr>\n</tbody>\n</table>\n\n</td>\n</tr>\n</tbody>\n</table>\n\nmulti-compartmental models, and users should opt for a simulator that does, e.g., NEURON (Hines and Carnevale, 1997) or EDEN (Panagiotou et al., 2022).\n\nAnother criteria that is relevant when choosing a simulation engine is the efficiency of simulation. Simulation engines implement different computing techniques—e.g., NetPyNE, Arbor, and EDEN support parallel execution on clusters and super computers via MPI—to enable simulation of large-scale models. Thus, for efficient large-scale simulation, users may prefer one of these simulation engines.\n\nThe preferred programming language for working with NeuroML is Python (Muller et al., 2015). A Python-based ecosystem ensures that automated simulation of models can easily be carried out either using scripts, or the command line tools. Utilities to enable the execution of simulations on dedicated supercomputing resources, such as the Neuroscience Gateway (NSG) (Sivagnanam, 2013;\n\n**Table 7.** Features supported by NeuroML in different simulation engines.\n\nNote: the simulators themselves may support more features, but these have not been mapped onto by the NeuroML tools. Abstract cell models: abstract cell models included in the NeuroML standard (see Table 1). Single compartmental cells: neuronal models that include a single compartment (these engines do not support multi-compartmental cells). Multiple compartmental cells: neuronal models that include multiple compartments. Conductance-based models: models that support ionic conductances. Parallel execution: engines that support parallel execution using MPI/GPUs. Y: full support; N: no support; L: limited support in NeuroML toolchain.\n\n<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Abstract cell models</th>\n<th>Single compartment cells</th>\n<th>Multiple compartment cells</th>\n<th>Conductance-based models</th>\n<th>Parallel execution</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jNeuroML/pyNeuroML</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>NEURON</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>NetPyNE</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>EDEN</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>MOOSE</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>PyNN</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>L</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>NEST</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>Brian2</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n</tr>\n<tr>\n<td>Arbor</td>\n<td>L</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>Y</td>\n</tr>\n</tbody>\n</table>\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    19 of 44\n","images":[{"name":"img_p18_1.png","height":185.201,"width":393.72,"x":174.639,"y":60.034,"original_width":1653,"original_height":777,"rotation":0,"ocr":[{"x":1019,"y":723,"w":214,"h":47,"confidence":1,"text":"postsynaptic"},{"x":234,"y":655,"w":114,"h":36,"confidence":0.921,"text":"35 cells"},{"x":1194,"y":627,"w":150,"h":99,"confidence":0.64,"text":"HL23V Pp"},{"x":1049,"y":627,"w":156,"h":103,"confidence":0.699,"text":"H.23ST op"},{"x":908,"y":626,"w":158,"h":106,"confidence":0.626,"text":"H.23BR Dp"},{"x":780,"y":627,"w":143,"h":98,"confidence":0.712,"text":"H.23V Pp"},{"x":198,"y":626,"w":188,"h":42,"confidence":0.973,"text":"HL23PV_pop"},{"x":678,"y":527,"w":150,"h":33,"confidence":0.993,"text":"HL23VIP_pop"},{"x":1526,"y":524,"w":77,"h":24,"confidence":1,"text":"10000"},{"x":236,"y":491,"w":110,"h":31,"confidence":0.928,"text":"40 celIs"},{"x":194,"y":456,"w":196,"h":46,"confidence":0.983,"text":"HL23VIP_ pop"},{"x":1522,"y":444,"w":79,"h":26,"confidence":0.973,"text":"-20000"},{"x":673,"y":387,"w":157,"h":33,"confidence":0.983,"text":"HL23SST_pop"},{"x":1526,"y":364,"w":75,"h":26,"confidence":1,"text":"30000"},{"x":195,"y":321,"w":111,"h":31,"confidence":0.964,"text":"25 cells"},{"x":149,"y":287,"w":201,"h":45,"confidence":0.982,"text":"HL23SST_pop"},{"x":1526,"y":283,"w":79,"h":31,"confidence":1,"text":"40000"},{"x":1601,"y":263,"w":42,"h":138,"confidence":0.412,"text":"20"},{"x":673,"y":242,"w":159,"h":38,"confidence":0.998,"text":"HL23PYR_pop"},{"x":639,"y":236,"w":41,"h":194,"confidence":0.833,"text":"20"},{"x":1526,"y":206,"w":75,"h":25,"confidence":0.999,"text":"50000"},{"x":258,"y":152,"w":133,"h":36,"confidence":0.808,"text":"400 cells"},{"x":223,"y":121,"w":204,"h":44,"confidence":0.983,"text":"HL23PYR pop"},{"x":1526,"y":127,"w":75,"h":26,"confidence":1,"text":"60000"},{"x":685,"y":102,"w":145,"h":37,"confidence":0.983,"text":"HL23PV_pop"},{"x":276,"y":50,"w":60,"h":33,"confidence":1,"text":"L23"},{"x":3,"y":47,"w":45,"h":36,"confidence":0.999,"text":"a."},{"x":1526,"y":47,"w":75,"h":26,"confidence":1,"text":"70000"},{"x":587,"y":38,"w":48,"h":45,"confidence":1,"text":"b."},{"x":842,"y":14,"w":568,"h":35,"confidence":0.974,"text":"Chemical conns (number of conns)"}]},{"name":"page_19.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_19_table_1_v2.jpg","height":132321.478,"width":331229.005,"x":20764.052,"y":436659.64,"original_width":2188,"original_height":676,"rotation":0,"type":"layout_v2_table"},{"name":"page_19_text_1_v2.jpg","height":45135.565,"width":250199.137,"x":101226.94,"y":268706.548,"original_width":1652,"original_height":231,"rotation":0,"type":"layout_v2_text"},{"name":"page_19_text_2_v2.jpg","height":36362.278,"width":250135.734,"x":101330.645,"y":316198.352,"original_width":1652,"original_height":186,"rotation":0,"type":"layout_v2_text"},{"name":"page_19_text_3_v2.jpg","height":17049.074,"width":250010.603,"x":101314.545,"y":249440.095,"original_width":1651,"original_height":87,"rotation":0,"type":"layout_v2_text"},{"name":"page_19_figure_title_1_v2.jpg","height":24799.646,"width":247286.564,"x":101421.229,"y":204198.62,"original_width":1633,"original_height":127,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_19_footer_1_v2.jpg","height":6992.092,"width":192141.549,"x":21421.667,"y":591470.551,"original_width":1269,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_19_header_1_v2.jpg","height":5722.341,"width":30443.324,"x":320826.817,"y":27627.45,"original_width":202,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_19_number_1_v2.jpg","height":5965.613,"width":17784.812,"x":333368.301,"y":591777.774,"original_width":118,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_19_header_2_v2.jpg","height":5830.916,"width":42813.752,"x":47782.534,"y":27712.709,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_19_figure_title_2_v2.jpg","height":55585.175,"width":328104.272,"x":20300.705,"y":376742.481,"original_width":2167,"original_height":284,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_19_image_1_v2.jpg","height":154268.371,"width":248147.705,"x":102681.101,"y":44028.459,"original_width":1639,"original_height":788,"rotation":0,"type":"layout_v2_image"},{"name":"page_19_header_3_v2.jpg","height":10691.877,"width":24469.998,"x":21785.21,"y":22322.608,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_19_image_2_v2.jpg","height":131187.945,"width":76505.541,"x":110294.257,"y":54790.683,"original_width":506,"original_height":670,"rotation":0,"type":"layout_v2_image"},{"name":"page_19_figure_title_3_v2.jpg","height":7728.735,"width":181197.068,"x":21047.876,"y":368239.937,"original_width":1197,"original_height":40,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_19_chart_1_v2.jpg","height":145948.17,"width":150381.157,"x":198001.284,"y":48443.079,"original_width":993,"original_height":745,"rotation":0,"type":"layout_v2_chart"}],"charts":[],"items":[{"type":"text","value":"**Figure 9.** Analysis and visualization of network connectivity from NeuroML model descriptions prior to simulation. Network connectivity schematic (a) and connectivity matrix (b) for a half scale implementation of the human layer 2/3 cortical network model (Yao et al., 2022) generated using pyNeuroML.","md":"**Figure 9.** Analysis and visualization of network connectivity from NeuroML model descriptions prior to simulation. Network connectivity schematic (a) and connectivity matrix (b) for a half scale implementation of the human layer 2/3 cortical network model (Yao et al., 2022) generated using pyNeuroML.","bBox":{"x":152,"y":116.29,"w":184.61,"h":532.9},"layoutAwareBbox":[{"x":165,"y":257,"w":404,"h":31,"startIndex":0,"endIndex":303}]},{"type":"table","rows":[["Network Schematic (a)","Connectivity Matrix (b)"],["Network nodes:<br/>• HL23PYR_pop (400 cells) - Red<br/>• HL23SST_pop (25 cells) - Green<br/>• HL23VIP_pop (40 cells) - Gray<br/>• HL23PV_pop (35 cells) - Blue<br/><br/>Connections shown with arrows between populations","presynaptic \\ postsynaptic\tHL23PV_pop\tHL23PYR_pop\tHL23SST_pop\tHL23VIP_popHL23PV_pop\t~10000\t~25000\t~15000\t~5000\nHL23PYR_pop\t~70000\t~20000\t~25000\t~15000\nHL23SST_pop\t~15000\t~5000\t~5000\t~10000\nHL23VIP_pop\t~0\t~5000\t~15000\t~5000"]],"html":"<table>\n<thead>\n<tr>\n<th>Network Schematic (a)</th>\n<th>Connectivity Matrix (b)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\nNetwork nodes:<br />\n• HL23PYR_pop (400 cells) - Red<br />\n• HL23SST_pop (25 cells) - Green<br />\n• HL23VIP_pop (40 cells) - Gray<br />\n• HL23PV_pop (35 cells) - Blue<br />\n<br />\nConnections shown with arrows between populations\n</td>\n<td>\n\n<table>\n<thead>\n<tr>\n<th>presynaptic \\ postsynaptic</th>\n<th>HL23PV_pop</th>\n<th>HL23PYR_pop</th>\n<th>HL23SST_pop</th>\n<th>HL23VIP_pop</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>HL23PV_pop</td>\n<td>~10000</td>\n<td>~25000</td>\n<td>~15000</td>\n<td>~5000</td>\n</tr>\n<tr>\n<td>HL23PYR_pop</td>\n<td>~70000</td>\n<td>~20000</td>\n<td>~25000</td>\n<td>~15000</td>\n</tr>\n<tr>\n<td>HL23SST_pop</td>\n<td>~15000</td>\n<td>~5000</td>\n<td>~5000</td>\n<td>~10000</td>\n</tr>\n<tr>\n<td>HL23VIP_pop</td>\n<td>~0</td>\n<td>~5000</td>\n<td>~15000</td>\n<td>~5000</td>\n</tr>\n</tbody>\n</table></td></tr></tbody></table>","md":"| Network Schematic (a)                                                                                                                                                                                                         | Connectivity Matrix (b)                                                                                                                                                                                                                                            |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| Network nodes:<br/>• HL23PYR\\_pop (400 cells) - Red<br/>• HL23SST\\_pop (25 cells) - Green<br/>• HL23VIP\\_pop (40 cells) - Gray<br/>• HL23PV\\_pop (35 cells) - Blue<br/><br/>Connections shown with arrows between populations | presynaptic \\ postsynaptic\tHL23PV\\_pop\tHL23PYR\\_pop\tHL23SST\\_pop\tHL23VIP\\_popHL23PV\\_pop\t\\~10000\t\\~25000\t\\~15000\t\\~5000&#xA;HL23PYR\\_pop\t\\~70000\t\\~20000\t\\~25000\t\\~15000&#xA;HL23SST\\_pop\t\\~15000\t\\~5000\t\\~5000\t\\~10000&#xA;HL23VIP\\_pop\t\\~0\t\\~5000\t\\~15000\t\\~5000 |","isPerfectTable":false,"csv":"\"Network Schematic (a)\",\"Connectivity Matrix (b)\"\n\"Network nodes:<br/>• HL23PYR_pop (400 cells) - Red<br/>• HL23SST_pop (25 cells) - Green<br/>• HL23VIP_pop (40 cells) - Gray<br/>• HL23PV_pop (35 cells) - Blue<br/><br/>Connections shown with arrows between populations\",\"presynaptic \\ postsynaptic\tHL23PV_pop\tHL23PYR_pop\tHL23SST_pop\tHL23VIP_popHL23PV_pop\t~10000\t~25000\t~15000\t~5000\nHL23PYR_pop\t~70000\t~20000\t~25000\t~15000\nHL23SST_pop\t~15000\t~5000\t~5000\t~10000\nHL23VIP_pop\t~0\t~5000\t~15000\t~5000\"","bBox":{"x":168.53,"y":268.82,"w":399.87,"h":8},"layoutAwareBbox":[{"x":168.53,"y":268.82,"w":399.87,"h":8,"startIndex":0,"endIndex":1459}]},{"type":"text","value":"</td>\n</tr>\n</tbody>\n</table>","md":"</td>\n</tr>\n</tbody>\n</table>","bBox":{"x":152,"y":576.99,"w":166,"h":72.19},"layoutAwareBbox":[{"x":152,"y":576.99,"w":166,"h":72.19,"startIndex":0,"endIndex":28}]},{"type":"text","value":"multi-compartmental models, and users should opt for a simulator that does, e.g., NEURON (Hines and Carnevale, 1997) or EDEN (Panagiotou et al., 2022).","md":"multi-compartmental models, and users should opt for a simulator that does, e.g., NEURON (Hines and Carnevale, 1997) or EDEN (Panagiotou et al., 2022).","bBox":{"x":36.5,"y":116.29,"w":535.05,"h":516.85},"layoutAwareBbox":[{"x":165,"y":314,"w":408,"h":21,"startIndex":0,"endIndex":5}]},{"type":"text","value":"Another criteria that is relevant when choosing a simulation engine is the efficiency of simulation. Simulation engines implement different computing techniques—e.g., NetPyNE, Arbor, and EDEN support parallel execution on clusters and super computers via MPI—to enable simulation of large-scale models. Thus, for efficient large-scale simulation, users may prefer one of these simulation engines.","md":"Another criteria that is relevant when choosing a simulation engine is the efficiency of simulation. Simulation engines implement different computing techniques—e.g., NetPyNE, Arbor, and EDEN support parallel execution on clusters and super computers via MPI—to enable simulation of large-scale models. Thus, for efficient large-scale simulation, users may prefer one of these simulation engines.","bBox":{"x":152,"y":350.78,"w":415.72,"h":298.4},"layoutAwareBbox":[{"x":165,"y":339,"w":408,"h":56,"startIndex":112,"endIndex":119}]},{"type":"text","value":"The preferred programming language for working with NeuroML is Python (Muller et al., 2015). A Python-based ecosystem ensures that automated simulation of models can easily be carried out either using scripts, or the command line tools. Utilities to enable the execution of simulations on dedicated supercomputing resources, such as the Neuroscience Gateway (NSG) (Sivagnanam, 2013;","md":"The preferred programming language for working with NeuroML is Python (Muller et al., 2015). A Python-based ecosystem ensures that automated simulation of models can easily be carried out either using scripts, or the command line tools. Utilities to enable the execution of simulations on dedicated supercomputing resources, such as the Neuroscience Gateway (NSG) (Sivagnanam, 2013;","bBox":{"x":152,"y":116.29,"w":426.23,"h":532.9},"layoutAwareBbox":[{"x":165,"y":399,"w":408,"h":45,"startIndex":63,"endIndex":69}]},{"type":"text","value":"**Table 7.** Features supported by NeuroML in different simulation engines.","md":"**Table 7.** Features supported by NeuroML in different simulation engines.","bBox":{"x":152,"y":386.77,"w":168.22,"h":262.41},"layoutAwareBbox":[{"x":34,"y":464,"w":296,"h":9,"startIndex":0,"endIndex":74}]},{"type":"text","value":"Note: the simulators themselves may support more features, but these have not been mapped onto by the NeuroML tools. Abstract cell models: abstract cell models included in the NeuroML standard (see Table 1). Single compartmental cells: neuronal models that include a single compartment (these engines do not support multi-compartmental cells). Multiple compartmental cells: neuronal models that include multiple compartments. Conductance-based models: models that support ionic conductances. Parallel execution: engines that support parallel execution using MPI/GPUs. Y: full support; N: no support; L: limited support in NeuroML toolchain.","md":"Note: the simulators themselves may support more features, but these have not been mapped onto by the NeuroML tools. Abstract cell models: abstract cell models included in the NeuroML standard (see Table 1). Single compartmental cells: neuronal models that include a single compartment (these engines do not support multi-compartmental cells). Multiple compartmental cells: neuronal models that include multiple compartments. Conductance-based models: models that support ionic conductances. Parallel execution: engines that support parallel execution using MPI/GPUs. Y: full support; N: no support; L: limited support in NeuroML toolchain.","bBox":{"x":36.5,"y":476.77,"w":535.44,"h":124.27},"layoutAwareBbox":[{"x":33,"y":475,"w":536,"h":70,"startIndex":630,"endIndex":639}]},{"type":"table","rows":[["Tool","Abstract cell models","Single compartment cells","Multiple compartment cells","Conductance-based models","Parallel execution"],["jNeuroML/pyNeuroML","Y","Y","N","Y","N"],["NEURON","Y","Y","Y","Y","N"],["NetPyNE","Y","Y","Y","Y","Y"],["EDEN","Y","Y","Y","Y","Y"],["MOOSE","Y","Y","L","Y","N"],["PyNN","Y","Y","L","L","Y"],["NEST","Y","Y","N","N","Y"],["Brian2","Y","Y","Y","Y","L"],["Arbor","L","Y","Y","L","Y"]],"html":"<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Abstract cell models</th>\n<th>Single compartment cells</th>\n<th>Multiple compartment cells</th>\n<th>Conductance-based models</th>\n<th>Parallel execution</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jNeuroML/pyNeuroML</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>NEURON</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>NetPyNE</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>EDEN</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>MOOSE</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>PyNN</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>L</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>NEST</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>Brian2</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n</tr>\n<tr>\n<td>Arbor</td>\n<td>L</td>\n<td>Y</td>\n<td>Y</td>\n<td>L</td>\n<td>Y</td>\n</tr>\n</tbody>\n</table>","md":"| Tool               | Abstract cell models | Single compartment cells | Multiple compartment cells | Conductance-based models | Parallel execution |\n| ------------------ | -------------------- | ------------------------ | -------------------------- | ------------------------ | ------------------ |\n| jNeuroML/pyNeuroML | Y                    | Y                        | N                          | Y                        | N                  |\n| NEURON             | Y                    | Y                        | Y                          | Y                        | N                  |\n| NetPyNE            | Y                    | Y                        | Y                          | Y                        | Y                  |\n| EDEN               | Y                    | Y                        | Y                          | Y                        | Y                  |\n| MOOSE              | Y                    | Y                        | L                          | Y                        | N                  |\n| PyNN               | Y                    | Y                        | L                          | L                        | Y                  |\n| NEST               | Y                    | Y                        | N                          | N                        | Y                  |\n| Brian2             | Y                    | Y                        | Y                          | Y                        | L                  |\n| Arbor              | L                    | Y                        | Y                          | L                        | Y                  |","isPerfectTable":true,"csv":"\"Tool\",\"Abstract cell models\",\"Single compartment cells\",\"Multiple compartment cells\",\"Conductance-based models\",\"Parallel execution\"\n\"jNeuroML/pyNeuroML\",\"Y\",\"Y\",\"N\",\"Y\",\"N\"\n\"NEURON\",\"Y\",\"Y\",\"Y\",\"Y\",\"N\"\n\"NetPyNE\",\"Y\",\"Y\",\"Y\",\"Y\",\"Y\"\n\"EDEN\",\"Y\",\"Y\",\"Y\",\"Y\",\"Y\"\n\"MOOSE\",\"Y\",\"Y\",\"L\",\"Y\",\"N\"\n\"PyNN\",\"Y\",\"Y\",\"L\",\"L\",\"Y\"\n\"NEST\",\"Y\",\"Y\",\"N\",\"N\",\"Y\"\n\"Brian2\",\"Y\",\"Y\",\"Y\",\"Y\",\"L\"\n\"Arbor\",\"L\",\"Y\",\"Y\",\"L\",\"Y\"","bBox":{"x":36.5,"y":34.63,"w":541.72,"h":720.13},"layoutAwareBbox":[{"x":33,"y":551,"w":541,"h":167,"startIndex":2,"endIndex":6}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    19 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    19 of 44","bBox":{"x":314,"y":116.29,"w":260.99,"h":638.47},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    19 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.945,"layout":[{"image":"page_19_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.055,"y":0.696,"w":0.884,"h":0.211},"isLikelyNoise":false},{"image":"page_19_text_1_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.428,"w":0.668,"h":0.072},"isLikelyNoise":false},{"image":"page_19_text_2_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.271,"y":0.504,"w":0.668,"h":0.058},"isLikelyNoise":false},{"image":"page_19_text_3_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.271,"y":0.398,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_19_figure_title_1_v2.jpg","confidence":0.95,"label":"figure_title","bbox":{"x":0.271,"y":0.326,"w":0.66,"h":0.04},"isLikelyNoise":false},{"image":"page_19_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_19_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_19_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.89,"y":0.943,"w":0.047,"h":0.01},"isLikelyNoise":false},{"image":"page_19_header_2_v2.jpg","confidence":0.78,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_19_figure_title_2_v2.jpg","confidence":0.65,"label":"figure_title","bbox":{"x":0.054,"y":0.601,"w":0.876,"h":0.089},"isLikelyNoise":false},{"image":"page_19_image_1_v2.jpg","confidence":0.61,"label":"image","bbox":{"x":0.274,"y":0.07,"w":0.663,"h":0.246},"isLikelyNoise":false},{"image":"page_19_header_3_v2.jpg","confidence":0.6,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false},{"image":"page_19_image_2_v2.jpg","confidence":0.59,"label":"image","bbox":{"x":0.294,"y":0.087,"w":0.204,"h":0.209},"isLikelyNoise":true},{"image":"page_19_figure_title_3_v2.jpg","confidence":0.54,"label":"figure_title","bbox":{"x":0.056,"y":0.587,"w":0.484,"h":0.012},"isLikelyNoise":true},{"image":"page_19_chart_1_v2.jpg","confidence":0.52,"label":"chart","bbox":{"x":0.529,"y":0.077,"w":0.402,"h":0.233},"isLikelyNoise":true}]},{"page":20,"text":"Tools  and  resources  Neuroscience\n\na.  Search  Gallery  API  Documentation  About  NeuroML Home\n\nLayer 5b Pyramidal cell\n\nOverview  Electrophysiology  Morphology  Computational Complexity\n\nCurrent Clamp Response\n\nProtocol:  Stimulus: ALL\nSquare (Long)  V\n40.00\n20.00\n2 0.000  0\n-20.0\n-40.0\n-60.0\n-80.0\n-100.  290  580\n0.008  870  1160  1450  1740  2030  2320  2610  2900  3250\n1.200  Time (ms)  8\n1.000\n2 0.800  2\n0.600\n0.400\n0.200\n0.000\n-0.20\n0.008  290  580  870  1160  1450  1740  2030  2320  2610  2900  3250\nTime (ms)\n\nb.  1.0  8  na channel m tau\n\n200.8  20₆  na_channel h tau\n0.6  na_channel m inf\n0.4  na_channel h inf  4\n\n0.2  2\n\n0.0  0\n-100  -50  0  50  100  -100  -50  0  50  100\nMembrane potential (mV)  Membrane potential (mV)\n\nC.\n140\n\n100  120\n\n2 0  100\n-100  80 2\n-60\n-200  40\n-200  0  200  400x (μm) 600  800  1000  1200   20\n\n\n  Figure 10. Examples of visualizing biophysical properties of a NeuroML model neuron. (a) Electrophysiological\n  properties generated by the NeuroML-DB web-based platform (Birgiolas et al., 2023). (Plots show four\n  superimposed voltage traces in the top panel and corresponding current injection traces below). (b) Example\n  plots of steady states of activation (na_channel na_m inf) and inactivation (na_channel na_h inf) variables and their\n  time courses (na_channel na_m tau and na_channel na_h tau) for the Na channel from the classic Hodgkin Huxley\n  model (Hodgkin and Huxley, 1952). (c) The distribution of the peak conductances for the Ih channel over a layer\n  5 Pyramidal cell (Hay et al., 2011). Both (b) and (c) were generated using the analysis features in pyNeuroML, and\n  similar functionality is also available in OSBv1 (Gleeson et al., 2019b).\n\n\n\n\n\n\n\n  Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    20 of 44","md":"\n\neLife Tools and resources                                                                                                                                           Neuroscience\n\n**Figure 10.** Examples of visualizing biophysical properties of a NeuroML model neuron. **(a)** Electrophysiological properties generated by the NeuroML-DB web-based platform (Birgiolas et al., 2023). The interface shows a \"Layer 5b Pyramidal cell\" with tabs for Overview, Electrophysiology, Morphology, and Computational Complexity. The Current Clamp Response section displays a Square (Long) protocol with stimulus ALL, showing voltage traces ranging from -100 to 40.00 mV over time (0.008 to 3250 ms) in the top panel, and corresponding current traces ranging from -0.20 to 1.200 in the bottom panel. **(b)** Example plots of steady states of activation (na_channel na_m inf) and inactivation (na_channel na_h inf) variables and their time courses (na_channel na_m tau and na_channel na_h tau) for the Na channel from the classic Hodgkin Huxley model (Hodgkin and Huxley, 1952). The left graph shows steady state curves plotted against membrane potential (-100 to 100 mV), while the right graph shows time constants with na_channel m tau peaking around 8 and na_channel h tau remaining low across the voltage range. **(c)** The distribution of the peak conductances for the Ih channel over a layer 5 Pyramidal cell (Hay et al., 2011), displayed as a morphological visualization with a color scale ranging from 20 to 140 (S/m²), showing the dendritic tree structure with conductance values color-coded from purple (low) to yellow (high). Both **(b)** and **(c)** were generated using the analysis features in pyNeuroML, and similar functionality is also available in OSBv1 (Gleeson et al., 2019b).\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    20 of 44\n","images":[{"name":"img_p19_1.jpg","height":521.055,"width":358.721,"x":174.64,"y":60.114,"original_width":1676,"original_height":2434,"rotation":0,"ocr":[{"x":756,"y":2366,"w":94,"h":38,"confidence":0.874,"text":"x (μm)"},{"x":1207,"y":2335,"w":75,"h":36,"confidence":1,"text":"1000"},{"x":155,"y":2335,"w":77,"h":38,"confidence":0.999,"text":"-200"},{"x":1382,"y":2333,"w":77,"h":38,"confidence":1,"text":"1200"},{"x":1038,"y":2333,"w":62,"h":40,"confidence":0.999,"text":"800"},{"x":863,"y":2333,"w":62,"h":40,"confidence":1,"text":"600"},{"x":682,"y":2326,"w":70,"h":48,"confidence":1,"text":"400"},{"x":514,"y":2333,"w":60,"h":40,"confidence":1,"text":"200"},{"x":354,"y":2335,"w":30,"h":36,"confidence":0.996,"text":"0"},{"x":1579,"y":2330,"w":42,"h":36,"confidence":1,"text":"20"},{"x":55,"y":2272,"w":82,"h":38,"confidence":0.995,"text":"-200"},{"x":1571,"y":2259,"w":53,"h":43,"confidence":0.998,"text":"40"},{"x":1574,"y":2193,"w":50,"h":43,"confidence":0.92,"text":"-60"},{"x":55,"y":2186,"w":82,"h":38,"confidence":0.973,"text":"-100"},{"x":1574,"y":2127,"w":52,"h":41,"confidence":0.999,"text":"80"},{"x":1631,"y":2104,"w":38,"h":94,"confidence":0.184,"text":"2"},{"x":20,"y":2102,"w":45,"h":101,"confidence":0.347,"text":"2"},{"x":107,"y":2099,"w":35,"h":36,"confidence":0.995,"text":"0"},{"x":1571,"y":2061,"w":70,"h":41,"confidence":0.999,"text":"100"},{"x":72,"y":2011,"w":68,"h":38,"confidence":1,"text":"100"},{"x":1574,"y":1993,"w":65,"h":40,"confidence":0.999,"text":"120"},{"x":1574,"y":1927,"w":67,"h":38,"confidence":1,"text":"140"},{"x":0,"y":1884,"w":35,"h":38,"confidence":0.899,"text":"C."},{"x":1110,"y":1800,"w":372,"h":41,"confidence":0.995,"text":"Membrane potential (mV)"},{"x":307,"y":1803,"w":371,"h":35,"confidence":0.999,"text":"Membrane potential (mV)"},{"x":1569,"y":1767,"w":65,"h":41,"confidence":1,"text":"100"},{"x":1424,"y":1767,"w":52,"h":41,"confidence":1,"text":"50"},{"x":1284,"y":1770,"w":30,"h":35,"confidence":0.996,"text":"0"},{"x":1112,"y":1767,"w":73,"h":38,"confidence":0.989,"text":"-50"},{"x":953,"y":1767,"w":87,"h":38,"confidence":0.985,"text":"-100"},{"x":751,"y":1767,"w":67,"h":41,"confidence":1,"text":"100"},{"x":476,"y":1770,"w":33,"h":35,"confidence":0.993,"text":"0"},{"x":312,"y":1767,"w":70,"h":41,"confidence":0.987,"text":"-50"},{"x":157,"y":1765,"w":92,"h":45,"confidence":0.986,"text":"-100"},{"x":614,"y":1765,"w":49,"h":43,"confidence":0.999,"text":"50"},{"x":85,"y":1701,"w":67,"h":46,"confidence":1,"text":"0.0"},{"x":908,"y":1691,"w":32,"h":33,"confidence":0.995,"text":"0"},{"x":87,"y":1620,"w":60,"h":41,"confidence":1,"text":"0.2"},{"x":910,"y":1602,"w":30,"h":36,"confidence":1,"text":"2"},{"x":90,"y":1536,"w":60,"h":41,"confidence":1,"text":"0.4"},{"x":539,"y":1511,"w":244,"h":41,"confidence":0.958,"text":"na_channel h inf"},{"x":913,"y":1516,"w":25,"h":28,"confidence":1,"text":"4"},{"x":539,"y":1476,"w":252,"h":35,"confidence":0.992,"text":"na_channel m inf"},{"x":83,"y":1449,"w":65,"h":50,"confidence":1,"text":"0.6"},{"x":908,"y":1425,"w":32,"h":33,"confidence":1,"text":"6"},{"x":45,"y":1382,"w":47,"h":264,"confidence":0.842,"text":"20"},{"x":87,"y":1372,"w":63,"h":40,"confidence":1,"text":"0.8"},{"x":873,"y":1354,"w":35,"h":327,"confidence":0.605,"text":"20"},{"x":1347,"y":1349,"w":254,"h":35,"confidence":0.99,"text":"na_channel h tau"},{"x":913,"y":1339,"w":25,"h":28,"confidence":1,"text":"8"},{"x":1344,"y":1306,"w":265,"h":33,"confidence":0.999,"text":"na channel m tau"},{"x":87,"y":1288,"w":63,"h":41,"confidence":0.999,"text":"1.0"},{"x":0,"y":1278,"w":42,"h":43,"confidence":0.998,"text":"b."},{"x":843,"y":1176,"w":97,"h":36,"confidence":0.999,"text":"Time (ms)"},{"x":1521,"y":1141,"w":58,"h":30,"confidence":1,"text":"3250"},{"x":1377,"y":1136,"w":62,"h":38,"confidence":1,"text":"2900"},{"x":1259,"y":1136,"w":63,"h":38,"confidence":1,"text":"2610"},{"x":1142,"y":1136,"w":63,"h":38,"confidence":1,"text":"2320"},{"x":1025,"y":1136,"w":62,"h":38,"confidence":1,"text":"2030"},{"x":908,"y":1136,"w":62,"h":38,"confidence":1,"text":"1740"},{"x":791,"y":1136,"w":62,"h":38,"confidence":1,"text":"1450"},{"x":671,"y":1136,"w":65,"h":38,"confidence":1,"text":"1160"},{"x":561,"y":1138,"w":48,"h":33,"confidence":1,"text":"870"},{"x":444,"y":1138,"w":47,"h":33,"confidence":1,"text":"580"},{"x":324,"y":1138,"w":53,"h":36,"confidence":1,"text":"290"},{"x":197,"y":1136,"w":67,"h":38,"confidence":0.999,"text":"0.008"},{"x":161,"y":1107,"w":67,"h":45,"confidence":1,"text":"-0.20"},{"x":162,"y":1078,"w":65,"h":30,"confidence":0.999,"text":"0.000"},{"x":160,"y":1042,"w":62,"h":30,"confidence":1,"text":"0.200"},{"x":162,"y":1004,"w":62,"h":30,"confidence":1,"text":"0.400"},{"x":162,"y":966,"w":62,"h":30,"confidence":1,"text":"0.600"},{"x":1504,"y":946,"w":37,"h":35,"confidence":0.175,"text":"2"},{"x":120,"y":938,"w":35,"h":132,"confidence":0.133,"text":"2"},{"x":160,"y":930,"w":64,"h":31,"confidence":1,"text":"0.800"},{"x":160,"y":890,"w":67,"h":38,"confidence":0.999,"text":"1.000"},{"x":1501,"y":877,"w":40,"h":69,"confidence":0.998,"text":"8"},{"x":162,"y":857,"w":62,"h":30,"confidence":1,"text":"1.200"},{"x":843,"y":829,"w":97,"h":36,"confidence":0.98,"text":"Time (ms)"},{"x":1519,"y":789,"w":62,"h":38,"confidence":1,"text":"3250"},{"x":1377,"y":789,"w":62,"h":38,"confidence":1,"text":"2900"},{"x":1259,"y":789,"w":63,"h":38,"confidence":1,"text":"2610"},{"x":1142,"y":789,"w":63,"h":38,"confidence":1,"text":"2320"},{"x":1025,"y":789,"w":62,"h":38,"confidence":1,"text":"2030"},{"x":908,"y":789,"w":60,"h":38,"confidence":1,"text":"1740"},{"x":791,"y":789,"w":59,"h":38,"confidence":1,"text":"1450"},{"x":671,"y":789,"w":65,"h":38,"confidence":1,"text":"1160"},{"x":561,"y":791,"w":53,"h":36,"confidence":1,"text":"870"},{"x":197,"y":789,"w":67,"h":38,"confidence":0.999,"text":"0.008"},{"x":441,"y":786,"w":53,"h":41,"confidence":1,"text":"580"},{"x":322,"y":786,"w":55,"h":41,"confidence":0.999,"text":"290"},{"x":162,"y":763,"w":65,"h":38,"confidence":0.99,"text":"-100."},{"x":165,"y":725,"w":64,"h":38,"confidence":0.999,"text":"-80.0"},{"x":165,"y":690,"w":62,"h":38,"confidence":0.999,"text":"-60.0"},{"x":167,"y":657,"w":57,"h":30,"confidence":1,"text":"-40.0"},{"x":167,"y":619,"w":57,"h":30,"confidence":1,"text":"-20.0"},{"x":1504,"y":601,"w":35,"h":35,"confidence":0.61,"text":"0"},{"x":120,"y":586,"w":35,"h":139,"confidence":0.17,"text":"2"},{"x":162,"y":583,"w":62,"h":31,"confidence":1,"text":"0.000"},{"x":160,"y":543,"w":67,"h":38,"confidence":1,"text":"20.00"},{"x":162,"y":510,"w":60,"h":30,"confidence":1,"text":"40.00"},{"x":561,"y":459,"w":20,"h":25,"confidence":0.919,"text":"V"},{"x":165,"y":449,"w":177,"h":43,"confidence":0.937,"text":"Square (Long)"},{"x":758,"y":413,"w":170,"h":36,"confidence":0.999,"text":"Stimulus: ALL"},{"x":322,"y":413,"w":112,"h":36,"confidence":0.999,"text":"Protocol:"},{"x":673,"y":342,"w":342,"h":33,"confidence":0.979,"text":"Current Clamp Response"},{"x":1013,"y":236,"w":301,"h":35,"confidence":0.99,"text":"Computational Complexity"},{"x":808,"y":233,"w":150,"h":43,"confidence":1,"text":"Morphology"},{"x":541,"y":228,"w":218,"h":49,"confidence":1,"text":"Electrophysiology"},{"x":374,"y":233,"w":117,"h":38,"confidence":1,"text":"Overview"},{"x":661,"y":127,"w":374,"h":46,"confidence":0.981,"text":"Layer 5b Pyramidal cell"},{"x":1080,"y":30,"w":187,"h":36,"confidence":0.997,"text":"NeuroML Home"},{"x":973,"y":30,"w":79,"h":38,"confidence":1,"text":"About"},{"x":763,"y":30,"w":182,"h":36,"confidence":1,"text":"Documentation"},{"x":681,"y":30,"w":57,"h":38,"confidence":1,"text":"API"},{"x":564,"y":30,"w":92,"h":38,"confidence":0.984,"text":"Gallery"},{"x":446,"y":30,"w":93,"h":38,"confidence":1,"text":"Search"},{"x":0,"y":3,"w":45,"h":43,"confidence":1,"text":"a."}]},{"name":"page_20.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_20_figure_title_1_v2.jpg","height":68174.05,"width":247016.311,"x":101446.295,"y":470491.163,"original_width":1631,"original_height":348,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_20_footer_1_v2.jpg","height":7074.538,"width":191820.253,"x":21692.62,"y":591332.847,"original_width":1267,"original_height":37,"rotation":0,"type":"layout_v2_footer"},{"name":"page_20_header_1_v2.jpg","height":5611.766,"width":30279.663,"x":320907.724,"y":27675.154,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_20_number_1_v2.jpg","height":5841.788,"width":18144.786,"x":332982.156,"y":591798.219,"original_width":120,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_20_chart_1_v2.jpg","height":416837.612,"width":226390.22,"x":102559.613,"y":45540.734,"original_width":1495,"original_height":2127,"rotation":0,"type":"layout_v2_chart"},{"name":"page_20_header_2_v2.jpg","height":5690.687,"width":42932.691,"x":47915.029,"y":27854.242,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_20_header_3_v2.jpg","height":10643.371,"width":24413.683,"x":21905.557,"y":22389.534,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_20_chart_2_v2.jpg","height":91164.373,"width":221168.322,"x":104965.448,"y":366453.176,"original_width":1461,"original_height":466,"rotation":0,"type":"layout_v2_chart"},{"name":"page_20_chart_3_v2.jpg","height":209569.302,"width":215658.668,"x":104649.633,"y":45947.021,"original_width":1424,"original_height":1070,"rotation":0,"type":"layout_v2_chart"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                                                                           Neuroscience","md":"eLife Tools and resources                                                                                                                                           Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":164,"endIndex":176}]},{"type":"text","value":"**Figure 10.** Examples of visualizing biophysical properties of a NeuroML model neuron. **(a)** Electrophysiological properties generated by the NeuroML-DB web-based platform (Birgiolas et al., 2023). The interface shows a \"Layer 5b Pyramidal cell\" with tabs for Overview, Electrophysiology, Morphology, and Computational Complexity. The Current Clamp Response section displays a Square (Long) protocol with stimulus ALL, showing voltage traces ranging from -100 to 40.00 mV over time (0.008 to 3250 ms) in the top panel, and corresponding current traces ranging from -0.20 to 1.200 in the bottom panel. **(b)** Example plots of steady states of activation (na_channel na_m inf) and inactivation (na_channel na_h inf) variables and their time courses (na_channel na_m tau and na_channel na_h tau) for the Na channel from the classic Hodgkin Huxley model (Hodgkin and Huxley, 1952). The left graph shows steady state curves plotted against membrane potential (-100 to 100 mV), while the right graph shows time constants with na_channel m tau peaking around 8 and na_channel h tau remaining low across the voltage range. **(c)** The distribution of the peak conductances for the Ih channel over a layer 5 Pyramidal cell (Hay et al., 2011), displayed as a morphological visualization with a color scale ranging from 20 to 140 (S/m²), showing the dendritic tree structure with conductance values color-coded from purple (low) to yellow (high). Both **(b)** and **(c)** were generated using the analysis features in pyNeuroML, and similar functionality is also available in OSBv1 (Gleeson et al., 2019b).","md":"**Figure 10.** Examples of visualizing biophysical properties of a NeuroML model neuron. **(a)** Electrophysiological properties generated by the NeuroML-DB web-based platform (Birgiolas et al., 2023). The interface shows a \"Layer 5b Pyramidal cell\" with tabs for Overview, Electrophysiology, Morphology, and Computational Complexity. The Current Clamp Response section displays a Square (Long) protocol with stimulus ALL, showing voltage traces ranging from -100 to 40.00 mV over time (0.008 to 3250 ms) in the top panel, and corresponding current traces ranging from -0.20 to 1.200 in the bottom panel. **(b)** Example plots of steady states of activation (na_channel na_m inf) and inactivation (na_channel na_h inf) variables and their time courses (na_channel na_m tau and na_channel na_h tau) for the Na channel from the classic Hodgkin Huxley model (Hodgkin and Huxley, 1952). The left graph shows steady state curves plotted against membrane potential (-100 to 100 mV), while the right graph shows time constants with na_channel m tau peaking around 8 and na_channel h tau remaining low across the voltage range. **(c)** The distribution of the peak conductances for the Ih channel over a layer 5 Pyramidal cell (Hay et al., 2011), displayed as a morphological visualization with a color scale ranging from 20 to 140 (S/m²), showing the dendritic tree structure with conductance values color-coded from purple (low) to yellow (high). Both **(b)** and **(c)** were generated using the analysis features in pyNeuroML, and similar functionality is also available in OSBv1 (Gleeson et al., 2019b).","bBox":{"x":168.53,"y":87.3,"w":403.31,"h":558.62},"layoutAwareBbox":[{"x":165,"y":594,"w":403,"h":86,"startIndex":15,"endIndex":22}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    20 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    20 of 44","bBox":{"x":178.92,"y":384.65,"w":396.07,"h":370.11},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":160},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":160}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                                                                           Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                    20 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.786,"layout":[{"image":"page_20_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.271,"y":0.75,"w":0.66,"h":0.109},"isLikelyNoise":false},{"image":"page_20_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_20_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_20_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.048,"h":0.009},"isLikelyNoise":false},{"image":"page_20_chart_1_v2.jpg","confidence":0.77,"label":"chart","bbox":{"x":0.274,"y":0.073,"w":0.604,"h":0.665},"isLikelyNoise":false},{"image":"page_20_header_2_v2.jpg","confidence":0.74,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_20_header_3_v2.jpg","confidence":0.58,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true},{"image":"page_20_chart_2_v2.jpg","confidence":0.52,"label":"chart","bbox":{"x":0.28,"y":0.584,"w":0.591,"h":0.145},"isLikelyNoise":true},{"image":"page_20_chart_3_v2.jpg","confidence":0.5,"label":"chart","bbox":{"x":0.279,"y":0.073,"w":0.576,"h":0.334},"isLikelyNoise":true}]},{"page":21,"text":"Tools  and  resources                                                                                             Neuroscience\n\n                         http://www.nsgportal.org/) are also available within the ecosystem. OSBv1 takes advantage of these\n                         to support the submission of NeuroML model simulation jobs using the NEURON simulator on NSG.\n                         NetPyNE also includes parallel execution of simulations, batch processing, and parameter explora-\n                         tion features, and its deployment on OSBv2 allows users to easily access these features on a scal-\n                         able, cloud- based platform. Finally, the JupyterLab environment on OSBv2 contains all of the core\n                         NeuroML tools and various simulation engines as pre-installed software packages, ready to use.\n\n                         Optimizing NeuroML models\n                         Development of biologically detailed models of brain function requires that components and emer       -\n                         gent properties match the behavior of the corresponding biology as closely as possible. Thus, ﬁtting\n                         neurons and networks to experimental data is a critical step in the model life cycle (Rossant et al.,\n                         2011; Druckmann et  al., 2007). pyNeuroML promotes data-  driven modeling by providing func-\n                         tions to ﬁt and optimize NeuroML models against experimental data. It includes the NeuroMLTuner\n                         module (https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html), which builds on\n                         the Neurotune package (https://github.com/NeuralEnsemble/neurotune; Vella and Gleeson, 2023)\n                         for tuning and optimizing NeuroML models against data using evolutionary computation techniques.\n                         This module allows users to select a set of weighted features from their data to calculate the ﬁtness\n                         of populations of candidate models. In each generation, the ﬁttest models are found and mutated to\n                         create the next generation of models, until a set of models that best exhibit the selected data features\n                         are isolated (see Guide 6 in\n                                                  Table 5) (https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.\n                         html).\n                                The NeuroML ecosystem includes multiple tools that also provide model ﬁtting features. The Blue\n                         Brain Python Optimisation Library (BluePyOpt) (Van Geit et al., 2016), an extensible framework for\n                         data-driven model parameter optimization, supports exporting optimized models to NeuroML ﬁles\n                         (https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb). Similar\n                         to pyNeuroML, NetPyNE also uses the inspyred Python package (https://github.com/aarongarrett/\n                         inspyred; Sinha and Garrett, 2024) to provide evolutionary computation- based model optimization\n                         features (Dura‐Bernal et al., 2019).\n\n                         Sharing NeuroML models\n                         The NeuroML ecosystem includes the advanced web- based model sharing platforms NeuroML- DB\n                         (Birgiolas et al., 2023;  https://neuroml-db.org) and OSB (Gleeson et al., 2019b). These resources\n                         have been designed speciﬁcally for the dissemination of models and model elements standardized\n                         in NeuroML. The OSB platform also supports visualization, analysis, simulation, and development of\n                         NeuroML models. Researchers can create shared, collaborative NeuroML projects on it and can take\n                         advantage of the in-built automated visualization and analysis pipelines to explore and re-\n                                                                                                                  use models\n                         and their components. Whereas version 1 (OSBv1) focused on providing an interactive 3D interface\n                         for running pre- existing NeuroML models (e.g. sourced from linked GitHub repositories) (Gleeson\n                         et al., 2019b), OSBv2 provides cloud-based workspaces for researchers to construct NeuroML-\n                                                                                                                          based\n                         computational models as well as analyze, and compare them to, the experimental data on which they\n                         are based, thus facilitating data- driven computational modeling. Table  8 provides a list of stable,\n                         well-tested NeuroML compliant models from brain regions including the neocortex, cerebellum, and\n                         hippocampus, which have been shared on OSB.\n                                      NeuroML-DB aims to promote the uptake of standardized NeuroML models by providing a conve-\n                         nient location for archiving and exploration. It includes advanced database search functions, including\n                         ontology-based search (Birgiolas et al., 2015), coupled with pre-\n                                                                                   computed analyses on models’ elec-\n                         trophysiological and morphological properties, as well as an indication of the relative speed of execu-\n                         tion of different models.\n                         NeuroML’s modular nature ensures that models and their components can be easily shared with\n                         others through standard code sharing resources. The simplest way of sharing NeuroML models and\n                         components is to make their Python descriptions or their XML serializations available through these\n                         resources. Indeed, it is straightforward to make Python descriptions or the XML serializations available\n                         via different ﬁle, code (GitHub, GitLab), model sharing (ModelDB Migliore et al., 2003;    McDougal\n                         et al., 2017), and archival (Zenodo, Open Science Framework) platforms, just like any other code/data\n                         produced in scientiﬁc investigations. Complex models with many components, spanning multiple ﬁles,\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    21 of 44","md":"\n\neLife Tools and resources                                                                                             Neuroscience\n\n[http://www.nsgportal.org/])(http://www.nsgportal.org/)) are also available within the ecosystem. OSBv1 takes advantage of these to support the submission of NeuroML model simulation jobs using the NEURON simulator on NSG. NetPyNE also includes parallel execution of simulations, batch processing, and parameter exploration features, and its deployment on OSBv2 allows users to easily access these features on a scalable, cloud-based platform. Finally, the JupyterLab environment on OSBv2 contains all of the core NeuroML tools and various simulation engines as pre-installed software packages, ready to use.\n\n## Optimizing NeuroML models\n\nDevelopment of biologically detailed models of brain function requires that components and emergent properties match the behavior of the corresponding biology as closely as possible. Thus, fitting neurons and networks to experimental data is a critical step in the model life cycle (Rossant et al., 2011; Druckmann et al., 2007). pyNeuroML promotes data-driven modeling by providing functions to fit and optimize NeuroML models against experimental data. It includes the NeuroMLTuner module ([https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html])(https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html)), which builds on the Neurotune package ([https://github.com/NeuralEnsemble/neurotune])(https://github.com/NeuralEnsemble/neurotune); Vella and Gleeson, 2023) for tuning and optimizing NeuroML models against data using evolutionary computation techniques. This module allows users to select a set of weighted features from their data to calculate the fitness of populations of candidate models. In each generation, the fittest models are found and mutated to create the next generation of models, until a set of models that best exhibit the selected data features are isolated (see Guide 6 in **Table 5**) ([https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html])(https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html)).\n\nThe NeuroML ecosystem includes multiple tools that also provide model fitting features. The Blue Brain Python Optimisation Library (BluePyOpt) (Van Geit et al., 2016), an extensible framework for data-driven model parameter optimization, supports exporting optimized models to NeuroML files ([https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb])(https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb)). Similar to pyNeuroML, NetPyNE also uses the inspyred Python package ([https://github.com/aarongarrett/inspyred])(https://github.com/aarongarrett/inspyred); Sinha and Garrett, 2024) to provide evolutionary computation-based model optimization features (Dura-Bernal et al., 2019).\n\n## Sharing NeuroML models\n\nThe NeuroML ecosystem includes the advanced web-based model sharing platforms NeuroML-DB (Birgiolas et al., 2023; https://neuroml-db.org) and OSB (Gleeson et al., 2019b). These resources have been designed specifically for the dissemination of models and model elements standardized in NeuroML. The OSB platform also supports visualization, analysis, simulation, and development of NeuroML models. Researchers can create shared, collaborative NeuroML projects on it and can take advantage of the in-built automated visualization and analysis pipelines to explore and re-use models and their components. Whereas version 1 (OSBv1) focused on providing an interactive 3D interface for running pre-existing NeuroML models (e.g. sourced from linked GitHub repositories) (Gleeson et al., 2019b), OSBv2 provides cloud-based workspaces for researchers to construct NeuroML-based computational models as well as analyze, and compare them to, the experimental data on which they are based, thus facilitating data-driven computational modeling. **Table 8** provides a list of stable, well-tested NeuroML compliant models from brain regions including the neocortex, cerebellum, and hippocampus, which have been shared on OSB.\n\nNeuroML-DB aims to promote the uptake of standardized NeuroML models by providing a convenient location for archiving and exploration. It includes advanced database search functions, including ontology-based search (Birgiolas et al., 2015), coupled with pre-computed analyses on models' electrophysiological and morphological properties, as well as an indication of the relative speed of execution of different models.\n\nNeuroML's modular nature ensures that models and their components can be easily shared with others through standard code sharing resources. The simplest way of sharing NeuroML models and components is to make their Python descriptions or their XML serializations available through these resources. Indeed, it is straightforward to make Python descriptions or the XML serializations available via different file, code (GitHub, GitLab), model sharing (ModelDB Migliore et al., 2003; McDougal et al., 2017), and archival (Zenodo, Open Science Framework) platforms, just like any other code/data produced in scientific investigations. Complex models with many components, spanning multiple files,\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    21 of 44\n","images":[{"name":"page_21.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_21_text_1_v2.jpg","height":121748.276,"width":250502.024,"x":101044.549,"y":334956.682,"original_width":1654,"original_height":622,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_text_2_v2.jpg","height":121175.212,"width":250396.09,"x":101006.951,"y":121630.468,"original_width":1654,"original_height":619,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_text_3_v2.jpg","height":64245.241,"width":250305.271,"x":101127.107,"y":245197.301,"original_width":1653,"original_height":328,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_text_4_v2.jpg","height":65045.806,"width":250326.065,"x":101291.237,"y":506176.663,"original_width":1653,"original_height":332,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_text_5_v2.jpg","height":55457.443,"width":250284.219,"x":101079.656,"y":41362.062,"original_width":1653,"original_height":283,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_text_6_v2.jpg","height":45081.189,"width":250313.065,"x":101146.877,"y":458702.167,"original_width":1653,"original_height":230,"rotation":0,"type":"layout_v2_text"},{"name":"page_21_paragraph_title_1_v2.jpg","height":9334.889,"width":102170.403,"x":101575.973,"y":110027.053,"original_width":675,"original_height":48,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_21_paragraph_title_2_v2.jpg","height":8840.266,"width":90054.901,"x":101422.607,"y":323170.921,"original_width":595,"original_height":46,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_21_footer_1_v2.jpg","height":6891.906,"width":191844.337,"x":21521.323,"y":591498.484,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_21_header_1_v2.jpg","height":5595.739,"width":30344.47,"x":320727.085,"y":27703.363,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_21_number_1_v2.jpg","height":6089.89,"width":18326.621,"x":332792.143,"y":591764.033,"original_width":122,"original_height":32,"rotation":0,"type":"layout_v2_number"},{"name":"page_21_header_2_v2.jpg","height":5778.624,"width":42785.76,"x":47717.844,"y":27824.427,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_21_header_3_v2.jpg","height":10674.521,"width":24441.758,"x":21777.516,"y":22402.961,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                             Neuroscience","md":"eLife Tools and resources                                                                                             Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":118,"endIndex":130}]},{"type":"text","value":"[http://www.nsgportal.org/])(http://www.nsgportal.org/)) are also available within the ecosystem. OSBv1 takes advantage of these to support the submission of NeuroML model simulation jobs using the NEURON simulator on NSG. NetPyNE also includes parallel execution of simulations, batch processing, and parameter exploration features, and its deployment on OSBv2 allows users to easily access these features on a scalable, cloud-based platform. Finally, the JupyterLab environment on OSBv2 contains all of the core NeuroML tools and various simulation engines as pre-installed software packages, ready to use.","md":"[http://www.nsgportal.org/])(http://www.nsgportal.org/)) are also available within the ecosystem. OSBv1 takes advantage of these to support the submission of NeuroML model simulation jobs using the NEURON simulator on NSG. NetPyNE also includes parallel execution of simulations, batch processing, and parameter exploration features, and its deployment on OSBv2 allows users to easily access these features on a scalable, cloud-based platform. Finally, the JupyterLab environment on OSBv2 contains all of the core NeuroML tools and various simulation engines as pre-installed software packages, ready to use.","bBox":{"x":168.53,"y":63.8,"w":407.38,"h":56.99},"layoutAwareBbox":[{"x":165,"y":52,"w":408,"h":70,"startIndex":71,"endIndex":75}]},{"type":"heading","lvl":2,"value":"Optimizing NeuroML models","md":"## Optimizing NeuroML models","bBox":{"x":168.53,"y":137.14,"w":163.98,"h":12},"layoutAwareBbox":[{"x":165,"y":138,"w":166,"h":11,"startIndex":0,"endIndex":27}]},{"type":"text","value":"Development of biologically detailed models of brain function requires that components and emergent properties match the behavior of the corresponding biology as closely as possible. Thus, fitting neurons and networks to experimental data is a critical step in the model life cycle (Rossant et al., 2011; Druckmann et al., 2007). pyNeuroML promotes data-driven modeling by providing functions to fit and optimize NeuroML models against experimental data. It includes the NeuroMLTuner module ([https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html])(https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html)), which builds on the Neurotune package ([https://github.com/NeuralEnsemble/neurotune])(https://github.com/NeuralEnsemble/neurotune); Vella and Gleeson, 2023) for tuning and optimizing NeuroML models against data using evolutionary computation techniques. This module allows users to select a set of weighted features from their data to calculate the fitness of populations of candidate models. In each generation, the fittest models are found and mutated to create the next generation of models, until a set of models that best exhibit the selected data features are isolated (see Guide 6 in **Table 5**) ([https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html])(https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html)).","md":"Development of biologically detailed models of brain function requires that components and emergent properties match the behavior of the corresponding biology as closely as possible. Thus, fitting neurons and networks to experimental data is a critical step in the model life cycle (Rossant et al., 2011; Druckmann et al., 2007). pyNeuroML promotes data-driven modeling by providing functions to fit and optimize NeuroML models against experimental data. It includes the NeuroMLTuner module ([https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html])(https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html)), which builds on the Neurotune package ([https://github.com/NeuralEnsemble/neurotune])(https://github.com/NeuralEnsemble/neurotune); Vella and Gleeson, 2023) for tuning and optimizing NeuroML models against data using evolutionary computation techniques. This module allows users to select a set of weighted features from their data to calculate the fitness of populations of candidate models. In each generation, the fittest models are found and mutated to create the next generation of models, until a set of models that best exhibit the selected data features are isolated (see Guide 6 in **Table 5**) ([https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html])(https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html)).","bBox":{"x":168.53,"y":153.14,"w":415.9,"h":140.97},"layoutAwareBbox":[{"x":168.53,"y":153.14,"w":415.9,"h":140.97,"startIndex":0,"endIndex":1369}]},{"type":"text","value":"The NeuroML ecosystem includes multiple tools that also provide model fitting features. The Blue Brain Python Optimisation Library (BluePyOpt) (Van Geit et al., 2016), an extensible framework for data-driven model parameter optimization, supports exporting optimized models to NeuroML files ([https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb])(https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb)). Similar to pyNeuroML, NetPyNE also uses the inspyred Python package ([https://github.com/aarongarrett/inspyred])(https://github.com/aarongarrett/inspyred); Sinha and Garrett, 2024) to provide evolutionary computation-based model optimization features (Dura-Bernal et al., 2019).","md":"The NeuroML ecosystem includes multiple tools that also provide model fitting features. The Blue Brain Python Optimisation Library (BluePyOpt) (Van Geit et al., 2016), an extensible framework for data-driven model parameter optimization, supports exporting optimized models to NeuroML files ([https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb])(https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb)). Similar to pyNeuroML, NetPyNE also uses the inspyred Python package ([https://github.com/aarongarrett/inspyred])(https://github.com/aarongarrett/inspyred); Sinha and Garrett, 2024) to provide evolutionary computation-based model optimization features (Dura-Bernal et al., 2019).","bBox":{"x":550.51,"y":153.14,"w":27.01,"h":374.32},"layoutAwareBbox":[{"x":165,"y":309,"w":408,"h":81,"startIndex":78,"endIndex":86}]},{"type":"heading","lvl":2,"value":"Sharing NeuroML models","md":"## Sharing NeuroML models","bBox":{"x":168.53,"y":406.48,"w":143.97,"h":12},"layoutAwareBbox":[{"x":165,"y":408,"w":147,"h":11,"startIndex":0,"endIndex":24}]},{"type":"text","value":"The NeuroML ecosystem includes the advanced web-based model sharing platforms NeuroML-DB (Birgiolas et al., 2023; https://neuroml-db.org) and OSB (Gleeson et al., 2019b). These resources have been designed specifically for the dissemination of models and model elements standardized in NeuroML. The OSB platform also supports visualization, analysis, simulation, and development of NeuroML models. Researchers can create shared, collaborative NeuroML projects on it and can take advantage of the in-built automated visualization and analysis pipelines to explore and re-use models and their components. Whereas version 1 (OSBv1) focused on providing an interactive 3D interface for running pre-existing NeuroML models (e.g. sourced from linked GitHub repositories) (Gleeson et al., 2019b), OSBv2 provides cloud-based workspaces for researchers to construct NeuroML-based computational models as well as analyze, and compare them to, the experimental data on which they are based, thus facilitating data-driven computational modeling. **Table 8** provides a list of stable, well-tested NeuroML compliant models from brain regions including the neocortex, cerebellum, and hippocampus, which have been shared on OSB.","md":"The NeuroML ecosystem includes the advanced web-based model sharing platforms NeuroML-DB (Birgiolas et al., 2023; https://neuroml-db.org) and OSB (Gleeson et al., 2019b). These resources have been designed specifically for the dissemination of models and model elements standardized in NeuroML. The OSB platform also supports visualization, analysis, simulation, and development of NeuroML models. Researchers can create shared, collaborative NeuroML projects on it and can take advantage of the in-built automated visualization and analysis pipelines to explore and re-use models and their components. Whereas version 1 (OSBv1) focused on providing an interactive 3D interface for running pre-existing NeuroML models (e.g. sourced from linked GitHub repositories) (Gleeson et al., 2019b), OSBv2 provides cloud-based workspaces for researchers to construct NeuroML-based computational models as well as analyze, and compare them to, the experimental data on which they are based, thus facilitating data-driven computational modeling. **Table 8** provides a list of stable, well-tested NeuroML compliant models from brain regions including the neocortex, cerebellum, and hippocampus, which have been shared on OSB.","bBox":{"x":168.53,"y":422.48,"w":410.91,"h":152.96},"layoutAwareBbox":[{"x":165,"y":422,"w":409,"h":153,"startIndex":22,"endIndex":24}]},{"type":"text","value":"NeuroML-DB aims to promote the uptake of standardized NeuroML models by providing a convenient location for archiving and exploration. It includes advanced database search functions, including ontology-based search (Birgiolas et al., 2015), coupled with pre-computed analyses on models' electrophysiological and morphological properties, as well as an indication of the relative speed of execution of different models.","md":"NeuroML-DB aims to promote the uptake of standardized NeuroML models by providing a convenient location for archiving and exploration. It includes advanced database search functions, including ontology-based search (Birgiolas et al., 2015), coupled with pre-computed analyses on models' electrophysiological and morphological properties, as well as an indication of the relative speed of execution of different models.","bBox":{"x":168.54,"y":153.14,"w":412.72,"h":482.29},"layoutAwareBbox":[{"x":165,"y":579,"w":409,"h":56,"startIndex":0,"endIndex":7}]},{"type":"text","value":"NeuroML's modular nature ensures that models and their components can be easily shared with others through standard code sharing resources. The simplest way of sharing NeuroML models and components is to make their Python descriptions or their XML serializations available through these resources. Indeed, it is straightforward to make Python descriptions or the XML serializations available via different file, code (GitHub, GitLab), model sharing (ModelDB Migliore et al., 2003; McDougal et al., 2017), and archival (Zenodo, Open Science Framework) platforms, just like any other code/data produced in scientific investigations. Complex models with many components, spanning multiple files,","md":"NeuroML's modular nature ensures that models and their components can be easily shared with others through standard code sharing resources. The simplest way of sharing NeuroML models and components is to make their Python descriptions or their XML serializations available through these resources. Indeed, it is straightforward to make Python descriptions or the XML serializations available via different file, code (GitHub, GitLab), model sharing (ModelDB Migliore et al., 2003; McDougal et al., 2017), and archival (Zenodo, Open Science Framework) platforms, just like any other code/data produced in scientific investigations. Complex models with many components, spanning multiple files,","bBox":{"x":168.54,"y":650.43,"w":414.21,"h":44.99},"layoutAwareBbox":[{"x":165,"y":639,"w":409,"h":82,"startIndex":45,"endIndex":48}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    21 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    21 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"http://www.nsgportal.org/","unsafeUrl":"http://www.nsgportal.org/","text":"http://www.nsgportal.org/) are also available within the ecosystem. OSBv1 takes advantage of these "},{"url":"https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html","unsafeUrl":"https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html","text":"module (https://pyneuroml.readthedocs.io/en/development/pyneuroml.tune.html), which builds on "},{"url":"https://github.com/NeuralEnsemble/neurotune","unsafeUrl":"https://github.com/NeuralEnsemble/neurotune","text":"the Neurotune package (https://github.com/NeuralEnsemble/neurotune; "},{"url":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","text":"(https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels."},{"url":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/OptimisingNeuroMLModels.html","text":"html)."},{"url":"https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb","unsafeUrl":"https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb","text":"(https://github.com/BlueBrain/BluePyOpt/blob/master/examples/neuroml/neuroml.ipynb). Similar "},{"url":"https://github.com/aarongarrett/inspyred","unsafeUrl":"https://github.com/aarongarrett/inspyred","text":"to pyNeuroML, NetPyNE also uses the inspyred Python package (https://github.com/aarongarrett/"},{"url":"https://github.com/aarongarrett/inspyred","unsafeUrl":"https://github.com/aarongarrett/inspyred","text":"inspyred; "},{"url":"https://neuroml-db.org/","unsafeUrl":"https://neuroml-db.org","text":";   https://neuroml-db.org) and OSB ("}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                             Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    21 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.977,"layout":[{"image":"page_21_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.534,"w":0.669,"h":0.194},"isLikelyNoise":false},{"image":"page_21_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.194,"w":0.669,"h":0.193},"isLikelyNoise":false},{"image":"page_21_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.391,"w":0.668,"h":0.102},"isLikelyNoise":false},{"image":"page_21_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.807,"w":0.668,"h":0.104},"isLikelyNoise":false},{"image":"page_21_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.088},"isLikelyNoise":false},{"image":"page_21_text_6_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.731,"w":0.668,"h":0.072},"isLikelyNoise":false},{"image":"page_21_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.175,"w":0.273,"h":0.015},"isLikelyNoise":false},{"image":"page_21_paragraph_title_2_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.515,"w":0.24,"h":0.014},"isLikelyNoise":false},{"image":"page_21_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_21_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_21_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_21_header_2_v2.jpg","confidence":0.64,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_21_header_3_v2.jpg","confidence":0.5,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":22,"text":"         Tools  and  resources                                                                                          Neuroscience\n\nTable 8. Listing of NeuroML models and example repositories.\nModel                              Description                                          URL\n\nNeocortex\n\n                                   Morphologically detailed and point neuron\n                                   models based on electrophysiological recordings https://github.com/OpenSourceBrain/\nBilleh et al., 2020                from visual cortex neurons                           AllenInstituteNeuroML\n\n                                   Spiking network illustrating balance between\nBrunel, 2000                       excitation and inhibition                            https://github.com/OpenSourceBrain/Brunel2000\n\n                                   Layer 5 pyramidal cell model constrained by          https://github.com/OpenSourceBrain/\nHay et al., 2011                   somatic and dendritic recordings                     L5bPyrCellHayEtAl2011\n\n                                   Spiking neuron model reproducing wide range of https://github.com/OpenSourceBrain/\nIzhikevich, 2004                   neuronal activity                                    IzhikevichModel\n\n                                   Cell models from Neocortical Microcircuit of Blue https://github.com/OpenSourceBrain/\nMarkram et al., 2015               Brain Project                                        BlueBrainProjectShowcase\n\n                                   HH-based models for different classes of cortical    https://github.com/OpenSourceBrain/\nPospischil et al., 2008            and thalamic neurons                                 PospischilEtAl2008\n\n                                   Microcircuit model of sensory cortex with 8          https://github.com/OpenSourceBrain/\nPotjans and Diesmann, 2014         populations across 4 layers                          PotjansDiesmann2014\n\n                                                                                        https://github.com/OpenSourceBrain/\nDura‐Bernal et al., 2017           Model of mouse primary motor cortex (M1)             M1NetworkModel\n\n                                   Point neuron model of Inhibition Stabilized          https://github.com/OpenSourceBrain/\nSadeh et al., 2017                 Network                                              SadehEtAl2017-InhibitionStabilizedNetworks\n\n                                   Layer 2/3 cell model used to investigate dendritic https://github.com/OpenSourceBrain/\nSmith et al., 2013                 spikes                                               SmithEtAl2013-L23DendriticSpikes\n\n                                   Single column network model containing 14 cell       https://github.com/OpenSourceBrain/\nTraub et al., 2005                 populations from cortex and thalamus                 Thalamocortical\n\n                                   A set of reduced models of layer 5 pyramidal         https://github.com/OpenSourceBrain/\nBahl et al., 2012                  neurons                                              BahlEtAl2012_ReducedL5PyrCell\n\n                                   A classic rate-based model describing the\n                                   dynamics and interactions between the excitatory https://github.com/OpenSourceBrain/\nWilson and Cowan, 1972             and inhibitory populations of neurons                WilsonCowan\n\n                                   Rate-based model showing paradoxical response\n                                   reversal of top-down modulation in cortical          https://github.com/OpenSourceBrain/del-\nGarcia Del Molino et al., 2017     circuits with three interneuron types                Molino2017\n\n                                   A rate-based model simulating the dynamics of a\n                                   cortical laminar structure across multiple scales:\n                                   intralaminar, interlaminar, interareal and whole     https://github.com/OpenSourceBrain/\nMejias et al., 2016                cortex                                               MejiasEtAl2016\n\nCerebellum\n\n                                                                                        https://github.com/OpenSourceBrain/\nMaex and Schutter, 1998            Cerebellar granule cell                              GranuleCell\n\n                                                                                        https://github.com/SilverLabUCL/MF-GC-\nCayco‐Gajic et al., 2017           Cerebellar granule cell layer network                network-backprop-public\n\n                                                                                        https://github.com/OpenSourceBrain/\nMaex and Schutter, 1998            3D Cerebellar granule cell layer network             GranCellLayer\n\n                                                                                        https://github.com/OpenSourceBrain/\nSolinas et al., 2007               Cerebellar Golgi cell model                          SolinasEtAl-GolgiCell\n\n                                   Electrically connected cerebellar Golgi cell         https://github.com/OpenSourceBrain/\nVervaeke et al., 2010              network model                                        VervaekeEtAl-GolgiCellNetwork\n\nHippocampus\n\nBezaire et al., 2016               Full scale network model of CA1 region of            https://github.com/mbezaire/ca1\n                                   hippocampus\nTable 8 continued on next page\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    22 of 44","md":"\n\neLife Tools and resources                                                                                          Neuroscience\n\n**Table 8.** Listing of NeuroML models and example repositories.\n\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"3\"><strong>Neocortex</strong></td>\n</tr>\n<tr>\n<td><em>Billeh et al.</em>, 2020</td>\n<td>Morphologically detailed and point neuron models based on electrophysiological recordings from visual cortex neurons</td>\n<td>https://github.com/OpenSourceBrain/AllenInstituteNeuroML</td>\n</tr>\n<tr>\n<td><em>Brunel</em>, 2000</td>\n<td>Spiking network illustrating balance between excitation and inhibition</td>\n<td>https://github.com/OpenSourceBrain/Brunel2000</td>\n</tr>\n<tr>\n<td><em>Hay et al.</em>, 2011</td>\n<td>Layer 5 pyramidal cell model constrained by somatic and dendritic recordings</td>\n<td>https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011</td>\n</tr>\n<tr>\n<td><em>Izhikevich</em>, 2004</td>\n<td>Spiking neuron model reproducing wide range of neuronal activity</td>\n<td>https://github.com/OpenSourceBrain/IzhikevichModel</td>\n</tr>\n<tr>\n<td><em>Markram et al.</em>, 2015</td>\n<td>Cell models from Neocortical Microcircuit of Blue Brain Project</td>\n<td>https://github.com/OpenSourceBrain/BlueBrainProjectShowcase</td>\n</tr>\n<tr>\n<td><em>Pospischil et al.</em>, 2008</td>\n<td>HH-based models for different classes of cortical and thalamic neurons</td>\n<td>https://github.com/OpenSourceBrain/PospischilEtAl2008</td>\n</tr>\n<tr>\n<td><em>Potjans and Diesmann</em>, 2014</td>\n<td>Microcircuit model of sensory cortex with 8 populations across 4 layers</td>\n<td>https://github.com/OpenSourceBrain/PotjansDiesmann2014</td>\n</tr>\n<tr>\n<td><em>Dura-Bernal et al.</em>, 2017</td>\n<td>Model of mouse primary motor cortex (M1)</td>\n<td>https://github.com/OpenSourceBrain/M1NetworkModel</td>\n</tr>\n<tr>\n<td><em>Sadeh et al.</em>, 2017</td>\n<td>Point neuron model of Inhibition Stabilized Network</td>\n<td>https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks</td>\n</tr>\n<tr>\n<td><em>Smith et al.</em>, 2013</td>\n<td>Layer 2/3 cell model used to investigate dendritic spikes</td>\n<td>https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes</td>\n</tr>\n<tr>\n<td><em>Traub et al.</em>, 2005</td>\n<td>Single column network model containing 14 cell populations from cortex and thalamus</td>\n<td>https://github.com/OpenSourceBrain/Thalamocortical</td>\n</tr>\n<tr>\n<td><em>Bahl et al.</em>, 2012</td>\n<td>A set of reduced models of layer 5 pyramidal neurons</td>\n<td>https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell</td>\n</tr>\n<tr>\n<td><em>Wilson and Cowan</em>, 1972</td>\n<td>A classic rate-based model describing the dynamics and interactions between the excitatory and inhibitory populations of neurons</td>\n<td>https://github.com/OpenSourceBrain/WilsonCowan</td>\n</tr>\n<tr>\n<td><em>Garcia Del Molino et al.</em>, 2017</td>\n<td>Rate-based model showing paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types</td>\n<td>https://github.com/OpenSourceBrain/del-Molino2017</td>\n</tr>\n<tr>\n<td><em>Mejias et al.</em>, 2016</td>\n<td>A rate-based model simulating the dynamics of a cortical laminar structure across multiple scales: intralaminar, interlaminar, interareal and whole cortex</td>\n<td>https://github.com/OpenSourceBrain/MejiasEtAl2016</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Cerebellum</strong></td>\n</tr>\n<tr>\n<td><em>Maex and Schutter</em>, 1998</td>\n<td>Cerebellar granule cell</td>\n<td>https://github.com/OpenSourceBrain/GranuleCell</td>\n</tr>\n<tr>\n<td><em>Cayco-Gajic et al.</em>, 2017</td>\n<td>Cerebellar granule cell layer network</td>\n<td>https://github.com/SilverLabUCL/MF-GC-network-backprop-public</td>\n</tr>\n<tr>\n<td><em>Maex and Schutter</em>, 1998</td>\n<td>3D Cerebellar granule cell layer network</td>\n<td>https://github.com/OpenSourceBrain/GranCellLayer</td>\n</tr>\n<tr>\n<td><em>Solinas et al.</em>, 2007</td>\n<td>Cerebellar Golgi cell model</td>\n<td>https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell</td>\n</tr>\n<tr>\n<td><em>Vervaeke et al.</em>, 2010</td>\n<td>Electrically connected cerebellar Golgi cell network model</td>\n<td>https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Hippocampus</strong></td>\n</tr>\n<tr>\n<td><em>Bezaire et al.</em>, 2016</td>\n<td>Full scale network model of CA1 region of hippocampus</td>\n<td>https://github.com/mbezaire/ca1</td>\n</tr>\n</tbody>\n</table>\n\nTable 8 continued on next page\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    22 of 44\n","images":[{"name":"page_22.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_22_table_1_v2.jpg","height":509002.34,"width":331283.868,"x":20821.871,"y":56080.724,"original_width":2188,"original_height":2597,"rotation":0,"type":"layout_v2_table"},{"name":"page_22_footer_1_v2.jpg","height":6804.971,"width":192276.154,"x":21457.689,"y":591586.262,"original_width":1270,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_22_header_1_v2.jpg","height":5706.602,"width":30226.291,"x":320857.895,"y":27634.913,"original_width":200,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_22_number_1_v2.jpg","height":5938.7,"width":18209.411,"x":332965.117,"y":591806.393,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_22_figure_title_1_v2.jpg","height":7462.553,"width":155067.066,"x":21139.77,"y":45839.451,"original_width":1024,"original_height":39,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_22_header_2_v2.jpg","height":5876.322,"width":43029.629,"x":47729.349,"y":27802.51,"original_width":285,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_22_header_3_v2.jpg","height":10879.057,"width":24542.902,"x":21718.805,"y":22461.29,"original_width":163,"original_height":56,"rotation":0,"type":"layout_v2_header"},{"name":"page_22_figure_title_2_v2.jpg","height":18119.655,"width":155153.387,"x":21049.951,"y":45882.16,"original_width":1025,"original_height":93,"rotation":0,"type":"layout_v2_figure_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                          Neuroscience","md":"eLife Tools and resources                                                                                          Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":115,"endIndex":127}]},{"type":"text","value":"**Table 8.** Listing of NeuroML models and example repositories.","md":"**Table 8.** Listing of NeuroML models and example repositories.","bBox":{"x":36.5,"y":72.48,"w":24.14,"h":8},"layoutAwareBbox":[{"x":34,"y":57,"w":253,"h":9,"startIndex":0,"endIndex":63}]},{"type":"table","rows":[["Model","Description","URL"],["Neocortex","",""],["Billeh et al., 2020","Morphologically detailed and point neuron models based on electrophysiological recordings from visual cortex neurons","https://github.com/OpenSourceBrain/AllenInstituteNeuroML"],["Brunel, 2000","Spiking network illustrating balance between excitation and inhibition","https://github.com/OpenSourceBrain/Brunel2000"],["Hay et al., 2011","Layer 5 pyramidal cell model constrained by somatic and dendritic recordings","https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011"],["Izhikevich, 2004","Spiking neuron model reproducing wide range of neuronal activity","https://github.com/OpenSourceBrain/IzhikevichModel"],["Markram et al., 2015","Cell models from Neocortical Microcircuit of Blue Brain Project","https://github.com/OpenSourceBrain/BlueBrainProjectShowcase"],["Pospischil et al., 2008","HH-based models for different classes of cortical and thalamic neurons","https://github.com/OpenSourceBrain/PospischilEtAl2008"],["Potjans and Diesmann, 2014","Microcircuit model of sensory cortex with 8 populations across 4 layers","https://github.com/OpenSourceBrain/PotjansDiesmann2014"],["Dura-Bernal et al., 2017","Model of mouse primary motor cortex (M1)","https://github.com/OpenSourceBrain/M1NetworkModel"],["Sadeh et al., 2017","Point neuron model of Inhibition Stabilized Network","https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks"],["Smith et al., 2013","Layer 2/3 cell model used to investigate dendritic spikes","https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes"],["Traub et al., 2005","Single column network model containing 14 cell populations from cortex and thalamus","https://github.com/OpenSourceBrain/Thalamocortical"],["Bahl et al., 2012","A set of reduced models of layer 5 pyramidal neurons","https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell"],["Wilson and Cowan, 1972","A classic rate-based model describing the dynamics and interactions between the excitatory and inhibitory populations of neurons","https://github.com/OpenSourceBrain/WilsonCowan"],["Garcia Del Molino et al., 2017","Rate-based model showing paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types","https://github.com/OpenSourceBrain/del-Molino2017"],["Mejias et al., 2016","A rate-based model simulating the dynamics of a cortical laminar structure across multiple scales: intralaminar, interlaminar, interareal and whole cortex","https://github.com/OpenSourceBrain/MejiasEtAl2016"],["Cerebellum","",""],["Maex and Schutter, 1998","Cerebellar granule cell","https://github.com/OpenSourceBrain/GranuleCell"],["Cayco-Gajic et al., 2017","Cerebellar granule cell layer network","https://github.com/SilverLabUCL/MF-GC-network-backprop-public"],["Maex and Schutter, 1998","3D Cerebellar granule cell layer network","https://github.com/OpenSourceBrain/GranCellLayer"],["Solinas et al., 2007","Cerebellar Golgi cell model","https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell"],["Vervaeke et al., 2010","Electrically connected cerebellar Golgi cell network model","https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork"],["Hippocampus","",""],["Bezaire et al., 2016","Full scale network model of CA1 region of hippocampus","https://github.com/mbezaire/ca1"]],"html":"<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"3\"><strong>Neocortex</strong></td>\n</tr>\n<tr>\n<td><em>Billeh et al.</em>, 2020</td>\n<td>Morphologically detailed and point neuron models based on electrophysiological recordings from visual cortex neurons</td>\n<td>https://github.com/OpenSourceBrain/AllenInstituteNeuroML</td>\n</tr>\n<tr>\n<td><em>Brunel</em>, 2000</td>\n<td>Spiking network illustrating balance between excitation and inhibition</td>\n<td>https://github.com/OpenSourceBrain/Brunel2000</td>\n</tr>\n<tr>\n<td><em>Hay et al.</em>, 2011</td>\n<td>Layer 5 pyramidal cell model constrained by somatic and dendritic recordings</td>\n<td>https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011</td>\n</tr>\n<tr>\n<td><em>Izhikevich</em>, 2004</td>\n<td>Spiking neuron model reproducing wide range of neuronal activity</td>\n<td>https://github.com/OpenSourceBrain/IzhikevichModel</td>\n</tr>\n<tr>\n<td><em>Markram et al.</em>, 2015</td>\n<td>Cell models from Neocortical Microcircuit of Blue Brain Project</td>\n<td>https://github.com/OpenSourceBrain/BlueBrainProjectShowcase</td>\n</tr>\n<tr>\n<td><em>Pospischil et al.</em>, 2008</td>\n<td>HH-based models for different classes of cortical and thalamic neurons</td>\n<td>https://github.com/OpenSourceBrain/PospischilEtAl2008</td>\n</tr>\n<tr>\n<td><em>Potjans and Diesmann</em>, 2014</td>\n<td>Microcircuit model of sensory cortex with 8 populations across 4 layers</td>\n<td>https://github.com/OpenSourceBrain/PotjansDiesmann2014</td>\n</tr>\n<tr>\n<td><em>Dura-Bernal et al.</em>, 2017</td>\n<td>Model of mouse primary motor cortex (M1)</td>\n<td>https://github.com/OpenSourceBrain/M1NetworkModel</td>\n</tr>\n<tr>\n<td><em>Sadeh et al.</em>, 2017</td>\n<td>Point neuron model of Inhibition Stabilized Network</td>\n<td>https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks</td>\n</tr>\n<tr>\n<td><em>Smith et al.</em>, 2013</td>\n<td>Layer 2/3 cell model used to investigate dendritic spikes</td>\n<td>https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes</td>\n</tr>\n<tr>\n<td><em>Traub et al.</em>, 2005</td>\n<td>Single column network model containing 14 cell populations from cortex and thalamus</td>\n<td>https://github.com/OpenSourceBrain/Thalamocortical</td>\n</tr>\n<tr>\n<td><em>Bahl et al.</em>, 2012</td>\n<td>A set of reduced models of layer 5 pyramidal neurons</td>\n<td>https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell</td>\n</tr>\n<tr>\n<td><em>Wilson and Cowan</em>, 1972</td>\n<td>A classic rate-based model describing the dynamics and interactions between the excitatory and inhibitory populations of neurons</td>\n<td>https://github.com/OpenSourceBrain/WilsonCowan</td>\n</tr>\n<tr>\n<td><em>Garcia Del Molino et al.</em>, 2017</td>\n<td>Rate-based model showing paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types</td>\n<td>https://github.com/OpenSourceBrain/del-Molino2017</td>\n</tr>\n<tr>\n<td><em>Mejias et al.</em>, 2016</td>\n<td>A rate-based model simulating the dynamics of a cortical laminar structure across multiple scales: intralaminar, interlaminar, interareal and whole cortex</td>\n<td>https://github.com/OpenSourceBrain/MejiasEtAl2016</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Cerebellum</strong></td>\n</tr>\n<tr>\n<td><em>Maex and Schutter</em>, 1998</td>\n<td>Cerebellar granule cell</td>\n<td>https://github.com/OpenSourceBrain/GranuleCell</td>\n</tr>\n<tr>\n<td><em>Cayco-Gajic et al.</em>, 2017</td>\n<td>Cerebellar granule cell layer network</td>\n<td>https://github.com/SilverLabUCL/MF-GC-network-backprop-public</td>\n</tr>\n<tr>\n<td><em>Maex and Schutter</em>, 1998</td>\n<td>3D Cerebellar granule cell layer network</td>\n<td>https://github.com/OpenSourceBrain/GranCellLayer</td>\n</tr>\n<tr>\n<td><em>Solinas et al.</em>, 2007</td>\n<td>Cerebellar Golgi cell model</td>\n<td>https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell</td>\n</tr>\n<tr>\n<td><em>Vervaeke et al.</em>, 2010</td>\n<td>Electrically connected cerebellar Golgi cell network model</td>\n<td>https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Hippocampus</strong></td>\n</tr>\n<tr>\n<td><em>Bezaire et al.</em>, 2016</td>\n<td>Full scale network model of CA1 region of hippocampus</td>\n<td>https://github.com/mbezaire/ca1</td>\n</tr>\n</tbody>\n</table>","md":"| Model                            | Description                                                                                                                                                | URL                                                                             |\n| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| **Neocortex**                    |                                                                                                                                                            |                                                                                 |\n| *Billeh et al.*, 2020            | Morphologically detailed and point neuron models based on electrophysiological recordings from visual cortex neurons                                       | <https://github.com/OpenSourceBrain/AllenInstituteNeuroML>                      |\n| *Brunel*, 2000                   | Spiking network illustrating balance between excitation and inhibition                                                                                     | <https://github.com/OpenSourceBrain/Brunel2000>                                 |\n| *Hay et al.*, 2011               | Layer 5 pyramidal cell model constrained by somatic and dendritic recordings                                                                               | <https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011>                      |\n| *Izhikevich*, 2004               | Spiking neuron model reproducing wide range of neuronal activity                                                                                           | <https://github.com/OpenSourceBrain/IzhikevichModel>                            |\n| *Markram et al.*, 2015           | Cell models from Neocortical Microcircuit of Blue Brain Project                                                                                            | <https://github.com/OpenSourceBrain/BlueBrainProjectShowcase>                   |\n| *Pospischil et al.*, 2008        | HH-based models for different classes of cortical and thalamic neurons                                                                                     | <https://github.com/OpenSourceBrain/PospischilEtAl2008>                         |\n| *Potjans and Diesmann*, 2014     | Microcircuit model of sensory cortex with 8 populations across 4 layers                                                                                    | <https://github.com/OpenSourceBrain/PotjansDiesmann2014>                        |\n| *Dura-Bernal et al.*, 2017       | Model of mouse primary motor cortex (M1)                                                                                                                   | <https://github.com/OpenSourceBrain/M1NetworkModel>                             |\n| *Sadeh et al.*, 2017             | Point neuron model of Inhibition Stabilized Network                                                                                                        | <https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks> |\n| *Smith et al.*, 2013             | Layer 2/3 cell model used to investigate dendritic spikes                                                                                                  | <https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes>           |\n| *Traub et al.*, 2005             | Single column network model containing 14 cell populations from cortex and thalamus                                                                        | <https://github.com/OpenSourceBrain/Thalamocortical>                            |\n| *Bahl et al.*, 2012              | A set of reduced models of layer 5 pyramidal neurons                                                                                                       | <https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell>              |\n| *Wilson and Cowan*, 1972         | A classic rate-based model describing the dynamics and interactions between the excitatory and inhibitory populations of neurons                           | <https://github.com/OpenSourceBrain/WilsonCowan>                                |\n| *Garcia Del Molino et al.*, 2017 | Rate-based model showing paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types                            | <https://github.com/OpenSourceBrain/del-Molino2017>                             |\n| *Mejias et al.*, 2016            | A rate-based model simulating the dynamics of a cortical laminar structure across multiple scales: intralaminar, interlaminar, interareal and whole cortex | <https://github.com/OpenSourceBrain/MejiasEtAl2016>                             |\n| **Cerebellum**                   |                                                                                                                                                            |                                                                                 |\n| *Maex and Schutter*, 1998        | Cerebellar granule cell                                                                                                                                    | <https://github.com/OpenSourceBrain/GranuleCell>                                |\n| *Cayco-Gajic et al.*, 2017       | Cerebellar granule cell layer network                                                                                                                      | <https://github.com/SilverLabUCL/MF-GC-network-backprop-public>                 |\n| *Maex and Schutter*, 1998        | 3D Cerebellar granule cell layer network                                                                                                                   | <https://github.com/OpenSourceBrain/GranCellLayer>                              |\n| *Solinas et al.*, 2007           | Cerebellar Golgi cell model                                                                                                                                | <https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell>                      |\n| *Vervaeke et al.*, 2010          | Electrically connected cerebellar Golgi cell network model                                                                                                 | <https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork>              |\n| **Hippocampus**                  |                                                                                                                                                            |                                                                                 |\n| *Bezaire et al.*, 2016           | Full scale network model of CA1 region of hippocampus                                                                                                      | <https://github.com/mbezaire/ca1>                                               |","isPerfectTable":false,"csv":"\"Model\",\"Description\",\"URL\"\n\"Neocortex\",\"\",\"\"\n\"Billeh et al., 2020\",\"Morphologically detailed and point neuron models based on electrophysiological recordings from visual cortex neurons\",\"https://github.com/OpenSourceBrain/AllenInstituteNeuroML\"\n\"Brunel, 2000\",\"Spiking network illustrating balance between excitation and inhibition\",\"https://github.com/OpenSourceBrain/Brunel2000\"\n\"Hay et al., 2011\",\"Layer 5 pyramidal cell model constrained by somatic and dendritic recordings\",\"https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011\"\n\"Izhikevich, 2004\",\"Spiking neuron model reproducing wide range of neuronal activity\",\"https://github.com/OpenSourceBrain/IzhikevichModel\"\n\"Markram et al., 2015\",\"Cell models from Neocortical Microcircuit of Blue Brain Project\",\"https://github.com/OpenSourceBrain/BlueBrainProjectShowcase\"\n\"Pospischil et al., 2008\",\"HH-based models for different classes of cortical and thalamic neurons\",\"https://github.com/OpenSourceBrain/PospischilEtAl2008\"\n\"Potjans and Diesmann, 2014\",\"Microcircuit model of sensory cortex with 8 populations across 4 layers\",\"https://github.com/OpenSourceBrain/PotjansDiesmann2014\"\n\"Dura-Bernal et al., 2017\",\"Model of mouse primary motor cortex (M1)\",\"https://github.com/OpenSourceBrain/M1NetworkModel\"\n\"Sadeh et al., 2017\",\"Point neuron model of Inhibition Stabilized Network\",\"https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks\"\n\"Smith et al., 2013\",\"Layer 2/3 cell model used to investigate dendritic spikes\",\"https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes\"\n\"Traub et al., 2005\",\"Single column network model containing 14 cell populations from cortex and thalamus\",\"https://github.com/OpenSourceBrain/Thalamocortical\"\n\"Bahl et al., 2012\",\"A set of reduced models of layer 5 pyramidal neurons\",\"https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell\"\n\"Wilson and Cowan, 1972\",\"A classic rate-based model describing the dynamics and interactions between the excitatory and inhibitory populations of neurons\",\"https://github.com/OpenSourceBrain/WilsonCowan\"\n\"Garcia Del Molino et al., 2017\",\"Rate-based model showing paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types\",\"https://github.com/OpenSourceBrain/del-Molino2017\"\n\"Mejias et al., 2016\",\"A rate-based model simulating the dynamics of a cortical laminar structure across multiple scales: intralaminar, interlaminar, interareal and whole cortex\",\"https://github.com/OpenSourceBrain/MejiasEtAl2016\"\n\"Cerebellum\",\"\",\"\"\n\"Maex and Schutter, 1998\",\"Cerebellar granule cell\",\"https://github.com/OpenSourceBrain/GranuleCell\"\n\"Cayco-Gajic et al., 2017\",\"Cerebellar granule cell layer network\",\"https://github.com/SilverLabUCL/MF-GC-network-backprop-public\"\n\"Maex and Schutter, 1998\",\"3D Cerebellar granule cell layer network\",\"https://github.com/OpenSourceBrain/GranCellLayer\"\n\"Solinas et al., 2007\",\"Cerebellar Golgi cell model\",\"https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell\"\n\"Vervaeke et al., 2010\",\"Electrically connected cerebellar Golgi cell network model\",\"https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork\"\n\"Hippocampus\",\"\",\"\"\n\"Bezaire et al., 2016\",\"Full scale network model of CA1 region of hippocampus\",\"https://github.com/mbezaire/ca1\"","bBox":{"x":36.5,"y":34.63,"w":538.49,"h":720.13},"layoutAwareBbox":[{"x":34,"y":70,"w":541,"h":642,"startIndex":2,"endIndex":7}]},{"type":"text","value":"Table 8 continued on next page","md":"Table 8 continued on next page","bBox":{"x":36.5,"y":705.75,"w":126.59,"h":9},"layoutAwareBbox":[{"x":34,"y":70,"w":541,"h":642,"startIndex":0,"endIndex":29}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    22 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    22 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":314,"h":8,"startIndex":0,"endIndex":112},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/OpenSourceBrain/AllenInstituteNeuroML","unsafeUrl":"https://github.com/OpenSourceBrain/AllenInstituteNeuroML","text":"https://github.com/OpenSourceBrain/ AllenInstituteNeuroML"},{"url":"https://github.com/OpenSourceBrain/AllenInstituteNeuroML","unsafeUrl":"https://github.com/OpenSourceBrain/AllenInstituteNeuroML","text":"AllenInstituteNeuroML"},{"url":"https://github.com/OpenSourceBrain/Brunel2000","unsafeUrl":"https://github.com/OpenSourceBrain/Brunel2000","text":"https://github.com/OpenSourceBrain/Brunel2000"},{"url":"https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011","unsafeUrl":"https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011","text":"https://github.com/OpenSourceBrain/ L5bPyrCellHayEtAl2011"},{"url":"https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011","unsafeUrl":"https://github.com/OpenSourceBrain/L5bPyrCellHayEtAl2011","text":"L5bPyrCellHayEtAl2011"},{"url":"https://github.com/OpenSourceBrain/IzhikevichModel","unsafeUrl":"https://github.com/OpenSourceBrain/IzhikevichModel","text":"https://github.com/OpenSourceBrain/ IzhikevichModel"},{"url":"https://github.com/OpenSourceBrain/IzhikevichModel","unsafeUrl":"https://github.com/OpenSourceBrain/IzhikevichModel","text":"IzhikevichModel"},{"url":"https://github.com/OpenSourceBrain/BlueBrainProjectShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/BlueBrainProjectShowcase","text":"https://github.com/OpenSourceBrain/ BlueBrainProjectShowcase"},{"url":"https://github.com/OpenSourceBrain/BlueBrainProjectShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/BlueBrainProjectShowcase","text":"BlueBrainProjectShowcase"},{"url":"https://github.com/OpenSourceBrain/PospischilEtAl2008","unsafeUrl":"https://github.com/OpenSourceBrain/PospischilEtAl2008","text":"https://github.com/OpenSourceBrain/ PospischilEtAl2008"},{"url":"https://github.com/OpenSourceBrain/PospischilEtAl2008","unsafeUrl":"https://github.com/OpenSourceBrain/PospischilEtAl2008","text":"PospischilEtAl2008"},{"url":"https://github.com/OpenSourceBrain/PotjansDiesmann2014","unsafeUrl":"https://github.com/OpenSourceBrain/PotjansDiesmann2014","text":"https://github.com/OpenSourceBrain/ PotjansDiesmann2014"},{"url":"https://github.com/OpenSourceBrain/PotjansDiesmann2014","unsafeUrl":"https://github.com/OpenSourceBrain/PotjansDiesmann2014","text":"PotjansDiesmann2014"},{"url":"https://github.com/OpenSourceBrain/M1NetworkModel","unsafeUrl":"https://github.com/OpenSourceBrain/M1NetworkModel","text":"https://github.com/OpenSourceBrain/ M1NetworkModel"},{"url":"https://github.com/OpenSourceBrain/M1NetworkModel","unsafeUrl":"https://github.com/OpenSourceBrain/M1NetworkModel","text":"M1NetworkModel"},{"url":"https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks","unsafeUrl":"https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks","text":"https://github.com/OpenSourceBrain/ SadehEtAl2017-InhibitionStabilizedNetworks"},{"url":"https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks","unsafeUrl":"https://github.com/OpenSourceBrain/SadehEtAl2017-InhibitionStabilizedNetworks","text":"SadehEtAl2017-InhibitionStabilizedNetworks"},{"url":"https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes","unsafeUrl":"https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes","text":"https://github.com/OpenSourceBrain/ SmithEtAl2013-L23DendriticSpikes"},{"url":"https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes","unsafeUrl":"https://github.com/OpenSourceBrain/SmithEtAl2013-L23DendriticSpikes","text":"SmithEtAl2013-L23DendriticSpikes"},{"url":"https://github.com/OpenSourceBrain/Thalamocortical","unsafeUrl":"https://github.com/OpenSourceBrain/Thalamocortical","text":"https://github.com/OpenSourceBrain/ Thalamocortical"},{"url":"https://github.com/OpenSourceBrain/Thalamocortical","unsafeUrl":"https://github.com/OpenSourceBrain/Thalamocortical","text":"Thalamocortical"},{"url":"https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell","unsafeUrl":"https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell","text":"https://github.com/OpenSourceBrain/ BahlEtAl2012_ReducedL5PyrCell"},{"url":"https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell","unsafeUrl":"https://github.com/OpenSourceBrain/BahlEtAl2012_ReducedL5PyrCell","text":"BahlEtAl2012_ReducedL5PyrCell"},{"url":"https://github.com/OpenSourceBrain/WilsonCowan","unsafeUrl":"https://github.com/OpenSourceBrain/WilsonCowan","text":"WilsonCowan"},{"url":"https://github.com/OpenSourceBrain/WilsonCowan","unsafeUrl":"https://github.com/OpenSourceBrain/WilsonCowan","text":""},{"url":"https://github.com/OpenSourceBrain/del-Molino2017","unsafeUrl":"https://github.com/OpenSourceBrain/del-Molino2017","text":"Molino2017"},{"url":"https://github.com/OpenSourceBrain/del-Molino2017","unsafeUrl":"https://github.com/OpenSourceBrain/del-Molino2017","text":""},{"url":"https://github.com/OpenSourceBrain/MejiasEtAl2016","unsafeUrl":"https://github.com/OpenSourceBrain/MejiasEtAl2016","text":"MejiasEtAl2016"},{"url":"https://github.com/OpenSourceBrain/MejiasEtAl2016","unsafeUrl":"https://github.com/OpenSourceBrain/MejiasEtAl2016","text":""},{"url":"https://github.com/OpenSourceBrain/GranuleCell","unsafeUrl":"https://github.com/OpenSourceBrain/GranuleCell","text":"GranuleCell"},{"url":"https://github.com/OpenSourceBrain/GranuleCell","unsafeUrl":"https://github.com/OpenSourceBrain/GranuleCell","text":""},{"url":"https://github.com/SilverLabUCL/MF-GC-network-backprop-public","unsafeUrl":"https://github.com/SilverLabUCL/MF-GC-network-backprop-public","text":"network-backprop-public"},{"url":"https://github.com/SilverLabUCL/MF-GC-network-backprop-public","unsafeUrl":"https://github.com/SilverLabUCL/MF-GC-network-backprop-public","text":""},{"url":"https://github.com/OpenSourceBrain/GranCellLayer","unsafeUrl":"https://github.com/OpenSourceBrain/GranCellLayer","text":"GranCellLayer"},{"url":"https://github.com/OpenSourceBrain/GranCellLayer","unsafeUrl":"https://github.com/OpenSourceBrain/GranCellLayer","text":""},{"url":"https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell","unsafeUrl":"https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell","text":"SolinasEtAl-GolgiCell"},{"url":"https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell","unsafeUrl":"https://github.com/OpenSourceBrain/SolinasEtAl-GolgiCell","text":""},{"url":"https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork","unsafeUrl":"https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork","text":"VervaekeEtAl-GolgiCellNetwork"},{"url":"https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork","unsafeUrl":"https://github.com/OpenSourceBrain/VervaekeEtAl-GolgiCellNetwork","text":""},{"url":"https://github.com/mbezaire/ca1","unsafeUrl":"https://github.com/mbezaire/ca1","text":""}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                          Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    22 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":1,"layout":[{"image":"page_22_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.056,"y":0.089,"w":0.884,"h":0.811},"isLikelyNoise":false},{"image":"page_22_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_22_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_22_number_1_v2.jpg","confidence":0.9,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_22_figure_title_1_v2.jpg","confidence":0.71,"label":"figure_title","bbox":{"x":0.056,"y":0.073,"w":0.414,"h":0.012},"isLikelyNoise":false},{"image":"page_22_header_2_v2.jpg","confidence":0.69,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_22_header_3_v2.jpg","confidence":0.68,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.017},"isLikelyNoise":false},{"image":"page_22_figure_title_2_v2.jpg","confidence":0.58,"label":"figure_title","bbox":{"x":0.056,"y":0.073,"w":0.414,"h":0.029},"isLikelyNoise":true}]},{"page":23,"text":"         Tools  and  resources                                                                                         Neuroscience\n\nTable 8 continued\nModel                             Description                                         URL\n\n                                  Parvalbumin-positive interneuron from CA1,          https://github.com/OpenSourceBrain/\nFerguson et al., 2013             based on Izhikevich cell model                      FergusonEtAl2013-PVFastFiringCell\n\n                                  Pyramidal cell from CA1, based on Izhikevich cell   https://github.com/OpenSourceBrain/\nFerguson et al., 2014             model                                               FergusonEtAl2014-CA1PyrCell\n\n                                  Multi-compartmental model of pyramidal cell         https://github.com/OpenSourceBrain/\nMigliore et al., 2005             from CA1 region of hippocampus                      CA1PyramidalCell\n\n                                                                                      https://github.com/OpenSourceBrain/\nPinsky and Rinzel, 1994           Simplified model of CA3 pyramidal cell              PinskyRinzelModel\n\n                                  Hippocampal interneuronal network model             https://github.com/OpenSourceBrain/\nWang and Buzsáki, 1996            exhibiting gamma oscillations                       WangBuzsaki1996\n\nOlfactory bulb\n\n                                  Large-scale 3D olfactory bulb network with          https://github.com/OpenSourceBrain/\nMigliore et al., 2014             detailed mitral cells and granule cells             MiglioreEtAl14_OlfactoryBulb3D\n\nInvertebrate\n\n                                  Classic investigation of the ionic basis of the     https://github.com/openworm/hodgkin_huxley_\nHodgkin and Huxley, 1952          action potential                                    tutorial\n\n                                                                                      https://github.com/OpenSourceBrain/FitzHugh-\nFitzHugh, 1961                    Simplified form of Hodgkin Huxley model             Nagumo\n\n                                  Pyloric network of the lobster stomatogastric       https://github.com/OpenSourceBrain/\nPrinz et al., 2004                ganglion system                                     PyloricNetwork\n\nBoyle and Cohen, 2008             Model of body wall muscle from C. elegans           https://github.com/openworm/muscle_model\n\n                                  A multiscale framework for modeling the nervous\nGleeson et al., 2018              system of C. elegans                                https://github.com/openworm/c302\n\nGeneral\n\n                                  Two dimensional reduced neuron model with           https://github.com/OpenSourceBrain/\nMorris and Lecar, 1981            calcium and potassium conductances                  MorrisLecarModel\n\n                                  A simplified point cell model which captures\n                                  complex firing patterns of single neurons, such as https://github.com/OpenSourceBrain/\nHindmarsh and Rose, 1984          periodic and chaotic bursting                       HindmarshRose1984\n\nShowcases\n\n                                                                                      https://github.com/OpenSourceBrain/\nNEST Showcase                     Examples of interactions with simulator NEST        NESTShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nPyNN Showcase                     PyNN                                                PyNNShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nNetPyNE Showcase                  NetPyNE                                             NetPyNEShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nSBML Showcase                     SBML                                                SBMLShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nBrian Showcase                    Brian                                               BrianShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nMOOSE Showcase                    MOOSE                                               MOOSEShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nArbor Showcase                    Arbor                                               ArborShowcase\n\n                                  Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\nEDEN Showcase                     EDEN                                                EDENShowcase\n\nThe Virtual Brain Showcase        Examples of interactions between NeuroML and        https://github.com/OpenSourceBrain/\n                                  TVB                                                 TheVirtualBrainShowcase\nTable 8 continued on next page\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    23 of 44","md":"\n\neLife Tools and resources                                                                                         Neuroscience\n\nTable 8 continued\n\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ferguson et al., 2013</td>\n<td>Parvalbumin-positive interneuron from CA1, based on Izhikevich cell model</td>\n<td>https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell</td>\n</tr>\n<tr>\n<td>Ferguson et al., 2014</td>\n<td>Pyramidal cell from CA1, based on Izhikevich cell model</td>\n<td>https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell</td>\n</tr>\n<tr>\n<td>Migliore et al., 2005</td>\n<td>Multi-compartmental model of pyramidal cell from CA1 region of hippocampus</td>\n<td>https://github.com/OpenSourceBrain/CA1PyramidalCell</td>\n</tr>\n<tr>\n<td>Pinsky and Rinzel, 1994</td>\n<td>Simplified model of CA3 pyramidal cell</td>\n<td>https://github.com/OpenSourceBrain/PinskyRinzelModel</td>\n</tr>\n<tr>\n<td>Wang and Buzsáki, 1996</td>\n<td>Hippocampal interneuronal network model exhibiting gamma oscillations</td>\n<td>https://github.com/OpenSourceBrain/WangBuzsaki1996</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Olfactory bulb</strong></td>\n</tr>\n<tr>\n<td>Migliore et al., 2014</td>\n<td>Large-scale 3D olfactory bulb network with detailed mitral cells and granule cells</td>\n<td>https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Invertebrate</strong></td>\n</tr>\n<tr>\n<td>Hodgkin and Huxley, 1952</td>\n<td>Classic investigation of the ionic basis of the action potential</td>\n<td>https://github.com/openworm/hodgkin_huxley_tutorial</td>\n</tr>\n<tr>\n<td>FitzHugh, 1961</td>\n<td>Simplified form of Hodgkin Huxley model</td>\n<td>https://github.com/OpenSourceBrain/FitzHugh-Nagumo</td>\n</tr>\n<tr>\n<td>Prinz et al., 2004</td>\n<td>Pyloric network of the lobster stomatogastric ganglion system</td>\n<td>https://github.com/OpenSourceBrain/PyloricNetwork</td>\n</tr>\n<tr>\n<td>Boyle and Cohen, 2008</td>\n<td>Model of body wall muscle from C. elegans</td>\n<td>https://github.com/openworm/muscle_model</td>\n</tr>\n<tr>\n<td>Gleeson et al., 2018</td>\n<td>A multiscale framework for modeling the nervous system of C. elegans</td>\n<td>https://github.com/openworm/c302</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>General</strong></td>\n</tr>\n<tr>\n<td>Morris and Lecar, 1981</td>\n<td>Two dimensional reduced neuron model with calcium and potassium conductances</td>\n<td>https://github.com/OpenSourceBrain/MorrisLecarModel</td>\n</tr>\n<tr>\n<td>Hindmarsh and Rose, 1984</td>\n<td>A simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting</td>\n<td>https://github.com/OpenSourceBrain/HindmarshRose1984</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Showcases</strong></td>\n</tr>\n<tr>\n<td>NEST Showcase</td>\n<td>Examples of interactions with simulator NEST</td>\n<td>https://github.com/OpenSourceBrain/NESTShowcase</td>\n</tr>\n<tr>\n<td>PyNN Showcase</td>\n<td>Examples of interactions between NeuroML and PyNN</td>\n<td>https://github.com/OpenSourceBrain/PyNNShowcase</td>\n</tr>\n<tr>\n<td>NetPyNE Showcase</td>\n<td>Examples of interactions between NeuroML and NetPyNE</td>\n<td>https://github.com/OpenSourceBrain/NetPyNEShowcase</td>\n</tr>\n<tr>\n<td>SBML Showcase</td>\n<td>Examples of interactions between NeuroML and SBML</td>\n<td>https://github.com/OpenSourceBrain/SBMLShowcase</td>\n</tr>\n<tr>\n<td>Brian Showcase</td>\n<td>Examples of interactions between NeuroML and Brian</td>\n<td>https://github.com/OpenSourceBrain/BrianShowcase</td>\n</tr>\n<tr>\n<td>MOOSE Showcase</td>\n<td>Examples of interactions between NeuroML and MOOSE</td>\n<td>https://github.com/OpenSourceBrain/MOOSEShowcase</td>\n</tr>\n<tr>\n<td>Arbor Showcase</td>\n<td>Examples of interactions between NeuroML and Arbor</td>\n<td>https://github.com/OpenSourceBrain/ArborShowcase</td>\n</tr>\n<tr>\n<td>EDEN Showcase</td>\n<td>Examples of interactions between NeuroML and EDEN</td>\n<td>https://github.com/OpenSourceBrain/EDENShowcase</td>\n</tr>\n<tr>\n<td>The Virtual Brain Showcase</td>\n<td>Examples of interactions between NeuroML and TVB</td>\n<td>https://github.com/OpenSourceBrain/TheVirtualBrainShowcase</td>\n</tr>\n</tbody>\n</table>\n\nTable 8 continued on next page\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    23 of 44\n","images":[{"name":"page_23.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_23_table_1_v2.jpg","height":498204.353,"width":331524.625,"x":20728.478,"y":52623.097,"original_width":2189,"original_height":2542,"rotation":0,"type":"layout_v2_table"},{"name":"page_23_footer_1_v2.jpg","height":6826.925,"width":192222.612,"x":21435.686,"y":591530.161,"original_width":1270,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_23_header_1_v2.jpg","height":5675.782,"width":30270.985,"x":320849.338,"y":27656.932,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_23_number_1_v2.jpg","height":5889.42,"width":18228.888,"x":332910.852,"y":591796.729,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_23_text_1_v2.jpg","height":7214.927,"width":77888.96,"x":21934.079,"y":553445.298,"original_width":515,"original_height":37,"rotation":0,"type":"layout_v2_text"},{"name":"page_23_figure_title_1_v2.jpg","height":6950.267,"width":44287.301,"x":21813.681,"y":41564.917,"original_width":293,"original_height":36,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_23_header_2_v2.jpg","height":11190.668,"width":24732.417,"x":21642.236,"y":22419.983,"original_width":164,"original_height":58,"rotation":0,"type":"layout_v2_header"},{"name":"page_23_header_3_v2.jpg","height":11475.106,"width":69323.372,"x":21492.697,"y":22584.407,"original_width":458,"original_height":59,"rotation":0,"type":"layout_v2_header"},{"name":"page_23_header_4_v2.jpg","height":6154.61,"width":42863.819,"x":47724.334,"y":27514.123,"original_width":284,"original_height":32,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                         Neuroscience","md":"eLife Tools and resources                                                                                         Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":35,"y":28,"w":113,"h":14,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":114,"endIndex":126}]},{"type":"text","value":"Table 8 continued","md":"Table 8 continued","bBox":{"x":36.5,"y":51.8,"w":71.21,"h":9},"layoutAwareBbox":[{"x":35,"y":52,"w":72,"h":8,"startIndex":0,"endIndex":16}]},{"type":"table","rows":[["Model","Description","URL"],["Ferguson et al., 2013","Parvalbumin-positive interneuron from CA1, based on Izhikevich cell model","https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell"],["Ferguson et al., 2014","Pyramidal cell from CA1, based on Izhikevich cell model","https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell"],["Migliore et al., 2005","Multi-compartmental model of pyramidal cell from CA1 region of hippocampus","https://github.com/OpenSourceBrain/CA1PyramidalCell"],["Pinsky and Rinzel, 1994","Simplified model of CA3 pyramidal cell","https://github.com/OpenSourceBrain/PinskyRinzelModel"],["Wang and Buzsáki, 1996","Hippocampal interneuronal network model exhibiting gamma oscillations","https://github.com/OpenSourceBrain/WangBuzsaki1996"],["Olfactory bulb","",""],["Migliore et al., 2014","Large-scale 3D olfactory bulb network with detailed mitral cells and granule cells","https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D"],["Invertebrate","",""],["Hodgkin and Huxley, 1952","Classic investigation of the ionic basis of the action potential","https://github.com/openworm/hodgkin_huxley_tutorial"],["FitzHugh, 1961","Simplified form of Hodgkin Huxley model","https://github.com/OpenSourceBrain/FitzHugh-Nagumo"],["Prinz et al., 2004","Pyloric network of the lobster stomatogastric ganglion system","https://github.com/OpenSourceBrain/PyloricNetwork"],["Boyle and Cohen, 2008","Model of body wall muscle from C. elegans","https://github.com/openworm/muscle_model"],["Gleeson et al., 2018","A multiscale framework for modeling the nervous system of C. elegans","https://github.com/openworm/c302"],["General","",""],["Morris and Lecar, 1981","Two dimensional reduced neuron model with calcium and potassium conductances","https://github.com/OpenSourceBrain/MorrisLecarModel"],["Hindmarsh and Rose, 1984","A simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting","https://github.com/OpenSourceBrain/HindmarshRose1984"],["Showcases","",""],["NEST Showcase","Examples of interactions with simulator NEST","https://github.com/OpenSourceBrain/NESTShowcase"],["PyNN Showcase","Examples of interactions between NeuroML and PyNN","https://github.com/OpenSourceBrain/PyNNShowcase"],["NetPyNE Showcase","Examples of interactions between NeuroML and NetPyNE","https://github.com/OpenSourceBrain/NetPyNEShowcase"],["SBML Showcase","Examples of interactions between NeuroML and SBML","https://github.com/OpenSourceBrain/SBMLShowcase"],["Brian Showcase","Examples of interactions between NeuroML and Brian","https://github.com/OpenSourceBrain/BrianShowcase"],["MOOSE Showcase","Examples of interactions between NeuroML and MOOSE","https://github.com/OpenSourceBrain/MOOSEShowcase"],["Arbor Showcase","Examples of interactions between NeuroML and Arbor","https://github.com/OpenSourceBrain/ArborShowcase"],["EDEN Showcase","Examples of interactions between NeuroML and EDEN","https://github.com/OpenSourceBrain/EDENShowcase"],["The Virtual Brain Showcase","Examples of interactions between NeuroML and TVB","https://github.com/OpenSourceBrain/TheVirtualBrainShowcase"]],"html":"<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ferguson et al., 2013</td>\n<td>Parvalbumin-positive interneuron from CA1, based on Izhikevich cell model</td>\n<td>https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell</td>\n</tr>\n<tr>\n<td>Ferguson et al., 2014</td>\n<td>Pyramidal cell from CA1, based on Izhikevich cell model</td>\n<td>https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell</td>\n</tr>\n<tr>\n<td>Migliore et al., 2005</td>\n<td>Multi-compartmental model of pyramidal cell from CA1 region of hippocampus</td>\n<td>https://github.com/OpenSourceBrain/CA1PyramidalCell</td>\n</tr>\n<tr>\n<td>Pinsky and Rinzel, 1994</td>\n<td>Simplified model of CA3 pyramidal cell</td>\n<td>https://github.com/OpenSourceBrain/PinskyRinzelModel</td>\n</tr>\n<tr>\n<td>Wang and Buzsáki, 1996</td>\n<td>Hippocampal interneuronal network model exhibiting gamma oscillations</td>\n<td>https://github.com/OpenSourceBrain/WangBuzsaki1996</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Olfactory bulb</strong></td>\n</tr>\n<tr>\n<td>Migliore et al., 2014</td>\n<td>Large-scale 3D olfactory bulb network with detailed mitral cells and granule cells</td>\n<td>https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Invertebrate</strong></td>\n</tr>\n<tr>\n<td>Hodgkin and Huxley, 1952</td>\n<td>Classic investigation of the ionic basis of the action potential</td>\n<td>https://github.com/openworm/hodgkin_huxley_tutorial</td>\n</tr>\n<tr>\n<td>FitzHugh, 1961</td>\n<td>Simplified form of Hodgkin Huxley model</td>\n<td>https://github.com/OpenSourceBrain/FitzHugh-Nagumo</td>\n</tr>\n<tr>\n<td>Prinz et al., 2004</td>\n<td>Pyloric network of the lobster stomatogastric ganglion system</td>\n<td>https://github.com/OpenSourceBrain/PyloricNetwork</td>\n</tr>\n<tr>\n<td>Boyle and Cohen, 2008</td>\n<td>Model of body wall muscle from C. elegans</td>\n<td>https://github.com/openworm/muscle_model</td>\n</tr>\n<tr>\n<td>Gleeson et al., 2018</td>\n<td>A multiscale framework for modeling the nervous system of C. elegans</td>\n<td>https://github.com/openworm/c302</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>General</strong></td>\n</tr>\n<tr>\n<td>Morris and Lecar, 1981</td>\n<td>Two dimensional reduced neuron model with calcium and potassium conductances</td>\n<td>https://github.com/OpenSourceBrain/MorrisLecarModel</td>\n</tr>\n<tr>\n<td>Hindmarsh and Rose, 1984</td>\n<td>A simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting</td>\n<td>https://github.com/OpenSourceBrain/HindmarshRose1984</td>\n</tr>\n<tr>\n<td colspan=\"3\"><strong>Showcases</strong></td>\n</tr>\n<tr>\n<td>NEST Showcase</td>\n<td>Examples of interactions with simulator NEST</td>\n<td>https://github.com/OpenSourceBrain/NESTShowcase</td>\n</tr>\n<tr>\n<td>PyNN Showcase</td>\n<td>Examples of interactions between NeuroML and PyNN</td>\n<td>https://github.com/OpenSourceBrain/PyNNShowcase</td>\n</tr>\n<tr>\n<td>NetPyNE Showcase</td>\n<td>Examples of interactions between NeuroML and NetPyNE</td>\n<td>https://github.com/OpenSourceBrain/NetPyNEShowcase</td>\n</tr>\n<tr>\n<td>SBML Showcase</td>\n<td>Examples of interactions between NeuroML and SBML</td>\n<td>https://github.com/OpenSourceBrain/SBMLShowcase</td>\n</tr>\n<tr>\n<td>Brian Showcase</td>\n<td>Examples of interactions between NeuroML and Brian</td>\n<td>https://github.com/OpenSourceBrain/BrianShowcase</td>\n</tr>\n<tr>\n<td>MOOSE Showcase</td>\n<td>Examples of interactions between NeuroML and MOOSE</td>\n<td>https://github.com/OpenSourceBrain/MOOSEShowcase</td>\n</tr>\n<tr>\n<td>Arbor Showcase</td>\n<td>Examples of interactions between NeuroML and Arbor</td>\n<td>https://github.com/OpenSourceBrain/ArborShowcase</td>\n</tr>\n<tr>\n<td>EDEN Showcase</td>\n<td>Examples of interactions between NeuroML and EDEN</td>\n<td>https://github.com/OpenSourceBrain/EDENShowcase</td>\n</tr>\n<tr>\n<td>The Virtual Brain Showcase</td>\n<td>Examples of interactions between NeuroML and TVB</td>\n<td>https://github.com/OpenSourceBrain/TheVirtualBrainShowcase</td>\n</tr>\n</tbody>\n</table>","md":"| Model                      | Description                                                                                                                   | URL                                                                    |\n| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| Ferguson et al., 2013      | Parvalbumin-positive interneuron from CA1, based on Izhikevich cell model                                                     | <https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell> |\n| Ferguson et al., 2014      | Pyramidal cell from CA1, based on Izhikevich cell model                                                                       | <https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell>       |\n| Migliore et al., 2005      | Multi-compartmental model of pyramidal cell from CA1 region of hippocampus                                                    | <https://github.com/OpenSourceBrain/CA1PyramidalCell>                  |\n| Pinsky and Rinzel, 1994    | Simplified model of CA3 pyramidal cell                                                                                        | <https://github.com/OpenSourceBrain/PinskyRinzelModel>                 |\n| Wang and Buzsáki, 1996     | Hippocampal interneuronal network model exhibiting gamma oscillations                                                         | <https://github.com/OpenSourceBrain/WangBuzsaki1996>                   |\n| **Olfactory bulb**         |                                                                                                                               |                                                                        |\n| Migliore et al., 2014      | Large-scale 3D olfactory bulb network with detailed mitral cells and granule cells                                            | <https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D>    |\n| **Invertebrate**           |                                                                                                                               |                                                                        |\n| Hodgkin and Huxley, 1952   | Classic investigation of the ionic basis of the action potential                                                              | <https://github.com/openworm/hodgkin_huxley_tutorial>                  |\n| FitzHugh, 1961             | Simplified form of Hodgkin Huxley model                                                                                       | <https://github.com/OpenSourceBrain/FitzHugh-Nagumo>                   |\n| Prinz et al., 2004         | Pyloric network of the lobster stomatogastric ganglion system                                                                 | <https://github.com/OpenSourceBrain/PyloricNetwork>                    |\n| Boyle and Cohen, 2008      | Model of body wall muscle from C. elegans                                                                                     | <https://github.com/openworm/muscle_model>                             |\n| Gleeson et al., 2018       | A multiscale framework for modeling the nervous system of C. elegans                                                          | <https://github.com/openworm/c302>                                     |\n| **General**                |                                                                                                                               |                                                                        |\n| Morris and Lecar, 1981     | Two dimensional reduced neuron model with calcium and potassium conductances                                                  | <https://github.com/OpenSourceBrain/MorrisLecarModel>                  |\n| Hindmarsh and Rose, 1984   | A simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting | <https://github.com/OpenSourceBrain/HindmarshRose1984>                 |\n| **Showcases**              |                                                                                                                               |                                                                        |\n| NEST Showcase              | Examples of interactions with simulator NEST                                                                                  | <https://github.com/OpenSourceBrain/NESTShowcase>                      |\n| PyNN Showcase              | Examples of interactions between NeuroML and PyNN                                                                             | <https://github.com/OpenSourceBrain/PyNNShowcase>                      |\n| NetPyNE Showcase           | Examples of interactions between NeuroML and NetPyNE                                                                          | <https://github.com/OpenSourceBrain/NetPyNEShowcase>                   |\n| SBML Showcase              | Examples of interactions between NeuroML and SBML                                                                             | <https://github.com/OpenSourceBrain/SBMLShowcase>                      |\n| Brian Showcase             | Examples of interactions between NeuroML and Brian                                                                            | <https://github.com/OpenSourceBrain/BrianShowcase>                     |\n| MOOSE Showcase             | Examples of interactions between NeuroML and MOOSE                                                                            | <https://github.com/OpenSourceBrain/MOOSEShowcase>                     |\n| Arbor Showcase             | Examples of interactions between NeuroML and Arbor                                                                            | <https://github.com/OpenSourceBrain/ArborShowcase>                     |\n| EDEN Showcase              | Examples of interactions between NeuroML and EDEN                                                                             | <https://github.com/OpenSourceBrain/EDENShowcase>                      |\n| The Virtual Brain Showcase | Examples of interactions between NeuroML and TVB                                                                              | <https://github.com/OpenSourceBrain/TheVirtualBrainShowcase>           |","isPerfectTable":false,"csv":"\"Model\",\"Description\",\"URL\"\n\"Ferguson et al., 2013\",\"Parvalbumin-positive interneuron from CA1, based on Izhikevich cell model\",\"https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell\"\n\"Ferguson et al., 2014\",\"Pyramidal cell from CA1, based on Izhikevich cell model\",\"https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell\"\n\"Migliore et al., 2005\",\"Multi-compartmental model of pyramidal cell from CA1 region of hippocampus\",\"https://github.com/OpenSourceBrain/CA1PyramidalCell\"\n\"Pinsky and Rinzel, 1994\",\"Simplified model of CA3 pyramidal cell\",\"https://github.com/OpenSourceBrain/PinskyRinzelModel\"\n\"Wang and Buzsáki, 1996\",\"Hippocampal interneuronal network model exhibiting gamma oscillations\",\"https://github.com/OpenSourceBrain/WangBuzsaki1996\"\n\"Olfactory bulb\",\"\",\"\"\n\"Migliore et al., 2014\",\"Large-scale 3D olfactory bulb network with detailed mitral cells and granule cells\",\"https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D\"\n\"Invertebrate\",\"\",\"\"\n\"Hodgkin and Huxley, 1952\",\"Classic investigation of the ionic basis of the action potential\",\"https://github.com/openworm/hodgkin_huxley_tutorial\"\n\"FitzHugh, 1961\",\"Simplified form of Hodgkin Huxley model\",\"https://github.com/OpenSourceBrain/FitzHugh-Nagumo\"\n\"Prinz et al., 2004\",\"Pyloric network of the lobster stomatogastric ganglion system\",\"https://github.com/OpenSourceBrain/PyloricNetwork\"\n\"Boyle and Cohen, 2008\",\"Model of body wall muscle from C. elegans\",\"https://github.com/openworm/muscle_model\"\n\"Gleeson et al., 2018\",\"A multiscale framework for modeling the nervous system of C. elegans\",\"https://github.com/openworm/c302\"\n\"General\",\"\",\"\"\n\"Morris and Lecar, 1981\",\"Two dimensional reduced neuron model with calcium and potassium conductances\",\"https://github.com/OpenSourceBrain/MorrisLecarModel\"\n\"Hindmarsh and Rose, 1984\",\"A simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting\",\"https://github.com/OpenSourceBrain/HindmarshRose1984\"\n\"Showcases\",\"\",\"\"\n\"NEST Showcase\",\"Examples of interactions with simulator NEST\",\"https://github.com/OpenSourceBrain/NESTShowcase\"\n\"PyNN Showcase\",\"Examples of interactions between NeuroML and PyNN\",\"https://github.com/OpenSourceBrain/PyNNShowcase\"\n\"NetPyNE Showcase\",\"Examples of interactions between NeuroML and NetPyNE\",\"https://github.com/OpenSourceBrain/NetPyNEShowcase\"\n\"SBML Showcase\",\"Examples of interactions between NeuroML and SBML\",\"https://github.com/OpenSourceBrain/SBMLShowcase\"\n\"Brian Showcase\",\"Examples of interactions between NeuroML and Brian\",\"https://github.com/OpenSourceBrain/BrianShowcase\"\n\"MOOSE Showcase\",\"Examples of interactions between NeuroML and MOOSE\",\"https://github.com/OpenSourceBrain/MOOSEShowcase\"\n\"Arbor Showcase\",\"Examples of interactions between NeuroML and Arbor\",\"https://github.com/OpenSourceBrain/ArborShowcase\"\n\"EDEN Showcase\",\"Examples of interactions between NeuroML and EDEN\",\"https://github.com/OpenSourceBrain/EDENShowcase\"\n\"The Virtual Brain Showcase\",\"Examples of interactions between NeuroML and TVB\",\"https://github.com/OpenSourceBrain/TheVirtualBrainShowcase\"","bBox":{"x":36.5,"y":34.63,"w":538.49,"h":720.13},"layoutAwareBbox":[{"x":33,"y":66,"w":541,"h":629,"startIndex":2,"endIndex":7}]},{"type":"text","value":"Table 8 continued on next page","md":"Table 8 continued on next page","bBox":{"x":36.5,"y":697.85,"w":126.59,"h":9},"layoutAwareBbox":[{"x":35,"y":698,"w":127,"h":9,"startIndex":0,"endIndex":29}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    23 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    23 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":314,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell","unsafeUrl":"https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell","text":"https://github.com/OpenSourceBrain/ FergusonEtAl2013-PVFastFiringCell"},{"url":"https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell","unsafeUrl":"https://github.com/OpenSourceBrain/FergusonEtAl2013-PVFastFiringCell","text":"FergusonEtAl2013-PVFastFiringCell"},{"url":"https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell","unsafeUrl":"https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell","text":"https://github.com/OpenSourceBrain/ FergusonEtAl2014-CA1PyrCell"},{"url":"https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell","unsafeUrl":"https://github.com/OpenSourceBrain/FergusonEtAl2014-CA1PyrCell","text":"FergusonEtAl2014-CA1PyrCell"},{"url":"https://github.com/OpenSourceBrain/CA1PyramidalCell","unsafeUrl":"https://github.com/OpenSourceBrain/CA1PyramidalCell","text":"https://github.com/OpenSourceBrain/ CA1PyramidalCell"},{"url":"https://github.com/OpenSourceBrain/CA1PyramidalCell","unsafeUrl":"https://github.com/OpenSourceBrain/CA1PyramidalCell","text":"CA1PyramidalCell"},{"url":"https://github.com/OpenSourceBrain/PinskyRinzelModel","unsafeUrl":"https://github.com/OpenSourceBrain/PinskyRinzelModel","text":"https://github.com/OpenSourceBrain/ PinskyRinzelModel"},{"url":"https://github.com/OpenSourceBrain/PinskyRinzelModel","unsafeUrl":"https://github.com/OpenSourceBrain/PinskyRinzelModel","text":"PinskyRinzelModel"},{"url":"https://github.com/OpenSourceBrain/WangBuzsaki1996","unsafeUrl":"https://github.com/OpenSourceBrain/WangBuzsaki1996","text":"https://github.com/OpenSourceBrain/ WangBuzsaki1996"},{"url":"https://github.com/OpenSourceBrain/WangBuzsaki1996","unsafeUrl":"https://github.com/OpenSourceBrain/WangBuzsaki1996","text":"WangBuzsaki1996"},{"url":"https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D","unsafeUrl":"https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D","text":"https://github.com/OpenSourceBrain/ MiglioreEtAl14_OlfactoryBulb3D"},{"url":"https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D","unsafeUrl":"https://github.com/OpenSourceBrain/MiglioreEtAl14_OlfactoryBulb3D","text":"MiglioreEtAl14_OlfactoryBulb3D"},{"url":"https://github.com/openworm/hodgkin_huxley_tutorial","unsafeUrl":"https://github.com/openworm/hodgkin_huxley_tutorial","text":"https://github.com/openworm/hodgkin_huxley_ tutorial"},{"url":"https://github.com/openworm/hodgkin_huxley_tutorial","unsafeUrl":"https://github.com/openworm/hodgkin_huxley_tutorial","text":"tutorial"},{"url":"https://github.com/OpenSourceBrain/FitzHugh-Nagumo","unsafeUrl":"https://github.com/OpenSourceBrain/FitzHugh-Nagumo","text":"https://github.com/OpenSourceBrain/FitzHugh- Nagumo"},{"url":"https://github.com/OpenSourceBrain/FitzHugh-Nagumo","unsafeUrl":"https://github.com/OpenSourceBrain/FitzHugh-Nagumo","text":"Nagumo"},{"url":"https://github.com/OpenSourceBrain/PyloricNetwork","unsafeUrl":"https://github.com/OpenSourceBrain/PyloricNetwork","text":"https://github.com/OpenSourceBrain/ PyloricNetwork"},{"url":"https://github.com/OpenSourceBrain/PyloricNetwork","unsafeUrl":"https://github.com/OpenSourceBrain/PyloricNetwork","text":"PyloricNetwork"},{"url":"https://github.com/openworm/muscle_model","unsafeUrl":"https://github.com/openworm/muscle_model","text":"https://github.com/openworm/muscle_model"},{"url":"https://github.com/openworm/c302","unsafeUrl":"https://github.com/openworm/c302","text":"https://github.com/openworm/c302"},{"url":"https://github.com/OpenSourceBrain/MorrisLecarModel","unsafeUrl":"https://github.com/OpenSourceBrain/MorrisLecarModel","text":"https://github.com/OpenSourceBrain/ MorrisLecarModel"},{"url":"https://github.com/OpenSourceBrain/MorrisLecarModel","unsafeUrl":"https://github.com/OpenSourceBrain/MorrisLecarModel","text":"MorrisLecarModel"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984","text":"HindmarshRose1984"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984","text":""},{"url":"https://github.com/OpenSourceBrain/NESTShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NESTShowcase","text":"NESTShowcase"},{"url":"https://github.com/OpenSourceBrain/NESTShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NESTShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/PyNNShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/PyNNShowcase","text":"PyNNShowcase"},{"url":"https://github.com/OpenSourceBrain/PyNNShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/PyNNShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/NetPyNEShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NetPyNEShowcase","text":"NetPyNEShowcase"},{"url":"https://github.com/OpenSourceBrain/NetPyNEShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NetPyNEShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/SBMLShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/SBMLShowcase","text":"SBMLShowcase"},{"url":"https://github.com/OpenSourceBrain/SBMLShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/SBMLShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/BrianShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/BrianShowcase","text":"BrianShowcase"},{"url":"https://github.com/OpenSourceBrain/BrianShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/BrianShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/MOOSEShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/MOOSEShowcase","text":"MOOSEShowcase"},{"url":"https://github.com/OpenSourceBrain/MOOSEShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/MOOSEShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/ArborShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/ArborShowcase","text":"ArborShowcase"},{"url":"https://github.com/OpenSourceBrain/ArborShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/ArborShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/EDENShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/EDENShowcase","text":"EDENShowcase"},{"url":"https://github.com/OpenSourceBrain/EDENShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/EDENShowcase","text":""},{"url":"https://github.com/OpenSourceBrain/TheVirtualBrainShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/TheVirtualBrainShowcase","text":"TheVirtualBrainShowcase"},{"url":"https://github.com/OpenSourceBrain/TheVirtualBrainShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/TheVirtualBrainShowcase","text":""}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                         Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    23 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":1,"layout":[{"image":"page_23_table_1_v2.jpg","confidence":0.99,"label":"table","bbox":{"x":0.055,"y":0.084,"w":0.885,"h":0.794},"isLikelyNoise":false},{"image":"page_23_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.513,"h":0.011},"isLikelyNoise":false},{"image":"page_23_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_23_number_1_v2.jpg","confidence":0.9,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_23_text_1_v2.jpg","confidence":0.83,"label":"text","bbox":{"x":0.059,"y":0.882,"w":0.208,"h":0.012},"isLikelyNoise":false},{"image":"page_23_figure_title_1_v2.jpg","confidence":0.68,"label":"figure_title","bbox":{"x":0.058,"y":0.066,"w":0.118,"h":0.011},"isLikelyNoise":false},{"image":"page_23_header_2_v2.jpg","confidence":0.57,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":true},{"image":"page_23_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.057,"y":0.036,"w":0.185,"h":0.018},"isLikelyNoise":true},{"image":"page_23_header_4_v2.jpg","confidence":0.52,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.01},"isLikelyNoise":true}]},{"page":24,"text":"         Tools  and  resources                                                                         Neuroscience\n\nTable 8 continued\nModel                             Description                                    URL\n                                  Examples of interactions between NeuroML and   https://github.com/OpenSourceBrain/\nNEURON Showcase                   NEURON                                         NEURONShowcase\n                                                                                 https://github.com/OpenSourceBrain/\nneuroConstruct Showcase           Examples of neuroConstruct projects            neuroConstructShowcase\n                                  Examples of reconstructions from NeuroMorpho.  https://github.com/OpenSourceBrain/\nNeuroMorpho.Org                   Org                                            NeuroMorpho\n                                  Janelia MouseLight project neuronal            https://github.com/OpenSourceBrain/\nJanelia MouseLight                reconstructions                                MouseLightShowcase\n\n\n\nsuch as networks and neuronal models that reference multiple cell and ionic conductance deﬁnitions,\ncan also be exported into a COMBINE zip archive (Bergmann et al., 2014), a zip ﬁle that includes\nmetadata about its contents. pyNeuroML includes functions to easily create COMBINE archives from\nNeuroML models and simulations (Figure 6).\nOSB is designed so that researchers can share their code on their chosen platform (e.g. GitHub),\nwhile retaining full control over write access to their repositories. Afterwards, a page for the model\ncan be created on OSB which lists the latest ﬁles present there, with links to OSB visualization/anal-\nysis/simulation features which can use the standardized ﬁles found in the resource.\nNeuroML supports the embedding of structured ontological information in model descriptions\n(Neal et al., 2019). Models can include NeuroLex (now InterLex) (Larson and Martone, 2013) identi-\nﬁers for their components (e.g. neuro_lex_id in Figure 6). This links model components to their biolog-\nical counterparts and makes them more transparent, ﬁndable, and reusable. For example, different\ntypes of neurons and brain regions have unique ontological ids. A user can use these ids to search for\nrelevant model components on NeuroML-DB. More general information to maintain provenance can\nalso be included in NeuroML models (https://docs.neuroml.org/Userdocs/Provenance.html).\n\nReusing NeuroML models\nNeuroML models, once openly shared, become community resources that are accessible to all.\nResearchers can use models shared on NeuroML-DB and OSB without restrictions. Guide 5 in Table 5\nprovides an example of ﬁnding NeuroML- based model components using the API of NeuroML- DB,\nand creating novel models incorporating these elements.\nIn addition to these platforms, other experimental data and model dissemination platforms also\nprovide standardized NeuroML versions of relevant models to promote uptake and reuse. For example,\nNeuroMorpho. org  (Ascoli et  al., 2007) includes a tool to download NeuroML compliant versions\nof its cellular reconstructions (https://github.com/NeuroML/Cvapp-NeuroMorpho.org,  https://docs.\nneuroml.org/Userdocs/Software/Tools/SWC.html). NeuroML versions of models released by organiza-\ntions such as the Blue Brain Project (Markram et al., 2015) (whole cell models as well as ion channel\nmodels from Channelpedia Ranjan et al., 2011), the Allen Institute for Brain Science (Billeh et al.,\n2020), and the OpenWorm project (Gleeson et al., 2018) are also openly available for reuse (Table 8).\nNeuroML can also interact with other standards to further promote model re-\n                                                                            use. Whereas NeuroML\nis a declarative standard, PyNN (Davison et al., 2008) is a procedural standard with a Python API for\ncreating network models that can be simulated on multiple simulators. NeuroML models which are\nwithin the scope of PyNN can be converted to the PyNN format, and vice- versa. Similarly, NeuroML\nalso interacts with SONATA (Dai et  al., 2020) data format by supporting the two way conversion\nof the network structures of NeuroML models into SONATA. In standards not speciﬁc to neurosci-\nence, models from the well established SBML standard (Hucka et  al., 2003) can be converted to\nLEMS (Cannon et al., 2014), for inclusion in neuroscience- related modeling pipelines, and a subset\nof NeuroML/LEMS models can be exported to SBML, which allows use with simulators and anal-\nysis packages compliant to this standard, e.g., Tellurium (Choi et  al., 2018). Simulation execution\ndetails of NeuroML/LEMS models can also be exported to Simulation Experiment Description Markup\nLanguage (SED-ML) (Waltemath et  al., 2011), allowing advanced resources such as Biosimulators\n(Shaikh et al., 2022) (https://biosimulators.org) to feature NeuroML models.\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    24 of 44","md":"\n\neLife Tools and resources                                                                         Neuroscience\n\nTable 8 continued\n\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NEURON Showcase</td>\n<td>Examples of interactions between NeuroML and NEURON</td>\n<td>https://github.com/OpenSourceBrain/NEURONShowcase</td>\n</tr>\n<tr>\n<td>neuroConstruct Showcase</td>\n<td>Examples of neuroConstruct projects</td>\n<td>https://github.com/OpenSourceBrain/neuroConstructShowcase</td>\n</tr>\n<tr>\n<td>NeuroMorpho.Org</td>\n<td>Examples of reconstructions from NeuroMorpho.Org</td>\n<td>https://github.com/OpenSourceBrain/NeuroMorpho</td>\n</tr>\n<tr>\n<td>Janelia MouseLight</td>\n<td>Janelia MouseLight project neuronal reconstructions</td>\n<td>https://github.com/OpenSourceBrain/MouseLightShowcase</td>\n</tr>\n</tbody>\n</table>\n\nsuch as networks and neuronal models that reference multiple cell and ionic conductance definitions, can also be exported into a COMBINE zip archive (Bergmann et al., 2014), a zip file that includes metadata about its contents. pyNeuroML includes functions to easily create COMBINE archives from NeuroML models and simulations (Figure 6).\n\nOSB is designed so that researchers can share their code on their chosen platform (e.g. GitHub), while retaining full control over write access to their repositories. Afterwards, a page for the model can be created on OSB which lists the latest files present there, with links to OSB visualization/analysis/simulation features which can use the standardized files found in the resource.\n\nNeuroML supports the embedding of structured ontological information in model descriptions (Neal et al., 2019). Models can include NeuroLex (now InterLex) (Larson and Martone, 2013) identifiers for their components (e.g. neuro_lex_id in Figure 6). This links model components to their biological counterparts and makes them more transparent, findable, and reusable. For example, different types of neurons and brain regions have unique ontological ids. A user can use these ids to search for relevant model components on NeuroML-DB. More general information to maintain provenance can also be included in NeuroML models (https://docs.neuroml.org/Userdocs/Provenance.html).\n\n## Reusing NeuroML models\n\nNeuroML models, once openly shared, become community resources that are accessible to all. Researchers can use models shared on NeuroML-DB and OSB without restrictions. Guide 5 in Table 5 provides an example of finding NeuroML-based model components using the API of NeuroML-DB, and creating novel models incorporating these elements.\n\nIn addition to these platforms, other experimental data and model dissemination platforms also provide standardized NeuroML versions of relevant models to promote uptake and reuse. For example, NeuroMorpho.org (Ascoli et al., 2007) includes a tool to download NeuroML compliant versions of its cellular reconstructions (https://github.com/NeuroML/Cvapp-NeuroMorpho.org, https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html). NeuroML versions of models released by organizations such as the Blue Brain Project (Markram et al., 2015) (whole cell models as well as ion channel models from Channelpedia Ranjan et al., 2011), the Allen Institute for Brain Science (Billeh et al., 2020), and the OpenWorm project (Gleeson et al., 2018) are also openly available for reuse (Table 8).\n\nNeuroML can also interact with other standards to further promote model re-use. Whereas NeuroML is a declarative standard, PyNN (Davison et al., 2008) is a procedural standard with a Python API for creating network models that can be simulated on multiple simulators. NeuroML models which are within the scope of PyNN can be converted to the PyNN format, and vice-versa. Similarly, NeuroML also interacts with SONATA (Dai et al., 2020) data format by supporting the two way conversion of the network structures of NeuroML models into SONATA. In standards not specific to neuroscience, models from the well established SBML standard (Hucka et al., 2003) can be converted to LEMS (Cannon et al., 2014), for inclusion in neuroscience-related modeling pipelines, and a subset of NeuroML/LEMS models can be exported to SBML, which allows use with simulators and analysis packages compliant to this standard, e.g., Tellurium (Choi et al., 2018). Simulation execution details of NeuroML/LEMS models can also be exported to Simulation Experiment Description Markup Language (SED-ML) (Waltemath et al., 2011), allowing advanced resources such as Biosimulators (Shaikh et al., 2022) (https://biosimulators.org) to feature NeuroML models.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    24 of 44\n","images":[{"name":"page_24.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_24_text_1_v2.jpg","height":121647.836,"width":250454.589,"x":100998.114,"y":449216.387,"original_width":1654,"original_height":621,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_text_2_v2.jpg","height":64400.822,"width":250398.369,"x":101108.342,"y":247065.45,"original_width":1654,"original_height":329,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_text_3_v2.jpg","height":74058.943,"width":250522.197,"x":100970.989,"y":373007.006,"original_width":1655,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_table_1_v2.jpg","height":91308.468,"width":330804.46,"x":21064.708,"y":52881.765,"original_width":2185,"original_height":466,"rotation":0,"type":"layout_v2_table"},{"name":"page_24_text_4_v2.jpg","height":35809.619,"width":250475.651,"x":101017.489,"y":209150.889,"original_width":1654,"original_height":183,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_text_5_v2.jpg","height":36049.214,"width":250489.574,"x":101176.995,"y":335063.023,"original_width":1654,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_text_6_v2.jpg","height":35719.372,"width":250386.344,"x":101013.668,"y":171164.095,"original_width":1654,"original_height":183,"rotation":0,"type":"layout_v2_text"},{"name":"page_24_paragraph_title_1_v2.jpg","height":8659.026,"width":91165.973,"x":101582.047,"y":323302.254,"original_width":602,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_24_footer_1_v2.jpg","height":6918.369,"width":191910.396,"x":21472.287,"y":591479.059,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_24_header_1_v2.jpg","height":5737.587,"width":30272.802,"x":320778.776,"y":27631.353,"original_width":200,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_24_number_1_v2.jpg","height":5969.945,"width":18265.358,"x":332858.843,"y":591791.181,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_24_figure_title_1_v2.jpg","height":6883.793,"width":44303.667,"x":21799.104,"y":41602.969,"original_width":293,"original_height":36,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_24_header_2_v2.jpg","height":5943.669,"width":42804.464,"x":47766.703,"y":27736.898,"original_width":283,"original_height":31,"rotation":0,"type":"layout_v2_header"},{"name":"page_24_header_3_v2.jpg","height":11230.771,"width":24738.893,"x":21638.941,"y":22436.77,"original_width":164,"original_height":58,"rotation":0,"type":"layout_v2_header"},{"name":"page_24_header_4_v2.jpg","height":11492.945,"width":69279.377,"x":21527.392,"y":22613.703,"original_width":458,"original_height":59,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                         Neuroscience","md":"eLife Tools and resources                                                                         Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":98,"endIndex":110}]},{"type":"text","value":"Table 8 continued","md":"Table 8 continued","bBox":{"x":36.5,"y":51.8,"w":71.21,"h":9},"layoutAwareBbox":[{"x":35,"y":52,"w":72,"h":8,"startIndex":0,"endIndex":16}]},{"type":"table","rows":[["Model","Description","URL"],["NEURON Showcase","Examples of interactions between NeuroML and NEURON","https://github.com/OpenSourceBrain/NEURONShowcase"],["neuroConstruct Showcase","Examples of neuroConstruct projects","https://github.com/OpenSourceBrain/neuroConstructShowcase"],["NeuroMorpho.Org","Examples of reconstructions from NeuroMorpho.Org","https://github.com/OpenSourceBrain/NeuroMorpho"],["Janelia MouseLight","Janelia MouseLight project neuronal reconstructions","https://github.com/OpenSourceBrain/MouseLightShowcase"]],"html":"<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n<th>URL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NEURON Showcase</td>\n<td>Examples of interactions between NeuroML and NEURON</td>\n<td>https://github.com/OpenSourceBrain/NEURONShowcase</td>\n</tr>\n<tr>\n<td>neuroConstruct Showcase</td>\n<td>Examples of neuroConstruct projects</td>\n<td>https://github.com/OpenSourceBrain/neuroConstructShowcase</td>\n</tr>\n<tr>\n<td>NeuroMorpho.Org</td>\n<td>Examples of reconstructions from NeuroMorpho.Org</td>\n<td>https://github.com/OpenSourceBrain/NeuroMorpho</td>\n</tr>\n<tr>\n<td>Janelia MouseLight</td>\n<td>Janelia MouseLight project neuronal reconstructions</td>\n<td>https://github.com/OpenSourceBrain/MouseLightShowcase</td>\n</tr>\n</tbody>\n</table>","md":"| Model                   | Description                                         | URL                                                         |\n| ----------------------- | --------------------------------------------------- | ----------------------------------------------------------- |\n| NEURON Showcase         | Examples of interactions between NeuroML and NEURON | <https://github.com/OpenSourceBrain/NEURONShowcase>         |\n| neuroConstruct Showcase | Examples of neuroConstruct projects                 | <https://github.com/OpenSourceBrain/neuroConstructShowcase> |\n| NeuroMorpho.Org         | Examples of reconstructions from NeuroMorpho.Org    | <https://github.com/OpenSourceBrain/NeuroMorpho>            |\n| Janelia MouseLight      | Janelia MouseLight project neuronal reconstructions | <https://github.com/OpenSourceBrain/MouseLightShowcase>     |","isPerfectTable":false,"csv":"\"Model\",\"Description\",\"URL\"\n\"NEURON Showcase\",\"Examples of interactions between NeuroML and NEURON\",\"https://github.com/OpenSourceBrain/NEURONShowcase\"\n\"neuroConstruct Showcase\",\"Examples of neuroConstruct projects\",\"https://github.com/OpenSourceBrain/neuroConstructShowcase\"\n\"NeuroMorpho.Org\",\"Examples of reconstructions from NeuroMorpho.Org\",\"https://github.com/OpenSourceBrain/NeuroMorpho\"\n\"Janelia MouseLight\",\"Janelia MouseLight project neuronal reconstructions\",\"https://github.com/OpenSourceBrain/MouseLightShowcase\"","bBox":{"x":36.5,"y":68.48,"w":552.12,"h":650.93},"layoutAwareBbox":[{"x":34,"y":66,"w":540,"h":115,"startIndex":2,"endIndex":7}]},{"type":"text","value":"such as networks and neuronal models that reference multiple cell and ionic conductance definitions, can also be exported into a COMBINE zip archive (Bergmann et al., 2014), a zip file that includes metadata about its contents. pyNeuroML includes functions to easily create COMBINE archives from NeuroML models and simulations (Figure 6).","md":"such as networks and neuronal models that reference multiple cell and ionic conductance definitions, can also be exported into a COMBINE zip archive (Bergmann et al., 2014), a zip file that includes metadata about its contents. pyNeuroML includes functions to easily create COMBINE archives from NeuroML models and simulations (Figure 6).","bBox":{"x":36.5,"y":68.48,"w":540.28,"h":179.9},"layoutAwareBbox":[{"x":165,"y":216,"w":409,"h":45,"startIndex":0,"endIndex":337}]},{"type":"text","value":"OSB is designed so that researchers can share their code on their chosen platform (e.g. GitHub), while retaining full control over write access to their repositories. Afterwards, a page for the model can be created on OSB which lists the latest files present there, with links to OSB visualization/analysis/simulation features which can use the standardized files found in the resource.","md":"OSB is designed so that researchers can share their code on their chosen platform (e.g. GitHub), while retaining full control over write access to their repositories. Afterwards, a page for the model can be created on OSB which lists the latest files present there, with links to OSB visualization/analysis/simulation features which can use the standardized files found in the resource.","bBox":{"x":168.53,"y":263.38,"w":403.17,"h":21},"layoutAwareBbox":[{"x":165,"y":264,"w":409,"h":45,"startIndex":0,"endIndex":3}]},{"type":"text","value":"NeuroML supports the embedding of structured ontological information in model descriptions (Neal et al., 2019). Models can include NeuroLex (now InterLex) (Larson and Martone, 2013) identifiers for their components (e.g. neuro_lex_id in Figure 6). This links model components to their biological counterparts and makes them more transparent, findable, and reusable. For example, different types of neurons and brain regions have unique ontological ids. A user can use these ids to search for relevant model components on NeuroML-DB. More general information to maintain provenance can also be included in NeuroML models (https://docs.neuroml.org/Userdocs/Provenance.html).","md":"NeuroML supports the embedding of structured ontological information in model descriptions (Neal et al., 2019). Models can include NeuroLex (now InterLex) (Larson and Martone, 2013) identifiers for their components (e.g. neuro_lex_id in Figure 6). This links model components to their biological counterparts and makes them more transparent, findable, and reusable. For example, different types of neurons and brain regions have unique ontological ids. A user can use these ids to search for relevant model components on NeuroML-DB. More general information to maintain provenance can also be included in NeuroML models (https://docs.neuroml.org/Userdocs/Provenance.html).","bBox":{"x":168.53,"y":311.36,"w":411.61,"h":80.98},"layoutAwareBbox":[{"x":165,"y":311,"w":409,"h":81,"startIndex":92,"endIndex":96}]},{"type":"heading","lvl":2,"value":"Reusing NeuroML models","md":"## Reusing NeuroML models","bBox":{"x":168.53,"y":406.48,"w":145.98,"h":12},"layoutAwareBbox":[{"x":165,"y":408,"w":148,"h":10,"startIndex":0,"endIndex":24}]},{"type":"text","value":"NeuroML models, once openly shared, become community resources that are accessible to all. Researchers can use models shared on NeuroML-DB and OSB without restrictions. Guide 5 in Table 5 provides an example of finding NeuroML-based model components using the API of NeuroML-DB, and creating novel models incorporating these elements.","md":"NeuroML models, once openly shared, become community resources that are accessible to all. Researchers can use models shared on NeuroML-DB and OSB without restrictions. Guide 5 in Table 5 provides an example of finding NeuroML-based model components using the API of NeuroML-DB, and creating novel models incorporating these elements.","bBox":{"x":168.53,"y":422.48,"w":384.6,"h":44.99},"layoutAwareBbox":[{"x":165,"y":423,"w":409,"h":45,"startIndex":136,"endIndex":138}]},{"type":"text","value":"In addition to these platforms, other experimental data and model dissemination platforms also provide standardized NeuroML versions of relevant models to promote uptake and reuse. For example, NeuroMorpho.org (Ascoli et al., 2007) includes a tool to download NeuroML compliant versions of its cellular reconstructions (https://github.com/NeuroML/Cvapp-NeuroMorpho.org, https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html). NeuroML versions of models released by organizations such as the Blue Brain Project (Markram et al., 2015) (whole cell models as well as ion channel models from Channelpedia Ranjan et al., 2011), the Allen Institute for Brain Science (Billeh et al., 2020), and the OpenWorm project (Gleeson et al., 2018) are also openly available for reuse (Table 8).","md":"In addition to these platforms, other experimental data and model dissemination platforms also provide standardized NeuroML versions of relevant models to promote uptake and reuse. For example, NeuroMorpho.org (Ascoli et al., 2007) includes a tool to download NeuroML compliant versions of its cellular reconstructions (https://github.com/NeuroML/Cvapp-NeuroMorpho.org, https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html). NeuroML versions of models released by organizations such as the Blue Brain Project (Markram et al., 2015) (whole cell models as well as ion channel models from Channelpedia Ranjan et al., 2011), the Allen Institute for Brain Science (Billeh et al., 2020), and the OpenWorm project (Gleeson et al., 2018) are also openly available for reuse (Table 8).","bBox":{"x":36.53,"y":143.62,"w":552.1,"h":371.84},"layoutAwareBbox":[{"x":164,"y":470,"w":409,"h":93,"startIndex":194,"endIndex":205}]},{"type":"text","value":"NeuroML can also interact with other standards to further promote model re-use. Whereas NeuroML is a declarative standard, PyNN (Davison et al., 2008) is a procedural standard with a Python API for creating network models that can be simulated on multiple simulators. NeuroML models which are within the scope of PyNN can be converted to the PyNN format, and vice-versa. Similarly, NeuroML also interacts with SONATA (Dai et al., 2020) data format by supporting the two way conversion of the network structures of NeuroML models into SONATA. In standards not specific to neuroscience, models from the well established SBML standard (Hucka et al., 2003) can be converted to LEMS (Cannon et al., 2014), for inclusion in neuroscience-related modeling pipelines, and a subset of NeuroML/LEMS models can be exported to SBML, which allows use with simulators and analysis packages compliant to this standard, e.g., Tellurium (Choi et al., 2018). Simulation execution details of NeuroML/LEMS models can also be exported to Simulation Experiment Description Markup Language (SED-ML) (Waltemath et al., 2011), allowing advanced resources such as Biosimulators (Shaikh et al., 2022) (https://biosimulators.org) to feature NeuroML models.","md":"NeuroML can also interact with other standards to further promote model re-use. Whereas NeuroML is a declarative standard, PyNN (Davison et al., 2008) is a procedural standard with a Python API for creating network models that can be simulated on multiple simulators. NeuroML models which are within the scope of PyNN can be converted to the PyNN format, and vice-versa. Similarly, NeuroML also interacts with SONATA (Dai et al., 2020) data format by supporting the two way conversion of the network structures of NeuroML models into SONATA. In standards not specific to neuroscience, models from the well established SBML standard (Hucka et al., 2003) can be converted to LEMS (Cannon et al., 2014), for inclusion in neuroscience-related modeling pipelines, and a subset of NeuroML/LEMS models can be exported to SBML, which allows use with simulators and analysis packages compliant to this standard, e.g., Tellurium (Choi et al., 2018). Simulation execution details of NeuroML/LEMS models can also be exported to Simulation Experiment Description Markup Language (SED-ML) (Waltemath et al., 2011), allowing advanced resources such as Biosimulators (Shaikh et al., 2022) (https://biosimulators.org) to feature NeuroML models.","bBox":{"x":168.52,"y":34.63,"w":413.51,"h":660.78},"layoutAwareBbox":[{"x":165,"y":567,"w":409,"h":153,"startIndex":5,"endIndex":7}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    24 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    24 of 44","bBox":{"x":216.36,"y":143.62,"w":358.63,"h":611.14},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/Provenance.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Provenance.html","text":"also be included in NeuroML models (https://docs.neuroml.org/Userdocs/Provenance.html)."},{"url":"https://github.com/NeuroML/Cvapp-NeuroMorpho.org","unsafeUrl":"https://github.com/NeuroML/Cvapp-NeuroMorpho.org","text":"of its cellular reconstructions (https://github.com/NeuroML/Cvapp-NeuroMorpho.org, "},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html","text":"https://docs."},{"url":"https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/Software/Tools/SWC.html","text":"neuroml.org/Userdocs/Software/Tools/SWC.html). NeuroML versions of models released by organiza-"},{"url":"https://biosimulators.org/","unsafeUrl":"https://biosimulators.org","text":") (https://biosimulators.org) to feature NeuroML models."},{"url":"https://github.com/OpenSourceBrain/NEURONShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NEURONShowcase","text":"https://github.com/OpenSourceBrain/ NEURONShowcase"},{"url":"https://github.com/OpenSourceBrain/NEURONShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/NEURONShowcase","text":"NEURONShowcase"},{"url":"https://github.com/OpenSourceBrain/neuroConstructShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/neuroConstructShowcase","text":"https://github.com/OpenSourceBrain/ neuroConstructShowcase"},{"url":"https://github.com/OpenSourceBrain/neuroConstructShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/neuroConstructShowcase","text":"neuroConstructShowcase"},{"url":"https://github.com/OpenSourceBrain/NeuroMorpho","unsafeUrl":"https://github.com/OpenSourceBrain/NeuroMorpho","text":"https://github.com/OpenSourceBrain/ NeuroMorpho"},{"url":"https://github.com/OpenSourceBrain/NeuroMorpho","unsafeUrl":"https://github.com/OpenSourceBrain/NeuroMorpho","text":"NeuroMorpho"},{"url":"https://github.com/OpenSourceBrain/MouseLightShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/MouseLightShowcase","text":"https://github.com/OpenSourceBrain/ MouseLightShowcase"},{"url":"https://github.com/OpenSourceBrain/MouseLightShowcase","unsafeUrl":"https://github.com/OpenSourceBrain/MouseLightShowcase","text":"MouseLightShowcase"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                         Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    24 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.982,"layout":[{"image":"page_24_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.716,"w":0.669,"h":0.194},"isLikelyNoise":false},{"image":"page_24_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.394,"w":0.669,"h":0.103},"isLikelyNoise":false},{"image":"page_24_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.595,"w":0.669,"h":0.118},"isLikelyNoise":false},{"image":"page_24_table_1_v2.jpg","confidence":0.98,"label":"table","bbox":{"x":0.056,"y":0.084,"w":0.883,"h":0.146},"isLikelyNoise":false},{"image":"page_24_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.333,"w":0.669,"h":0.057},"isLikelyNoise":false},{"image":"page_24_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.534,"w":0.669,"h":0.057},"isLikelyNoise":false},{"image":"page_24_text_6_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.273,"w":0.669,"h":0.057},"isLikelyNoise":false},{"image":"page_24_paragraph_title_1_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.271,"y":0.515,"w":0.243,"h":0.014},"isLikelyNoise":false},{"image":"page_24_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_24_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_24_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_24_figure_title_1_v2.jpg","confidence":0.66,"label":"figure_title","bbox":{"x":0.058,"y":0.066,"w":0.118,"h":0.011},"isLikelyNoise":false},{"image":"page_24_header_2_v2.jpg","confidence":0.57,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":true},{"image":"page_24_header_3_v2.jpg","confidence":0.54,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.066,"h":0.018},"isLikelyNoise":true},{"image":"page_24_header_4_v2.jpg","confidence":0.51,"label":"header","bbox":{"x":0.057,"y":0.036,"w":0.185,"h":0.018},"isLikelyNoise":true}]},{"page":25,"text":"Tools  and  resources                                                                               Neuroscience\n                         NeuroML is extensible\n                         While the standard NeuroML elements (Tables 1 and 2) provide a broad range of curated model types\n                         for simulation- based investigations, NeuroML can be extended (using LEMS) to incorporate novel\n                         model elements and types when they are not (yet) available in the standard.\n                         LEMS is a general purpose model speciﬁcation language for creating fully machine readable deﬁni-\n                         tions of the structure and behavior of model elements (Cannon et al., 2014). The dynamics of NeuroML\n                         elements are described in LEMS. The hierarchical nature of LEMS means that new elements can build\n                         on pre- existing elements of the modular NeuroML framework. For example, a novel ionic conduc-\n                         tance element can extend the ‘ionChannelHH’ element, which in turn extends ‘baseIonChannel.’ Thus,\n                         the new element will be known to the NeuroML elements as depending on an external voltage and\n                         producing a conductance, properties that are inherited from ‘baseIonChannel.’ Other elements, such\n                         as a cell, can incorporate this new type without needing any other information about its internal\n                         workings.\n                         LEMS (and, therefore, NeuroML) element deﬁnitions (called ‘ComponentTypes’) specify the dynam-\n                         ical behavior of the model element in terms of a list of yet to be set parameters. Once the generic\n                         model behavior is deﬁned, modelers only need to ﬁll in the appropriate values of the required param-\n                         eters (e.g. conductance density, reversal potential, etc.) to create new instances (called ‘Compo-\n                         nents’) of the element (see Methods for more details). Users can, therefore create arbitrary, reusable\n                         model elements in LEMS, which can be treated the same way as the standard model elements (for an\n                         example see Guide 7 in Table 5).\n                         Another major advantage of NeuroML’s use of the LEMS language is its translatability. Since LEMS\n                         is fully machine readable, its primitives (e.g. state variables and their dynamics, expressed as ordinary\n                         differential equations) can be readily mapped into other languages. As a result, simulator speciﬁc\n                         code (Blundell et  al., 2018) can be generated from NeuroML models and their LEMS extensions\n                         (Figure 5), allowing NeuroML to remain simulator- independent while supporting multiple simulation\n                         engines.\n                         Newly created elements that may be of interest to the wider research community can be submitted\n                         to the NeuroML Editorial Board for inclusion into the standard. The standard, therefore, evolves as\n                         new model elements are added and improved versions of the standard and associated software tool\n                         chain are regularly released to the community.\n\n                         NeuroML is a global open community initiative\n                         NeuroML is a global open community standard that is used and maintained collectively by a diverse\n                         set of stakeholders. The NeuroML Scientiﬁc Committee (https://docs.neuroml.org/NeuroMLOrg/\n                         ScientiﬁcCommittee.html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/\n                         NeuroMLOrg/Board.html) oversee the standard, the core tools, and the initiative. This ensures that\n                         NeuroML supports the myriad of use cases generated by a multi-\n                                                                       disciplinary computational modeling\n                         community.\n                         NeuroML is an endorsed INCF (Abrams et al., 2022) community standard (Martone and Das,\n                         2019) and is one of the main standards of the international COMBINE initiative (Hucka et  al.,\n                         2015), which supports the development of other standards in computational biology as well (e.g.\n                         SBML (Hucka et  al., 2003) and CellML Lloyd et  al., 2004). Participation in these organizations\n                         guarantees that NeuroML follows current best practices in standardization, and remains linked to\n                         and interoperable with other standards wherever possible. The NeuroML community also partic-\n                         ipates in training and outreach activities such as Google Summer of Code (https://docs.neuroml.\n                         org/NeuroMLOrg/OutreachTraining.html), tutorials, and internships under these and other\n                         organizations.\n                         The NeuroML community maintains public open communication channels to ensure that all\n                         community members can easily participate in troubleshooting, discussions, and development activ-\n                         ities. A public mailing list (https://lists.sourceforge.net/lists/listinfo/neuroml-technology) is used for\n                         asynchronous communication and announcements while open chat channels on Gitter (now Matrix/\n                         Element (#/#NeuroML_community:gitter.im)) provide immediate access to the NeuroML community.\n                         All software repositories hosted on GitHub also have issue trackers for software speciﬁc queries. A\n                         community Code of Conduct (https://docs.neuroml.org/NeuroMLOrg/CoC.html) sets the standards\n                         of communication and behavior expected on all community channels.\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    25 of 44","md":"\n\neLife Tools and resources                                                                               Neuroscience\n\n## NeuroML is extensible\n\nWhile the standard NeuroML elements (*Tables 1 and 2*) provide a broad range of curated model types for simulation-based investigations, NeuroML can be extended (using LEMS) to incorporate novel model elements and types when they are not (yet) available in the standard.\n\nLEMS is a general purpose model specification language for creating fully machine readable definitions of the structure and behavior of model elements (Cannon et al., 2014). The dynamics of NeuroML elements are described in LEMS. The hierarchical nature of LEMS means that new elements can build on pre-existing elements of the modular NeuroML framework. For example, a novel ionic conductance element can extend the 'ionChannelHH' element, which in turn extends 'baseIonChannel.' Thus, the new element will be known to the NeuroML elements as depending on an external voltage and producing a conductance, properties that are inherited from 'baseIonChannel.' Other elements, such as a cell, can incorporate this new type without needing any other information about its internal workings.\n\nLEMS (and, therefore, NeuroML) element definitions (called 'ComponentTypes') specify the dynamical behavior of the model element in terms of a list of yet to be set parameters. Once the generic model behavior is defined, modelers only need to fill in the appropriate values of the required parameters (e.g. conductance density, reversal potential, etc.) to create new instances (called 'Components') of the element (see Methods for more details). Users can, therefore create arbitrary, reusable model elements in LEMS, which can be treated the same way as the standard model elements (for an example see Guide 7 in *Table 5*).\n\nAnother major advantage of NeuroML's use of the LEMS language is its translatability. Since LEMS is fully machine readable, its primitives (e.g. state variables and their dynamics, expressed as ordinary differential equations) can be readily mapped into other languages. As a result, simulator specific code (Blundell et al., 2018) can be generated from NeuroML models and their LEMS extensions (*Figure 5*), allowing NeuroML to remain simulator-independent while supporting multiple simulation engines.\n\nNewly created elements that may be of interest to the wider research community can be submitted to the NeuroML Editorial Board for inclusion into the standard. The standard, therefore, evolves as new model elements are added and improved versions of the standard and associated software tool chain are regularly released to the community.\n\n## NeuroML is a global open community initiative\n\nNeuroML is a global open community standard that is used and maintained collectively by a diverse set of stakeholders. The NeuroML Scientific Committee ([https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html])(https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html)) and the elected NeuroML Editorial Board ([https://docs.neuroml.org/NeuroMLOrg/Board.html])(https://docs.neuroml.org/NeuroMLOrg/Board.html)) oversee the standard, the core tools, and the initiative. This ensures that NeuroML supports the myriad of use cases generated by a multi-disciplinary computational modeling community.\n\nNeuroML is an endorsed INCF (Abrams et al., 2022) community standard (Martone and Das, 2019) and is one of the main standards of the international COMBINE initiative (Hucka et al., 2015), which supports the development of other standards in computational biology as well (e.g. SBML (Hucka et al., 2003) and CellML Lloyd et al., 2004). Participation in these organizations guarantees that NeuroML follows current best practices in standardization, and remains linked to and interoperable with other standards wherever possible. The NeuroML community also participates in training and outreach activities such as Google Summer of Code ([https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html])(https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html)), tutorials, and internships under these and other organizations.\n\nThe NeuroML community maintains public open communication channels to ensure that all community members can easily participate in troubleshooting, discussions, and development activities. A public mailing list ([https://lists.sourceforge.net/lists/listinfo/neuroml-technology])(https://lists.sourceforge.net/lists/listinfo/neuroml-technology)) is used for asynchronous communication and announcements while open chat channels on Gitter (now Matrix/Element (#/#NeuroML_community:gitter.im)) provide immediate access to the NeuroML community. All software repositories hosted on GitHub also have issue trackers for software specific queries. A community Code of Conduct ([https://docs.neuroml.org/NeuroMLOrg/CoC.html])(https://docs.neuroml.org/NeuroMLOrg/CoC.html)) sets the standards of communication and behavior expected on all community channels.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    25 of 44\n","images":[{"name":"page_25.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_25_text_1_v2.jpg","height":83101.189,"width":250388.076,"x":101101.157,"y":82174.073,"original_width":1654,"original_height":424,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_2_v2.jpg","height":83344.41,"width":250446.092,"x":101123.593,"y":410710.12,"original_width":1654,"original_height":426,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_3_v2.jpg","height":74007.801,"width":250362.626,"x":101222.734,"y":496424.178,"original_width":1654,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_4_v2.jpg","height":64278.721,"width":250258.411,"x":101195.942,"y":167555.445,"original_width":1653,"original_height":328,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_5_v2.jpg","height":54709.083,"width":250283.165,"x":101257.971,"y":234074.362,"original_width":1653,"original_height":280,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_6_v2.jpg","height":54560.912,"width":250562.333,"x":101088.819,"y":353940.415,"original_width":1655,"original_height":279,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_7_v2.jpg","height":36058.055,"width":250059.114,"x":101384.471,"y":291175.948,"original_width":1652,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_text_8_v2.jpg","height":26477.762,"width":250367.785,"x":101056.323,"y":53526.069,"original_width":1654,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_25_paragraph_title_1_v2.jpg","height":8666.945,"width":164061.767,"x":101591.311,"y":342143.599,"original_width":1084,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_25_paragraph_title_2_v2.jpg","height":8218.83,"width":79405.554,"x":101659.071,"y":41825.626,"original_width":525,"original_height":42,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_25_footer_1_v2.jpg","height":6852.212,"width":191900.065,"x":21507.426,"y":591536.022,"original_width":1268,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_25_header_1_v2.jpg","height":5664.27,"width":30251.326,"x":320811.869,"y":27710.018,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_25_number_1_v2.jpg","height":5859.371,"width":18212.758,"x":332919.893,"y":591847.165,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_25_header_2_v2.jpg","height":5736.146,"width":42888.968,"x":47709.387,"y":27884.856,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_25_header_3_v2.jpg","height":10685.402,"width":24469.965,"x":21783.68,"y":22441.113,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                               Neuroscience","md":"eLife Tools and resources                                                                               Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":104,"endIndex":116}]},{"type":"heading","lvl":2,"value":"NeuroML is extensible","md":"## NeuroML is extensible","bBox":{"x":168.53,"y":51.07,"w":127.56,"h":12},"layoutAwareBbox":[{"x":166,"y":52,"w":129,"h":10,"startIndex":0,"endIndex":23}]},{"type":"text","value":"While the standard NeuroML elements (*Tables 1 and 2*) provide a broad range of curated model types for simulation-based investigations, NeuroML can be extended (using LEMS) to incorporate novel model elements and types when they are not (yet) available in the standard.","md":"While the standard NeuroML elements (*Tables 1 and 2*) provide a broad range of curated model types for simulation-based investigations, NeuroML can be extended (using LEMS) to incorporate novel model elements and types when they are not (yet) available in the standard.","bBox":{"x":168.53,"y":79.07,"w":397.06,"h":21},"layoutAwareBbox":[{"x":165,"y":67,"w":409,"h":33,"startIndex":0,"endIndex":5}]},{"type":"text","value":"LEMS is a general purpose model specification language for creating fully machine readable definitions of the structure and behavior of model elements (Cannon et al., 2014). The dynamics of NeuroML elements are described in LEMS. The hierarchical nature of LEMS means that new elements can build on pre-existing elements of the modular NeuroML framework. For example, a novel ionic conductance element can extend the 'ionChannelHH' element, which in turn extends 'baseIonChannel.' Thus, the new element will be known to the NeuroML elements as depending on an external voltage and producing a conductance, properties that are inherited from 'baseIonChannel.' Other elements, such as a cell, can incorporate this new type without needing any other information about its internal workings.","md":"LEMS is a general purpose model specification language for creating fully machine readable definitions of the structure and behavior of model elements (Cannon et al., 2014). The dynamics of NeuroML elements are described in LEMS. The hierarchical nature of LEMS means that new elements can build on pre-existing elements of the modular NeuroML framework. For example, a novel ionic conductance element can extend the 'ionChannelHH' element, which in turn extends 'baseIonChannel.' Thus, the new element will be known to the NeuroML elements as depending on an external voltage and producing a conductance, properties that are inherited from 'baseIonChannel.' Other elements, such as a cell, can incorporate this new type without needing any other information about its internal workings.","bBox":{"x":168.53,"y":127.06,"w":410.18,"h":80.98},"layoutAwareBbox":[{"x":165,"y":103,"w":409,"h":104,"startIndex":778,"endIndex":786}]},{"type":"text","value":"LEMS (and, therefore, NeuroML) element definitions (called 'ComponentTypes') specify the dynamical behavior of the model element in terms of a list of yet to be set parameters. Once the generic model behavior is defined, modelers only need to fill in the appropriate values of the required parameters (e.g. conductance density, reversal potential, etc.) to create new instances (called 'Components') of the element (see Methods for more details). Users can, therefore create arbitrary, reusable model elements in LEMS, which can be treated the same way as the standard model elements (for an example see Guide 7 in *Table 5*).","md":"LEMS (and, therefore, NeuroML) element definitions (called 'ComponentTypes') specify the dynamical behavior of the model element in terms of a list of yet to be set parameters. Once the generic model behavior is defined, modelers only need to fill in the appropriate values of the required parameters (e.g. conductance density, reversal potential, etc.) to create new instances (called 'Components') of the element (see Methods for more details). Users can, therefore create arbitrary, reusable model elements in LEMS, which can be treated the same way as the standard model elements (for an example see Guide 7 in *Table 5*).","bBox":{"x":168.53,"y":223.03,"w":410.55,"h":56.99},"layoutAwareBbox":[{"x":165,"y":211,"w":408,"h":81,"startIndex":0,"endIndex":625}]},{"type":"text","value":"Another major advantage of NeuroML's use of the LEMS language is its translatability. Since LEMS is fully machine readable, its primitives (e.g. state variables and their dynamics, expressed as ordinary differential equations) can be readily mapped into other languages. As a result, simulator specific code (Blundell et al., 2018) can be generated from NeuroML models and their LEMS extensions (*Figure 5*), allowing NeuroML to remain simulator-independent while supporting multiple simulation engines.","md":"Another major advantage of NeuroML's use of the LEMS language is its translatability. Since LEMS is fully machine readable, its primitives (e.g. state variables and their dynamics, expressed as ordinary differential equations) can be readily mapped into other languages. As a result, simulator specific code (Blundell et al., 2018) can be generated from NeuroML models and their LEMS extensions (*Figure 5*), allowing NeuroML to remain simulator-independent while supporting multiple simulation engines.","bBox":{"x":168.53,"y":307.01,"w":410.14,"h":56.99},"layoutAwareBbox":[{"x":165,"y":295,"w":408,"h":69,"startIndex":27,"endIndex":34}]},{"type":"text","value":"Newly created elements that may be of interest to the wider research community can be submitted to the NeuroML Editorial Board for inclusion into the standard. The standard, therefore, evolves as new model elements are added and improved versions of the standard and associated software tool chain are regularly released to the community.","md":"Newly created elements that may be of interest to the wider research community can be submitted to the NeuroML Editorial Board for inclusion into the standard. The standard, therefore, evolves as new model elements are added and improved versions of the standard and associated software tool chain are regularly released to the community.","bBox":{"x":168.53,"y":367,"w":414.73,"h":44.99},"layoutAwareBbox":[{"x":165,"y":367,"w":408,"h":45,"startIndex":0,"endIndex":337}]},{"type":"heading","lvl":2,"value":"NeuroML is a global open community initiative","md":"## NeuroML is a global open community initiative","bBox":{"x":168.53,"y":430.06,"w":265.1,"h":12},"layoutAwareBbox":[{"x":165,"y":431,"w":268,"h":10,"startIndex":0,"endIndex":47}]},{"type":"text","value":"NeuroML is a global open community standard that is used and maintained collectively by a diverse set of stakeholders. The NeuroML Scientific Committee ([https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html])(https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html)) and the elected NeuroML Editorial Board ([https://docs.neuroml.org/NeuroMLOrg/Board.html])(https://docs.neuroml.org/NeuroMLOrg/Board.html)) oversee the standard, the core tools, and the initiative. This ensures that NeuroML supports the myriad of use cases generated by a multi-disciplinary computational modeling community.","md":"NeuroML is a global open community standard that is used and maintained collectively by a diverse set of stakeholders. The NeuroML Scientific Committee ([https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html])(https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html)) and the elected NeuroML Editorial Board ([https://docs.neuroml.org/NeuroMLOrg/Board.html])(https://docs.neuroml.org/NeuroMLOrg/Board.html)) oversee the standard, the core tools, and the initiative. This ensures that NeuroML supports the myriad of use cases generated by a multi-disciplinary computational modeling community.","bBox":{"x":168.53,"y":446.06,"w":409.4,"h":68.99},"layoutAwareBbox":[{"x":165,"y":446,"w":409,"h":68,"startIndex":25,"endIndex":34}]},{"type":"text","value":"NeuroML is an endorsed INCF (Abrams et al., 2022) community standard (Martone and Das, 2019) and is one of the main standards of the international COMBINE initiative (Hucka et al., 2015), which supports the development of other standards in computational biology as well (e.g. SBML (Hucka et al., 2003) and CellML Lloyd et al., 2004). Participation in these organizations guarantees that NeuroML follows current best practices in standardization, and remains linked to and interoperable with other standards wherever possible. The NeuroML community also participates in training and outreach activities such as Google Summer of Code ([https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html])(https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html)), tutorials, and internships under these and other organizations.","md":"NeuroML is an endorsed INCF (Abrams et al., 2022) community standard (Martone and Das, 2019) and is one of the main standards of the international COMBINE initiative (Hucka et al., 2015), which supports the development of other standards in computational biology as well (e.g. SBML (Hucka et al., 2003) and CellML Lloyd et al., 2004). Participation in these organizations guarantees that NeuroML follows current best practices in standardization, and remains linked to and interoperable with other standards wherever possible. The NeuroML community also participates in training and outreach activities such as Google Summer of Code ([https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html])(https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html)), tutorials, and internships under these and other organizations.","bBox":{"x":168.53,"y":542.04,"w":406.71,"h":80.98},"layoutAwareBbox":[{"x":165,"y":518,"w":409,"h":105,"startIndex":0,"endIndex":7}]},{"type":"text","value":"The NeuroML community maintains public open communication channels to ensure that all community members can easily participate in troubleshooting, discussions, and development activities. A public mailing list ([https://lists.sourceforge.net/lists/listinfo/neuroml-technology])(https://lists.sourceforge.net/lists/listinfo/neuroml-technology)) is used for asynchronous communication and announcements while open chat channels on Gitter (now Matrix/Element (#/#NeuroML_community:gitter.im)) provide immediate access to the NeuroML community. All software repositories hosted on GitHub also have issue trackers for software specific queries. A community Code of Conduct ([https://docs.neuroml.org/NeuroMLOrg/CoC.html])(https://docs.neuroml.org/NeuroMLOrg/CoC.html)) sets the standards of communication and behavior expected on all community channels.","md":"The NeuroML community maintains public open communication channels to ensure that all community members can easily participate in troubleshooting, discussions, and development activities. A public mailing list ([https://lists.sourceforge.net/lists/listinfo/neuroml-technology])(https://lists.sourceforge.net/lists/listinfo/neuroml-technology)) is used for asynchronous communication and announcements while open chat channels on Gitter (now Matrix/Element (#/#NeuroML_community:gitter.im)) provide immediate access to the NeuroML community. All software repositories hosted on GitHub also have issue trackers for software specific queries. A community Code of Conduct ([https://docs.neuroml.org/NeuroMLOrg/CoC.html])(https://docs.neuroml.org/NeuroMLOrg/CoC.html)) sets the standards of communication and behavior expected on all community channels.","bBox":{"x":168.53,"y":626.02,"w":406.56,"h":92.98},"layoutAwareBbox":[{"x":165,"y":626,"w":409,"h":93,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    25 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    25 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","text":"set of stakeholders. The NeuroML Scientiﬁc Committee (https://docs.neuroml.org/NeuroMLOrg/"},{"url":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","text":"ScientiﬁcCommittee.html) and the elected "},{"url":"https://docs.neuroml.org/NeuroMLOrg/Board.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/Board.html","text":"Board (https://docs.neuroml.org/"},{"url":"https://docs.neuroml.org/NeuroMLOrg/Board.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/Board.html","text":"NeuroMLOrg/Board.html) oversee the standard, the core tools, and the initiative. This ensures that "},{"url":"https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html","text":"(https://docs.neuroml."},{"url":"https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/OutreachTraining.html","text":"org/NeuroMLOrg/OutreachTraining.html), "},{"url":"https://lists.sourceforge.net/lists/listinfo/neuroml-technology","unsafeUrl":"https://lists.sourceforge.net/lists/listinfo/neuroml-technology","text":"ities. A public mailing list (https://lists.sourceforge.net/lists/listinfo/neuroml-technology) is used for "},{"url":"https://docs.neuroml.org/NeuroMLOrg/CoC.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/CoC.html","text":"(https://docs.neuroml.org/NeuroMLOrg/CoC.html) "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                               Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    25 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.979,"layout":[{"image":"page_25_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.131,"w":0.669,"h":0.132},"isLikelyNoise":false},{"image":"page_25_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.655,"w":0.669,"h":0.133},"isLikelyNoise":false},{"image":"page_25_text_3_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.791,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_25_text_4_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.267,"w":0.668,"h":0.102},"isLikelyNoise":false},{"image":"page_25_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.373,"w":0.668,"h":0.087},"isLikelyNoise":false},{"image":"page_25_text_6_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.564,"w":0.669,"h":0.087},"isLikelyNoise":false},{"image":"page_25_text_7_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.271,"y":0.464,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_25_text_8_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.085,"w":0.668,"h":0.042},"isLikelyNoise":false},{"image":"page_25_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.545,"w":0.438,"h":0.014},"isLikelyNoise":false},{"image":"page_25_paragraph_title_2_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.067,"w":0.212,"h":0.013},"isLikelyNoise":false},{"image":"page_25_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_25_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_25_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_25_header_2_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_25_header_3_v2.jpg","confidence":0.51,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":26,"text":"Tools  and  resources                                                                      Neuroscience\n\n                         A crucial aim of NeuroML is to enable Open Science and ensure models in computational neuro-\n                         science are FAIR. To this end, all development and discussions related to NeuroML are done publicly.\n                         The schema, all core software tools, and relevant resources such as documentation are made freely\n                         available under suitable Free/Open Source Software (FOSS) licenses on public platforms. Everyone\n                         can, therefore, use, modify, study, and share all NeuroML artifacts without restriction. Users and devel-\n                         opers are encouraged to contribute modiﬁcations and improvements to the schema and core tools\n                         and to participate in the general maintenance and release process.\n\n\nDiscussion\nNeuroMLv2 has matured into a widely adopted community standard for computational neurosci-\nence. Its modular, hierarchical structure can deﬁne a wide range of neuronal and circuit model types\nincluding simpliﬁed representations and those with a high degree of biological detail. The standard-\nized, machine readable format of the NeuroMLv2/LEMS framework provides a ﬂexible, common\nlanguage for communicating between a wide range of tools and simulators used to create, validate,\nvisualize, analyze, simulate, share, and reuse models. By enabling this interoperability, NeuroMLv2\nhas spawned a large ecosystem of interacting tools that cover all stages of the model development\nlife cycle, bringing greater coherence to a previously fragmented landscape. Moreover, the modular\nnature of the model components and hierarchical structure conferred by NeuroMLv2, combined with\nthe ﬂexibility of coding in Python, has created a powerful ‘building block’ approach for constructing\nstandardized models from scratch.\nNeuroML has, therefore, evolved from a standardized archiving format into a mature language\nthat supports an ecosystem of tools for the creation and execution of models that support the FAIR\nprinciples and promote open, transparent, and reproducible science.\n\nEvolution of NeuroML and emergence of the NeuroMLv2 tool\necosystem\nNeuroML was conceived (Goddard et al., 2001) and developed (Gleeson et al., 2010) as a declar       -\native XML-based framework for deﬁning biophysical models of neurons and networks in a standard-\nized form in order to compare model properties across simulators and to promote transparency and\nreuse. NeuroML version 1 achieved these aims and was mainly used to archive and visualize existing\nmodels (Gleeson et  al., 2010). Building on this, the subsequent development of the NeuroMLv2/\nLEMS framework provided a way to describe models as a hierarchical set of components with dimen-\nsional parameters and state variables, so that their structure and dynamics are fully machine readable\n(Cannon et al., 2014). This enabled models to be losslessly mapped to other representations, greatly\npromoting interoperability between tools through read-write and automated code generation (Blun‐\ndell et al., 2018). As NeuroMLv2 matured and became a community standard recognized by the INCF\nwith a formal governance structure, an increasingly wide range of models and modeling tools have\nbeen developed or modiﬁed to be NeuroMLv2 compliant (Tables 8, 3 and 4). The core tools, main-\ntained directly by the NeuroML developers (Figure 4), provide functionality to read, modify, or create\nnew NeuroML models, as well as to analyze and visualize, and simulate the models. Furthermore,\nthere are now a larger number of tools that have been developed by other members of the commu-\nnity (Figure 3) including a neuronal simulator designed speciﬁcally for NeuroMLv2 (Panagiotou et al.,\n2022). The emergence of an ecosystem of NeuroMLv2 compliant tools enables modelers to build tool\nchains that span the model life cycle and build and reuse standardized models.\n\nNeuroML and other standards in computational neuroscience\nSeveral other standards and formats exist to support computational modeling of neuronal systems.\nWhereas NeuroML is a modular, declarative simulator independent standard for biophysical neuronal\nmodeling, PyNN (Davison et al., 2008) and SONATA (Dai et al., 2020) provide a procedural Python-\nbased simulator independent API and a framework for efﬁciently handling large-\n                                                                              scale network simula-\ntions, respectively. Even though there is some overlap in the functionality provided by these standards,\nthey each target distinct use cases and have their own goals and features. The teams developing these\nstandards work in concert to ensure that they remain interoperable with each other, frequently sharing\nmethods and techniques (Dai et al., 2020). This allows researchers to use their standard of choice and\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    26 of 44","md":"\n\neLife Tools and resources                                                                      Neuroscience\n\nA crucial aim of NeuroML is to enable Open Science and ensure models in computational neuroscience are FAIR. To this end, all development and discussions related to NeuroML are done publicly. The schema, all core software tools, and relevant resources such as documentation are made freely available under suitable Free/Open Source Software (FOSS) licenses on public platforms. Everyone can, therefore, use, modify, study, and share all NeuroML artifacts without restriction. Users and developers are encouraged to contribute modifications and improvements to the schema and core tools and to participate in the general maintenance and release process.\n\n## Discussion\n\nNeuroMLv2 has matured into a widely adopted community standard for computational neuroscience. Its modular, hierarchical structure can define a wide range of neuronal and circuit model types including simplified representations and those with a high degree of biological detail. The standardized, machine readable format of the NeuroMLv2/LEMS framework provides a flexible, common language for communicating between a wide range of tools and simulators used to create, validate, visualize, analyze, simulate, share, and reuse models. By enabling this interoperability, NeuroMLv2 has spawned a large ecosystem of interacting tools that cover all stages of the model development life cycle, bringing greater coherence to a previously fragmented landscape. Moreover, the modular nature of the model components and hierarchical structure conferred by NeuroMLv2, combined with the flexibility of coding in Python, has created a powerful 'building block' approach for constructing standardized models from scratch.\n\nNeuroML has, therefore, evolved from a standardized archiving format into a mature language that supports an ecosystem of tools for the creation and execution of models that support the FAIR principles and promote open, transparent, and reproducible science.\n\n## Evolution of NeuroML and emergence of the NeuroMLv2 tool ecosystem\n\nNeuroML was conceived (Goddard et al., 2001) and developed (Gleeson et al., 2010) as a declarative XML-based framework for defining biophysical models of neurons and networks in a standardized form in order to compare model properties across simulators and to promote transparency and reuse. NeuroML version 1 achieved these aims and was mainly used to archive and visualize existing models (Gleeson et al., 2010). Building on this, the subsequent development of the NeuroMLv2/LEMS framework provided a way to describe models as a hierarchical set of components with dimensional parameters and state variables, so that their structure and dynamics are fully machine readable (Cannon et al., 2014). This enabled models to be losslessly mapped to other representations, greatly promoting interoperability between tools through read-write and automated code generation (Blundell et al., 2018). As NeuroMLv2 matured and became a community standard recognized by the INCF with a formal governance structure, an increasingly wide range of models and modeling tools have been developed or modified to be NeuroMLv2 compliant (Tables 8, 3 and 4). The core tools, maintained directly by the NeuroML developers (Figure 4), provide functionality to read, modify, or create new NeuroML models, as well as to analyze and visualize, and simulate the models. Furthermore, there are now a larger number of tools that have been developed by other members of the community (Figure 3) including a neuronal simulator designed specifically for NeuroMLv2 (Panagiotou et al., 2022). The emergence of an ecosystem of NeuroMLv2 compliant tools enables modelers to build tool chains that span the model life cycle and build and reuse standardized models.\n\n## NeuroML and other standards in computational neuroscience\n\nSeveral other standards and formats exist to support computational modeling of neuronal systems. Whereas NeuroML is a modular, declarative simulator independent standard for biophysical neuronal modeling, PyNN (Davison et al., 2008) and SONATA (Dai et al., 2020) provide a procedural Python-based simulator independent API and a framework for efficiently handling large-scale network simulations, respectively. Even though there is some overlap in the functionality provided by these standards, they each target distinct use cases and have their own goals and features. The teams developing these standards work in concert to ensure that they remain interoperable with each other, frequently sharing methods and techniques (Dai et al., 2020). This allows researchers to use their standard of choice and\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    26 of 44\n","images":[{"name":"page_26.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_26_text_1_v2.jpg","height":169208.266,"width":250382.426,"x":101055.298,"y":303899.312,"original_width":1654,"original_height":864,"rotation":0,"type":"layout_v2_text"},{"name":"page_26_text_2_v2.jpg","height":102215.295,"width":250400.141,"x":100971.579,"y":138336.704,"original_width":1654,"original_height":522,"rotation":0,"type":"layout_v2_text"},{"name":"page_26_text_3_v2.jpg","height":64967.522,"width":250086.224,"x":101125.638,"y":41410.248,"original_width":1652,"original_height":332,"rotation":0,"type":"layout_v2_text"},{"name":"page_26_text_4_v2.jpg","height":73764.619,"width":250329.261,"x":101084.836,"y":496965.644,"original_width":1653,"original_height":377,"rotation":0,"type":"layout_v2_text"},{"name":"page_26_text_5_v2.jpg","height":26747.105,"width":250219.563,"x":101155.822,"y":242874.856,"original_width":1653,"original_height":137,"rotation":0,"type":"layout_v2_text"},{"name":"page_26_paragraph_title_1_v2.jpg","height":19738.273,"width":216545.689,"x":101198.144,"y":281003.745,"original_width":1430,"original_height":101,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_26_paragraph_title_2_v2.jpg","height":8557.351,"width":213569.592,"x":101482.25,"y":485000.093,"original_width":1411,"original_height":44,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_26_footer_1_v2.jpg","height":6864.208,"width":191881.391,"x":21508.744,"y":591500.151,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_26_paragraph_title_3_v2.jpg","height":8387.003,"width":43215.955,"x":101753.421,"y":125914.099,"original_width":286,"original_height":43,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_26_header_1_v2.jpg","height":5538.06,"width":30334.595,"x":320725.238,"y":27716.694,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_26_number_1_v2.jpg","height":5833.319,"width":18192.645,"x":332890.103,"y":591840.559,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_26_header_2_v2.jpg","height":5684.681,"width":42909.502,"x":47670.881,"y":27879.556,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                      Neuroscience","md":"eLife Tools and resources                                                                      Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":6,"startIndex":95,"endIndex":107}]},{"type":"text","value":"A crucial aim of NeuroML is to enable Open Science and ensure models in computational neuroscience are FAIR. To this end, all development and discussions related to NeuroML are done publicly. The schema, all core software tools, and relevant resources such as documentation are made freely available under suitable Free/Open Source Software (FOSS) licenses on public platforms. Everyone can, therefore, use, modify, study, and share all NeuroML artifacts without restriction. Users and developers are encouraged to contribute modifications and improvements to the schema and core tools and to participate in the general maintenance and release process.","md":"A crucial aim of NeuroML is to enable Open Science and ensure models in computational neuroscience are FAIR. To this end, all development and discussions related to NeuroML are done publicly. The schema, all core software tools, and relevant resources such as documentation are made freely available under suitable Free/Open Source Software (FOSS) licenses on public platforms. Everyone can, therefore, use, modify, study, and share all NeuroML artifacts without restriction. Users and developers are encouraged to contribute modifications and improvements to the schema and core tools and to participate in the general maintenance and release process.","bBox":{"x":168.53,"y":63.8,"w":409.55,"h":68.98},"layoutAwareBbox":[{"x":165,"y":52,"w":408,"h":82,"startIndex":17,"endIndex":24}]},{"type":"heading","lvl":2,"value":"Discussion","md":"## Discussion","bBox":{"x":168.53,"y":156.22,"w":68.71,"h":14},"layoutAwareBbox":[{"x":166,"y":158,"w":70,"h":10,"startIndex":3,"endIndex":13}]},{"type":"text","value":"NeuroMLv2 has matured into a widely adopted community standard for computational neuroscience. Its modular, hierarchical structure can define a wide range of neuronal and circuit model types including simplified representations and those with a high degree of biological detail. The standardized, machine readable format of the NeuroMLv2/LEMS framework provides a flexible, common language for communicating between a wide range of tools and simulators used to create, validate, visualize, analyze, simulate, share, and reuse models. By enabling this interoperability, NeuroMLv2 has spawned a large ecosystem of interacting tools that cover all stages of the model development life cycle, bringing greater coherence to a previously fragmented landscape. Moreover, the modular nature of the model components and hierarchical structure conferred by NeuroMLv2, combined with the flexibility of coding in Python, has created a powerful 'building block' approach for constructing standardized models from scratch.","md":"NeuroMLv2 has matured into a widely adopted community standard for computational neuroscience. Its modular, hierarchical structure can define a wide range of neuronal and circuit model types including simplified representations and those with a high degree of biological detail. The standardized, machine readable format of the NeuroMLv2/LEMS framework provides a flexible, common language for communicating between a wide range of tools and simulators used to create, validate, visualize, analyze, simulate, share, and reuse models. By enabling this interoperability, NeuroMLv2 has spawned a large ecosystem of interacting tools that cover all stages of the model development life cycle, bringing greater coherence to a previously fragmented landscape. Moreover, the modular nature of the model components and hierarchical structure conferred by NeuroMLv2, combined with the flexibility of coding in Python, has created a powerful 'building block' approach for constructing standardized models from scratch.","bBox":{"x":168.53,"y":34.63,"w":408.61,"h":268.55},"layoutAwareBbox":[{"x":164,"y":174,"w":409,"h":129,"startIndex":10,"endIndex":13}]},{"type":"text","value":"NeuroML has, therefore, evolved from a standardized archiving format into a mature language that supports an ecosystem of tools for the creation and execution of models that support the FAIR principles and promote open, transparent, and reproducible science.","md":"NeuroML has, therefore, evolved from a standardized archiving format into a mature language that supports an ecosystem of tools for the creation and execution of models that support the FAIR principles and promote open, transparent, and reproducible science.","bBox":{"x":168.53,"y":306.18,"w":403.08,"h":32.99},"layoutAwareBbox":[{"x":165,"y":306,"w":408,"h":33,"startIndex":13,"endIndex":16}]},{"type":"heading","lvl":2,"value":"Evolution of NeuroML and emergence of the NeuroMLv2 tool ecosystem","md":"## Evolution of NeuroML and emergence of the NeuroMLv2 tool ecosystem","bBox":{"x":168.53,"y":353.35,"w":354.97,"h":26},"layoutAwareBbox":[{"x":165,"y":354,"w":353,"h":24,"startIndex":60,"endIndex":69}]},{"type":"text","value":"NeuroML was conceived (Goddard et al., 2001) and developed (Gleeson et al., 2010) as a declarative XML-based framework for defining biophysical models of neurons and networks in a standardized form in order to compare model properties across simulators and to promote transparency and reuse. NeuroML version 1 achieved these aims and was mainly used to archive and visualize existing models (Gleeson et al., 2010). Building on this, the subsequent development of the NeuroMLv2/LEMS framework provided a way to describe models as a hierarchical set of components with dimensional parameters and state variables, so that their structure and dynamics are fully machine readable (Cannon et al., 2014). This enabled models to be losslessly mapped to other representations, greatly promoting interoperability between tools through read-write and automated code generation (Blundell et al., 2018). As NeuroMLv2 matured and became a community standard recognized by the INCF with a formal governance structure, an increasingly wide range of models and modeling tools have been developed or modified to be NeuroMLv2 compliant (Tables 8, 3 and 4). The core tools, maintained directly by the NeuroML developers (Figure 4), provide functionality to read, modify, or create new NeuroML models, as well as to analyze and visualize, and simulate the models. Furthermore, there are now a larger number of tools that have been developed by other members of the community (Figure 3) including a neuronal simulator designed specifically for NeuroMLv2 (Panagiotou et al., 2022). The emergence of an ecosystem of NeuroMLv2 compliant tools enables modelers to build tool chains that span the model life cycle and build and reuse standardized models.","md":"NeuroML was conceived (Goddard et al., 2001) and developed (Gleeson et al., 2010) as a declarative XML-based framework for defining biophysical models of neurons and networks in a standardized form in order to compare model properties across simulators and to promote transparency and reuse. NeuroML version 1 achieved these aims and was mainly used to archive and visualize existing models (Gleeson et al., 2010). Building on this, the subsequent development of the NeuroMLv2/LEMS framework provided a way to describe models as a hierarchical set of components with dimensional parameters and state variables, so that their structure and dynamics are fully machine readable (Cannon et al., 2014). This enabled models to be losslessly mapped to other representations, greatly promoting interoperability between tools through read-write and automated code generation (Blundell et al., 2018). As NeuroMLv2 matured and became a community standard recognized by the INCF with a formal governance structure, an increasingly wide range of models and modeling tools have been developed or modified to be NeuroMLv2 compliant (Tables 8, 3 and 4). The core tools, maintained directly by the NeuroML developers (Figure 4), provide functionality to read, modify, or create new NeuroML models, as well as to analyze and visualize, and simulate the models. Furthermore, there are now a larger number of tools that have been developed by other members of the community (Figure 3) including a neuronal simulator designed specifically for NeuroMLv2 (Panagiotou et al., 2022). The emergence of an ecosystem of NeuroMLv2 compliant tools enables modelers to build tool chains that span the model life cycle and build and reuse standardized models.","bBox":{"x":168.53,"y":383.35,"w":414.05,"h":212.95},"layoutAwareBbox":[{"x":165,"y":383,"w":409,"h":213,"startIndex":13,"endIndex":15}]},{"type":"heading","lvl":2,"value":"NeuroML and other standards in computational neuroscience","md":"## NeuroML and other standards in computational neuroscience","bBox":{"x":168.53,"y":610.47,"w":346.6,"h":12},"layoutAwareBbox":[{"x":165,"y":612,"w":348,"h":10,"startIndex":0,"endIndex":59}]},{"type":"text","value":"Several other standards and formats exist to support computational modeling of neuronal systems. Whereas NeuroML is a modular, declarative simulator independent standard for biophysical neuronal modeling, PyNN (Davison et al., 2008) and SONATA (Dai et al., 2020) provide a procedural Python-based simulator independent API and a framework for efficiently handling large-scale network simulations, respectively. Even though there is some overlap in the functionality provided by these standards, they each target distinct use cases and have their own goals and features. The teams developing these standards work in concert to ensure that they remain interoperable with each other, frequently sharing methods and techniques (Dai et al., 2020). This allows researchers to use their standard of choice and","md":"Several other standards and formats exist to support computational modeling of neuronal systems. Whereas NeuroML is a modular, declarative simulator independent standard for biophysical neuronal modeling, PyNN (Davison et al., 2008) and SONATA (Dai et al., 2020) provide a procedural Python-based simulator independent API and a framework for efficiently handling large-scale network simulations, respectively. Even though there is some overlap in the functionality provided by these standards, they each target distinct use cases and have their own goals and features. The teams developing these standards work in concert to ensure that they remain interoperable with each other, frequently sharing methods and techniques (Dai et al., 2020). This allows researchers to use their standard of choice and","bBox":{"x":168.53,"y":383.35,"w":416.91,"h":324.11},"layoutAwareBbox":[{"x":165,"y":627,"w":409,"h":93,"startIndex":245,"endIndex":248}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    26 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    26 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                      Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    26 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.978,"layout":[{"image":"page_26_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.484,"w":0.668,"h":0.27},"isLikelyNoise":false},{"image":"page_26_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.221,"w":0.669,"h":0.163},"isLikelyNoise":false},{"image":"page_26_text_3_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.104},"isLikelyNoise":false},{"image":"page_26_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.792,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_26_text_5_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.387,"w":0.668,"h":0.043},"isLikelyNoise":false},{"image":"page_26_paragraph_title_1_v2.jpg","confidence":0.93,"label":"paragraph_title","bbox":{"x":0.27,"y":0.448,"w":0.578,"h":0.031},"isLikelyNoise":false},{"image":"page_26_paragraph_title_2_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.773,"w":0.57,"h":0.014},"isLikelyNoise":false},{"image":"page_26_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_26_paragraph_title_3_v2.jpg","confidence":0.87,"label":"paragraph_title","bbox":{"x":0.272,"y":0.201,"w":0.115,"h":0.013},"isLikelyNoise":false},{"image":"page_26_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_26_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_26_header_2_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false}]},{"page":27,"text":"Tools  and  resources                                                                       Neuroscience\n\n                         easily combine with another if the need arises. PyNN and SONATA are, therefore, integral parts of the\n                         wider NeuroML ecosystem.\n\n                         Why using NeuroML and Python promotes the construction of FAIR\n                         models\n                         The modular and hierarchical structure of NeuroMLv2, when combined with Python, provides a\n                         powerful combination of structured declarative elements and ﬂexible procedural approaches that\n                         enables a ‘Lego- like’ building block approach for constructing biologically detailed models (Cayco‐\n                         Gajic et al., 2017; Billings et al., 2014; Kriener et al., 2022; Gurnani and Silver, 2021). This has\n                         been advanced by the development of pyNeuroML, which provides a single installable package\n                         offering direct access to a range of functionality for handling NeuroML models (Figure  6). More-\n                         over, the web-based documentation of NeuroMLv2, with multiple Python scripts illustrating the usage\n                         of the language and associated tools (Table 5), has recently been updated and expanded (https://\n                         docs.neuroml.org). This provides a central resource for both new and experienced users of NeuroML\n                         supporting its use in model building. As the examples of this resource illustrate, building models\n                         using NeuroMLv2 is efﬁcient and intuitive, as the model components are pre- made and how they ﬁt\n                         together speciﬁed. The structured format allows APIs like libNeuroML to incorporate features such as\n                         auto-completion and inline validation of model parameters and structure as scripts are being devel-\n                         oped. In addition, automated multi-stage model validation ensures the code, equations and internal\n                         structure are validated against the NeuroML schema minimizing human errors and model simulations\n                         outputs are within acceptable bounds (Figure 7). The NeuroMLv2 ecosystem also provides convenient\n                         ways to visualize and inspect the inner structure of models. pyNeuroML provides Python functions\n                         and corresponding command line utilities to view neuronal morphology (Figure 8), neuronal electro-\n                         physiology (Figure  10), circuit connectivity and schematics (Figure  9). In addition, custom analysis\n                         pipelines and advanced neuroinformatics resources can easily be built using the APIs. For example,\n                         loading a NeuroML model of a neuron into OSB enables visualization of the morphology and the\n                         spatial distribution of ionic conductance over the membrane as well as inspection of the conductance\n                         state variables, while the connectivity and synaptic weight matrices can be automatically displayed for\n                         circuit models (Figure 8; Gleeson et al., 2019b). Such features of OSB, which are made possible by\n                         the structured format of NeuroMLv2, promote model transparency, reproducibility, and sharing. By\n                         enabling the development and sharing of well tested and transparent models the wider NeuroMLv2\n                         ecosystem promotes Open Science.\n\n                         Limitations of NeuroML and current work\n                         A limitation of any standardized framework is that there will always be models and model elements\n                         that fall outside the current scope of the standard. Although NeuroML suffers from this limitation, the\n                         underlying LEMS- based framework provides a ﬂexible route to develop a wide range of new types\n                         of physio-chemical models (Cannon et al., 2014). This is relatively straightforward if the new model\n                         component, such as a synaptic plasticity mechanism, ﬁts within the existing hierarchical structure of\n                         NeuroMLv2 as the new type of synaptic element can build on an existing base synapse type which\n                         speciﬁes the relevant input and outputs (e.g. local voltage and synaptic current). For more radical\n                         shifts in model types (e.g. neuronal morphologies that grow during learning) that do not ﬁt neatly into\n                         the current NeuroMLv2 schema, structural changes to the language would be required. This route\n                         is more involved as the pros and cons of changes to the structure of NeuroMLv2 would need to be\n                         considered by the Scientiﬁc Committee and, if approved, implemented by the Editorial Board.\n                         Whereas the current scope of NeuroMLv2 encompasses models of spiking neurons and networks\n                         at different levels of biological detail, plans are in place to extend its scope to include more abstract,\n                         rate-based models of neuronal populations (e.g. see Wilson and Cowan, 1972; Mejias et al., 2016\n                         in Table 8). Additionally, work is under way to extend current support for SBML (Hucka et al., 2003)\n                         based descriptions of chemical signaling pathways (Cannon et al., 2014), to enable better biochem-\n                         ical descriptions of sub-cellular activity in neurons and synapses.\n                         There is a growing interest in the ﬁeld for the efﬁcient generation and serialization of large- scale\n                         network models, containing numbers of neurons closer to their biological equivalents (Markram et al.,\n                         2015; Billeh et al., 2020; Einevoll et al., 2019). While a multitude of applications in the NeuroML\n                         ecosystem support large-scale model generation (e.g. NetPyNE, neuroConstruct, PyNN), the default\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    27 of 44","md":"\n\neLife Tools and resourcesNeuroscience\n\neasily combine with another if the need arises. PyNN and SONATA are, therefore, integral parts of the wider NeuroML ecosystem.\n\n## Why using NeuroML and Python promotes the construction of FAIR models\n\nThe modular and hierarchical structure of NeuroMLv2, when combined with Python, provides a powerful combination of structured declarative elements and flexible procedural approaches that enables a 'Lego-like' building block approach for constructing biologically detailed models (Cayco-Gajic et al., 2017; Billings et al., 2014; Kriener et al., 2022; Gurnani and Silver, 2021). This has been advanced by the development of pyNeuroML, which provides a single installable package offering direct access to a range of functionality for handling NeuroML models (Figure 6). Moreover, the web-based documentation of NeuroMLv2, with multiple Python scripts illustrating the usage of the language and associated tools (Table 5), has recently been updated and expanded (https://docs.neuroml.org). This provides a central resource for both new and experienced users of NeuroML supporting its use in model building. As the examples of this resource illustrate, building models using NeuroMLv2 is efficient and intuitive, as the model components are pre-made and how they fit together specified. The structured format allows APIs like libNeuroML to incorporate features such as auto-completion and inline validation of model parameters and structure as scripts are being developed. In addition, automated multi-stage model validation ensures the code, equations and internal structure are validated against the NeuroML schema minimizing human errors and model simulations outputs are within acceptable bounds (Figure 7). The NeuroMLv2 ecosystem also provides convenient ways to visualize and inspect the inner structure of models. pyNeuroML provides Python functions and corresponding command line utilities to view neuronal morphology (Figure 8), neuronal electrophysiology (Figure 10), circuit connectivity and schematics (Figure 9). In addition, custom analysis pipelines and advanced neuroinformatics resources can easily be built using the APIs. For example, loading a NeuroML model of a neuron into OSB enables visualization of the morphology and the spatial distribution of ionic conductance over the membrane as well as inspection of the conductance state variables, while the connectivity and synaptic weight matrices can be automatically displayed for circuit models (Figure 8; Gleeson et al., 2019b). Such features of OSB, which are made possible by the structured format of NeuroMLv2, promote model transparency, reproducibility, and sharing. By enabling the development and sharing of well tested and transparent models the wider NeuroMLv2 ecosystem promotes Open Science.\n\n## Limitations of NeuroML and current work\n\nA limitation of any standardized framework is that there will always be models and model elements that fall outside the current scope of the standard. Although NeuroML suffers from this limitation, the underlying LEMS-based framework provides a flexible route to develop a wide range of new types of physio-chemical models (Cannon et al., 2014). This is relatively straightforward if the new model component, such as a synaptic plasticity mechanism, fits within the existing hierarchical structure of NeuroMLv2 as the new type of synaptic element can build on an existing base synapse type which specifies the relevant input and outputs (e.g. local voltage and synaptic current). For more radical shifts in model types (e.g. neuronal morphologies that grow during learning) that do not fit neatly into the current NeuroMLv2 schema, structural changes to the language would be required. This route is more involved as the pros and cons of changes to the structure of NeuroMLv2 would need to be considered by the Scientific Committee and, if approved, implemented by the Editorial Board.\n\nWhereas the current scope of NeuroMLv2 encompasses models of spiking neurons and networks at different levels of biological detail, plans are in place to extend its scope to include more abstract, rate-based models of neuronal populations (e.g. see Wilson and Cowan, 1972; Mejias et al., 2016 in Table 8). Additionally, work is under way to extend current support for SBML (Hucka et al., 2003) based descriptions of chemical signaling pathways (Cannon et al., 2014), to enable better biochemical descriptions of sub-cellular activity in neurons and synapses.\n\nThere is a growing interest in the field for the efficient generation and serialization of large-scale network models, containing numbers of neurons closer to their biological equivalents (Markram et al., 2015; Billeh et al., 2020; Einevoll et al., 2019). While a multitude of applications in the NeuroML ecosystem support large-scale model generation (e.g. NetPyNE, neuroConstruct, PyNN), the default\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                27 of 44\n","images":[{"name":"page_27.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_27_text_1_v2.jpg","height":255340.134,"width":250387.54,"x":101055.696,"y":93952.999,"original_width":1654,"original_height":1303,"rotation":0,"type":"layout_v2_text"},{"name":"page_27_text_2_v2.jpg","height":102891.427,"width":250497.026,"x":101002.96,"y":372870.498,"original_width":1654,"original_height":525,"rotation":0,"type":"layout_v2_text"},{"name":"page_27_text_3_v2.jpg","height":54695.323,"width":250508.582,"x":101073.644,"y":477884.116,"original_width":1655,"original_height":280,"rotation":0,"type":"layout_v2_text"},{"name":"page_27_text_4_v2.jpg","height":36754.573,"width":250353.736,"x":101279.408,"y":534458.134,"original_width":1654,"original_height":188,"rotation":0,"type":"layout_v2_text"},{"name":"page_27_text_5_v2.jpg","height":16671.761,"width":250025.703,"x":101150.446,"y":41463.746,"original_width":1651,"original_height":86,"rotation":0,"type":"layout_v2_text"},{"name":"page_27_paragraph_title_1_v2.jpg","height":19009.717,"width":236549.344,"x":100921.66,"y":71043.305,"original_width":1562,"original_height":97,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_27_paragraph_title_2_v2.jpg","height":7687.218,"width":146243.771,"x":101422.88,"y":361465.839,"original_width":966,"original_height":40,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_27_footer_1_v2.jpg","height":6909.508,"width":191856.248,"x":21506.367,"y":591519.164,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_27_header_1_v2.jpg","height":5659.609,"width":30353.603,"x":320734.961,"y":27736.749,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_27_number_1_v2.jpg","height":5952.147,"width":18340.524,"x":332793.551,"y":591832.228,"original_width":122,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_27_header_2_v2.jpg","height":5751.705,"width":42849.233,"x":47706.988,"y":27892.861,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_27_header_3_v2.jpg","height":10719.89,"width":24461.588,"x":21777.184,"y":22425.591,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resourcesNeuroscience","md":"eLife Tools and resourcesNeuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":25,"endIndex":37}]},{"type":"text","value":"easily combine with another if the need arises. PyNN and SONATA are, therefore, integral parts of the wider NeuroML ecosystem.","md":"easily combine with another if the need arises. PyNN and SONATA are, therefore, integral parts of the wider NeuroML ecosystem.","bBox":{"x":168.53,"y":51.8,"w":414.05,"h":21},"layoutAwareBbox":[{"x":165,"y":52,"w":408,"h":21,"startIndex":0,"endIndex":6}]},{"type":"heading","lvl":2,"value":"Why using NeuroML and Python promotes the construction of FAIR models","md":"## Why using NeuroML and Python promotes the construction of FAIR models","bBox":{"x":168.53,"y":88.14,"w":387.44,"h":26},"layoutAwareBbox":[{"x":164,"y":89,"w":386,"h":24,"startIndex":66,"endIndex":72}]},{"type":"text","value":"The modular and hierarchical structure of NeuroMLv2, when combined with Python, provides a powerful combination of structured declarative elements and flexible procedural approaches that enables a 'Lego-like' building block approach for constructing biologically detailed models (Cayco-Gajic et al., 2017; Billings et al., 2014; Kriener et al., 2022; Gurnani and Silver, 2021). This has been advanced by the development of pyNeuroML, which provides a single installable package offering direct access to a range of functionality for handling NeuroML models (Figure 6). Moreover, the web-based documentation of NeuroMLv2, with multiple Python scripts illustrating the usage of the language and associated tools (Table 5), has recently been updated and expanded (https://docs.neuroml.org). This provides a central resource for both new and experienced users of NeuroML supporting its use in model building. As the examples of this resource illustrate, building models using NeuroMLv2 is efficient and intuitive, as the model components are pre-made and how they fit together specified. The structured format allows APIs like libNeuroML to incorporate features such as auto-completion and inline validation of model parameters and structure as scripts are being developed. In addition, automated multi-stage model validation ensures the code, equations and internal structure are validated against the NeuroML schema minimizing human errors and model simulations outputs are within acceptable bounds (Figure 7). The NeuroMLv2 ecosystem also provides convenient ways to visualize and inspect the inner structure of models. pyNeuroML provides Python functions and corresponding command line utilities to view neuronal morphology (Figure 8), neuronal electrophysiology (Figure 10), circuit connectivity and schematics (Figure 9). In addition, custom analysis pipelines and advanced neuroinformatics resources can easily be built using the APIs. For example, loading a NeuroML model of a neuron into OSB enables visualization of the morphology and the spatial distribution of ionic conductance over the membrane as well as inspection of the conductance state variables, while the connectivity and synaptic weight matrices can be automatically displayed for circuit models (Figure 8; Gleeson et al., 2019b). Such features of OSB, which are made possible by the structured format of NeuroMLv2, promote model transparency, reproducibility, and sharing. By enabling the development and sharing of well tested and transparent models the wider NeuroMLv2 ecosystem promotes Open Science.","md":"The modular and hierarchical structure of NeuroMLv2, when combined with Python, provides a powerful combination of structured declarative elements and flexible procedural approaches that enables a 'Lego-like' building block approach for constructing biologically detailed models (Cayco-Gajic et al., 2017; Billings et al., 2014; Kriener et al., 2022; Gurnani and Silver, 2021). This has been advanced by the development of pyNeuroML, which provides a single installable package offering direct access to a range of functionality for handling NeuroML models (Figure 6). Moreover, the web-based documentation of NeuroMLv2, with multiple Python scripts illustrating the usage of the language and associated tools (Table 5), has recently been updated and expanded (https://docs.neuroml.org). This provides a central resource for both new and experienced users of NeuroML supporting its use in model building. As the examples of this resource illustrate, building models using NeuroMLv2 is efficient and intuitive, as the model components are pre-made and how they fit together specified. The structured format allows APIs like libNeuroML to incorporate features such as auto-completion and inline validation of model parameters and structure as scripts are being developed. In addition, automated multi-stage model validation ensures the code, equations and internal structure are validated against the NeuroML schema minimizing human errors and model simulations outputs are within acceptable bounds (Figure 7). The NeuroMLv2 ecosystem also provides convenient ways to visualize and inspect the inner structure of models. pyNeuroML provides Python functions and corresponding command line utilities to view neuronal morphology (Figure 8), neuronal electrophysiology (Figure 10), circuit connectivity and schematics (Figure 9). In addition, custom analysis pipelines and advanced neuroinformatics resources can easily be built using the APIs. For example, loading a NeuroML model of a neuron into OSB enables visualization of the morphology and the spatial distribution of ionic conductance over the membrane as well as inspection of the conductance state variables, while the connectivity and synaptic weight matrices can be automatically displayed for circuit models (Figure 8; Gleeson et al., 2019b). Such features of OSB, which are made possible by the structured format of NeuroMLv2, promote model transparency, reproducibility, and sharing. By enabling the development and sharing of well tested and transparent models the wider NeuroMLv2 ecosystem promotes Open Science.","bBox":{"x":168.53,"y":102.15,"w":413.18,"h":336.92},"layoutAwareBbox":[{"x":165,"y":118,"w":409,"h":322,"startIndex":0,"endIndex":3}]},{"type":"heading","lvl":2,"value":"Limitations of NeuroML and current work","md":"## Limitations of NeuroML and current work","bBox":{"x":168.53,"y":454.48,"w":235.7,"h":12},"layoutAwareBbox":[{"x":165,"y":456,"w":238,"h":9,"startIndex":0,"endIndex":41}]},{"type":"text","value":"A limitation of any standardized framework is that there will always be models and model elements that fall outside the current scope of the standard. Although NeuroML suffers from this limitation, the underlying LEMS-based framework provides a flexible route to develop a wide range of new types of physio-chemical models (Cannon et al., 2014). This is relatively straightforward if the new model component, such as a synaptic plasticity mechanism, fits within the existing hierarchical structure of NeuroMLv2 as the new type of synaptic element can build on an existing base synapse type which specifies the relevant input and outputs (e.g. local voltage and synaptic current). For more radical shifts in model types (e.g. neuronal morphologies that grow during learning) that do not fit neatly into the current NeuroMLv2 schema, structural changes to the language would be required. This route is more involved as the pros and cons of changes to the structure of NeuroMLv2 would need to be considered by the Scientific Committee and, if approved, implemented by the Editorial Board.","md":"A limitation of any standardized framework is that there will always be models and model elements that fall outside the current scope of the standard. Although NeuroML suffers from this limitation, the underlying LEMS-based framework provides a flexible route to develop a wide range of new types of physio-chemical models (Cannon et al., 2014). This is relatively straightforward if the new model component, such as a synaptic plasticity mechanism, fits within the existing hierarchical structure of NeuroMLv2 as the new type of synaptic element can build on an existing base synapse type which specifies the relevant input and outputs (e.g. local voltage and synaptic current). For more radical shifts in model types (e.g. neuronal morphologies that grow during learning) that do not fit neatly into the current NeuroMLv2 schema, structural changes to the language would be required. This route is more involved as the pros and cons of changes to the structure of NeuroMLv2 would need to be considered by the Scientific Committee and, if approved, implemented by the Editorial Board.","bBox":{"x":168.53,"y":470.48,"w":411.25,"h":116.97},"layoutAwareBbox":[{"x":168.53,"y":470.48,"w":411.25,"h":116.97,"startIndex":0,"endIndex":1084}]},{"type":"text","value":"Whereas the current scope of NeuroMLv2 encompasses models of spiking neurons and networks at different levels of biological detail, plans are in place to extend its scope to include more abstract, rate-based models of neuronal populations (e.g. see Wilson and Cowan, 1972; Mejias et al., 2016 in Table 8). Additionally, work is under way to extend current support for SBML (Hucka et al., 2003) based descriptions of chemical signaling pathways (Cannon et al., 2014), to enable better biochemical descriptions of sub-cellular activity in neurons and synapses.","md":"Whereas the current scope of NeuroMLv2 encompasses models of spiking neurons and networks at different levels of biological detail, plans are in place to extend its scope to include more abstract, rate-based models of neuronal populations (e.g. see Wilson and Cowan, 1972; Mejias et al., 2016 in Table 8). Additionally, work is under way to extend current support for SBML (Hucka et al., 2003) based descriptions of chemical signaling pathways (Cannon et al., 2014), to enable better biochemical descriptions of sub-cellular activity in neurons and synapses.","bBox":{"x":168.53,"y":602.45,"w":408.7,"h":68.99},"layoutAwareBbox":[{"x":165,"y":603,"w":409,"h":69,"startIndex":65,"endIndex":67}]},{"type":"text","value":"There is a growing interest in the field for the efficient generation and serialization of large-scale network models, containing numbers of neurons closer to their biological equivalents (Markram et al., 2015; Billeh et al., 2020; Einevoll et al., 2019). While a multitude of applications in the NeuroML ecosystem support large-scale model generation (e.g. NetPyNE, neuroConstruct, PyNN), the default","md":"There is a growing interest in the field for the efficient generation and serialization of large-scale network models, containing numbers of neurons closer to their biological equivalents (Markram et al., 2015; Billeh et al., 2020; Einevoll et al., 2019). While a multitude of applications in the NeuroML ecosystem support large-scale model generation (e.g. NetPyNE, neuroConstruct, PyNN), the default","bBox":{"x":168.52,"y":102.15,"w":408.98,"h":617.28},"layoutAwareBbox":[{"x":165,"y":674,"w":409,"h":46,"startIndex":97,"endIndex":102}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                27 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                27 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":108},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":108}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/","unsafeUrl":"https://docs.neuroml.org","text":"), has recently been updated and expanded (https://"},{"url":"https://docs.neuroml.org/","unsafeUrl":"https://docs.neuroml.org","text":"docs.neuroml.org). This provides a central resource for both new and experienced users of NeuroML "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resourcesNeuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                27 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.976,"layout":[{"image":"page_27_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.15,"w":0.669,"h":0.407},"isLikelyNoise":false},{"image":"page_27_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.594,"w":0.669,"h":0.164},"isLikelyNoise":false},{"image":"page_27_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.762,"w":0.669,"h":0.087},"isLikelyNoise":false},{"image":"page_27_text_4_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.852,"w":0.668,"h":0.059},"isLikelyNoise":false},{"image":"page_27_text_5_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_27_paragraph_title_1_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.269,"y":0.113,"w":0.632,"h":0.03},"isLikelyNoise":false},{"image":"page_27_paragraph_title_2_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.576,"w":0.39,"h":0.012},"isLikelyNoise":false},{"image":"page_27_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_27_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_27_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_27_header_2_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_27_header_3_v2.jpg","confidence":0.52,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":28,"text":"Tools  and  resources                                                                                            Neuroscience\n\n                         serialization of NeuroML (XML) is inefﬁcient for reading/writing/storing such extensive descriptions.\n                         NeuroML does have an internal format for serializing in the binary format HDF5 (see Methods), but\n                         has also recently added support for export of models to the SONATA data format (Dai et al., 2020)\n                         allowing efﬁcient serialization of large- scale models. Even though individual instances of large- scale\n                         models are useful, the ability to generate families of these for multiple simulation runs and more\n                         particularly a way to encapsulate, examine and reuse templates for network models, is also required.\n                         A prototype package, NeuroMLlite (https://github.com/NeuroML/NeuroMLlite), has been developed\n                         which allows these concise network templates to be described and multiple instances of networks to\n                         be generated, and facilitates interaction with simulation platforms and efﬁcient serialization formats.\n                         As discoveries and insights in neuroscience inform machine learning and visa versa, there is an\n                         increasing need to develop a common framework for describing both biological and artiﬁcial neural\n                         networks. Model Description Format (MDF) has been developed to address this (Gleeson et  al.,\n                         2023). This initiative has developed a standardized format, along with a Python API, which allows\n                         the speciﬁcation of artiﬁcial neural networks (e.g. Convolutional Neural Networks, Recurrent Neural\n                         Networks) and biological neurons using the same underlying entities. Support for mapping MDF to/\n                         from NeuroMLv2/LEMS has been included from the start. This work will enable deeper integration of\n                         computational neuroscience and ‘brain-inspired’ networks in Artiﬁcial Intelligence (AI).\n\n                         Conclusion and vision for the future\n                         NeuroMLv2 is already a mature community standard that provides a framework for standardizing\n                         biologically detailed neuronal network models. By providing a stable, common framework deﬁning\n                         the essential entities required for biologically detailed neuronal modeling, NeuroML has spawned an\n                         ecosystem of tools that span all stages of the model development life cycle. In the short term, we\n                         envision the functionality of NeuroML to expand further and for new online resources that encourage\n                         the construction of FAIR models using pyNeuroML to be taken up by the community. The NeuroML\n                         development team are also beginning to explore how to combine NeuroML-\n                                                             based circuit models with\n                         musculo-skeletal simulations to enable models of the neural control of behavior. In the longer term,\n                         developing seamless interfaces between NeuroML and other domain speciﬁc standards will enable\n                         the development of more holistic models of the neural control of body systems across a wide range of\n                         organisms, as well as greater exchange of models and insights between computational neuroscience\n                         and AI.\n\n\nMaterials and methods\nNeuroMLv2 is formally speciﬁed by the NeuroMLv2 XML schema, which deﬁnes the allowed structure\nof XML ﬁles which comply to the standard, and the LEMS ComponentType deﬁnitions, which deﬁne\nthe internal state variables of the underlying elements, providing a machine-readable speciﬁcation of\nthe time evolution of model components. The speciﬁcation is backed up by a suite of software tools\nthat support the model life cycle and the accompanying usage and development documentation.\n We illustrate the key parts of this framework using the HindmarshRose cell model (Hindmarsh and\nRose, 1984; Figure 11), which as an abstract point neuron model, serves as an appropriate simple\nNeuroMLv2 ComponentType.\n\nThe NeuroML XML Schema\nWe begin with the NeuroMLv2 standard. The standard consists of two parts, each serving different\nfunctions:\n\n 1. the NeuroMLv2 XML schema\n 2. corresponding LEMS component type definitions\n\n The NeuroMLv2 schema is a language independent data model that constrains the structure of a\nNeuroMLv2 model description. The NeuroML schema is formally described as an XML Schema docu-\nment (https://neuroml.org/schema/neuroml2) in the XML Schema Deﬁnition (XSD) format, a recom-\nmendation of the World Wide Web Consortium (W3C) (https://www.w3.org/TR/xmlschema-1/). An\nXML document that claims to conform to a particular schema can be validated against the schema. All\nNeuroMLv2 model descriptions can, therefore, be validated against the NeuroMLv2 schema.\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    28 of 44","md":"\n\neLife Tools and resources                                                                                            Neuroscience\n\nserialization of NeuroML (XML) is inefficient for reading/writing/storing such extensive descriptions. NeuroML does have an internal format for serializing in the binary format HDF5 (see Methods), but has also recently added support for export of models to the SONATA data format (Dai et al., 2020) allowing efficient serialization of large-scale models. Even though individual instances of large-scale models are useful, the ability to generate families of these for multiple simulation runs and more particularly a way to encapsulate, examine and reuse templates for network models, is also required. A prototype package, NeuroMLlite (https://github.com/NeuroML/NeuroMLlite), has been developed which allows these concise network templates to be described and multiple instances of networks to be generated, and facilitates interaction with simulation platforms and efficient serialization formats.\n\nAs discoveries and insights in neuroscience inform machine learning and visa versa, there is an increasing need to develop a common framework for describing both biological and artificial neural networks. Model Description Format (MDF) has been developed to address this (Gleeson et al., 2023). This initiative has developed a standardized format, along with a Python API, which allows the specification of artificial neural networks (e.g. Convolutional Neural Networks, Recurrent Neural Networks) and biological neurons using the same underlying entities. Support for mapping MDF to/ from NeuroMLv2/LEMS has been included from the start. This work will enable deeper integration of computational neuroscience and 'brain-inspired' networks in Artificial Intelligence (AI).\n\n## Conclusion and vision for the future\n\nNeuroMLv2 is already a mature community standard that provides a framework for standardizing biologically detailed neuronal network models. By providing a stable, common framework defining the essential entities required for biologically detailed neuronal modeling, NeuroML has spawned an ecosystem of tools that span all stages of the model development life cycle. In the short term, we envision the functionality of NeuroML to expand further and for new online resources that encourage the construction of FAIR models using pyNeuroML to be taken up by the community. The NeuroML development team are also beginning to explore how to combine NeuroML-based circuit models with musculo-skeletal simulations to enable models of the neural control of behavior. In the longer term, developing seamless interfaces between NeuroML and other domain specific standards will enable the development of more holistic models of the neural control of body systems across a wide range of organisms, as well as greater exchange of models and insights between computational neuroscience and AI.\n\n## Materials and methods\n\nNeuroMLv2 is formally specified by the NeuroMLv2 XML schema, which defines the allowed structure of XML files which comply to the standard, and the LEMS ComponentType definitions, which define the internal state variables of the underlying elements, providing a machine-readable specification of the time evolution of model components. The specification is backed up by a suite of software tools that support the model life cycle and the accompanying usage and development documentation.\n\nWe illustrate the key parts of this framework using the HindmarshRose cell model (Hindmarsh and Rose, 1984; Figure 11), which as an abstract point neuron model, serves as an appropriate simple NeuroMLv2 ComponentType.\n\n### The NeuroML XML Schema\n\nWe begin with the NeuroMLv2 standard. The standard consists of two parts, each serving different functions:\n\n1. the NeuroMLv2 XML schema\n2. corresponding LEMS component type definitions\n\nThe NeuroMLv2 schema is a language independent data model that constrains the structure of a NeuroMLv2 model description. The NeuroML schema is formally described as an XML Schema document (https://neuroml.org/schema/neuroml2) in the XML Schema Definition (XSD) format, a recommendation of the World Wide Web Consortium (W3C) (https://www.w3.org/TR/xmlschema-1/). An XML document that claims to conform to a particular schema can be validated against the schema. All NeuroMLv2 model descriptions can, therefore, be validated against the NeuroMLv2 schema.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    28 of 44\n","images":[{"name":"page_28.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_28_text_1_v2.jpg","height":111368.057,"width":250426.888,"x":101065.117,"y":224923.639,"original_width":1654,"original_height":569,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_2_v2.jpg","height":83656.9,"width":250323.248,"x":101095.953,"y":41298.767,"original_width":1653,"original_height":427,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_3_v2.jpg","height":73743.194,"width":250515.382,"x":101199.91,"y":127225.193,"original_width":1655,"original_height":377,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_4_v2.jpg","height":55156.127,"width":250365.696,"x":101137.864,"y":515486.711,"original_width":1654,"original_height":282,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_5_v2.jpg","height":45604.151,"width":250754.739,"x":101019.242,"y":369603.844,"original_width":1656,"original_height":233,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_6_v2.jpg","height":26170.12,"width":250393.803,"x":101278.234,"y":417294.079,"original_width":1654,"original_height":134,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_text_7_v2.jpg","height":16415.44,"width":250607.844,"x":100982.438,"y":467220.844,"original_width":1655,"original_height":84,"rotation":0,"type":"layout_v2_text"},{"name":"page_28_paragraph_title_1_v2.jpg","height":7804.105,"width":125265.733,"x":101538.181,"y":213051.256,"original_width":828,"original_height":40,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_28_paragraph_title_2_v2.jpg","height":9048.322,"width":94443.342,"x":101686.069,"y":356768.22,"original_width":624,"original_height":47,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_28_paragraph_title_3_v2.jpg","height":7874.044,"width":96351.845,"x":101313.273,"y":455602.503,"original_width":637,"original_height":41,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_28_footer_1_v2.jpg","height":6888.672,"width":191831.539,"x":21517.037,"y":591466.631,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_28_header_1_v2.jpg","height":5543.114,"width":30367.87,"x":320707.381,"y":27715.455,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_28_number_1_v2.jpg","height":5825.047,"width":18193.069,"x":332888.543,"y":591807.98,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_28_paragraph_title_4_v2.jpg","height":7118.505,"width":130035.255,"x":109095.958,"y":500509.98,"original_width":859,"original_height":37,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_28_paragraph_title_5_v2.jpg","height":6430.2,"width":80764.862,"x":109153.98,"y":491471.615,"original_width":534,"original_height":33,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_28_header_2_v2.jpg","height":5686.732,"width":42858.159,"x":47715.803,"y":27865.313,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_28_header_3_v2.jpg","height":10616.368,"width":24440.739,"x":21788.854,"y":22437.037,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                            Neuroscience","md":"eLife Tools and resources                                                                                            Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":6,"startIndex":117,"endIndex":129}]},{"type":"text","value":"serialization of NeuroML (XML) is inefficient for reading/writing/storing such extensive descriptions. NeuroML does have an internal format for serializing in the binary format HDF5 (see Methods), but has also recently added support for export of models to the SONATA data format (Dai et al., 2020) allowing efficient serialization of large-scale models. Even though individual instances of large-scale models are useful, the ability to generate families of these for multiple simulation runs and more particularly a way to encapsulate, examine and reuse templates for network models, is also required. A prototype package, NeuroMLlite (https://github.com/NeuroML/NeuroMLlite), has been developed which allows these concise network templates to be described and multiple instances of networks to be generated, and facilitates interaction with simulation platforms and efficient serialization formats.","md":"serialization of NeuroML (XML) is inefficient for reading/writing/storing such extensive descriptions. NeuroML does have an internal format for serializing in the binary format HDF5 (see Methods), but has also recently added support for export of models to the SONATA data format (Dai et al., 2020) allowing efficient serialization of large-scale models. Even though individual instances of large-scale models are useful, the ability to generate families of these for multiple simulation runs and more particularly a way to encapsulate, examine and reuse templates for network models, is also required. A prototype package, NeuroMLlite (https://github.com/NeuroML/NeuroMLlite), has been developed which allows these concise network templates to be described and multiple instances of networks to be generated, and facilitates interaction with simulation platforms and efficient serialization formats.","bBox":{"x":168.53,"y":63.8,"w":410.03,"h":80.98},"layoutAwareBbox":[{"x":165,"y":52,"w":409,"h":105,"startIndex":341,"endIndex":346}]},{"type":"text","value":"As discoveries and insights in neuroscience inform machine learning and visa versa, there is an increasing need to develop a common framework for describing both biological and artificial neural networks. Model Description Format (MDF) has been developed to address this (Gleeson et al., 2023). This initiative has developed a standardized format, along with a Python API, which allows the specification of artificial neural networks (e.g. Convolutional Neural Networks, Recurrent Neural Networks) and biological neurons using the same underlying entities. Support for mapping MDF to/ from NeuroMLv2/LEMS has been included from the start. This work will enable deeper integration of computational neuroscience and 'brain-inspired' networks in Artificial Intelligence (AI).","md":"As discoveries and insights in neuroscience inform machine learning and visa versa, there is an increasing need to develop a common framework for describing both biological and artificial neural networks. Model Description Format (MDF) has been developed to address this (Gleeson et al., 2023). This initiative has developed a standardized format, along with a Python API, which allows the specification of artificial neural networks (e.g. Convolutional Neural Networks, Recurrent Neural Networks) and biological neurons using the same underlying entities. Support for mapping MDF to/ from NeuroMLv2/LEMS has been included from the start. This work will enable deeper integration of computational neuroscience and 'brain-inspired' networks in Artificial Intelligence (AI).","bBox":{"x":168.53,"y":159.78,"w":409.36,"h":80.98},"layoutAwareBbox":[{"x":165,"y":160,"w":409,"h":93,"startIndex":170,"endIndex":172}]},{"type":"heading","lvl":2,"value":"Conclusion and vision for the future","md":"## Conclusion and vision for the future","bBox":{"x":168.53,"y":267.23,"w":202.39,"h":12},"layoutAwareBbox":[{"x":165,"y":269,"w":204,"h":9,"startIndex":0,"endIndex":38}]},{"type":"text","value":"NeuroMLv2 is already a mature community standard that provides a framework for standardizing biologically detailed neuronal network models. By providing a stable, common framework defining the essential entities required for biologically detailed neuronal modeling, NeuroML has spawned an ecosystem of tools that span all stages of the model development life cycle. In the short term, we envision the functionality of NeuroML to expand further and for new online resources that encourage the construction of FAIR models using pyNeuroML to be taken up by the community. The NeuroML development team are also beginning to explore how to combine NeuroML-based circuit models with musculo-skeletal simulations to enable models of the neural control of behavior. In the longer term, developing seamless interfaces between NeuroML and other domain specific standards will enable the development of more holistic models of the neural control of body systems across a wide range of organisms, as well as greater exchange of models and insights between computational neuroscience and AI.","md":"NeuroMLv2 is already a mature community standard that provides a framework for standardizing biologically detailed neuronal network models. By providing a stable, common framework defining the essential entities required for biologically detailed neuronal modeling, NeuroML has spawned an ecosystem of tools that span all stages of the model development life cycle. In the short term, we envision the functionality of NeuroML to expand further and for new online resources that encourage the construction of FAIR models using pyNeuroML to be taken up by the community. The NeuroML development team are also beginning to explore how to combine NeuroML-based circuit models with musculo-skeletal simulations to enable models of the neural control of behavior. In the longer term, developing seamless interfaces between NeuroML and other domain specific standards will enable the development of more holistic models of the neural control of body systems across a wide range of organisms, as well as greater exchange of models and insights between computational neuroscience and AI.","bBox":{"x":168.53,"y":283.23,"w":414.63,"h":140.97},"layoutAwareBbox":[{"x":165,"y":283,"w":409,"h":140,"startIndex":677,"endIndex":684}]},{"type":"heading","lvl":2,"value":"Materials and methods","md":"## Materials and methods","bBox":{"x":168.53,"y":448.12,"w":151.9,"h":14},"layoutAwareBbox":[{"x":166,"y":450,"w":154,"h":11,"startIndex":0,"endIndex":23}]},{"type":"text","value":"NeuroMLv2 is formally specified by the NeuroMLv2 XML schema, which defines the allowed structure of XML files which comply to the standard, and the LEMS ComponentType definitions, which define the internal state variables of the underlying elements, providing a machine-readable specification of the time evolution of model components. The specification is backed up by a suite of software tools that support the model life cycle and the accompanying usage and development documentation.","md":"NeuroMLv2 is formally specified by the NeuroMLv2 XML schema, which defines the allowed structure of XML files which comply to the standard, and the LEMS ComponentType definitions, which define the internal state variables of the underlying elements, providing a machine-readable specification of the time evolution of model components. The specification is backed up by a suite of software tools that support the model life cycle and the accompanying usage and development documentation.","bBox":{"x":168.53,"y":514.11,"w":392.39,"h":9},"layoutAwareBbox":[{"x":168.53,"y":514.11,"w":392.39,"h":9,"startIndex":0,"endIndex":486}]},{"type":"text","value":"We illustrate the key parts of this framework using the HindmarshRose cell model (Hindmarsh and Rose, 1984; Figure 11), which as an abstract point neuron model, serves as an appropriate simple NeuroMLv2 ComponentType.","md":"We illustrate the key parts of this framework using the HindmarshRose cell model (Hindmarsh and Rose, 1984; Figure 11), which as an abstract point neuron model, serves as an appropriate simple NeuroMLv2 ComponentType.","bBox":{"x":168.53,"y":526.11,"w":411.37,"h":32.99},"layoutAwareBbox":[{"x":165,"y":526,"w":409,"h":33,"startIndex":0,"endIndex":216}]},{"type":"heading","lvl":3,"value":"The NeuroML XML Schema","md":"### The NeuroML XML Schema","bBox":{"x":168.53,"y":573.55,"w":154.4,"h":12},"layoutAwareBbox":[{"x":165,"y":575,"w":157,"h":9,"startIndex":0,"endIndex":25}]},{"type":"text","value":"We begin with the NeuroMLv2 standard. The standard consists of two parts, each serving different functions:","md":"We begin with the NeuroMLv2 standard. The standard consists of two parts, each serving different functions:","bBox":{"x":168.53,"y":589.55,"w":399.91,"h":21},"layoutAwareBbox":[{"x":165,"y":589,"w":409,"h":20,"startIndex":0,"endIndex":2}]},{"type":"text","value":"1. the NeuroMLv2 XML schema\n2. corresponding LEMS component type definitions","md":"1. the NeuroMLv2 XML schema\n2. corresponding LEMS component type definitions","bBox":{"x":180.52,"y":620,"w":210.28,"h":20},"layoutAwareBbox":[{"x":178,"y":631,"w":212,"h":8,"startIndex":0,"endIndex":75},{"x":178,"y":620,"w":131,"h":8,"startIndex":0,"endIndex":75}]},{"type":"text","value":"The NeuroMLv2 schema is a language independent data model that constrains the structure of a NeuroMLv2 model description. The NeuroML schema is formally described as an XML Schema document (https://neuroml.org/schema/neuroml2) in the XML Schema Definition (XSD) format, a recommendation of the World Wide Web Consortium (W3C) (https://www.w3.org/TR/xmlschema-1/). An XML document that claims to conform to a particular schema can be validated against the schema. All NeuroMLv2 model descriptions can, therefore, be validated against the NeuroMLv2 schema.","md":"The NeuroMLv2 schema is a language independent data model that constrains the structure of a NeuroMLv2 model description. The NeuroML schema is formally described as an XML Schema document (https://neuroml.org/schema/neuroml2) in the XML Schema Definition (XSD) format, a recommendation of the World Wide Web Consortium (W3C) (https://www.w3.org/TR/xmlschema-1/). An XML document that claims to conform to a particular schema can be validated against the schema. All NeuroMLv2 model descriptions can, therefore, be validated against the NeuroMLv2 schema.","bBox":{"x":168.53,"y":650.44,"w":414.21,"h":68.99},"layoutAwareBbox":[{"x":165,"y":650,"w":409,"h":69,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    28 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    28 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/NeuroML/NeuroMLlite","unsafeUrl":"https://github.com/NeuroML/NeuroMLlite","text":"A prototype package, NeuroMLlite (https://github.com/NeuroML/NeuroMLlite), has been developed "},{"url":"https://neuroml.org/schema/neuroml2","unsafeUrl":"https://neuroml.org/schema/neuroml2","text":"ment (https://neuroml.org/schema/neuroml2) in the XML Schema Deﬁnition (XSD) format, a recom-"},{"url":"https://www.w3.org/TR/xmlschema-1/","unsafeUrl":"https://www.w3.org/TR/xmlschema-1/","text":"(https://www.w3.org/TR/xmlschema-1/). "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                            Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    28 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.971,"layout":[{"image":"page_28_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.359,"w":0.669,"h":0.178},"isLikelyNoise":false},{"image":"page_28_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.133},"isLikelyNoise":false},{"image":"page_28_text_3_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.203,"w":0.669,"h":0.118},"isLikelyNoise":false},{"image":"page_28_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.822,"w":0.668,"h":0.088},"isLikelyNoise":false},{"image":"page_28_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.589,"w":0.669,"h":0.073},"isLikelyNoise":false},{"image":"page_28_text_6_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.665,"w":0.669,"h":0.042},"isLikelyNoise":false},{"image":"page_28_text_7_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.27,"y":0.745,"w":0.669,"h":0.026},"isLikelyNoise":false},{"image":"page_28_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.34,"w":0.334,"h":0.012},"isLikelyNoise":false},{"image":"page_28_paragraph_title_2_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.569,"w":0.252,"h":0.014},"isLikelyNoise":false},{"image":"page_28_paragraph_title_3_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.27,"y":0.726,"w":0.257,"h":0.013},"isLikelyNoise":false},{"image":"page_28_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_28_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_28_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_28_paragraph_title_4_v2.jpg","confidence":0.81,"label":"paragraph_title","bbox":{"x":0.291,"y":0.798,"w":0.347,"h":0.011},"isLikelyNoise":false},{"image":"page_28_paragraph_title_5_v2.jpg","confidence":0.79,"label":"paragraph_title","bbox":{"x":0.291,"y":0.784,"w":0.216,"h":0.01},"isLikelyNoise":false},{"image":"page_28_header_2_v2.jpg","confidence":0.68,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_28_header_3_v2.jpg","confidence":0.5,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":29,"text":"Tools  and  resources                                                                                        Neuroscience\n\n                          a. NeuroML model description serialization\n\n                          <neuroml xmlns=\"http://www.neuroml.org/schema/neuroml2\"\n                                xmlns:xs=\"http://www.w3.org/2001/ΧMLSchema\"\n                                xmlns:xsi=\"http://www.w3.org/2001/ΧMLSchema–instance\"\n                                xsi:schemaLocation=\"http://www.neuroml.org/schema/neuroml2\n                                https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2.3.xsd\"\n                                id=\"ΗindmarshRoseNeuron\">\n\n                                <hindmarshRose1984Cell id=\"hr_regular_bursting\" C=\"28.57142857pF\" a=\"1.0\" b=\"3.0\"\n                                   c=\"–3.0\" d=\"5.0\" s=\"4.0\" x1=\"–1.3\" r=\"0.002\" x0=\"–1.1\" y0=\"–9\" z0=\"1.0\"\n                                   v_scaling=\"1.0mV\"/>\n\n                                <pulseGenerator id=\"pulseGen_0\" delay=\"0s\" duration=\"1000s\" amplitude=\"5nΑ\"/>\n\n                                <network id=\"ΗRNet\">\n                                   <population id=\"ΗRPop0\" component=\"hr_regular_bursting\" size=\"1\"/>\n                                   <explicitΙnput target=\"ΗRPop0[0]\" input=\"pulseGen_0\" destination=\"synapses\"/>\n                                </network>\n                          </neuroml>\n\n                          b.                         0.06\n                                                  20 0.04\n                                                     0.02\n\n                                                     0.00\n\n                                                       -0.02\n\n                                                       -0.04\n\n                                                       -0.060.00 0.25 0.50 0.75  1.00 1.25\n                                                                           time (s)\n\n                         Figure 11. Example model description of a HindmarshRose1984Cell NeuroML component. (a) XML serialization of\n                         the model description containing the main hindmarshRose1984Cell element with a set of parameters which result\n                         in regular bursting. A current clamp stimulus is applied using a pulseGenerator, and a population of one cell is\n                         added with this in a network. This XML can be validated against the NeuroML Schema. (b) Membrane potentials\n                         generated from a simulation of the model in (a). The LEMS simulation file to execute this is shown in Figure 15.\n                         The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/\n                         master/NeuroML2/examples.\n\n\n\nThe basic building blocks of an XSD schema are ‘simple’ or ‘complex’ types and their ‘attributes.’\nAll types are created as ‘extensions’ or ‘restrictions’ of other types. Complex types may contain other\ntypes and attributes whereas simple types may not. Figure 12 shows some example types deﬁned\nin the NeuroMLv2 schema. For example, the Nml2Quantity_none simple type restricts the in- built\n‘string’ type using a regular expression ‘pattern’ that limits what string values it can contain. The type\nis Nml2Quantity_none is to be used for unit-less quantities (e.g. 3, 6.7, –1.1e-5) and the restriction\npattern for translates to ‘a string that may start with a hyphen (negative sign), followed by any number\nof numerical characters (potentially containing a decimal point) and a string containing capital or\nsmall ‘e’ (to specify the exponent).’ The restriction pattern for the Nml2Quantity_voltage  type is\nsimilar, but must be followed by a ‘V’ or ‘mV.’ In this way, the restriction ensures that a value of type\n‘Nml2Quantity_voltage’ represents a physical voltage quantity with units ‘V’ (volt) or ‘mV’ (millivolt).\nFurthermore, a NeuroMLv2 model description that uses a voltage value that does not match this\npattern, for example ‘0.5 s,’ will be invalid.\nThe example of a complex type in Figure 12 is the HindmarshRose1984Cell type that extends\nthe BaseCellMembPotCap complex type (the base type for any cell producing a membrane potential\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    29 of 44","md":"\n\neLife Tools and resources                                                                                        Neuroscience\n\n**a. NeuroML model description serialization**\n\n```xml\n<neuroml xmlns=\"http://www.neuroml.org/schema/neuroml2\"\n      xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.neuroml.org/schema/neuroml2\n      https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2.3.xsd\"\n      id=\"HindmarshRoseNeuron\">\n\n      <hindmarshRose1984Cell id=\"hr_regular_bursting\" C=\"28.57142857pF\" a=\"1.0\" b=\"3.0\"\n         c=\"-3.0\" d=\"5.0\" s=\"4.0\" x1=\"-1.3\" r=\"0.002\" x0=\"-1.1\" y0=\"-9\" z0=\"1.0\"\n         v_scaling=\"1.0mV\"/>\n\n      <pulseGenerator id=\"pulseGen_0\" delay=\"0s\" duration=\"1000s\" amplitude=\"5nA\"/>\n\n      <network id=\"HRNet\">\n         <population id=\"HRPop0\" component=\"hr_regular_bursting\" size=\"1\"/>\n         <explicitInput target=\"HRPop0[0]\" input=\"pulseGen_0\" destination=\"synapses\"/>\n      </network>\n</neuroml>\n```\n\n**b.**\n\n<table>\n<thead>\n<tr>\n<th>time (s)</th>\n<th>membrane potential (V)</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>0.00</td><td>-0.06</td></tr>\n<tr><td>0.05</td><td>-0.04</td></tr>\n<tr><td>0.10</td><td>-0.02</td></tr>\n<tr><td>0.15</td><td>0.00</td></tr>\n<tr><td>0.20</td><td>0.02</td></tr>\n<tr><td>0.22</td><td>0.04</td></tr>\n<tr><td>0.24</td><td>0.06</td></tr>\n<tr><td>0.25</td><td>0.04</td></tr>\n<tr><td>0.26</td><td>0.02</td></tr>\n<tr><td>0.28</td><td>0.00</td></tr>\n<tr><td>0.30</td><td>-0.02</td></tr>\n<tr><td>0.35</td><td>-0.04</td></tr>\n<tr><td>0.45</td><td>-0.02</td></tr>\n<tr><td>0.47</td><td>0.00</td></tr>\n<tr><td>0.49</td><td>0.02</td></tr>\n<tr><td>0.50</td><td>0.04</td></tr>\n<tr><td>0.51</td><td>0.06</td></tr>\n<tr><td>0.52</td><td>0.04</td></tr>\n<tr><td>0.53</td><td>0.02</td></tr>\n<tr><td>0.55</td><td>0.00</td></tr>\n<tr><td>0.57</td><td>-0.02</td></tr>\n<tr><td>0.62</td><td>-0.04</td></tr>\n<tr><td>0.72</td><td>-0.02</td></tr>\n<tr><td>0.74</td><td>0.00</td></tr>\n<tr><td>0.76</td><td>0.02</td></tr>\n<tr><td>0.77</td><td>0.04</td></tr>\n<tr><td>0.78</td><td>0.06</td></tr>\n<tr><td>0.79</td><td>0.04</td></tr>\n<tr><td>0.80</td><td>0.02</td></tr>\n<tr><td>0.82</td><td>0.00</td></tr>\n<tr><td>0.84</td><td>-0.02</td></tr>\n<tr><td>0.89</td><td>-0.04</td></tr>\n<tr><td>0.99</td><td>-0.02</td></tr>\n<tr><td>1.01</td><td>0.00</td></tr>\n<tr><td>1.03</td><td>0.02</td></tr>\n<tr><td>1.04</td><td>0.04</td></tr>\n<tr><td>1.05</td><td>0.06</td></tr>\n<tr><td>1.06</td><td>0.04</td></tr>\n<tr><td>1.07</td><td>0.02</td></tr>\n<tr><td>1.09</td><td>0.00</td></tr>\n<tr><td>1.11</td><td>-0.02</td></tr>\n<tr><td>1.16</td><td>-0.04</td></tr>\n<tr><td>1.25</td><td>-0.06</td></tr>\n</tbody>\n</table>\n\n**Figure 11.** Example model description of a HindmarshRose1984Cell NeuroML component. **(a)** XML serialization of the model description containing the main hindmarshRose1984Cell element with a set of parameters which result in regular bursting. A current clamp stimulus is applied using a pulseGenerator, and a population of one cell is added with this in a network. This XML can be validated against the NeuroML Schema. **(b)** Membrane potentials generated from a simulation of the model in (a). The LEMS simulation file to execute this is shown in **Figure 15**. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.\n\nThe basic building blocks of an XSD schema are 'simple' or 'complex' types and their 'attributes.' All types are created as 'extensions' or 'restrictions' of other types. Complex types may contain other types and attributes whereas simple types may not. **Figure 12** shows some example types defined in the NeuroMLv2 schema. For example, the Nml2Quantity_none simple type restricts the in-built 'string' type using a regular expression 'pattern' that limits what string values it can contain. The type is Nml2Quantity_none is to be used for unit-less quantities (e.g. 3, 6.7, –1.1e-5) and the restriction pattern for translates to 'a string that may start with a hyphen (negative sign), followed by any number of numerical characters (potentially containing a decimal point) and a string containing capital or small 'e' (to specify the exponent).' The restriction pattern for the Nml2Quantity_voltage type is similar, but must be followed by a 'V' or 'mV.' In this way, the restriction ensures that a value of type 'Nml2Quantity_voltage' represents a physical voltage quantity with units 'V' (volt) or 'mV' (millivolt). Furthermore, a NeuroMLv2 model description that uses a voltage value that does not match this pattern, for example '0.5 s,' will be invalid.\n\nThe example of a complex type in **Figure 12** is the HindmarshRose1984Cell type that extends the BaseCellMembPotCap complex type (the base type for any cell producing a membrane potential\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    29 of 44\n","images":[{"name":"img_p28_1.png","height":149.424,"width":199.104,"x":273.519,"y":275.171,"original_width":612,"original_height":459,"rotation":0,"ocr":[{"x":308,"y":428,"w":94,"h":31,"confidence":0.999,"text":"time (s)"},{"x":503,"y":407,"w":53,"h":22,"confidence":1,"text":"1.25"},{"x":425,"y":407,"w":52,"h":23,"confidence":1,"text":"1.00"},{"x":344,"y":407,"w":53,"h":23,"confidence":1,"text":"0.75"},{"x":265,"y":405,"w":55,"h":26,"confidence":1,"text":"0.50"},{"x":185,"y":405,"w":56,"h":26,"confidence":1,"text":"0.25"},{"x":106,"y":405,"w":55,"h":26,"confidence":1,"text":"0.00"},{"x":32,"y":382,"w":74,"h":26,"confidence":0.997,"text":"-0.06"},{"x":31,"y":325,"w":71,"h":22,"confidence":0.997,"text":"-0.04"},{"x":32,"y":267,"w":72,"h":26,"confidence":0.995,"text":"-0.02"},{"x":50,"y":210,"w":56,"h":26,"confidence":1,"text":"0.00"},{"x":51,"y":154,"w":53,"h":23,"confidence":1,"text":"0.02"},{"x":51,"y":96,"w":53,"h":24,"confidence":1,"text":"0.04"},{"x":4,"y":79,"w":24,"h":269,"confidence":0.391,"text":"20"},{"x":50,"y":38,"w":56,"h":27,"confidence":1,"text":"0.06"}]},{"name":"page_29.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_29_text_1_v2.jpg","height":122220.155,"width":250430.795,"x":101127.167,"y":429667.215,"original_width":1654,"original_height":624,"rotation":0,"type":"layout_v2_text"},{"name":"page_29_figure_title_1_v2.jpg","height":59259.198,"width":248826.563,"x":101355.265,"y":345554.307,"original_width":1643,"original_height":303,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_29_text_2_v2.jpg","height":17532.185,"width":250251.363,"x":101351.4,"y":553655,"original_width":1653,"original_height":90,"rotation":0,"type":"layout_v2_text"},{"name":"page_29_footer_1_v2.jpg","height":7051.897,"width":191861.592,"x":21531.906,"y":591393.712,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_29_header_1_v2.jpg","height":5707.659,"width":30302.321,"x":320716.135,"y":27658.455,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_29_number_1_v2.jpg","height":6019.382,"width":18200.763,"x":332926.845,"y":591721.457,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_29_chart_1_v2.jpg","height":113379.555,"width":119559.064,"x":167138.328,"y":223227.517,"original_width":790,"original_height":579,"rotation":0,"type":"layout_v2_chart"},{"name":"page_29_header_2_v2.jpg","height":5738.085,"width":42856.831,"x":47739.37,"y":27856.059,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_29_header_3_v2.jpg","height":10755.941,"width":24420.265,"x":21842.8,"y":22384.449,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_29_paragraph_title_1_v2.jpg","height":8334.254,"width":111796.952,"x":105497.906,"y":46858.296,"original_width":739,"original_height":43,"rotation":0,"type":"layout_v2_paragraph_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                        Neuroscience","md":"eLife Tools and resources                                                                                        Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":113,"endIndex":125}]},{"type":"text","value":"**a. NeuroML model description serialization**","md":"**a. NeuroML model description serialization**","bBox":{"x":174.65,"y":58.84,"w":180.36,"h":8.97},"layoutAwareBbox":[{"x":172,"y":59,"w":182,"h":10,"startIndex":5,"endIndex":12}]},{"type":"text","value":"```xml\n<neuroml xmlns=\"http://www.neuroml.org/schema/neuroml2\"\n      xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.neuroml.org/schema/neuroml2\n      https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2.3.xsd\"\n      id=\"HindmarshRoseNeuron\">","md":"```xml\n<neuroml xmlns=\"http://www.neuroml.org/schema/neuroml2\"\n      xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.neuroml.org/schema/neuroml2\n      https://raw.github.com/NeuroML/NeuroML2/development/Schemas/NeuroML2/NeuroML_v2.3.xsd\"\n      id=\"HindmarshRoseNeuron\">","bBox":{"x":174.65,"y":79.47,"w":380.9,"h":308.99},"layoutAwareBbox":[{"x":174.65,"y":79.47,"w":380.9,"h":308.99,"startIndex":0,"endIndex":361}]},{"type":"text","value":"<hindmarshRose1984Cell id=\"hr_regular_bursting\" C=\"28.57142857pF\" a=\"1.0\" b=\"3.0\"\n         c=\"-3.0\" d=\"5.0\" s=\"4.0\" x1=\"-1.3\" r=\"0.002\" x0=\"-1.1\" y0=\"-9\" z0=\"1.0\"\n         v_scaling=\"1.0mV\"/>","md":"<hindmarshRose1984Cell id=\"hr_regular_bursting\" C=\"28.57142857pF\" a=\"1.0\" b=\"3.0\"\n         c=\"-3.0\" d=\"5.0\" s=\"4.0\" x1=\"-1.3\" r=\"0.002\" x0=\"-1.1\" y0=\"-9\" z0=\"1.0\"\n         v_scaling=\"1.0mV\"/>","bBox":{"x":191.59,"y":154.78,"w":341.85,"h":197.22},"layoutAwareBbox":[{"x":191.59,"y":154.78,"w":341.85,"h":197.22,"startIndex":0,"endIndex":190}]},{"type":"text","value":"<pulseGenerator id=\"pulseGen_0\" delay=\"0s\" duration=\"1000s\" amplitude=\"5nA\"/>","md":"<pulseGenerator id=\"pulseGen_0\" delay=\"0s\" duration=\"1000s\" amplitude=\"5nA\"/>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":76}]},{"type":"text","value":"<network id=\"HRNet\">\n         <population id=\"HRPop0\" component=\"hr_regular_bursting\" size=\"1\"/>\n         <explicitInput target=\"HRPop0[0]\" input=\"pulseGen_0\" destination=\"synapses\"/>\n      </network>\n</neuroml>\n```","md":"<network id=\"HRNet\">\n         <population id=\"HRPop0\" component=\"hr_regular_bursting\" size=\"1\"/>\n         <explicitInput target=\"HRPop0[0]\" input=\"pulseGen_0\" destination=\"synapses\"/>\n      </network>\n</neuroml>\n```","bBox":{"x":174.67,"y":219.34,"w":79.9,"h":51.01},"layoutAwareBbox":[{"x":174.67,"y":219.34,"w":79.9,"h":51.01,"startIndex":0,"endIndex":214}]},{"type":"text","value":"**b.**","md":"**b.**","bBox":{"x":174.65,"y":284.68,"w":8.23,"h":8.97},"layoutAwareBbox":[{"x":165,"y":542,"w":409,"h":154,"startIndex":0,"endIndex":5}]},{"type":"table","rows":[["time (s)","membrane potential (V)"],["0.00","-0.06"],["0.05","-0.04"],["0.10","-0.02"],["0.15","0.00"],["0.20","0.02"],["0.22","0.04"],["0.24","0.06"],["0.25","0.04"],["0.26","0.02"],["0.28","0.00"],["0.30","-0.02"],["0.35","-0.04"],["0.45","-0.02"],["0.47","0.00"],["0.49","0.02"],["0.50","0.04"],["0.51","0.06"],["0.52","0.04"],["0.53","0.02"],["0.55","0.00"],["0.57","-0.02"],["0.62","-0.04"],["0.72","-0.02"],["0.74","0.00"],["0.76","0.02"],["0.77","0.04"],["0.78","0.06"],["0.79","0.04"],["0.80","0.02"],["0.82","0.00"],["0.84","-0.02"],["0.89","-0.04"],["0.99","-0.02"],["1.01","0.00"],["1.03","0.02"],["1.04","0.04"],["1.05","0.06"],["1.06","0.04"],["1.07","0.02"],["1.09","0.00"],["1.11","-0.02"],["1.16","-0.04"],["1.25","-0.06"]],"html":"<table>\n<thead>\n<tr>\n<th>time (s)</th>\n<th>membrane potential (V)</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>0.00</td><td>-0.06</td></tr>\n<tr><td>0.05</td><td>-0.04</td></tr>\n<tr><td>0.10</td><td>-0.02</td></tr>\n<tr><td>0.15</td><td>0.00</td></tr>\n<tr><td>0.20</td><td>0.02</td></tr>\n<tr><td>0.22</td><td>0.04</td></tr>\n<tr><td>0.24</td><td>0.06</td></tr>\n<tr><td>0.25</td><td>0.04</td></tr>\n<tr><td>0.26</td><td>0.02</td></tr>\n<tr><td>0.28</td><td>0.00</td></tr>\n<tr><td>0.30</td><td>-0.02</td></tr>\n<tr><td>0.35</td><td>-0.04</td></tr>\n<tr><td>0.45</td><td>-0.02</td></tr>\n<tr><td>0.47</td><td>0.00</td></tr>\n<tr><td>0.49</td><td>0.02</td></tr>\n<tr><td>0.50</td><td>0.04</td></tr>\n<tr><td>0.51</td><td>0.06</td></tr>\n<tr><td>0.52</td><td>0.04</td></tr>\n<tr><td>0.53</td><td>0.02</td></tr>\n<tr><td>0.55</td><td>0.00</td></tr>\n<tr><td>0.57</td><td>-0.02</td></tr>\n<tr><td>0.62</td><td>-0.04</td></tr>\n<tr><td>0.72</td><td>-0.02</td></tr>\n<tr><td>0.74</td><td>0.00</td></tr>\n<tr><td>0.76</td><td>0.02</td></tr>\n<tr><td>0.77</td><td>0.04</td></tr>\n<tr><td>0.78</td><td>0.06</td></tr>\n<tr><td>0.79</td><td>0.04</td></tr>\n<tr><td>0.80</td><td>0.02</td></tr>\n<tr><td>0.82</td><td>0.00</td></tr>\n<tr><td>0.84</td><td>-0.02</td></tr>\n<tr><td>0.89</td><td>-0.04</td></tr>\n<tr><td>0.99</td><td>-0.02</td></tr>\n<tr><td>1.01</td><td>0.00</td></tr>\n<tr><td>1.03</td><td>0.02</td></tr>\n<tr><td>1.04</td><td>0.04</td></tr>\n<tr><td>1.05</td><td>0.06</td></tr>\n<tr><td>1.06</td><td>0.04</td></tr>\n<tr><td>1.07</td><td>0.02</td></tr>\n<tr><td>1.09</td><td>0.00</td></tr>\n<tr><td>1.11</td><td>-0.02</td></tr>\n<tr><td>1.16</td><td>-0.04</td></tr>\n<tr><td>1.25</td><td>-0.06</td></tr>\n</tbody>\n</table>","md":"| time (s) | membrane potential (V) |\n| -------- | ---------------------- |\n| 0.00     | -0.06                  |\n| 0.05     | -0.04                  |\n| 0.10     | -0.02                  |\n| 0.15     | 0.00                   |\n| 0.20     | 0.02                   |\n| 0.22     | 0.04                   |\n| 0.24     | 0.06                   |\n| 0.25     | 0.04                   |\n| 0.26     | 0.02                   |\n| 0.28     | 0.00                   |\n| 0.30     | -0.02                  |\n| 0.35     | -0.04                  |\n| 0.45     | -0.02                  |\n| 0.47     | 0.00                   |\n| 0.49     | 0.02                   |\n| 0.50     | 0.04                   |\n| 0.51     | 0.06                   |\n| 0.52     | 0.04                   |\n| 0.53     | 0.02                   |\n| 0.55     | 0.00                   |\n| 0.57     | -0.02                  |\n| 0.62     | -0.04                  |\n| 0.72     | -0.02                  |\n| 0.74     | 0.00                   |\n| 0.76     | 0.02                   |\n| 0.77     | 0.04                   |\n| 0.78     | 0.06                   |\n| 0.79     | 0.04                   |\n| 0.80     | 0.02                   |\n| 0.82     | 0.00                   |\n| 0.84     | -0.02                  |\n| 0.89     | -0.04                  |\n| 0.99     | -0.02                  |\n| 1.01     | 0.00                   |\n| 1.03     | 0.02                   |\n| 1.04     | 0.04                   |\n| 1.05     | 0.06                   |\n| 1.06     | 0.04                   |\n| 1.07     | 0.02                   |\n| 1.09     | 0.00                   |\n| 1.11     | -0.02                  |\n| 1.16     | -0.04                  |\n| 1.25     | -0.06                  |","isPerfectTable":true,"csv":"\"time (s)\",\"membrane potential (V)\"\n\"0.00\",\"-0.06\"\n\"0.05\",\"-0.04\"\n\"0.10\",\"-0.02\"\n\"0.15\",\"0.00\"\n\"0.20\",\"0.02\"\n\"0.22\",\"0.04\"\n\"0.24\",\"0.06\"\n\"0.25\",\"0.04\"\n\"0.26\",\"0.02\"\n\"0.28\",\"0.00\"\n\"0.30\",\"-0.02\"\n\"0.35\",\"-0.04\"\n\"0.45\",\"-0.02\"\n\"0.47\",\"0.00\"\n\"0.49\",\"0.02\"\n\"0.50\",\"0.04\"\n\"0.51\",\"0.06\"\n\"0.52\",\"0.04\"\n\"0.53\",\"0.02\"\n\"0.55\",\"0.00\"\n\"0.57\",\"-0.02\"\n\"0.62\",\"-0.04\"\n\"0.72\",\"-0.02\"\n\"0.74\",\"0.00\"\n\"0.76\",\"0.02\"\n\"0.77\",\"0.04\"\n\"0.78\",\"0.06\"\n\"0.79\",\"0.04\"\n\"0.80\",\"0.02\"\n\"0.82\",\"0.00\"\n\"0.84\",\"-0.02\"\n\"0.89\",\"-0.04\"\n\"0.99\",\"-0.02\"\n\"1.01\",\"0.00\"\n\"1.03\",\"0.02\"\n\"1.04\",\"0.04\"\n\"1.05\",\"0.06\"\n\"1.06\",\"0.04\"\n\"1.07\",\"0.02\"\n\"1.09\",\"0.00\"\n\"1.11\",\"-0.02\"\n\"1.16\",\"-0.04\"\n\"1.25\",\"-0.06\"","bBox":{"x":208.52,"y":165.54,"w":300.63,"h":259.05},"layoutAwareBbox":[{"x":208.52,"y":165.54,"w":300.63,"h":259.05,"startIndex":0,"endIndex":1708}]},{"type":"text","value":"**Figure 11.** Example model description of a HindmarshRose1984Cell NeuroML component. **(a)** XML serialization of the model description containing the main hindmarshRose1984Cell element with a set of parameters which result in regular bursting. A current clamp stimulus is applied using a pulseGenerator, and a population of one cell is added with this in a network. This XML can be validated against the NeuroML Schema. **(b)** Membrane potentials generated from a simulation of the model in (a). The LEMS simulation file to execute this is shown in **Figure 15**. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","md":"**Figure 11.** Example model description of a HindmarshRose1984Cell NeuroML component. **(a)** XML serialization of the model description containing the main hindmarshRose1984Cell element with a set of parameters which result in regular bursting. A current clamp stimulus is applied using a pulseGenerator, and a population of one cell is added with this in a network. This XML can be validated against the NeuroML Schema. **(b)** Membrane potentials generated from a simulation of the model in (a). The LEMS simulation file to execute this is shown in **Figure 15**. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","bBox":{"x":168.53,"y":447.35,"w":402.57,"h":63},"layoutAwareBbox":[{"x":165,"y":436,"w":406,"h":74,"startIndex":675,"endIndex":699}]},{"type":"text","value":"The basic building blocks of an XSD schema are 'simple' or 'complex' types and their 'attributes.' All types are created as 'extensions' or 'restrictions' of other types. Complex types may contain other types and attributes whereas simple types may not. **Figure 12** shows some example types defined in the NeuroMLv2 schema. For example, the Nml2Quantity_none simple type restricts the in-built 'string' type using a regular expression 'pattern' that limits what string values it can contain. The type is Nml2Quantity_none is to be used for unit-less quantities (e.g. 3, 6.7, –1.1e-5) and the restriction pattern for translates to 'a string that may start with a hyphen (negative sign), followed by any number of numerical characters (potentially containing a decimal point) and a string containing capital or small 'e' (to specify the exponent).' The restriction pattern for the Nml2Quantity_voltage type is similar, but must be followed by a 'V' or 'mV.' In this way, the restriction ensures that a value of type 'Nml2Quantity_voltage' represents a physical voltage quantity with units 'V' (volt) or 'mV' (millivolt). Furthermore, a NeuroMLv2 model description that uses a voltage value that does not match this pattern, for example '0.5 s,' will be invalid.","md":"The basic building blocks of an XSD schema are 'simple' or 'complex' types and their 'attributes.' All types are created as 'extensions' or 'restrictions' of other types. Complex types may contain other types and attributes whereas simple types may not. **Figure 12** shows some example types defined in the NeuroMLv2 schema. For example, the Nml2Quantity_none simple type restricts the in-built 'string' type using a regular expression 'pattern' that limits what string values it can contain. The type is Nml2Quantity_none is to be used for unit-less quantities (e.g. 3, 6.7, –1.1e-5) and the restriction pattern for translates to 'a string that may start with a hyphen (negative sign), followed by any number of numerical characters (potentially containing a decimal point) and a string containing capital or small 'e' (to specify the exponent).' The restriction pattern for the Nml2Quantity_voltage type is similar, but must be followed by a 'V' or 'mV.' In this way, the restriction ensures that a value of type 'Nml2Quantity_voltage' represents a physical voltage quantity with units 'V' (volt) or 'mV' (millivolt). Furthermore, a NeuroMLv2 model description that uses a voltage value that does not match this pattern, for example '0.5 s,' will be invalid.","bBox":{"x":168.53,"y":578.48,"w":408.98,"h":104.98},"layoutAwareBbox":[{"x":165,"y":542,"w":409,"h":154,"startIndex":0,"endIndex":3}]},{"type":"text","value":"The example of a complex type in **Figure 12** is the HindmarshRose1984Cell type that extends the BaseCellMembPotCap complex type (the base type for any cell producing a membrane potential","md":"The example of a complex type in **Figure 12** is the HindmarshRose1984Cell type that extends the BaseCellMembPotCap complex type (the base type for any cell producing a membrane potential","bBox":{"x":168.53,"y":710.45,"w":415.05,"h":9},"layoutAwareBbox":[{"x":165,"y":699,"w":408,"h":22,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    29 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    29 of 44","bBox":{"x":274.82,"y":300.89,"w":300.17,"h":453.87},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","text":"The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","text":"master/NeuroML2/examples."}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                        Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    29 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.909,"layout":[{"image":"page_29_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.685,"w":0.669,"h":0.195},"isLikelyNoise":false},{"image":"page_29_figure_title_1_v2.jpg","confidence":0.96,"label":"figure_title","bbox":{"x":0.271,"y":0.551,"w":0.664,"h":0.094},"isLikelyNoise":false},{"image":"page_29_text_2_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.271,"y":0.883,"w":0.668,"h":0.028},"isLikelyNoise":false},{"image":"page_29_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_29_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_29_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_29_chart_1_v2.jpg","confidence":0.81,"label":"chart","bbox":{"x":0.446,"y":0.356,"w":0.319,"h":0.181},"isLikelyNoise":false},{"image":"page_29_header_2_v2.jpg","confidence":0.72,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_29_header_3_v2.jpg","confidence":0.55,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true},{"image":"page_29_paragraph_title_1_v2.jpg","confidence":0.51,"label":"paragraph_title","bbox":{"x":0.282,"y":0.075,"w":0.298,"h":0.013},"isLikelyNoise":true}]},{"page":30,"text":"Tools  and  resources                                                                                        Neuroscience\n\n                          <xs:simpleType name=\"Nml2Quantity_none\"> <!-- For dimensionless parameters -->\n                           <xs:restriction base=\"xs:string\">\n                            <xs:pattern  value=\"–?([0–9]*(\\.[0–9]+)?)([eΕ]–?[0–9]+)?\"/>\n                           </xs:restriction>\n                          </xs:simpleType>\n\n                          <xs:simpleType name=\"Nml2Quantity_voltage\"> <!-- For params with dimension voltage -->\n                           <xs:restriction base=\"xs:string\">\n                            <xs:pattern  value=\"–?([0–9]*(\\.[0–9]+)?)([eΕ]–?[0–9]+)?[\\s]*(V|mV)\"/>\n                           </xs:restriction>\n                          </xs:simpleType>\n\n                          <xs:complexType name=\"ΗindmarshRose1984Cell\">\n                           <xs:annotation>\n                            <xs:documentation>The Ηindmarsh Rose model is a simpliƒied point cell model which\n                              captures complex ƒiring patterns oƒ single neurons, such as\n                              periodic and chaotic bursting...\n                            </xs:documentation>\n                           </xs:annotation>\n                           <xs:complexContent>\n                            <xs:extension base=\"ΒaseCellMembPotCap\">\n                             <xs:attribute name=\"a\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"b\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"c\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"d\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"s\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"x1\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"r\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"x0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"y0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"z0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n                             <xs:attribute name=\"v_scaling\" type=\"Nml2Quantity_voltage\" use=\"required\"/>\n                            </xs:extension>\n                           </xs:complexContent>\n                          </xs:complexType>\n\n                         Figure 12. Type definitions taken from the NeuroMLv2 schema (https://github.com/NeuroML/NeuroML2/\n                         blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd) which describes the structure of NeuroMLv2 elements.\n                         Top: ‘simple’ types may not include other elements or attributes. Here, the Nml2Quantity_none and\n                         Nml2Quantity_voltage types define restrictions on the default string type to limit what strings can be used\n                         as valid values for attributes of these types. Bottom: example of a ‘complex’ type, the HindmarshRose cell model\n                         (Hindmarsh and Rose, 1984), that can also include other elements of other types, and extend other types.\n\n\n\nv with a capacitance parameter C), and deﬁnes new ‘required’ (compulsory) attributes. These attri-\nbutes are of simple types—these are all unit-less quantities apart from v_scaling, which has dimen-\nsion voltage. Note that inherited attributes are not re-  listed in the complex type deﬁnition—the\ncompulsory capacitance attribute, C, is inherited here from BaseCellMembPotCap.\nThe NeuroMLv2 schema serves multiple critical functions. A variety of tools and libraries support\nthe validation of ﬁles against XSD schema deﬁnitions. Therefore, the NeuroMLv2 schema enables\nthe validation of model descriptions—model structure, parameters, parameter values and their units,\ncardinality, element positioning in the model hierarchy (level 1 validation in Figure 7)—prior to simu‐\nlation. XSD schema deﬁnitions, as language independent data models, also allow the generation of\nAPIs in different languages. More information on how APIs in different languages are generated using\nthe NeuroMLv2 XSD schema deﬁnition is provided in later sections.\nThe NeuroMLv2 XSD schema is also released and maintained as a versioned artifact, similar to\nthe software packages. The current version is 2.3, and can be found in the NeuroML2 repository on\nGitHub (https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2).\n\nLEMS ComponentType definitions\nThe second part of the NeuroMLv2 standard consists of the corresponding LEMS ComponentType\ndeﬁnitions. Whereas the XSD Schema describes the\n                              structure of a NeuroMLv2 model description, the\nLEMS ComponentType deﬁnitions formally describe the dynamics of the model elements.\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    30 of 44","md":"\n\neLife Tools and resources                                                                                        Neuroscience\n\n```xml\n<xs:simpleType name=\"Nml2Quantity_none\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?\"/>\n </xs:restriction>\n</xs:simpleType>\n\n<xs:simpleType name=\"Nml2Quantity_voltage\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?[\\s]*(V|mV)\"/>\n </xs:restriction>\n</xs:simpleType>\n\n<xs:complexType name=\"HindmarshRose1984Cell\">\n <xs:annotation>\n  <xs:documentation>The Hindmarsh Rose model is a simplified point cell model which\n    captures complex firing patterns of single neurons, such as\n    periodic and chaotic bursting...\n  </xs:documentation>\n </xs:annotation>\n <xs:complexContent>\n  <xs:extension base=\"BaseCellMembPotCap\">\n   <xs:attribute name=\"a\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"b\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"c\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"d\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"s\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x1\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"r\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"y0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"z0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"v_scaling\" type=\"Nml2Quantity_voltage\" use=\"required\"/>\n  </xs:extension>\n </xs:complexContent>\n</xs:complexType>\n```\n\n**Figure 12.** Type definitions taken from the NeuroMLv2 schema (https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd) which describes the structure of NeuroMLv2 elements. Top: 'simple' types may not include other elements or attributes. Here, the Nml2Quantity_none and Nml2Quantity_voltage types define restrictions on the default string type to limit what strings can be used as valid values for attributes of these types. Bottom: example of a 'complex' type, the HindmarshRose cell model (Hindmarsh and Rose, 1984), that can also include other elements of other types, and extend other types.\n\nv with a capacitance parameter C), and defines new 'required' (compulsory) attributes. These attributes are of simple types—these are all unit-less quantities apart from v_scaling, which has dimension voltage. Note that inherited attributes are not re-listed in the complex type definition—the compulsory capacitance attribute, C, is inherited here from BaseCellMembPotCap.\n\nThe NeuroMLv2 schema serves multiple critical functions. A variety of tools and libraries support the validation of files against XSD schema definitions. Therefore, the NeuroMLv2 schema enables the validation of model descriptions—model structure, parameters, parameter values and their units, cardinality, element positioning in the model hierarchy (level 1 validation in **Figure 7**)—prior to simulation. XSD schema definitions, as language independent data models, also allow the generation of APIs in different languages. More information on how APIs in different languages are generated using the NeuroMLv2 XSD schema definition is provided in later sections.\n\nThe NeuroMLv2 XSD schema is also released and maintained as a versioned artifact, similar to the software packages. The current version is 2.3, and can be found in the NeuroML2 repository on GitHub (https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2).\n\n## LEMS ComponentType definitions\n\nThe second part of the NeuroMLv2 standard consists of the corresponding LEMS ComponentType definitions. Whereas the XSD Schema describes the structure of a NeuroMLv2 model description, the LEMS ComponentType definitions formally describe the *dynamics* of the model elements.\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    30 of 44\n","images":[{"name":"page_30.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_30_text_1_v2.jpg","height":64271.292,"width":250695.543,"x":101050.343,"y":429390.67,"original_width":1656,"original_height":328,"rotation":0,"type":"layout_v2_text"},{"name":"page_30_text_2_v2.jpg","height":36330.562,"width":250377.235,"x":101100.972,"y":391198.858,"original_width":1654,"original_height":186,"rotation":0,"type":"layout_v2_text"},{"name":"page_30_text_3_v2.jpg","height":26239.942,"width":250312.359,"x":101161.714,"y":495811.811,"original_width":1653,"original_height":134,"rotation":0,"type":"layout_v2_text"},{"name":"page_30_text_4_v2.jpg","height":26939.244,"width":250261.107,"x":101102.208,"y":544070.602,"original_width":1653,"original_height":138,"rotation":0,"type":"layout_v2_text"},{"name":"page_30_paragraph_title_1_v2.jpg","height":9019.468,"width":119449.669,"x":101408.764,"y":532439.717,"original_width":789,"original_height":47,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_30_footer_1_v2.jpg","height":6919.898,"width":191874.976,"x":21517.885,"y":591458.771,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_30_header_1_v2.jpg","height":5564.496,"width":30355.253,"x":320788.802,"y":27701.368,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_30_figure_title_1_v2.jpg","height":51228.905,"width":245141.546,"x":101278.181,"y":320780.104,"original_width":1619,"original_height":262,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_30_number_1_v2.jpg","height":5844.512,"width":18233.386,"x":332885.559,"y":591807.882,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_30_header_2_v2.jpg","height":5625.26,"width":43018.435,"x":47723.322,"y":27990.632,"original_width":285,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_30_image_1_v2.jpg","height":272480.451,"width":203158.663,"x":103223.584,"y":42691.481,"original_width":1342,"original_height":1391,"rotation":0,"type":"layout_v2_image"},{"name":"page_30_header_3_v2.jpg","height":10801.194,"width":24467.282,"x":21816.65,"y":22432.517,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                        Neuroscience","md":"eLife Tools and resources                                                                                        Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":113,"endIndex":125}]},{"type":"text","value":"```xml\n<xs:simpleType name=\"Nml2Quantity_none\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?\"/>\n </xs:restriction>\n</xs:simpleType>","md":"```xml\n<xs:simpleType name=\"Nml2Quantity_none\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?\"/>\n </xs:restriction>\n</xs:simpleType>","bBox":{"x":174.65,"y":58.77,"w":147.54,"h":45.23},"layoutAwareBbox":[{"x":168,"y":53,"w":331,"h":344,"startIndex":8,"endIndex":21}]},{"type":"text","value":"<xs:simpleType name=\"Nml2Quantity_voltage\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?[\\s]*(V|mV)\"/>\n </xs:restriction>\n</xs:simpleType>","md":"<xs:simpleType name=\"Nml2Quantity_voltage\"> \n <xs:restriction base=\"xs:string\">\n  <xs:pattern value=\"–?([0–9]*(\\.[0–9]+)?)([eE]–?[0–9]+)?[\\s]*(V|mV)\"/>\n </xs:restriction>\n</xs:simpleType>","bBox":{"x":174.65,"y":58.77,"w":158.66,"h":64.35},"layoutAwareBbox":[{"x":168,"y":53,"w":331,"h":344,"startIndex":1,"endIndex":14}]},{"type":"text","value":"<xs:complexType name=\"HindmarshRose1984Cell\">\n <xs:annotation>\n  <xs:documentation>The Hindmarsh Rose model is a simplified point cell model which\n    captures complex firing patterns of single neurons, such as\n    periodic and chaotic bursting...\n  </xs:documentation>\n </xs:annotation>\n <xs:complexContent>\n  <xs:extension base=\"BaseCellMembPotCap\">\n   <xs:attribute name=\"a\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"b\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"c\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"d\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"s\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x1\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"r\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"y0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"z0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"v_scaling\" type=\"Nml2Quantity_voltage\" use=\"required\"/>\n  </xs:extension>\n </xs:complexContent>\n</xs:complexType>\n```","md":"<xs:complexType name=\"HindmarshRose1984Cell\">\n <xs:annotation>\n  <xs:documentation>The Hindmarsh Rose model is a simplified point cell model which\n    captures complex firing patterns of single neurons, such as\n    periodic and chaotic bursting...\n  </xs:documentation>\n </xs:annotation>\n <xs:complexContent>\n  <xs:extension base=\"BaseCellMembPotCap\">\n   <xs:attribute name=\"a\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"b\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"c\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"d\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"s\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x1\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"r\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"x0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"y0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"z0\" type=\"Nml2Quantity_none\" use=\"required\"/>\n   <xs:attribute name=\"v_scaling\" type=\"Nml2Quantity_voltage\" use=\"required\"/>\n  </xs:extension>\n </xs:complexContent>\n</xs:complexType>\n```","bBox":{"x":174.72,"y":183.08,"w":299.44,"h":207.77},"layoutAwareBbox":[{"x":168,"y":53,"w":331,"h":344,"startIndex":1,"endIndex":15}]},{"type":"text","value":"**Figure 12.** Type definitions taken from the NeuroMLv2 schema (https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd) which describes the structure of NeuroMLv2 elements. Top: 'simple' types may not include other elements or attributes. Here, the Nml2Quantity_none and Nml2Quantity_voltage types define restrictions on the default string type to limit what strings can be used as valid values for attributes of these types. Bottom: example of a 'complex' type, the HindmarshRose cell model (Hindmarsh and Rose, 1984), that can also include other elements of other types, and extend other types.","md":"**Figure 12.** Type definitions taken from the NeuroMLv2 schema (https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd) which describes the structure of NeuroMLv2 elements. Top: 'simple' types may not include other elements or attributes. Here, the Nml2Quantity_none and Nml2Quantity_voltage types define restrictions on the default string type to limit what strings can be used as valid values for attributes of these types. Bottom: example of a 'complex' type, the HindmarshRose cell model (Hindmarsh and Rose, 1984), that can also include other elements of other types, and extend other types.","bBox":{"x":168.53,"y":416.19,"w":392.73,"h":52},"layoutAwareBbox":[{"x":165,"y":405,"w":400,"h":64,"startIndex":279,"endIndex":296}]},{"type":"text","value":"v with a capacitance parameter C), and defines new 'required' (compulsory) attributes. These attributes are of simple types—these are all unit-less quantities apart from v_scaling, which has dimension voltage. Note that inherited attributes are not re-listed in the complex type definition—the compulsory capacitance attribute, C, is inherited here from BaseCellMembPotCap.","md":"v with a capacitance parameter C), and defines new 'required' (compulsory) attributes. These attributes are of simple types—these are all unit-less quantities apart from v_scaling, which has dimension voltage. Note that inherited attributes are not re-listed in the complex type definition—the compulsory capacitance attribute, C, is inherited here from BaseCellMembPotCap.","bBox":{"x":168.53,"y":517.48,"w":338.75,"h":21},"layoutAwareBbox":[{"x":165,"y":493,"w":409,"h":45,"startIndex":52,"endIndex":54}]},{"type":"text","value":"The NeuroMLv2 schema serves multiple critical functions. A variety of tools and libraries support the validation of files against XSD schema definitions. Therefore, the NeuroMLv2 schema enables the validation of model descriptions—model structure, parameters, parameter values and their units, cardinality, element positioning in the model hierarchy (level 1 validation in **Figure 7**)—prior to simulation. XSD schema definitions, as language independent data models, also allow the generation of APIs in different languages. More information on how APIs in different languages are generated using the NeuroMLv2 XSD schema definition is provided in later sections.","md":"The NeuroMLv2 schema serves multiple critical functions. A variety of tools and libraries support the validation of files against XSD schema definitions. Therefore, the NeuroMLv2 schema enables the validation of model descriptions—model structure, parameters, parameter values and their units, cardinality, element positioning in the model hierarchy (level 1 validation in **Figure 7**)—prior to simulation. XSD schema definitions, as language independent data models, also allow the generation of APIs in different languages. More information on how APIs in different languages are generated using the NeuroMLv2 XSD schema definition is provided in later sections.","bBox":{"x":168.53,"y":541.48,"w":413.01,"h":68.99},"layoutAwareBbox":[{"x":165,"y":542,"w":409,"h":81,"startIndex":0,"endIndex":3}]},{"type":"text","value":"The NeuroMLv2 XSD schema is also released and maintained as a versioned artifact, similar to the software packages. The current version is 2.3, and can be found in the NeuroML2 repository on GitHub (https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2).","md":"The NeuroMLv2 XSD schema is also released and maintained as a versioned artifact, similar to the software packages. The current version is 2.3, and can be found in the NeuroML2 repository on GitHub (https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2).","bBox":{"x":168.53,"y":625.46,"w":402.45,"h":32.99},"layoutAwareBbox":[{"x":165,"y":626,"w":409,"h":33,"startIndex":0,"endIndex":264}]},{"type":"heading","lvl":2,"value":"LEMS ComponentType definitions","md":"## LEMS ComponentType definitions","bBox":{"x":168.53,"y":670.49,"w":192.19,"h":12},"layoutAwareBbox":[{"x":165,"y":672,"w":195,"h":11,"startIndex":0,"endIndex":32}]},{"type":"text","value":"The second part of the NeuroMLv2 standard consists of the corresponding LEMS ComponentType definitions. Whereas the XSD Schema describes the structure of a NeuroMLv2 model description, the LEMS ComponentType definitions formally describe the *dynamics* of the model elements.","md":"The second part of the NeuroMLv2 standard consists of the corresponding LEMS ComponentType definitions. Whereas the XSD Schema describes the structure of a NeuroMLv2 model description, the LEMS ComponentType definitions formally describe the *dynamics* of the model elements.","bBox":{"x":168.53,"y":686.49,"w":409.86,"h":21},"layoutAwareBbox":[{"x":165,"y":686,"w":408,"h":34,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    30 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    30 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2","unsafeUrl":"https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2","text":"GitHub (https://github.com/NeuroML/NeuroML2/tree/master/Schemas/NeuroML2)."},{"url":"https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd","unsafeUrl":"https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd","text":"Type definitions taken from the NeuroMLv2 schema (https://github.com/NeuroML/NeuroML2/"},{"url":"https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd","unsafeUrl":"https://github.com/NeuroML/NeuroML2/blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd","text":"blob/master/Schemas/NeuroML2/NeuroML_v2.3.1.xsd) which describes the structure of NeuroMLv2 elements. "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                        Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    30 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.973,"layout":[{"image":"page_30_text_1_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.685,"w":0.669,"h":0.102},"isLikelyNoise":false},{"image":"page_30_text_2_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.624,"w":0.668,"h":0.058},"isLikelyNoise":false},{"image":"page_30_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.79,"w":0.668,"h":0.042},"isLikelyNoise":false},{"image":"page_30_text_4_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.867,"w":0.668,"h":0.043},"isLikelyNoise":false},{"image":"page_30_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.849,"w":0.319,"h":0.014},"isLikelyNoise":false},{"image":"page_30_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.057,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_30_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_30_figure_title_1_v2.jpg","confidence":0.85,"label":"figure_title","bbox":{"x":0.27,"y":0.511,"w":0.655,"h":0.082},"isLikelyNoise":false},{"image":"page_30_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_30_header_2_v2.jpg","confidence":0.67,"label":"header","bbox":{"x":0.127,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_30_image_1_v2.jpg","confidence":0.61,"label":"image","bbox":{"x":0.276,"y":0.068,"w":0.542,"h":0.434},"isLikelyNoise":false},{"image":"page_30_header_3_v2.jpg","confidence":0.5,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":31,"text":"Tools  and  resources                                                                               Neuroscience\n\n                         LEMS (Cannon et al., 2014) is a domain independent general purpose machine-\n                                                                                                                     readable language\n                         for describing models and their simulations. A complete description of LEMS is provided in             Cannon\n                         et al., 2014 and in our documentation (https://docs.neuroml.org/Userdocs/LEMSSchema.html). Here,\n                         we limit ourselves to a short summary necessary for understanding the NeuroMLv2 ComponentType\n                         deﬁnitions.\n                         LEMS allows the deﬁnition of new model types called\n                                                                           ComponentTypes. These are formal descrip-\n                         tions of how a generic model element of that type behaves (the ‘dynamics’), independent of the\n                         speciﬁc set of parameters in any instance. To describe the dynamics, such descriptions must list any\n                         necessary parameters that are required, as well as the time- varying state variables. The dimensions\n                         of these parameters and state variables must be speciﬁed, and any expressions involving them must\n                         be dimensionally consistent. An instance of such a generic model is termed a Component      and can\n                         be instantiated from a ComponentType  by providing the necessary parameters. One can think of\n                         ComponentTypes as user deﬁned data types similar to ‘classes’ in many programming languages and\n                         Components as ‘objects’ of these types with particular sets of parameters. Types in LEMS can also\n                         extend other types, enabling the construction of a hierarchical library of types. In addition, since LEMS\n                         is designed for model simulation, ComponentType  deﬁnitions also include other simulation- related\n                         features such as Exposures, specifying quantities that may be accessed/recorded by users.\n                         For model elements included in the NeuroML standard, there is a one- to-one mapping between\n                         types speciﬁed in the NeuroML XSD schema and LEMS\n                                                                      ComponentTypes, with the same parameters\n                         speciﬁed in each. The addition of new model elements to the NeuroML standard, therefore, requires\n                         the addition of new type deﬁnitions to both the XSD schema and the LEMS deﬁnitions. New user\n                         deﬁned ComponentTypes, nevertheless, can be deﬁned in LEMS and used freely in models, and\n                         these do not need to be added to the standard before use. The only limitation here is that new user\n                         deﬁned ComponentTypes cannot be validated against the NeuroML schema since their type deﬁni-\n                         tions will not be included there.\n                         Figure  13 shows the ComponentType         deﬁnition for the HindmarshRose1984Cell          model\n                         element. Here, the HindmarshRose1984Cell     ComponentType extends baseCellMembPotCap\n                         and inherits its elements. The ComponentType               includes parameters that users must provide when\n                         creating a new instance (component): a, b, c, d, r, v, x1, v_scaling.\n                         Other parameters,        , y0, and         are used to initialize the three state variables of the model,   .\n                                                  x0          z0                                                              x, y, z\n                         x is the proxy for the membrane potential of the cell used in the original formulation of the model\n                         (Hindmarsh and Rose, 1984) and is here scaled by a factor v_scaled to expose a more physiological\n                         value for the membrane potential of the cell in StateVariable        v. A Constant , MSEC, is deﬁned\n                         to hold the value of                   for use in the ComponentType. Next, an Attachment enables the addition\n                                    1 ms\n                         of entities that would provide external inputs to the ComponentType. Here, synapses are Attach-\n                         ments of the type basePointCurrent and provide synaptic current input to this ComponentType.\n                         The Dynamics block lists the mathematical formalism required to simulate the ComponentType .\n                         By default, variables deﬁned in the Dynamics  block are private, i.e., they are not visible outside the\n                         ComponentType. To make these visible to other ComponentTypes         and to allow users to record\n                         them, they must be connected to Exposures. Exposures for this ComponentType include the three\n                         state variables and also the internal derived variables, which while not used by other components,\n                         are useful in inspecting the ComponentType  and its dynamics. An extra exposure, spiking, is added\n                         to allow other NeuroML components access to the spiking state of the cell that will be determined in\n                         the Dynamics block.\n                         StateVariable deﬁnitions are followed by DerivedVariables\n                                                                                              , variables whose values depend\n                         on other variables but are not time derivatives (which are handled separately in TimeDerivative\n                         blocks (below)). The total synaptic current, iSyn, is a summation of all the synaptic currents, i received\n                         by the synapses that may be attached on to this ComponentType. The synapse[*]/i  value of the\n                         select ﬁeld tells LEMS to collect all the  i exposures from any synapses Attachments, and the add\n                         value of the reduce ﬁeld tells LEMS to sum the multiple values. As noted, x is a scaled version of the\n                         membrane potential variable, v. This is followed by the three derived variables, phi, chi, rho where:\n\n                         phi = y − ax3 + bx2                                                                                      (1)\n\n                          chi = c − dx2 − y                                                                                       (2)\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    31 of 44","md":"\n\neLife Tools and resources                                                                               Neuroscience\n\nLEMS (Cannon et al., 2014) is a domain independent general purpose machine-readable language for describing models and their simulations. A complete description of LEMS is provided in Cannon et al., 2014 and in our documentation (https://docs.neuroml.org/Userdocs/LEMSSchema.html). Here, we limit ourselves to a short summary necessary for understanding the NeuroMLv2 `ComponentType` definitions.\n\nLEMS allows the definition of new model types called `ComponentTypes`. These are formal descriptions of how a generic model element of that type behaves (the 'dynamics'), *independent of the specific set of parameters in any instance*. To describe the dynamics, such descriptions must list any necessary parameters that are required, as well as the time-varying state variables. The dimensions of these parameters and state variables must be specified, and any expressions involving them must be dimensionally consistent. An instance of such a generic model is termed a `Component` and can be instantiated from a `ComponentType` by providing the necessary parameters. One can think of `ComponentTypes` as user defined data types similar to 'classes' in many programming languages and Components as 'objects' of these types with particular sets of parameters. Types in LEMS can also extend other types, enabling the construction of a hierarchical library of types. In addition, since LEMS is designed for model simulation, `ComponentType` definitions also include other simulation-related features such as `Exposures`, specifying quantities that may be accessed/recorded by users.\n\nFor model elements included in the NeuroML standard, there is a one-to-one mapping between types specified in the NeuroML XSD schema and LEMS `ComponentTypes`, with the same parameters specified in each. The addition of new model elements to the NeuroML standard, therefore, requires the addition of new type definitions to both the XSD schema and the LEMS definitions. New user defined `ComponentTypes`, nevertheless, can be defined in LEMS and used freely in models, and these do not need to be added to the standard before use. The only limitation here is that new user defined `ComponentTypes` cannot be validated against the NeuroML schema since their type definitions will not be included there.\n\nFigure 13 shows the `ComponentType` definition for the `HindmarshRose1984Cell` model element. Here, the `HindmarshRose1984Cell` `ComponentType` extends `baseCellMembPotCap` and inherits its elements. The `ComponentType` includes parameters that users must provide when creating a new instance (component): a, b, c, d, r, v, x1, v_scaling.\n\nOther parameters, x0, y0, and z0 are used to initialize the three state variables of the model, x, y, z. x is the proxy for the membrane potential of the cell used in the original formulation of the model (Hindmarsh and Rose, 1984) and is here scaled by a factor v_scaled to expose a more physiological value for the membrane potential of the cell in `StateVariable` v. A `Constant`, MSEC, is defined to hold the value of 1 ms for use in the `ComponentType`. Next, an `Attachment` enables the addition of entities that would provide external inputs to the `ComponentType`. Here, synapses are `Attachments` of the type `basePointCurrent` and provide synaptic current input to this `ComponentType`.\n\nThe `Dynamics` block lists the mathematical formalism required to simulate the `ComponentType`. By default, variables defined in the `Dynamics` block are private, i.e., they are not visible outside the `ComponentType`. To make these visible to other `ComponentTypes` and to allow users to record them, they must be connected to `Exposures`. Exposures for this `ComponentType` include the three state variables and also the internal derived variables, which while not used by other components, are useful in inspecting the `ComponentType` and its dynamics. An extra exposure, spiking, is added to allow other NeuroML components access to the spiking state of the cell that will be determined in the `Dynamics` block.\n\n`StateVariable` definitions are followed by `DerivedVariables`, variables whose values depend on other variables but are not time derivatives (which are handled separately in `TimeDerivative` blocks (below)). The total synaptic current, iSyn, is a summation of all the synaptic currents, i received by the synapses that may be attached on to this `ComponentType`. The `synapse[*]/i` value of the select field tells LEMS to collect all the i exposures from any synapses `Attachments`, and the add value of the reduce field tells LEMS to sum the multiple values. As noted, x is a scaled version of the membrane potential variable, v. This is followed by the three derived variables, phi, chi, rho where:\n\n$$phi = y - ax^3 + bx^2$$                                                                                      (1)\n\n$$chi = c - dx^2 - y$$                                                                                       (2)\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    31 of 44\n","images":[{"name":"page_31.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_31_text_1_v2.jpg","height":113020.323,"width":250311.814,"x":101238.91,"y":89498.778,"original_width":1653,"original_height":577,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_2_v2.jpg","height":74103.165,"width":250397.112,"x":101176.496,"y":204670.225,"original_width":1654,"original_height":379,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_3_v2.jpg","height":74029.638,"width":250328.443,"x":101291.282,"y":386905.079,"original_width":1653,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_4_v2.jpg","height":65048.962,"width":250264.318,"x":101231.064,"y":463454.986,"original_width":1653,"original_height":332,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_5_v2.jpg","height":64738.172,"width":250468.998,"x":101203.857,"y":319734.082,"original_width":1654,"original_height":331,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_6_v2.jpg","height":45391.306,"width":250165.722,"x":101152.823,"y":41406.227,"original_width":1652,"original_height":232,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_text_7_v2.jpg","height":36418.967,"width":250168.206,"x":101391.468,"y":281244.673,"original_width":1652,"original_height":186,"rotation":0,"type":"layout_v2_text"},{"name":"page_31_formula_1_v2.jpg","height":8255.735,"width":41986.382,"x":205973.104,"y":560572.742,"original_width":278,"original_height":43,"rotation":0,"type":"layout_v2_formula"},{"name":"page_31_formula_2_v2.jpg","height":9309.636,"width":46770.065,"x":203686.947,"y":541314.13,"original_width":309,"original_height":48,"rotation":0,"type":"layout_v2_formula"},{"name":"page_31_footer_1_v2.jpg","height":7010.674,"width":191781.255,"x":21726.877,"y":591498.484,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_31_formula_number_1_v2.jpg","height":7420.101,"width":6059.6,"x":345291.553,"y":543044.595,"original_width":41,"original_height":38,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_31_header_1_v2.jpg","height":5700.824,"width":30397.494,"x":320706.488,"y":27710.273,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_31_formula_number_2_v2.jpg","height":7182.976,"width":5894.516,"x":345363.387,"y":561794.476,"original_width":39,"original_height":37,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_31_number_1_v2.jpg","height":6121.175,"width":18373.723,"x":332790.704,"y":591769.972,"original_width":122,"original_height":32,"rotation":0,"type":"layout_v2_number"},{"name":"page_31_header_2_v2.jpg","height":5778.267,"width":42879.299,"x":47665.635,"y":27893.577,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_31_header_3_v2.jpg","height":10826.217,"width":24467.888,"x":21815.472,"y":22412.303,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                               Neuroscience","md":"eLife Tools and resources                                                                               Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":104,"endIndex":116}]},{"type":"text","value":"LEMS (Cannon et al., 2014) is a domain independent general purpose machine-readable language for describing models and their simulations. A complete description of LEMS is provided in Cannon et al., 2014 and in our documentation (https://docs.neuroml.org/Userdocs/LEMSSchema.html). Here, we limit ourselves to a short summary necessary for understanding the NeuroMLv2 `ComponentType` definitions.","md":"LEMS (Cannon et al., 2014) is a domain independent general purpose machine-readable language for describing models and their simulations. A complete description of LEMS is provided in Cannon et al., 2014 and in our documentation (https://docs.neuroml.org/Userdocs/LEMSSchema.html). Here, we limit ourselves to a short summary necessary for understanding the NeuroMLv2 `ComponentType` definitions.","bBox":{"x":168.52,"y":51.8,"w":409.41,"h":359.9},"layoutAwareBbox":[{"x":165,"y":52,"w":408,"h":57,"startIndex":0,"endIndex":4}]},{"type":"text","value":"LEMS allows the definition of new model types called `ComponentTypes`. These are formal descriptions of how a generic model element of that type behaves (the 'dynamics'), *independent of the specific set of parameters in any instance*. To describe the dynamics, such descriptions must list any necessary parameters that are required, as well as the time-varying state variables. The dimensions of these parameters and state variables must be specified, and any expressions involving them must be dimensionally consistent. An instance of such a generic model is termed a `Component` and can be instantiated from a `ComponentType` by providing the necessary parameters. One can think of `ComponentTypes` as user defined data types similar to 'classes' in many programming languages and Components as 'objects' of these types with particular sets of parameters. Types in LEMS can also extend other types, enabling the construction of a hierarchical library of types. In addition, since LEMS is designed for model simulation, `ComponentType` definitions also include other simulation-related features such as `Exposures`, specifying quantities that may be accessed/recorded by users.","md":"LEMS allows the definition of new model types called `ComponentTypes`. These are formal descriptions of how a generic model element of that type behaves (the 'dynamics'), *independent of the specific set of parameters in any instance*. To describe the dynamics, such descriptions must list any necessary parameters that are required, as well as the time-varying state variables. The dimensions of these parameters and state variables must be specified, and any expressions involving them must be dimensionally consistent. An instance of such a generic model is termed a `Component` and can be instantiated from a `ComponentType` by providing the necessary parameters. One can think of `ComponentTypes` as user defined data types similar to 'classes' in many programming languages and Components as 'objects' of these types with particular sets of parameters. Types in LEMS can also extend other types, enabling the construction of a hierarchical library of types. In addition, since LEMS is designed for model simulation, `ComponentType` definitions also include other simulation-related features such as `Exposures`, specifying quantities that may be accessed/recorded by users.","bBox":{"x":168.51,"y":148.57,"w":415.22,"h":263.13},"layoutAwareBbox":[{"x":168.51,"y":148.57,"w":415.22,"h":263.13,"startIndex":0,"endIndex":1178}]},{"type":"text","value":"For model elements included in the NeuroML standard, there is a one-to-one mapping between types specified in the NeuroML XSD schema and LEMS `ComponentTypes`, with the same parameters specified in each. The addition of new model elements to the NeuroML standard, therefore, requires the addition of new type definitions to both the XSD schema and the LEMS definitions. New user defined `ComponentTypes`, nevertheless, can be defined in LEMS and used freely in models, and these do not need to be added to the standard before use. The only limitation here is that new user defined `ComponentTypes` cannot be validated against the NeuroML schema since their type definitions will not be included there.","md":"For model elements included in the NeuroML standard, there is a one-to-one mapping between types specified in the NeuroML XSD schema and LEMS `ComponentTypes`, with the same parameters specified in each. The addition of new model elements to the NeuroML standard, therefore, requires the addition of new type definitions to both the XSD schema and the LEMS definitions. New user defined `ComponentTypes`, nevertheless, can be defined in LEMS and used freely in models, and these do not need to be added to the standard before use. The only limitation here is that new user defined `ComponentTypes` cannot be validated against the NeuroML schema since their type definitions will not be included there.","bBox":{"x":168.51,"y":257.44,"w":408.99,"h":154.27},"layoutAwareBbox":[{"x":168.51,"y":257.44,"w":408.99,"h":154.27,"startIndex":0,"endIndex":700}]},{"type":"text","value":"Figure 13 shows the `ComponentType` definition for the `HindmarshRose1984Cell` model element. Here, the `HindmarshRose1984Cell` `ComponentType` extends `baseCellMembPotCap` and inherits its elements. The `ComponentType` includes parameters that users must provide when creating a new instance (component): a, b, c, d, r, v, x1, v_scaling.","md":"Figure 13 shows the `ComponentType` definition for the `HindmarshRose1984Cell` model element. Here, the `HindmarshRose1984Cell` `ComponentType` extends `baseCellMembPotCap` and inherits its elements. The `ComponentType` includes parameters that users must provide when creating a new instance (component): a, b, c, d, r, v, x1, v_scaling.","bBox":{"x":168.5,"y":354.2,"w":409,"h":57.5},"layoutAwareBbox":[{"x":165,"y":355,"w":408,"h":45,"startIndex":0,"endIndex":6}]},{"type":"text","value":"Other parameters, x0, y0, and z0 are used to initialize the three state variables of the model, x, y, z. x is the proxy for the membrane potential of the cell used in the original formulation of the model (Hindmarsh and Rose, 1984) and is here scaled by a factor v_scaled to expose a more physiological value for the membrane potential of the cell in `StateVariable` v. A `Constant`, MSEC, is defined to hold the value of 1 ms for use in the `ComponentType`. Next, an `Attachment` enables the addition of entities that would provide external inputs to the `ComponentType`. Here, synapses are `Attachments` of the type `basePointCurrent` and provide synaptic current input to this `ComponentType`.","md":"Other parameters, x0, y0, and z0 are used to initialize the three state variables of the model, x, y, z. x is the proxy for the membrane potential of the cell used in the original formulation of the model (Hindmarsh and Rose, 1984) and is here scaled by a factor v_scaled to expose a more physiological value for the membrane potential of the cell in `StateVariable` v. A `Constant`, MSEC, is defined to hold the value of 1 ms for use in the `ComponentType`. Next, an `Attachment` enables the addition of entities that would provide external inputs to the `ComponentType`. Here, synapses are `Attachments` of the type `basePointCurrent` and provide synaptic current input to this `ComponentType`.","bBox":{"x":168.52,"y":402.7,"w":408.98,"h":57.41},"layoutAwareBbox":[{"x":165,"y":403,"w":409,"h":81,"startIndex":26,"endIndex":29}]},{"type":"text","value":"The `Dynamics` block lists the mathematical formalism required to simulate the `ComponentType`. By default, variables defined in the `Dynamics` block are private, i.e., they are not visible outside the `ComponentType`. To make these visible to other `ComponentTypes` and to allow users to record them, they must be connected to `Exposures`. Exposures for this `ComponentType` include the three state variables and also the internal derived variables, which while not used by other components, are useful in inspecting the `ComponentType` and its dynamics. An extra exposure, spiking, is added to allow other NeuroML components access to the spiking state of the cell that will be determined in the `Dynamics` block.","md":"The `Dynamics` block lists the mathematical formalism required to simulate the `ComponentType`. By default, variables defined in the `Dynamics` block are private, i.e., they are not visible outside the `ComponentType`. To make these visible to other `ComponentTypes` and to allow users to record them, they must be connected to `Exposures`. Exposures for this `ComponentType` include the three state variables and also the internal derived variables, which while not used by other components, are useful in inspecting the `ComponentType` and its dynamics. An extra exposure, spiking, is added to allow other NeuroML components access to the spiking state of the cell that will be determined in the `Dynamics` block.","bBox":{"x":168.52,"y":402.7,"w":409.72,"h":166.3},"layoutAwareBbox":[{"x":165,"y":488,"w":409,"h":93,"startIndex":0,"endIndex":3}]},{"type":"text","value":"`StateVariable` definitions are followed by `DerivedVariables`, variables whose values depend on other variables but are not time derivatives (which are handled separately in `TimeDerivative` blocks (below)). The total synaptic current, iSyn, is a summation of all the synaptic currents, i received by the synapses that may be attached on to this `ComponentType`. The `synapse[*]/i` value of the select field tells LEMS to collect all the i exposures from any synapses `Attachments`, and the add value of the reduce field tells LEMS to sum the multiple values. As noted, x is a scaled version of the membrane potential variable, v. This is followed by the three derived variables, phi, chi, rho where:","md":"`StateVariable` definitions are followed by `DerivedVariables`, variables whose values depend on other variables but are not time derivatives (which are handled separately in `TimeDerivative` blocks (below)). The total synaptic current, iSyn, is a summation of all the synaptic currents, i received by the synapses that may be attached on to this `ComponentType`. The `synapse[*]/i` value of the select field tells LEMS to collect all the i exposures from any synapses `Attachments`, and the add value of the reduce field tells LEMS to sum the multiple values. As noted, x is a scaled version of the membrane potential variable, v. This is followed by the three derived variables, phi, chi, rho where:","bBox":{"x":168.52,"y":584.19,"w":411.02,"h":81.62},"layoutAwareBbox":[{"x":165,"y":585,"w":408,"h":82,"startIndex":1,"endIndex":14}]},{"type":"text","value":"$$phi = y - ax^3 + bx^2$$                                                                                      (1)","md":"$$phi = y - ax^3 + bx^2$$                                                                                      (1)","bBox":{"x":564.99,"y":684.76,"w":10.01,"h":9},"layoutAwareBbox":[{"x":332,"y":683,"w":76,"h":11,"startIndex":2,"endIndex":5},{"x":564,"y":685,"w":9,"h":9,"startIndex":0,"endIndex":113}]},{"type":"text","value":"$$chi = c - dx^2 - y$$                                                                                       (2)","md":"$$chi = c - dx^2 - y$$                                                                                       (2)","bBox":{"x":564.99,"y":708.37,"w":10.01,"h":9},"layoutAwareBbox":[{"x":336,"y":707,"w":68,"h":10,"startIndex":2,"endIndex":5},{"x":564,"y":709,"w":9,"h":9,"startIndex":0,"endIndex":111}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    31 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    31 of 44","bBox":{"x":545.34,"y":402.7,"w":32.17,"h":352.06},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":30,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/LEMSSchema.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/LEMSSchema.html","text":" and in our documentation (https://docs.neuroml.org/Userdocs/LEMSSchema.html). Here, "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                               Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    31 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.966,"layout":[{"image":"page_31_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.143,"w":0.668,"h":0.18},"isLikelyNoise":false},{"image":"page_31_text_2_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.326,"w":0.669,"h":0.118},"isLikelyNoise":false},{"image":"page_31_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.617,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_31_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.739,"w":0.668,"h":0.104},"isLikelyNoise":false},{"image":"page_31_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.51,"w":0.669,"h":0.103},"isLikelyNoise":false},{"image":"page_31_text_6_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.668,"h":0.072},"isLikelyNoise":false},{"image":"page_31_text_7_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.271,"y":0.448,"w":0.668,"h":0.058},"isLikelyNoise":false},{"image":"page_31_formula_1_v2.jpg","confidence":0.9,"label":"formula","bbox":{"x":0.55,"y":0.894,"w":0.112,"h":0.013},"isLikelyNoise":false},{"image":"page_31_formula_2_v2.jpg","confidence":0.89,"label":"formula","bbox":{"x":0.544,"y":0.863,"w":0.125,"h":0.015},"isLikelyNoise":false},{"image":"page_31_footer_1_v2.jpg","confidence":0.88,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_31_formula_number_1_v2.jpg","confidence":0.87,"label":"formula_number","bbox":{"x":0.922,"y":0.866,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_31_header_1_v2.jpg","confidence":0.87,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_31_formula_number_2_v2.jpg","confidence":0.86,"label":"formula_number","bbox":{"x":0.922,"y":0.896,"w":0.016,"h":0.011},"isLikelyNoise":false},{"image":"page_31_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_31_header_2_v2.jpg","confidence":0.71,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_31_header_3_v2.jpg","confidence":0.59,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":32,"text":"Tools  and  resources    Neuroscience\n\n\n<ComponentType name=\"hindmarshRose1984Cell\" extends=\"baseCellMembPotCap\" description=\"The Ηindmarsh Rose\n model\">\n <Parameter  name=\"a\" dimension=\"none\" description=\"cubic term in x nullcline\"/>\n <Parameter  name=\"b\" dimension=\"none\" description=\"quadratic term in x nullcline\"/>\n <Parameter  name=\"c\" dimension=\"none\" description=\"constant term in y nullcline\"/>\n <Parameter  name=\"d\" dimension=\"none\" description=\"quadratic term in y nullcline\"/>\n <Parameter  name=\"r\" dimension=\"none\" description=\"timescale separation between slow and ƒast subsystem (r\n  greater than 0; r much less than 1)\"/>\n <Parameter  name=\"s\" dimension=\"none\" description=\"related to adaptation\"/>\n <Parameter  name=\"x1\" dimension=\"none\" description=\"related to the system s resting potential\"/>\n <Parameter  name=\"v_scaling\" dimension=\"voltage\" description=\"scaling oƒ x ƒor physiological membrane\n  potential\"/>\n\n <!-- Initial Conditions -->\n <Parameter  name=\"x0\" dimension=\"none\"/>\n <Parameter  name=\"y0\" dimension=\"none\"/>\n <Parameter  name=\"z0\" dimension=\"none\"/>\n\n <Constant name=\"MSΕC\" dimension=\"time\" value=\"1ms\"/>\n\n <Αttachments name=\"synapses\" type=\"basePointCurrent\"/>\n\n <Εxposure name=\"x\" dimension=\"none\"/>\n <Εxposure name=\"y\" dimension=\"none\"/>\n <Εxposure name=\"z\" dimension=\"none\"/>\n <Εxposure name=\"phi\" dimension=\"none\"/>\n <Εxposure name=\"chi\" dimension=\"none\"/>\n <Εxposure name=\"rho\" dimension=\"none\"/>\n <Εxposure name=\"spiking\" dimension=\"none\"/>\n <Dynamics>\n  <StateVariable name=\"v\" dimension=\"voltage\" exposure=\"v\"/>\n  <StateVariable name=\"y\" dimension=\"none\" exposure=\"y\"/>\n  <StateVariable name=\"z\" dimension=\"none\" exposure=\"z\"/>\n  <StateVariable name=\"spiking\" dimension=\"none\" exposure=\"spiking\"/>\n\n  <DerivedVariable  name=\"iSyn\" dimension=\"current\" exposure=\"iSyn\" select=\"synapses[*]/i\" reduce=\"add\" />\n  <DerivedVariable  name=\"x\" dimension=\"none\" exposure=\"x\" value=\"v / v_scaling\"/>\n  <DerivedVariable  name=\"phi\" dimension=\"none\" exposure=\"phi\" value=\"y – a * x^3 + b * x^2\"/>\n  <DerivedVariable  name=\"chi\" dimension=\"none\" exposure=\"chi\" value=\"c – d * x^2 – y\"/>\n  <DerivedVariable  name=\"rho\" dimension=\"none\" exposure=\"rho\" value=\"s * ( x – x1 ) – z\"/>\n  <DerivedVariable  name=\"iMemb\" dimension=\"current\" exposure=\"iMemb\"\n                    value=\"(C * (v_scaling * (phi – z) / MSΕC)) + iSyn\"/>\n\n  <TimeDerivative variable=\"v\" value=\"iMemb/C\"/>\n  <TimeDerivative variable=\"y\" value=\"chi / MSΕC\"/>\n  <TimeDerivative variable=\"z\" value=\"r * rho / MSΕC\"/>\n\n  <OnStart>\n   <StateΑssignment  variable=\"v\" value=\"x0 * v_scaling\"/>\n   <StateΑssignment  variable=\"y\" value=\"y0\"/>\n   <StateΑssignment  variable=\"z\" value=\"z0\"/>\n  </OnStart>\n  <OnCondition test=\"v .gt. 0 .and. spiking .lt. 0.5\">\n   <StateΑssignment  variable=\"spiking\" value=\"1\"/>\n   <ΕventOut port=\"spike\"/>\n  </OnCondition>\n  <OnCondition test=\"v .lt. 0\">\n   <StateΑssignment  variable=\"spiking\" value=\"0\"/>\n  </OnCondition>\n </Dynamics>\n</ComponentType>\n\nFigure 13. LEMS ComponentType definition of the HindmarshRose cell model (Hindmarsh and Rose, 1984,\nhttps://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml).\n\n\n\n\nrho = s(x − x1) − z    (3)\n\nThe total membrane potential of the cell, iMemb, is calculated as the sum of the capacitive current\nand the synaptic current:\n\n                         iMemb = C(v_scaling(phi − z)) + iSyn    (4)\n                         MSEC\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    32 of 44","md":"\n\neLife Tools and resources                                                                                                                                                                                                    Neuroscience\n\n```xml\n<ComponentType name=\"hindmarshRose1984Cell\" extends=\"baseCellMembPotCap\" description=\"The Hindmarsh Rose model\">\n <Parameter name=\"a\" dimension=\"none\" description=\"cubic term in x nullcline\"/>\n <Parameter name=\"b\" dimension=\"none\" description=\"quadratic term in x nullcline\"/>\n <Parameter name=\"c\" dimension=\"none\" description=\"constant term in y nullcline\"/>\n <Parameter name=\"d\" dimension=\"none\" description=\"quadratic term in y nullcline\"/>\n <Parameter name=\"r\" dimension=\"none\" description=\"timescale separation between slow and fast subsystem (r greater than 0; r much less than 1)\"/>\n <Parameter name=\"s\" dimension=\"none\" description=\"related to adaptation\"/>\n <Parameter name=\"x1\" dimension=\"none\" description=\"related to the system's resting potential\"/>\n <Parameter name=\"v_scaling\" dimension=\"voltage\" description=\"scaling of x for physiological membrane potential\"/>\n\n \n <Parameter name=\"x0\" dimension=\"none\"/>\n <Parameter name=\"y0\" dimension=\"none\"/>\n <Parameter name=\"z0\" dimension=\"none\"/>\n\n <Constant name=\"MSEC\" dimension=\"time\" value=\"1ms\"/>\n\n <Attachments name=\"synapses\" type=\"basePointCurrent\"/>\n\n <Exposure name=\"x\" dimension=\"none\"/>\n <Exposure name=\"y\" dimension=\"none\"/>\n <Exposure name=\"z\" dimension=\"none\"/>\n <Exposure name=\"phi\" dimension=\"none\"/>\n <Exposure name=\"chi\" dimension=\"none\"/>\n <Exposure name=\"rho\" dimension=\"none\"/>\n <Exposure name=\"spiking\" dimension=\"none\"/>\n <Dynamics>\n  <StateVariable name=\"v\" dimension=\"voltage\" exposure=\"v\"/>\n  <StateVariable name=\"y\" dimension=\"none\" exposure=\"y\"/>\n  <StateVariable name=\"z\" dimension=\"none\" exposure=\"z\"/>\n  <StateVariable name=\"spiking\" dimension=\"none\" exposure=\"spiking\"/>\n\n  <DerivedVariable name=\"iSyn\" dimension=\"current\" exposure=\"iSyn\" select=\"synapses[*]/i\" reduce=\"add\" />\n  <DerivedVariable name=\"x\" dimension=\"none\" exposure=\"x\" value=\"v / v_scaling\"/>\n  <DerivedVariable name=\"phi\" dimension=\"none\" exposure=\"phi\" value=\"y - a * x^3 + b * x^2\"/>\n  <DerivedVariable name=\"chi\" dimension=\"none\" exposure=\"chi\" value=\"c - d * x^2 - y\"/>\n  <DerivedVariable name=\"rho\" dimension=\"none\" exposure=\"rho\" value=\"s * ( x - x1 ) - z\"/>\n  <DerivedVariable name=\"iMemb\" dimension=\"current\" exposure=\"iMemb\"\n                   value=\"(C * (v_scaling * (phi - z) / MSEC)) + iSyn\"/>\n\n  <TimeDerivative variable=\"v\" value=\"iMemb/C\"/>\n  <TimeDerivative variable=\"y\" value=\"chi / MSEC\"/>\n  <TimeDerivative variable=\"z\" value=\"r * rho / MSEC\"/>\n\n  <OnStart>\n   <StateAssignment variable=\"v\" value=\"x0 * v_scaling\"/>\n   <StateAssignment variable=\"y\" value=\"y0\"/>\n   <StateAssignment variable=\"z\" value=\"z0\"/>\n  </OnStart>\n  <OnCondition test=\"v .gt. 0 .and. spiking .lt. 0.5\">\n   <StateAssignment variable=\"spiking\" value=\"1\"/>\n   <EventOut port=\"spike\"/>\n  </OnCondition>\n  <OnCondition test=\"v .lt. 0\">\n   <StateAssignment variable=\"spiking\" value=\"0\"/>\n  </OnCondition>\n </Dynamics>\n</ComponentType>\n```\n\n**Figure 13.** LEMS ComponentType definition of the HindmarshRose cell model (*Hindmarsh and Rose, 1984*, https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml).\n\n$$rho = s(x - x1) - z \\qquad (3)$$\n\nThe total membrane potential of the cell, iMemb, is calculated as the sum of the capacitive current and the synaptic current:\n\n$$iMemb = \\frac{C(v\\_scaling(phi - z))}{MSEC} + iSyn \\qquad (4)$$\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                                                                                    32 of 44\n","images":[{"name":"page_32.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_32_formula_1_v2.jpg","height":15623.068,"width":89446.105,"x":182186.077,"y":554372.551,"original_width":591,"original_height":80,"rotation":0,"type":"layout_v2_formula"},{"name":"page_32_text_1_v2.jpg","height":16951.652,"width":249795.54,"x":101654.013,"y":529924.388,"original_width":1650,"original_height":87,"rotation":0,"type":"layout_v2_text"},{"name":"page_32_formula_2_v2.jpg","height":6919.525,"width":45410.347,"x":204168.205,"y":514734.112,"original_width":300,"original_height":36,"rotation":0,"type":"layout_v2_formula"},{"name":"page_32_footer_1_v2.jpg","height":7001.305,"width":191134.322,"x":22448.34,"y":591496.759,"original_width":1263,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_32_formula_number_1_v2.jpg","height":7196.991,"width":6074.064,"x":345318.284,"y":559091.38,"original_width":41,"original_height":37,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_32_formula_number_2_v2.jpg","height":7341.458,"width":5967.683,"x":345349.711,"y":515554.475,"original_width":40,"original_height":38,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_32_header_1_v2.jpg","height":5540.275,"width":30312.18,"x":320830.21,"y":27825.45,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_32_number_1_v2.jpg","height":5951.226,"width":18267.978,"x":332856.147,"y":591838.363,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_32_algorithm_1_v2.jpg","height":426327.365,"width":226352.167,"x":103114.106,"y":43533.868,"original_width":1495,"original_height":2175,"rotation":0,"type":"layout_v2_algorithm"},{"name":"page_32_header_2_v2.jpg","height":5679.011,"width":42984.948,"x":47719.657,"y":27996.977,"original_width":284,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_32_figure_title_1_v2.jpg","height":16228.633,"width":238937.753,"x":101439.034,"y":475217.421,"original_width":1578,"original_height":83,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_32_header_3_v2.jpg","height":10754.378,"width":24446.997,"x":21832.01,"y":22479.31,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                                                                                                                                    Neuroscience","md":"eLife Tools and resources                                                                                                                                                                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":6,"startIndex":221,"endIndex":233}]},{"type":"text","value":"```xml\n<ComponentType name=\"hindmarshRose1984Cell\" extends=\"baseCellMembPotCap\" description=\"The Hindmarsh Rose model\">\n <Parameter name=\"a\" dimension=\"none\" description=\"cubic term in x nullcline\"/>\n <Parameter name=\"b\" dimension=\"none\" description=\"quadratic term in x nullcline\"/>\n <Parameter name=\"c\" dimension=\"none\" description=\"constant term in y nullcline\"/>\n <Parameter name=\"d\" dimension=\"none\" description=\"quadratic term in y nullcline\"/>\n <Parameter name=\"r\" dimension=\"none\" description=\"timescale separation between slow and fast subsystem (r greater than 0; r much less than 1)\"/>\n <Parameter name=\"s\" dimension=\"none\" description=\"related to adaptation\"/>\n <Parameter name=\"x1\" dimension=\"none\" description=\"related to the system's resting potential\"/>\n <Parameter name=\"v_scaling\" dimension=\"voltage\" description=\"scaling of x for physiological membrane potential\"/>","md":"```xml\n<ComponentType name=\"hindmarshRose1984Cell\" extends=\"baseCellMembPotCap\" description=\"The Hindmarsh Rose model\">\n <Parameter name=\"a\" dimension=\"none\" description=\"cubic term in x nullcline\"/>\n <Parameter name=\"b\" dimension=\"none\" description=\"quadratic term in x nullcline\"/>\n <Parameter name=\"c\" dimension=\"none\" description=\"constant term in y nullcline\"/>\n <Parameter name=\"d\" dimension=\"none\" description=\"quadratic term in y nullcline\"/>\n <Parameter name=\"r\" dimension=\"none\" description=\"timescale separation between slow and fast subsystem (r greater than 0; r much less than 1)\"/>\n <Parameter name=\"s\" dimension=\"none\" description=\"related to adaptation\"/>\n <Parameter name=\"x1\" dimension=\"none\" description=\"related to the system's resting potential\"/>\n <Parameter name=\"v_scaling\" dimension=\"voltage\" description=\"scaling of x for physiological membrane potential\"/>","bBox":{"x":181.38,"y":67.57,"w":275.3,"h":93.14},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":8,"endIndex":21}]},{"type":"text","value":"<Parameter name=\"x0\" dimension=\"none\"/>\n <Parameter name=\"y0\" dimension=\"none\"/>\n <Parameter name=\"z0\" dimension=\"none\"/>","md":"<Parameter name=\"x0\" dimension=\"none\"/>\n <Parameter name=\"y0\" dimension=\"none\"/>\n <Parameter name=\"z0\" dimension=\"none\"/>","bBox":{"x":181.38,"y":76.25,"w":130.68,"h":127.87},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":1,"endIndex":10}]},{"type":"text","value":"<Constant name=\"MSEC\" dimension=\"time\" value=\"1ms\"/>","md":"<Constant name=\"MSEC\" dimension=\"time\" value=\"1ms\"/>","bBox":{"x":364.73,"y":362.73,"w":169.07,"h":356.63},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":1,"endIndex":9}]},{"type":"text","value":"<Attachments name=\"synapses\" type=\"basePointCurrent\"/>","md":"<Attachments name=\"synapses\" type=\"basePointCurrent\"/>","bBox":{"x":527.16,"y":362.73,"w":6.65,"h":6.33},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":2,"endIndex":12}]},{"type":"text","value":"<Exposure name=\"x\" dimension=\"none\"/>\n <Exposure name=\"y\" dimension=\"none\"/>\n <Exposure name=\"z\" dimension=\"none\"/>\n <Exposure name=\"phi\" dimension=\"none\"/>\n <Exposure name=\"chi\" dimension=\"none\"/>\n <Exposure name=\"rho\" dimension=\"none\"/>\n <Exposure name=\"spiking\" dimension=\"none\"/>\n <Dynamics>\n  <StateVariable name=\"v\" dimension=\"voltage\" exposure=\"v\"/>\n  <StateVariable name=\"y\" dimension=\"none\" exposure=\"y\"/>\n  <StateVariable name=\"z\" dimension=\"none\" exposure=\"z\"/>\n  <StateVariable name=\"spiking\" dimension=\"none\" exposure=\"spiking\"/>","md":"<Exposure name=\"x\" dimension=\"none\"/>\n <Exposure name=\"y\" dimension=\"none\"/>\n <Exposure name=\"z\" dimension=\"none\"/>\n <Exposure name=\"phi\" dimension=\"none\"/>\n <Exposure name=\"chi\" dimension=\"none\"/>\n <Exposure name=\"rho\" dimension=\"none\"/>\n <Exposure name=\"spiking\" dimension=\"none\"/>\n <Dynamics>\n  <StateVariable name=\"v\" dimension=\"voltage\" exposure=\"v\"/>\n  <StateVariable name=\"y\" dimension=\"none\" exposure=\"y\"/>\n  <StateVariable name=\"z\" dimension=\"none\" exposure=\"z\"/>\n  <StateVariable name=\"spiking\" dimension=\"none\" exposure=\"spiking\"/>","bBox":{"x":181.39,"y":310.64,"w":352.41,"h":58.42},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":2,"endIndex":9}]},{"type":"text","value":"<DerivedVariable name=\"iSyn\" dimension=\"current\" exposure=\"iSyn\" select=\"synapses[*]/i\" reduce=\"add\" />\n  <DerivedVariable name=\"x\" dimension=\"none\" exposure=\"x\" value=\"v / v_scaling\"/>\n  <DerivedVariable name=\"phi\" dimension=\"none\" exposure=\"phi\" value=\"y - a * x^3 + b * x^2\"/>\n  <DerivedVariable name=\"chi\" dimension=\"none\" exposure=\"chi\" value=\"c - d * x^2 - y\"/>\n  <DerivedVariable name=\"rho\" dimension=\"none\" exposure=\"rho\" value=\"s * ( x - x1 ) - z\"/>\n  <DerivedVariable name=\"iMemb\" dimension=\"current\" exposure=\"iMemb\"\n                   value=\"(C * (v_scaling * (phi - z) / MSEC)) + iSyn\"/>","md":"<DerivedVariable name=\"iSyn\" dimension=\"current\" exposure=\"iSyn\" select=\"synapses[*]/i\" reduce=\"add\" />\n  <DerivedVariable name=\"x\" dimension=\"none\" exposure=\"x\" value=\"v / v_scaling\"/>\n  <DerivedVariable name=\"phi\" dimension=\"none\" exposure=\"phi\" value=\"y - a * x^3 + b * x^2\"/>\n  <DerivedVariable name=\"chi\" dimension=\"none\" exposure=\"chi\" value=\"c - d * x^2 - y\"/>\n  <DerivedVariable name=\"rho\" dimension=\"none\" exposure=\"rho\" value=\"s * ( x - x1 ) - z\"/>\n  <DerivedVariable name=\"iMemb\" dimension=\"current\" exposure=\"iMemb\"\n                   value=\"(C * (v_scaling * (phi - z) / MSEC)) + iSyn\"/>","bBox":{"x":188.11,"y":362.73,"w":345.69,"h":356.63},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":1,"endIndex":16}]},{"type":"text","value":"<TimeDerivative variable=\"v\" value=\"iMemb/C\"/>\n  <TimeDerivative variable=\"y\" value=\"chi / MSEC\"/>\n  <TimeDerivative variable=\"z\" value=\"r * rho / MSEC\"/>","md":"<TimeDerivative variable=\"v\" value=\"iMemb/C\"/>\n  <TimeDerivative variable=\"y\" value=\"chi / MSEC\"/>\n  <TimeDerivative variable=\"z\" value=\"r * rho / MSEC\"/>","bBox":{"x":188.14,"y":432.18,"w":201.01,"h":287.18},"layoutAwareBbox":[{"x":168,"y":54,"w":369,"h":538,"startIndex":1,"endIndex":15}]},{"type":"text","value":"<OnStart>\n   <StateAssignment variable=\"v\" value=\"x0 * v_scaling\"/>\n   <StateAssignment variable=\"y\" value=\"y0\"/>\n   <StateAssignment variable=\"z\" value=\"z0\"/>\n  </OnStart>\n  <OnCondition test=\"v .gt. 0 .and. spiking .lt. 0.5\">\n   <StateAssignment variable=\"spiking\" value=\"1\"/>\n   <EventOut port=\"spike\"/>\n  </OnCondition>\n  <OnCondition test=\"v .lt. 0\">\n   <StateAssignment variable=\"spiking\" value=\"0\"/>\n  </OnCondition>\n </Dynamics>\n</ComponentType>\n```","md":"<OnStart>\n   <StateAssignment variable=\"v\" value=\"x0 * v_scaling\"/>\n   <StateAssignment variable=\"y\" value=\"y0\"/>\n   <StateAssignment variable=\"z\" value=\"z0\"/>\n  </OnStart>\n  <OnCondition test=\"v .gt. 0 .and. spiking .lt. 0.5\">\n   <StateAssignment variable=\"spiking\" value=\"1\"/>\n   <EventOut port=\"spike\"/>\n  </OnCondition>\n  <OnCondition test=\"v .lt. 0\">\n   <StateAssignment variable=\"spiking\" value=\"0\"/>\n  </OnCondition>\n </Dynamics>\n</ComponentType>\n```","bBox":{"x":174.73,"y":466.91,"w":201.05,"h":119.2},"layoutAwareBbox":[{"x":174.73,"y":466.91,"w":201.05,"h":119.2,"startIndex":0,"endIndex":456}]},{"type":"text","value":"**Figure 13.** LEMS ComponentType definition of the HindmarshRose cell model (*Hindmarsh and Rose, 1984*, https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml).","md":"**Figure 13.** LEMS ComponentType definition of the HindmarshRose cell model (*Hindmarsh and Rose, 1984*, https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml).","bBox":{"x":168.53,"y":611.2,"w":307.67,"h":8},"layoutAwareBbox":[{"x":165,"y":600,"w":390,"h":20,"startIndex":15,"endIndex":19}]},{"type":"text","value":"$$rho = s(x - x1) - z \\qquad (3)$$","md":"$$rho = s(x - x1) - z \\qquad (3)$$","bBox":{"x":564.99,"y":649.85,"w":10.01,"h":9},"layoutAwareBbox":[{"x":333,"y":649,"w":74,"h":8,"startIndex":2,"endIndex":5},{"x":564,"y":650,"w":9,"h":9,"startIndex":0,"endIndex":33}]},{"type":"text","value":"The total membrane potential of the cell, iMemb, is calculated as the sum of the capacitive current and the synaptic current:","md":"The total membrane potential of the cell, iMemb, is calculated as the sum of the capacitive current and the synaptic current:","bBox":{"x":168.52,"y":668.38,"w":408.91,"h":21},"layoutAwareBbox":[{"x":166,"y":669,"w":408,"h":21,"startIndex":42,"endIndex":47}]},{"type":"text","value":"$$iMemb = \\frac{C(v\\_scaling(phi - z))}{MSEC} + iSyn \\qquad (4)$$","md":"$$iMemb = \\frac{C(v\\_scaling(phi - z))}{MSEC} + iSyn \\qquad (4)$$","bBox":{"x":364.73,"y":704.84,"w":210.27,"h":14.52},"layoutAwareBbox":[{"x":297,"y":699,"w":146,"h":19,"startIndex":2,"endIndex":7},{"x":564,"y":705,"w":9,"h":9,"startIndex":0,"endIndex":64}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                                                                                    32 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                                                                                    32 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":36,"y":746,"w":312,"h":8,"startIndex":0,"endIndex":224},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":224}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml","unsafeUrl":"https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml","text":"https://github.com/NeuroML/NeuroML2/blob/master/NeuroML2CoreTypes/Cells.xml)."}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                                                                                                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                                                                                                                                    32 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.943,"layout":[{"image":"page_32_formula_1_v2.jpg","confidence":0.96,"label":"formula","bbox":{"x":0.486,"y":0.884,"w":0.239,"h":0.025},"isLikelyNoise":false},{"image":"page_32_text_1_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.271,"y":0.845,"w":0.667,"h":0.027},"isLikelyNoise":false},{"image":"page_32_formula_2_v2.jpg","confidence":0.92,"label":"formula","bbox":{"x":0.545,"y":0.821,"w":0.121,"h":0.011},"isLikelyNoise":false},{"image":"page_32_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.06,"y":0.943,"w":0.51,"h":0.011},"isLikelyNoise":false},{"image":"page_32_formula_number_1_v2.jpg","confidence":0.89,"label":"formula_number","bbox":{"x":0.922,"y":0.891,"w":0.016,"h":0.011},"isLikelyNoise":false},{"image":"page_32_formula_number_2_v2.jpg","confidence":0.89,"label":"formula_number","bbox":{"x":0.922,"y":0.822,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_32_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_32_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_32_algorithm_1_v2.jpg","confidence":0.85,"label":"algorithm","bbox":{"x":0.275,"y":0.069,"w":0.604,"h":0.68},"isLikelyNoise":false},{"image":"page_32_header_2_v2.jpg","confidence":0.74,"label":"header","bbox":{"x":0.127,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_32_figure_title_1_v2.jpg","confidence":0.67,"label":"figure_title","bbox":{"x":0.271,"y":0.758,"w":0.638,"h":0.026},"isLikelyNoise":false},{"image":"page_32_header_3_v2.jpg","confidence":0.62,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false}]},{"page":33,"text":"Tools  and  resources                                                                                  Neuroscience\n\n                         v, y, z are TimeDerivatives, with the ‘value’ representing the rate of change of each variable:\n\n                                                                         dv/dt = iMemb/C                                      (5)\n                                                                         dy/dt = chi/MSEC                                     (6)\n                                                                      dz/dt = (r × rho)/MSEC                                  (7)\n\n                         The ﬁnal few blocks set the initial state of the component (OnStart),\n\n                                                                        v = x0 × v_scaling                                    (8)\n                                                                              y = y0                                          (9)\n                                                                      z = z0                                                 (10)\n\n                         and deﬁne conditional expressions to set the spiking state of the cell:\n                                                                  ⎧\n                                                                  ⎪\n                                     spiking = ⎨1                     if (v > 0) ∧ (spiking < 0.5)                           (11)\n                                                                  ⎪\n                                                                  ⎩0  if (v < 0)\n\n                         Both the XSD schema and the LEMS ComponentType         deﬁnitions enable model validation.\n                         However, despite some overlap, they support different types of validation. Whereas the XSD schema\n                         allows for the validation of model descriptions (e.g. the XML ﬁles), the LEMS\n                                                                                                      ComponentType deﬁni-\n                         tions enable validation of model instances, i.e., the ‘runnable’ instances of models that are constructed\n                         once components have been created by instantiating ComponentTypes with the necessary parame-\n                         ters, and various attachments created between source and target components. A model description\n                         may be used to create many different model instances for simulation. Indeed, it is common practice to\n                         run models that include stochasticity with different seeds for random number generators to verify the\n                         robustness of simulation results. Thus, the validation of dimensions and units that LEMS carries out is\n                         done only after a runnable instance of a model has been created.\n                         The LEMS ComponentType deﬁnitions for NeuroMLv2 are also maintained as versioned ﬁles that\n                         are updated along with the XSD schema. These can also be seen in the NeuroMLv2 GitHub repos-\n                         itory (https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes). An index of the\n                         ComponentTypes included in version 2.3 of the NeuroML standard, with links to online documenta-\n                         tion, is also provided in Tables 1 and 2.\n\n                         NeuroML APIs\n                         The NeuroMLv2 software stack relies on the NeuroML APIs that provide functionality to read, write,\n                         validate, and inspect NeuroML models. The APIs are programmatically generated from the machine\n                         readable XSD schema, thus ensuring that the class for deﬁning a speciﬁc NeuroML element in a given\n                         language (e.g. Java) has the correct set of ﬁelds with the appropriate type (e.g. ﬂoat or string) corre-\n                         sponding to the allowed parameters in the corresponding NeuroML element. NeuroMLv2 currently\n                         provides APIs in numerous languages—Python (libNeuroML which is generated via generateDS\n                         (http://www.davekuhlman.org/generateDS.html)), Java (  org.neuroml.model via JAXB XJC (https://\n                         javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/\n                         xsd/)) and MATLAB (NeuroMLToolbox which accesses the Java API from MATLAB), and APIs for\n                         other languages can also be easily generated as required. LEMS is also supported by a similar set of\n                         APIs—PyLEMS in Python, and jLEMS in Java—and since a NeuroMLv2 model description is a set of\n                         LEMS Components, the LEMS APIs also support them (e.g. the hindmarshRose1984 Cell example\n                         in Figure 11 could be loaded by jLEMS and treated as a LEMS Component).\n                         Figure 14 shows the use of the NeuroML Python API to describe a model with one HindmarshRose\n                         cell. In Python, the instances of ComponentTypes , their Components , are represented as Python\n                         objects. The hr0 Python variable stores the created HindmarshRose1984        Cell component/object.\n                         This is added to a Population pop0 in the Network net. The network also includes a PulseGen\n                                                                                                                        -\n                         erator with amplitude 5 nA as an ExplicitInputthat is targeted at the cell in the population. The\n                         model description is serialized to XML (Figure 11) and validated. Note that as the standard conven-\n                         tion for classes in Python is to use capitalized names, HindmarshRose1984Cell  is used in Python\n                         but is serialized as <hindmarshRose1984Cell>in the XML. Users can either share the Python script\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    33 of 44","md":"\n\neLife Tools and resources                                                                                  Neuroscience\n\n*v*, *y*, *z* are TimeDerivatives, with the 'value' representing the rate of change of each variable:\n\n$$dv/dt = iMemb/C$$ (5)\n\n$$dy/dt = chi/MSEC$$ (6)\n\n$$dz/dt = (r × rho)/MSEC$$ (7)\n\nThe final few blocks set the initial state of the component (OnStart),\n\n$$v = x0 × v\\_scaling$$ (8)\n\n$$y = y0$$ (9)\n\n$$z = z0$$ (10)\n\nand define conditional expressions to set the spiking state of the cell:\n\n$$spiking = \\begin{cases} \n1 & \\text{if } (v > 0) \\land (spiking < 0.5) \\\\\n0 & \\text{if } (v < 0)\n\\end{cases}$$ (11)\n\nBoth the XSD schema and the LEMS `ComponentType` definitions enable model validation. However, despite some overlap, they support different types of validation. Whereas the XSD schema allows for the validation of model descriptions (e.g. the XML files), the LEMS `ComponentType` definitions enable validation of model instances, i.e., the 'runnable' instances of models that are constructed once components have been created by instantiating `ComponentTypes` with the necessary parameters, and various attachments created between source and target components. A model description may be used to create many different model instances for simulation. Indeed, it is common practice to run models that include stochasticity with different seeds for random number generators to verify the robustness of simulation results. Thus, the validation of dimensions and units that LEMS carries out is done only after a runnable instance of a model has been created.\n\nThe LEMS `ComponentType` definitions for NeuroMLv2 are also maintained as versioned files that are updated along with the XSD schema. These can also be seen in the NeuroMLv2 GitHub repository (https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes). An index of the `ComponentTypes` included in version 2.3 of the NeuroML standard, with links to online documentation, is also provided in **Tables 1** and **2**.\n\n## NeuroML APIs\n\nThe NeuroMLv2 software stack relies on the NeuroML APIs that provide functionality to read, write, validate, and inspect NeuroML models. The APIs are programmatically generated from the machine readable XSD schema, thus ensuring that the class for defining a specific NeuroML element in a given language (e.g. Java) has the correct set of fields with the appropriate type (e.g. float or string) corresponding to the allowed parameters in the corresponding NeuroML element. NeuroMLv2 currently provides APIs in numerous languages—Python (libNeuroML which is generated via generateDS (http://www.davekuhlman.org/generateDS.html)), Java (`org.neuroml.model` via JAXB XJC (https://javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/xsd/)) and MATLAB (NeuroMLToolbox which accesses the Java API from MATLAB), and APIs for other languages can also be easily generated as required. LEMS is also supported by a similar set of APIs—PyLEMS in Python, and jLEMS in Java—and since a NeuroMLv2 model description is a set of LEMS `Components`, the LEMS APIs also support them (e.g. the `hindmarshRose1984Cell` example in **Figure 11** could be loaded by jLEMS and treated as a LEMS `Component`).\n\n**Figure 14** shows the use of the NeuroML Python API to describe a model with one HindmarshRose cell. In Python, the instances of `ComponentTypes`, their `Components`, are represented as Python objects. The `hr0` Python variable stores the created `HindmarshRose1984Cell` component/object. This is added to a `Population` `pop0` in the `Network` `net`. The network also includes a `PulseGenerator` with amplitude 5 nA as an `ExplicitInput` that is targeted at the cell in the population. The model description is serialized to XML (**Figure 11**) and validated. Note that as the standard convention for classes in Python is to use capitalized names, `HindmarshRose1984Cell` is used in Python but is serialized as `<hindmarshRose1984Cell>` in the XML. Users can either share the Python script\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    33 of 44\n","images":[{"name":"page_33.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_33_text_1_v2.jpg","height":121737.044,"width":250603.323,"x":101026.549,"y":372918.052,"original_width":1655,"original_height":622,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_text_2_v2.jpg","height":93100.443,"width":250226.909,"x":101244.846,"y":209418.182,"original_width":1653,"original_height":475,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_text_3_v2.jpg","height":74026.6,"width":250331.003,"x":101159.003,"y":496494.255,"original_width":1653,"original_height":378,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_text_4_v2.jpg","height":45502.671,"width":250270.19,"x":101277.716,"y":304873.297,"original_width":1653,"original_height":233,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_formula_1_v2.jpg","height":29579.278,"width":97762.133,"x":177985.232,"y":169272.529,"original_width":646,"original_height":151,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_formula_number_1_v2.jpg","height":7531.411,"width":8879.63,"x":342386.754,"y":181294.164,"original_width":59,"original_height":39,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_text_5_v2.jpg","height":7654.488,"width":226098.566,"x":109070.393,"y":41575.861,"original_width":1493,"original_height":40,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_text_6_v2.jpg","height":7557.727,"width":172400.255,"x":101833.954,"y":153224.992,"original_width":1139,"original_height":39,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_formula_number_2_v2.jpg","height":7494.415,"width":8902.879,"x":342391.192,"y":137727.523,"original_width":59,"original_height":39,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_footer_1_v2.jpg","height":6980.017,"width":191905.238,"x":21557.959,"y":591472.061,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_33_text_7_v2.jpg","height":7547.769,"width":168366.721,"x":109013.022,"y":97689.311,"original_width":1112,"original_height":39,"rotation":0,"type":"layout_v2_text"},{"name":"page_33_formula_2_v2.jpg","height":7179.832,"width":56089.985,"x":198963.634,"y":80627.738,"original_width":371,"original_height":37,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_paragraph_title_1_v2.jpg","height":7566.548,"width":52231.894,"x":101572.107,"y":361066.115,"original_width":345,"original_height":39,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_33_header_1_v2.jpg","height":5701.927,"width":30294.899,"x":320856.684,"y":27694.326,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_33_formula_number_3_v2.jpg","height":7573.761,"width":6082.349,"x":345286.933,"y":114609.404,"original_width":41,"original_height":39,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_formula_number_4_v2.jpg","height":7192.638,"width":5934.682,"x":345450.836,"y":81853.568,"original_width":40,"original_height":37,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_formula_number_5_v2.jpg","height":7529.279,"width":6033.853,"x":345358.798,"y":58621.907,"original_width":40,"original_height":39,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_formula_number_6_v2.jpg","height":7397.204,"width":5845.809,"x":345449.882,"y":70069.003,"original_width":39,"original_height":38,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_formula_3_v2.jpg","height":6928.571,"width":44320.898,"x":204914.627,"y":114018.747,"original_width":293,"original_height":36,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_formula_number_7_v2.jpg","height":7222.505,"width":6032.354,"x":345246.662,"y":126527.644,"original_width":40,"original_height":37,"rotation":0,"type":"layout_v2_formula_number"},{"name":"page_33_number_1_v2.jpg","height":6020.852,"width":18289.984,"x":332876.593,"y":591767.973,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_33_formula_4_v2.jpg","height":7020.573,"width":42430.928,"x":205802.583,"y":68920.769,"original_width":281,"original_height":36,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_formula_5_v2.jpg","height":7149.854,"width":40936.538,"x":206666.578,"y":58204.461,"original_width":271,"original_height":37,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_header_2_v2.jpg","height":5864.883,"width":42810.527,"x":47826.606,"y":27844.674,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_33_formula_6_v2.jpg","height":7418.782,"width":16415.613,"x":218898.689,"y":126059.977,"original_width":109,"original_height":38,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_formula_7_v2.jpg","height":6570.582,"width":15310.974,"x":219646.868,"y":137899.568,"original_width":102,"original_height":34,"rotation":0,"type":"layout_v2_formula"},{"name":"page_33_header_3_v2.jpg","height":10804.344,"width":24512.555,"x":21843.416,"y":22439.036,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                  Neuroscience","md":"eLife Tools and resources                                                                                  Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":107,"endIndex":119}]},{"type":"text","value":"*v*, *y*, *z* are TimeDerivatives, with the 'value' representing the rate of change of each variable:","md":"*v*, *y*, *z* are TimeDerivatives, with the 'value' representing the rate of change of each variable:","bBox":{"x":360.54,"y":172.42,"w":3.49,"h":8.97},"layoutAwareBbox":[{"x":178,"y":52,"w":369,"h":9,"startIndex":0,"endIndex":100}]},{"type":"text","value":"$$dv/dt = iMemb/C$$ (5)","md":"$$dv/dt = iMemb/C$$ (5)","bBox":{"x":340.34,"y":72.77,"w":234.66,"h":9.4},"layoutAwareBbox":[{"x":337,"y":73,"w":66,"h":9,"startIndex":2,"endIndex":4},{"x":564,"y":74,"w":9,"h":9,"startIndex":0,"endIndex":22}]},{"type":"text","value":"$$dy/dt = chi/MSEC$$ (6)","md":"$$dy/dt = chi/MSEC$$ (6)","bBox":{"x":338.35,"y":86.06,"w":236.65,"h":10.24},"layoutAwareBbox":[{"x":336,"y":87,"w":69,"h":8,"startIndex":2,"endIndex":4},{"x":564,"y":88,"w":9,"h":9,"startIndex":0,"endIndex":23}]},{"type":"text","value":"$$dz/dt = (r × rho)/MSEC$$ (7)","md":"$$dz/dt = (r × rho)/MSEC$$ (7)","bBox":{"x":327.48,"y":101.02,"w":247.52,"h":10.11},"layoutAwareBbox":[{"x":325,"y":101,"w":91,"h":9,"startIndex":2,"endIndex":4},{"x":564,"y":103,"w":9,"h":9,"startIndex":0,"endIndex":29}]},{"type":"text","value":"The final few blocks set the initial state of the component (OnStart),","md":"The final few blocks set the initial state of the component (OnStart),","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":178,"y":123,"w":275,"h":9,"startIndex":0,"endIndex":69}]},{"type":"text","value":"$$v = x0 × v\\_scaling$$ (8)","md":"$$v = x0 × v\\_scaling$$ (8)","bBox":{"x":564.99,"y":143.84,"w":10.01,"h":9},"layoutAwareBbox":[{"x":334,"y":143,"w":72,"h":8,"startIndex":14,"endIndex":21},{"x":564,"y":144,"w":9,"h":9,"startIndex":0,"endIndex":26}]},{"type":"text","value":"$$y = y0$$ (9)","md":"$$y = y0$$ (9)","bBox":{"x":360.14,"y":157.51,"w":214.86,"h":10.26},"layoutAwareBbox":[{"x":357,"y":159,"w":26,"h":9,"startIndex":0,"endIndex":13},{"x":564,"y":159,"w":9,"h":9,"startIndex":0,"endIndex":13}]},{"type":"text","value":"$$z = z0$$ (10)","md":"$$z = z0$$ (10)","bBox":{"x":360.54,"y":172.42,"w":214.46,"h":9.7},"layoutAwareBbox":[{"x":358,"y":174,"w":25,"h":8,"startIndex":0,"endIndex":14},{"x":559,"y":173,"w":14,"h":9,"startIndex":12,"endIndex":14}]},{"type":"text","value":"and define conditional expressions to set the spiking state of the cell:","md":"and define conditional expressions to set the spiking state of the cell:","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":166,"y":193,"w":281,"h":9,"startIndex":0,"endIndex":71}]},{"type":"text","value":"$$spiking = \\begin{cases} \n1 & \\text{if } (v > 0) \\land (spiking < 0.5) \\\\\n0 & \\text{if } (v < 0)\n\\end{cases}$$ (11)","md":"$$spiking = \\begin{cases} \n1 & \\text{if } (v > 0) \\land (spiking < 0.5) \\\\\n0 & \\text{if } (v < 0)\n\\end{cases}$$ (11)","bBox":{"x":559.99,"y":228.19,"w":15.01,"h":9},"layoutAwareBbox":[{"x":559,"y":228,"w":14,"h":9,"startIndex":113,"endIndex":115}]},{"type":"text","value":"Both the XSD schema and the LEMS `ComponentType` definitions enable model validation. However, despite some overlap, they support different types of validation. Whereas the XSD schema allows for the validation of model descriptions (e.g. the XML files), the LEMS `ComponentType` definitions enable validation of model instances, i.e., the 'runnable' instances of models that are constructed once components have been created by instantiating `ComponentTypes` with the necessary parameters, and various attachments created between source and target components. A model description may be used to create many different model instances for simulation. Indeed, it is common practice to run models that include stochasticity with different seeds for random number generators to verify the robustness of simulation results. Thus, the validation of dimensions and units that LEMS carries out is done only after a runnable instance of a model has been created.","md":"Both the XSD schema and the LEMS `ComponentType` definitions enable model validation. However, despite some overlap, they support different types of validation. Whereas the XSD schema allows for the validation of model descriptions (e.g. the XML files), the LEMS `ComponentType` definitions enable validation of model instances, i.e., the 'runnable' instances of models that are constructed once components have been created by instantiating `ComponentTypes` with the necessary parameters, and various attachments created between source and target components. A model description may be used to create many different model instances for simulation. Indeed, it is common practice to run models that include stochasticity with different seeds for random number generators to verify the robustness of simulation results. Thus, the validation of dimensions and units that LEMS carries out is done only after a runnable instance of a model has been created.","bBox":{"x":168.53,"y":275.94,"w":414.92,"h":104.98},"layoutAwareBbox":[{"x":165,"y":264,"w":408,"h":117,"startIndex":5,"endIndex":8}]},{"type":"text","value":"The LEMS `ComponentType` definitions for NeuroMLv2 are also maintained as versioned files that are updated along with the XSD schema. These can also be seen in the NeuroMLv2 GitHub repository (https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes). An index of the `ComponentTypes` included in version 2.3 of the NeuroML standard, with links to online documentation, is also provided in **Tables 1** and **2**.","md":"The LEMS `ComponentType` definitions for NeuroMLv2 are also maintained as versioned files that are updated along with the XSD schema. These can also be seen in the NeuroMLv2 GitHub repository (https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes). An index of the `ComponentTypes` included in version 2.3 of the NeuroML standard, with links to online documentation, is also provided in **Tables 1** and **2**.","bBox":{"x":168.53,"y":408.42,"w":398.55,"h":9},"layoutAwareBbox":[{"x":165,"y":384,"w":408,"h":57,"startIndex":10,"endIndex":23}]},{"type":"heading","lvl":2,"value":"NeuroML APIs","md":"## NeuroML APIs","bBox":{"x":168.53,"y":454.31,"w":82.43,"h":12},"layoutAwareBbox":[{"x":165,"y":455,"w":85,"h":9,"startIndex":0,"endIndex":14}]},{"type":"text","value":"The NeuroMLv2 software stack relies on the NeuroML APIs that provide functionality to read, write, validate, and inspect NeuroML models. The APIs are programmatically generated from the machine readable XSD schema, thus ensuring that the class for defining a specific NeuroML element in a given language (e.g. Java) has the correct set of fields with the appropriate type (e.g. float or string) corresponding to the allowed parameters in the corresponding NeuroML element. NeuroMLv2 currently provides APIs in numerous languages—Python (libNeuroML which is generated via generateDS (http://www.davekuhlman.org/generateDS.html)), Java (`org.neuroml.model` via JAXB XJC (https://javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/xsd/)) and MATLAB (NeuroMLToolbox which accesses the Java API from MATLAB), and APIs for other languages can also be easily generated as required. LEMS is also supported by a similar set of APIs—PyLEMS in Python, and jLEMS in Java—and since a NeuroMLv2 model description is a set of LEMS `Components`, the LEMS APIs also support them (e.g. the `hindmarshRose1984Cell` example in **Figure 11** could be loaded by jLEMS and treated as a LEMS `Component`).","md":"The NeuroMLv2 software stack relies on the NeuroML APIs that provide functionality to read, write, validate, and inspect NeuroML models. The APIs are programmatically generated from the machine readable XSD schema, thus ensuring that the class for defining a specific NeuroML element in a given language (e.g. Java) has the correct set of fields with the appropriate type (e.g. float or string) corresponding to the allowed parameters in the corresponding NeuroML element. NeuroMLv2 currently provides APIs in numerous languages—Python (libNeuroML which is generated via generateDS (http://www.davekuhlman.org/generateDS.html)), Java (`org.neuroml.model` via JAXB XJC (https://javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/xsd/)) and MATLAB (NeuroMLToolbox which accesses the Java API from MATLAB), and APIs for other languages can also be easily generated as required. LEMS is also supported by a similar set of APIs—PyLEMS in Python, and jLEMS in Java—and since a NeuroMLv2 model description is a set of LEMS `Components`, the LEMS APIs also support them (e.g. the `hindmarshRose1984Cell` example in **Figure 11** could be loaded by jLEMS and treated as a LEMS `Component`).","bBox":{"x":168.53,"y":470.31,"w":405.51,"h":128.97},"layoutAwareBbox":[{"x":165,"y":470,"w":409,"h":153,"startIndex":0,"endIndex":3}]},{"type":"text","value":"**Figure 14** shows the use of the NeuroML Python API to describe a model with one HindmarshRose cell. In Python, the instances of `ComponentTypes`, their `Components`, are represented as Python objects. The `hr0` Python variable stores the created `HindmarshRose1984Cell` component/object. This is added to a `Population` `pop0` in the `Network` `net`. The network also includes a `PulseGenerator` with amplitude 5 nA as an `ExplicitInput` that is targeted at the cell in the population. The model description is serialized to XML (**Figure 11**) and validated. Note that as the standard convention for classes in Python is to use capitalized names, `HindmarshRose1984Cell` is used in Python but is serialized as `<hindmarshRose1984Cell>` in the XML. Users can either share the Python script","md":"**Figure 14** shows the use of the NeuroML Python API to describe a model with one HindmarshRose cell. In Python, the instances of `ComponentTypes`, their `Components`, are represented as Python objects. The `hr0` Python variable stores the created `HindmarshRose1984Cell` component/object. This is added to a `Population` `pop0` in the `Network` `net`. The network also includes a `PulseGenerator` with amplitude 5 nA as an `ExplicitInput` that is targeted at the cell in the population. The model description is serialized to XML (**Figure 11**) and validated. Note that as the standard convention for classes in Python is to use capitalized names, `HindmarshRose1984Cell` is used in Python but is serialized as `<hindmarshRose1984Cell>` in the XML. Users can either share the Python script","bBox":{"x":360.54,"y":172.42,"w":215,"h":534.84},"layoutAwareBbox":[{"x":165,"y":626,"w":409,"h":93,"startIndex":132,"endIndex":146}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    33 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    33 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":112},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":112}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes","unsafeUrl":"https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes","text":"itory (https://github.com/NeuroML/NeuroML2/tree/master/NeuroML2CoreTypes). An index of the "},{"url":"http://www.davekuhlman.org/generateDS.html","unsafeUrl":"http://www.davekuhlman.org/generateDS.html","text":"(http://www.davekuhlman.org/generateDS.html)), Java ("},{"url":"https://javaee.github.io/jaxb-v2/","unsafeUrl":"https://javaee.github.io/jaxb-v2/","text":"model via JAXB XJC (https://"},{"url":"https://javaee.github.io/jaxb-v2/","unsafeUrl":"https://javaee.github.io/jaxb-v2/","text":"javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/"},{"url":"https://www.codesynthesis.com/products/xsd/","unsafeUrl":"https://www.codesynthesis.com/products/xsd/","text":"javaee.github.io/jaxb-v2/)), C++ (NeuroML_CPP via XSD (https://www.codesynthesis.com/products/"},{"url":"https://www.codesynthesis.com/products/xsd/","unsafeUrl":"https://www.codesynthesis.com/products/xsd/","text":"xsd/)) and MATLAB (NeuroMLToolbox which accesses the Java API from MATLAB), and APIs for "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                  Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                    33 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.96,"layout":[{"image":"page_33_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.595,"w":0.669,"h":0.194},"isLikelyNoise":false},{"image":"page_33_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.334,"w":0.668,"h":0.148},"isLikelyNoise":false},{"image":"page_33_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.792,"w":0.668,"h":0.118},"isLikelyNoise":false},{"image":"page_33_text_4_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.486,"w":0.668,"h":0.073},"isLikelyNoise":false},{"image":"page_33_formula_1_v2.jpg","confidence":0.96,"label":"formula","bbox":{"x":0.475,"y":0.27,"w":0.261,"h":0.047},"isLikelyNoise":false},{"image":"page_33_formula_number_1_v2.jpg","confidence":0.9,"label":"formula_number","bbox":{"x":0.914,"y":0.289,"w":0.024,"h":0.012},"isLikelyNoise":false},{"image":"page_33_text_5_v2.jpg","confidence":0.89,"label":"text","bbox":{"x":0.291,"y":0.066,"w":0.604,"h":0.012},"isLikelyNoise":false},{"image":"page_33_text_6_v2.jpg","confidence":0.89,"label":"text","bbox":{"x":0.272,"y":0.244,"w":0.46,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_number_2_v2.jpg","confidence":0.89,"label":"formula_number","bbox":{"x":0.914,"y":0.22,"w":0.024,"h":0.012},"isLikelyNoise":false},{"image":"page_33_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_33_text_7_v2.jpg","confidence":0.89,"label":"text","bbox":{"x":0.291,"y":0.156,"w":0.45,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_2_v2.jpg","confidence":0.88,"label":"formula","bbox":{"x":0.531,"y":0.129,"w":0.15,"h":0.011},"isLikelyNoise":false},{"image":"page_33_paragraph_title_1_v2.jpg","confidence":0.88,"label":"paragraph_title","bbox":{"x":0.271,"y":0.576,"w":0.139,"h":0.012},"isLikelyNoise":false},{"image":"page_33_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_33_formula_number_3_v2.jpg","confidence":0.87,"label":"formula_number","bbox":{"x":0.922,"y":0.183,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_number_4_v2.jpg","confidence":0.87,"label":"formula_number","bbox":{"x":0.922,"y":0.13,"w":0.016,"h":0.011},"isLikelyNoise":false},{"image":"page_33_formula_number_5_v2.jpg","confidence":0.87,"label":"formula_number","bbox":{"x":0.922,"y":0.093,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_number_6_v2.jpg","confidence":0.85,"label":"formula_number","bbox":{"x":0.922,"y":0.112,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_3_v2.jpg","confidence":0.84,"label":"formula","bbox":{"x":0.547,"y":0.182,"w":0.118,"h":0.011},"isLikelyNoise":false},{"image":"page_33_formula_number_7_v2.jpg","confidence":0.84,"label":"formula_number","bbox":{"x":0.922,"y":0.202,"w":0.016,"h":0.012},"isLikelyNoise":false},{"image":"page_33_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_33_formula_4_v2.jpg","confidence":0.82,"label":"formula","bbox":{"x":0.549,"y":0.11,"w":0.113,"h":0.011},"isLikelyNoise":false},{"image":"page_33_formula_5_v2.jpg","confidence":0.82,"label":"formula","bbox":{"x":0.552,"y":0.093,"w":0.109,"h":0.011},"isLikelyNoise":false},{"image":"page_33_header_2_v2.jpg","confidence":0.76,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_33_formula_6_v2.jpg","confidence":0.71,"label":"formula","bbox":{"x":0.584,"y":0.201,"w":0.044,"h":0.012},"isLikelyNoise":false},{"image":"page_33_formula_7_v2.jpg","confidence":0.66,"label":"formula","bbox":{"x":0.586,"y":0.22,"w":0.041,"h":0.01},"isLikelyNoise":false},{"image":"page_33_header_3_v2.jpg","confidence":0.62,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false}]},{"page":34,"text":"Tools  and  resources                                                                                      Neuroscience\n\n                          Create a new HindmarshRose cell component with parameters for regular spiking\n\n                          nml_doc = component_ƒactory(\"NeuroMLDocument\", id=\"ΗindmarshRoseNeuron\")\n                          hr0 = nml_doc.add(\"ΗindmarshRose1984Cell\", id=\"hr_regular\", a=\"1.0\", b=\"3.0\", c=\"-3.0\", d=\"5.0\",\n                           s=\"4.0\", x1=\"-1.3\", r=\"0.002\", x0=\"-1.1\", y0=\"-9\", z0=\"1.0\", C=\"28.57142857pF\",\n                           v_scaling=\"35.0mV\")\n                          net = nml_doc.add(\"Network\", id=\"ΗRNet\", validate=False)\n                          Create a population of cells (1 cell)\n\n                          pop0 = net.add(\"Population\", id=\"ΗRPop0\", component=hr0.id, size=1)\n                          Add external stimuli to the population\n\n                          pg = nml_doc.add(\"PulseGenerator\", id=\"pulseGen_%i\" % 0, delay=\"0s\", duration=\"1000s\",\n                           amplitude=\"5nΑ\")\n                          exp_input = net.add(\"ΕxplicitΙnput\", target=\"%s[%i]\" % (pop0.id, 0), input=pg.id,\n                           destination=\"synapses\")\n                          Save (serialize) the model to a ﬁle\n\n                          nml_ƒile =  hindmarshrose1984_single_cell_network.nml\n                          writers.NeuroMLWriter.write(nml_doc, nml_ƒile)\n                          Validate the model\n                          validate_neuroml2(nml_ƒile)\n\n                         Figure 14. Example model description of a HindmarshRose1984Cell NeuroML component in Python using\n                         parameters for regular bursting. This script generates the XML in Figure 11. The code used in this example is\n                         available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.\n\n\nitself or share the XML serialization. Any valid XML serialization can be also loaded into a Python\nobject model and modiﬁed.\nXML is the default serialization of NeuroML and all existing APIs can read and write the format (and\nit should be seen as a minimal requirement for new APIs to support XML). There is, however, an alter\n                                                                                                    -\nnative HDF5 (https://www.hdfgroup.org/solutions/hdf5) based serialization of NeuroML ﬁles which is\nsupported by both libNeuroML and the Java API,\n                                org.neuroml.model (https://docs.neuroml.org/User-\ndocs/HDF5.html). This format is based on an efﬁcient representation of cell positions and connectivity\ndata as HDF5 data sets which can be serialized in compact binary format and loaded into memory\nfor optimized access (e.g. as numpy arrays in libNeuroML). This reduces the size of the saved ﬁles for\nlarge-scale networks and speeds up loading/writing models eliminating the need to parse/generate\nlarge text ﬁles containing XML. Models serialized in this format can be loaded and transformed to\nsimulator code in the same way as XML-based models by the Java and Python APIs.\n\nSimulating NeuroML models\nThe model description shown in Figure 11 contains no information about how it is to be simulated,\nor on the dynamics of each model component. Providing this simulation information and linking in\nthe ComponentType deﬁnition requires creating a LEMS ﬁle to fully specify the simulation. Figure 15\nshows the use of utilities included in the Python pyNeuroML package to describe a LEMS simulation\nof the HindmarshRose model deﬁned in Figure 11. The LEMSSimulationobject includes simulation\nspeciﬁc information such as the duration of the simulation, the integration time step, and the seed\nvalue. It also allows the speciﬁcation of ﬁles for the storage of data recorded from the simulation. In\nthis example, we record the membrane potential, v, of our cell in its population, HRPop0[0]. Similar\nto the NeuroMLv2 model description, the simulation object can also be serialized to XML for storage\nand sharing (Figure 15, bottom).\nAs noted previously, NeuroML/LEMS model and simulation descriptions are machine readable and\nsimulator independent and can be simulated by simulation engines using a multitude of strategies\n(Figure 5).\nThe ﬁrst category of tools consists of the reference NeuroML and LEMS simulation engines. These\nwork directly with NeuroML and LEMS as their base descriptions of modeling entities and do not\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    34 of 44","md":"\n\neLife Tools and resources                                                                                      Neuroscience\n\nCreate a new HindmarshRose cell component with parameters for regular spiking\n\n```python\nnml_doc = component_factory(\"NeuroMLDocument\", id=\"HindmarshRoseNeuron\")\nhr0 = nml_doc.add(\"HindmarshRose1984Cell\", id=\"hr_regular\", a=\"1.0\", b=\"3.0\", c=\"-3.0\", d=\"5.0\",\n s=\"4.0\", x1=\"-1.3\", r=\"0.002\", x0=\"-1.1\", y0=\"-9\", z0=\"1.0\", C=\"28.57142857pF\",\n v_scaling=\"35.0mV\")\nnet = nml_doc.add(\"Network\", id=\"HRNet\", validate=False)\n```\n\nCreate a population of cells (1 cell)\n\n```python\npop0 = net.add(\"Population\", id=\"HRPop0\", component=hr0.id, size=1)\n```\n\nAdd external stimuli to the population\n\n```python\npg = nml_doc.add(\"PulseGenerator\", id=\"pulseGen_%i\" % 0, delay=\"0s\", duration=\"1000s\",\n amplitude=\"5nA\")\nexp_input = net.add(\"ExplicitInput\", target=\"%s[%i]\" % (pop0.id, 0), input=pg.id,\n destination=\"synapses\")\n```\n\nSave (serialize) the model to a file\n\n```python\nnml_file = 'hindmarshrose1984_single_cell_network.nml'\nwriters.NeuroMLWriter.write(nml_doc, nml_file)\n```\n\nValidate the model\n\n```python\nvalidate_neuroml2(nml_file)\n```\n\n**Figure 14.** Example model description of a HindmarshRose1984Cell NeuroML component in Python using parameters for regular bursting. This script generates the XML in Figure 11. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.\n\nitself or share the XML serialization. Any valid XML serialization can be also loaded into a Python object model and modified.\n\nXML is the default serialization of NeuroML and all existing APIs can read and write the format (and it should be seen as a minimal requirement for new APIs to support XML). There is, however, an alternative HDF5 (https://www.hdfgroup.org/solutions/hdf5) based serialization of NeuroML files which is supported by both libNeuroML and the Java API, org.neuroml.model (https://docs.neuroml.org/Userdocs/HDF5.html). This format is based on an efficient representation of cell positions and connectivity data as HDF5 data sets which can be serialized in compact binary format and loaded into memory for optimized access (e.g. as numpy arrays in libNeuroML). This reduces the size of the saved files for large-scale networks and speeds up loading/writing models eliminating the need to parse/generate large text files containing XML. Models serialized in this format can be loaded and transformed to simulator code in the same way as XML-based models by the Java and Python APIs.\n\n## Simulating NeuroML models\n\nThe model description shown in Figure 11 contains no information about how it is to be simulated, or on the dynamics of each model component. Providing this simulation information and linking in the ComponentType definition requires creating a LEMS file to fully specify the simulation. Figure 15 shows the use of utilities included in the Python pyNeuroML package to describe a LEMS simulation of the HindmarshRose model defined in Figure 11. The LEMSSimulation object includes simulation specific information such as the duration of the simulation, the integration time step, and the seed value. It also allows the specification of files for the storage of data recorded from the simulation. In this example, we record the membrane potential, v, of our cell in its population, HRPop0[0]. Similar to the NeuroMLv2 model description, the simulation object can also be serialized to XML for storage and sharing (Figure 15, bottom).\n\nAs noted previously, NeuroML/LEMS model and simulation descriptions are machine readable and simulator independent and can be simulated by simulation engines using a multitude of strategies (Figure 5).\n\nThe first category of tools consists of the reference NeuroML and LEMS simulation engines. These work directly with NeuroML and LEMS as their base descriptions of modeling entities and do not\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    34 of 44\n","images":[{"name":"page_34.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_34_text_1_v2.jpg","height":93390.965,"width":250336.319,"x":101105.101,"y":315146.862,"original_width":1653,"original_height":477,"rotation":0,"type":"layout_v2_text"},{"name":"page_34_text_2_v2.jpg","height":93084.311,"width":250448.356,"x":101044.602,"y":429930.254,"original_width":1654,"original_height":475,"rotation":0,"type":"layout_v2_text"},{"name":"page_34_text_3_v2.jpg","height":26323.976,"width":250240.137,"x":101243.689,"y":525104.06,"original_width":1653,"original_height":135,"rotation":0,"type":"layout_v2_text"},{"name":"page_34_text_4_v2.jpg","height":17512.818,"width":250187.168,"x":101391.696,"y":553460.117,"original_width":1652,"original_height":90,"rotation":0,"type":"layout_v2_text"},{"name":"page_34_text_5_v2.jpg","height":16976.919,"width":250078.258,"x":101196.578,"y":296058.689,"original_width":1652,"original_height":87,"rotation":0,"type":"layout_v2_text"},{"name":"page_34_paragraph_title_1_v2.jpg","height":8713.03,"width":100147.673,"x":101461.561,"y":418251.402,"original_width":662,"original_height":45,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_34_footer_1_v2.jpg","height":6965.119,"width":191771.515,"x":21597.25,"y":591440.345,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_34_figure_title_1_v2.jpg","height":24764.735,"width":238000.104,"x":101470.371,"y":250426.193,"original_width":1572,"original_height":127,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_34_header_1_v2.jpg","height":5700.714,"width":30405.354,"x":320734.673,"y":27704.2,"original_width":201,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_34_number_1_v2.jpg","height":5999.094,"width":18269.765,"x":332853.042,"y":591772.658,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_34_header_2_v2.jpg","height":5718.861,"width":42947.798,"x":47753.49,"y":27915.119,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_34_algorithm_1_v2.jpg","height":201996.087,"width":247727.415,"x":103428.727,"y":43324.589,"original_width":1636,"original_height":1031,"rotation":0,"type":"layout_v2_algorithm"},{"name":"page_34_header_3_v2.jpg","height":10771.052,"width":24389.551,"x":21853.842,"y":22413.487,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                      Neuroscience","md":"eLife Tools and resources                                                                                      Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":111,"endIndex":123}]},{"type":"text","value":"Create a new HindmarshRose cell component with parameters for regular spiking","md":"Create a new HindmarshRose cell component with parameters for regular spiking","bBox":{"x":174.65,"y":58.88,"w":329.52,"h":8.69},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":0,"endIndex":6}]},{"type":"text","value":"```python\nnml_doc = component_factory(\"NeuroMLDocument\", id=\"HindmarshRoseNeuron\")\nhr0 = nml_doc.add(\"HindmarshRose1984Cell\", id=\"hr_regular\", a=\"1.0\", b=\"3.0\", c=\"-3.0\", d=\"5.0\",\n s=\"4.0\", x1=\"-1.3\", r=\"0.002\", x0=\"-1.1\", y0=\"-9\", z0=\"1.0\", C=\"28.57142857pF\",\n v_scaling=\"35.0mV\")\nnet = nml_doc.add(\"Network\", id=\"HRNet\", validate=False)\n```","md":"```python\nnml_doc = component_factory(\"NeuroMLDocument\", id=\"HindmarshRoseNeuron\")\nhr0 = nml_doc.add(\"HindmarshRose1984Cell\", id=\"hr_regular\", a=\"1.0\", b=\"3.0\", c=\"-3.0\", d=\"5.0\",\n s=\"4.0\", x1=\"-1.3\", r=\"0.002\", x0=\"-1.1\", y0=\"-9\", z0=\"1.0\", C=\"28.57142857pF\",\n v_scaling=\"35.0mV\")\nnet = nml_doc.add(\"Network\", id=\"HRNet\", validate=False)\n```","bBox":{"x":190.88,"y":99.73,"w":384.12,"h":318.75},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":10,"endIndex":17}]},{"type":"text","value":"Create a population of cells (1 cell)","md":"Create a population of cells (1 cell)","bBox":{"x":174.65,"y":134.4,"w":138.39,"h":8.69},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":0,"endIndex":6}]},{"type":"text","value":"```python\npop0 = net.add(\"Population\", id=\"HRPop0\", component=hr0.id, size=1)\n```","md":"```python\npop0 = net.add(\"Population\", id=\"HRPop0\", component=hr0.id, size=1)\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":10,"endIndex":14}]},{"type":"text","value":"Add external stimuli to the population","md":"Add external stimuli to the population","bBox":{"x":174.65,"y":168.21,"w":153.59,"h":8.69},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":0,"endIndex":3}]},{"type":"text","value":"```python\npg = nml_doc.add(\"PulseGenerator\", id=\"pulseGen_%i\" % 0, delay=\"0s\", duration=\"1000s\",\n amplitude=\"5nA\")\nexp_input = net.add(\"ExplicitInput\", target=\"%s[%i]\" % (pop0.id, 0), input=pg.id,\n destination=\"synapses\")\n```","md":"```python\npg = nml_doc.add(\"PulseGenerator\", id=\"pulseGen_%i\" % 0, delay=\"0s\", duration=\"1000s\",\n amplitude=\"5nA\")\nexp_input = net.add(\"ExplicitInput\", target=\"%s[%i]\" % (pop0.id, 0), input=pg.id,\n destination=\"synapses\")\n```","bBox":{"x":174.65,"y":188.2,"w":352.85,"h":39.01},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":10,"endIndex":12}]},{"type":"text","value":"Save (serialize) the model to a file","md":"Save (serialize) the model to a file","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":0,"endIndex":4}]},{"type":"text","value":"```python\nnml_file = 'hindmarshrose1984_single_cell_network.nml'\nwriters.NeuroMLWriter.write(nml_doc, nml_file)\n```","md":"```python\nnml_file = 'hindmarshrose1984_single_cell_network.nml'\nwriters.NeuroMLWriter.write(nml_doc, nml_file)\n```","bBox":{"x":223.9,"y":252.56,"w":168.19,"h":7.73},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":16,"endIndex":18}]},{"type":"text","value":"Validate the model","md":"Validate the model","bBox":{"x":174.65,"y":276.81,"w":75.98,"h":8.69},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":0,"endIndex":8}]},{"type":"text","value":"```python\nvalidate_neuroml2(nml_file)\n```","md":"```python\nvalidate_neuroml2(nml_file)\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":169,"y":54,"w":404,"h":255,"startIndex":10,"endIndex":18}]},{"type":"text","value":"**Figure 14.** Example model description of a HindmarshRose1984Cell NeuroML component in Python using parameters for regular bursting. This script generates the XML in Figure 11. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","md":"**Figure 14.** Example model description of a HindmarshRose1984Cell NeuroML component in Python using parameters for regular bursting. This script generates the XML in Figure 11. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","bBox":{"x":168.53,"y":338.32,"w":385.5,"h":8},"layoutAwareBbox":[{"x":165,"y":316,"w":388,"h":31,"startIndex":0,"endIndex":310}]},{"type":"text","value":"itself or share the XML serialization. Any valid XML serialization can be also loaded into a Python object model and modified.","md":"itself or share the XML serialization. Any valid XML serialization can be also loaded into a Python object model and modified.","bBox":{"x":168.53,"y":373.49,"w":390.83,"h":9},"layoutAwareBbox":[{"x":165,"y":373,"w":408,"h":21,"startIndex":0,"endIndex":125}]},{"type":"text","value":"XML is the default serialization of NeuroML and all existing APIs can read and write the format (and it should be seen as a minimal requirement for new APIs to support XML). There is, however, an alternative HDF5 (https://www.hdfgroup.org/solutions/hdf5) based serialization of NeuroML files which is supported by both libNeuroML and the Java API, org.neuroml.model (https://docs.neuroml.org/Userdocs/HDF5.html). This format is based on an efficient representation of cell positions and connectivity data as HDF5 data sets which can be serialized in compact binary format and loaded into memory for optimized access (e.g. as numpy arrays in libNeuroML). This reduces the size of the saved files for large-scale networks and speeds up loading/writing models eliminating the need to parse/generate large text files containing XML. Models serialized in this format can be loaded and transformed to simulator code in the same way as XML-based models by the Java and Python APIs.","md":"XML is the default serialization of NeuroML and all existing APIs can read and write the format (and it should be seen as a minimal requirement for new APIs to support XML). There is, however, an alternative HDF5 (https://www.hdfgroup.org/solutions/hdf5) based serialization of NeuroML files which is supported by both libNeuroML and the Java API, org.neuroml.model (https://docs.neuroml.org/Userdocs/HDF5.html). This format is based on an efficient representation of cell positions and connectivity data as HDF5 data sets which can be serialized in compact binary format and loaded into memory for optimized access (e.g. as numpy arrays in libNeuroML). This reduces the size of the saved files for large-scale networks and speeds up loading/writing models eliminating the need to parse/generate large text files containing XML. Models serialized in this format can be loaded and transformed to simulator code in the same way as XML-based models by the Java and Python APIs.","bBox":{"x":168.53,"y":397.49,"w":415.1,"h":116.97},"layoutAwareBbox":[{"x":165,"y":397,"w":409,"h":117,"startIndex":0,"endIndex":3}]},{"type":"heading","lvl":2,"value":"Simulating NeuroML models","md":"## Simulating NeuroML models","bBox":{"x":168.53,"y":526.49,"w":160.65,"h":12},"layoutAwareBbox":[{"x":165,"y":528,"w":163,"h":11,"startIndex":0,"endIndex":27}]},{"type":"text","value":"The model description shown in Figure 11 contains no information about how it is to be simulated, or on the dynamics of each model component. Providing this simulation information and linking in the ComponentType definition requires creating a LEMS file to fully specify the simulation. Figure 15 shows the use of utilities included in the Python pyNeuroML package to describe a LEMS simulation of the HindmarshRose model defined in Figure 11. The LEMSSimulation object includes simulation specific information such as the duration of the simulation, the integration time step, and the seed value. It also allows the specification of files for the storage of data recorded from the simulation. In this example, we record the membrane potential, v, of our cell in its population, HRPop0[0]. Similar to the NeuroMLv2 model description, the simulation object can also be serialized to XML for storage and sharing (Figure 15, bottom).","md":"The model description shown in Figure 11 contains no information about how it is to be simulated, or on the dynamics of each model component. Providing this simulation information and linking in the ComponentType definition requires creating a LEMS file to fully specify the simulation. Figure 15 shows the use of utilities included in the Python pyNeuroML package to describe a LEMS simulation of the HindmarshRose model defined in Figure 11. The LEMSSimulation object includes simulation specific information such as the duration of the simulation, the integration time step, and the seed value. It also allows the specification of files for the storage of data recorded from the simulation. In this example, we record the membrane potential, v, of our cell in its population, HRPop0[0]. Similar to the NeuroMLv2 model description, the simulation object can also be serialized to XML for storage and sharing (Figure 15, bottom).","bBox":{"x":168.53,"y":554.49,"w":409.39,"h":93},"layoutAwareBbox":[{"x":168.53,"y":554.49,"w":409.39,"h":93,"startIndex":0,"endIndex":929}]},{"type":"text","value":"As noted previously, NeuroML/LEMS model and simulation descriptions are machine readable and simulator independent and can be simulated by simulation engines using a multitude of strategies (Figure 5).","md":"As noted previously, NeuroML/LEMS model and simulation descriptions are machine readable and simulator independent and can be simulated by simulation engines using a multitude of strategies (Figure 5).","bBox":{"x":168.53,"y":662.48,"w":411.35,"h":21},"layoutAwareBbox":[{"x":165,"y":663,"w":408,"h":33,"startIndex":0,"endIndex":200}]},{"type":"text","value":"The first category of tools consists of the reference NeuroML and LEMS simulation engines. These work directly with NeuroML and LEMS as their base descriptions of modeling entities and do not","md":"The first category of tools consists of the reference NeuroML and LEMS simulation engines. These work directly with NeuroML and LEMS as their base descriptions of modeling entities and do not","bBox":{"x":168.53,"y":710.47,"w":393.18,"h":9},"layoutAwareBbox":[{"x":165,"y":698,"w":408,"h":22,"startIndex":0,"endIndex":190}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    34 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    34 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://www.hdfgroup.org/solutions/hdf5","unsafeUrl":"https://www.hdfgroup.org/solutions/hdf5","text":"native HDF5 (https://www.hdfgroup.org/solutions/hdf5) based serialization of NeuroML ﬁles which is "},{"url":"https://docs.neuroml.org/Userdocs/HDF5.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/HDF5.html","text":"model (https://docs.neuroml.org/User-"},{"url":"https://docs.neuroml.org/Userdocs/HDF5.html","unsafeUrl":"https://docs.neuroml.org/Userdocs/HDF5.html","text":"docs/HDF5.html). This format is based on an efﬁcient representation of cell positions and connectivity "},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","text":"available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples."}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                      Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    34 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.95,"layout":[{"image":"page_34_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.502,"w":0.668,"h":0.149},"isLikelyNoise":false},{"image":"page_34_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.685,"w":0.669,"h":0.148},"isLikelyNoise":false},{"image":"page_34_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.837,"w":0.668,"h":0.042},"isLikelyNoise":false},{"image":"page_34_text_4_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.271,"y":0.882,"w":0.668,"h":0.028},"isLikelyNoise":false},{"image":"page_34_text_5_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.27,"y":0.472,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_34_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.271,"y":0.667,"w":0.267,"h":0.014},"isLikelyNoise":false},{"image":"page_34_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_34_figure_title_1_v2.jpg","confidence":0.89,"label":"figure_title","bbox":{"x":0.271,"y":0.399,"w":0.635,"h":0.039},"isLikelyNoise":false},{"image":"page_34_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_34_number_1_v2.jpg","confidence":0.84,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.01},"isLikelyNoise":false},{"image":"page_34_header_2_v2.jpg","confidence":0.67,"label":"header","bbox":{"x":0.127,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_34_algorithm_1_v2.jpg","confidence":0.65,"label":"algorithm","bbox":{"x":0.276,"y":0.069,"w":0.661,"h":0.322},"isLikelyNoise":false},{"image":"page_34_header_3_v2.jpg","confidence":0.53,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":35,"text":"Tools  and  resources                                                                         Neuroscience\n\n                          Create a simulation of the model\n\n                          simulation_id = \"example-single-hindmarshrose1984cell-sim\"\n                          simulation = LΕMSSimulation(sim_id=simulation_id, duration=1.4e3, dt=0.0025, simulation_seed=123)\n                          simulation.assign_simulation_target(net.id)\n                          simulation.include_neuroml2_ƒile(nml_ƒile)\n                          Record membrane potential to an output ﬁle\n\n                          simulation.create_output_ƒile(\"output0\", \"%s.v.dat\" % simulation_id)\n                          simulation.add_column_to_output_ƒile(\"output0\", ΗRPop0[0] ,  ΗRPop0[0]/v )\n                          Save the simulation to ﬁle and run it in jNeuroML/jLEMS\n\n                          lems_simulation_ƒile = simulation.save_to_ƒile()\n                          pynml.run_lems_with_jneuroml(lems_simulation_ƒile, max_memory=\"2G\", nogui=True, plot=False)\n\n                          LEMS simulation description serialization\n\n                          <Lems>\n                           <!-- Speciƒy which component to run -->\n                           <Target  component=\"example-single-hindmarshrose1984cell-sim\"/>\n\n                           <!-- Include core NeuroML2 ComponentType deƒinitions -->\n                           <Ιnclude  ƒile=\"Cells.xml\"/>\n                           <Ιnclude  ƒile=\"Networks.xml\"/>\n                           <Ιnclude  ƒile=\"Simulation.xml\"/>\n\n                           <Ιnclude  ƒile=\"hindmarshrose1984_single_cell_network.nml\"/>\n\n                           <Simulation id=\"example-single-hindmarshrose1984cell-sim\" length=\"1400.0ms\" step=\"0.0025ms\"\n                                 target=\"ΗRNet\" seed=\"123\">  <!-- Note seed: ensures same random numbers used every run\n                                 -->\n                                 <OutputFile id=\"output0\" ƒileName=\"example-single-hindmarshrose1984cell-sim.v.dat\">\n                                    <OutputColumn id=\"ΗRPop0[0]\" quantity=\"ΗRPop0[0]/v\"/>\n                                 </OutputFile>\n                           </Simulation>\n                          </Lems>\n\n                         Figure 15. An example simulation of the HindmarshRose model description shown in Figure 14 with the\n                         LEMS serialization shown at the bottom. The code used in this example is available here: https://github.com/\n                         OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.\n\n\n\nhave their own speciﬁc formats. They are maintained by the NeuroML Editorial Board—jLEMS, jNeu-\nroML, and PyLEMS (Figure 4). jLEMS serves as the reference implementation for the LEMS language\nand as such it can simulate any model described in LEMS (not necessarily from neuroscience). When\ncoupled with the LEMS deﬁnitions of NeuroML standard entity structure/dynamics, it can simulate\nmost NeuroML models, though it does not currently support multi-  compartmental neurons. jNeu-\nroML bundles the NeuroML standard LEMS deﬁnitions, jLEMS, and other functionality into a single\npackage for ease of installation/usage. There is also a pure Python implementation of a LEMS inter -\npreter, PyLEMS, which can be used in a similar way to jLEMS. The pyNeuroML package encapsulates\nall of these tools to give easy access (at both command line and in Python) to all of their functionality\n(Figure 6).\nThe second category consists of other simulators which support NeuroML natively. The EDEN\nsimulator is an independently developed tool that was designed from its inception to read NeuroML\nand LEMS models for efﬁcient, parallel simulation (Panagiotou et al., 2022).\nThe third category involves simulators which have their own internal formats and include methods\nto translate NeuroMLv2/LEMS models to their own formats. Examples include NetPyNE (Dura‐ Bernal\net al., 2019), MOOSE (Ray and Bhalla, 2008), and N2A (Rothganger et al., 2014).\nThe fourth category comprises tools for which the NeuroML tools generate simulator speciﬁc scripts.\nThe simulation engines then execute these scripts, similar to how they would execute handwritten\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    35 of 44","md":"\n\neLife Tools and resources                                                                         Neuroscience\n\n## Create a simulation of the model\n\n```python\nsimulation_id = \"example-single-hindmarshrose1984cell-sim\"\nsimulation = LEMSSimulation(sim_id=simulation_id, duration=1.4e3, dt=0.0025, simulation_seed=123)\nsimulation.assign_simulation_target(net.id)\nsimulation.include_neuroml2_file(nml_file)\n```\n\n## Record membrane potential to an output file\n\n```python\nsimulation.create_output_file(\"output0\", \"%s.v.dat\" % simulation_id)\nsimulation.add_column_to_output_file(\"output0\", 'HRPop0[0]', 'HRPop0[0]/v')\n```\n\n## Save the simulation to file and run it in jNeuroML/jLEMS\n\n```python\nlems_simulation_file = simulation.save_to_file()\npynml.run_lems_with_jneuroml(lems_simulation_file, max_memory=\"2G\", nogui=True, plot=False)\n```\n\n## LEMS simulation description serialization\n\n```xml\n<Lems>\n \n <Target component=\"example-single-hindmarshrose1984cell-sim\"/>\n\n \n <Include file=\"Cells.xml\"/>\n <Include file=\"Networks.xml\"/>\n <Include file=\"Simulation.xml\"/>\n\n <Include file=\"hindmarshrose1984_single_cell_network.nml\"/>\n\n <Simulation id=\"example-single-hindmarshrose1984cell-sim\" length=\"1400.0ms\" step=\"0.0025ms\"\n       target=\"HRNet\" seed=\"123\">  \n       <OutputFile id=\"output0\" fileName=\"example-single-hindmarshrose1984cell-sim.v.dat\">\n          <OutputColumn id=\"HRPop0[0]\" quantity=\"HRPop0[0]/v\"/>\n       </OutputFile>\n </Simulation>\n</Lems>\n```\n\n**Figure 15.** An example simulation of the HindmarshRose model description shown in Figure 14 with the LEMS serialization shown at the bottom. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.\n\nhave their own specific formats. They are maintained by the NeuroML Editorial Board—jLEMS, jNeuroML, and PyLEMS (Figure 4). jLEMS serves as the reference implementation for the LEMS language and as such it can simulate any model described in LEMS (not necessarily from neuroscience). When coupled with the LEMS definitions of NeuroML standard entity structure/dynamics, it can simulate most NeuroML models, though it does not currently support multi-compartmental neurons. jNeuroML bundles the NeuroML standard LEMS definitions, jLEMS, and other functionality into a single package for ease of installation/usage. There is also a pure Python implementation of a LEMS interpreter, PyLEMS, which can be used in a similar way to jLEMS. The pyNeuroML package encapsulates all of these tools to give easy access (at both command line and in Python) to all of their functionality (Figure 6).\n\nThe second category consists of other simulators which support NeuroML natively. The EDEN simulator is an independently developed tool that was designed from its inception to read NeuroML and LEMS models for efficient, parallel simulation (Panagiotou et al., 2022).\n\nThe third category involves simulators which have their own internal formats and include methods to translate NeuroMLv2/LEMS models to their own formats. Examples include NetPyNE (Dura-Bernal et al., 2019), MOOSE (Ray and Bhalla, 2008), and N2A (Rothganger et al., 2014).\n\nThe fourth category comprises tools for which the NeuroML tools generate simulator specific scripts. The simulation engines then execute these scripts, similar to how they would execute handwritten\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    35 of 44\n","images":[{"name":"page_35.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_35_text_1_v2.jpg","height":93194.67,"width":250245.544,"x":101056.887,"y":401267.445,"original_width":1653,"original_height":476,"rotation":0,"type":"layout_v2_text"},{"name":"page_35_text_2_v2.jpg","height":26600.698,"width":250751.77,"x":101156.686,"y":525045.842,"original_width":1656,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_35_text_3_v2.jpg","height":26591.426,"width":250477.488,"x":101098.119,"y":496342.163,"original_width":1654,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_35_text_4_v2.jpg","height":17161.551,"width":250048.376,"x":101351.666,"y":553719.511,"original_width":1651,"original_height":88,"rotation":0,"type":"layout_v2_text"},{"name":"page_35_figure_title_1_v2.jpg","height":24236.5,"width":237455.731,"x":101351.606,"y":352628.356,"original_width":1568,"original_height":124,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_35_footer_1_v2.jpg","height":6959.964,"width":191785.864,"x":21539.798,"y":591395.789,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_35_header_1_v2.jpg","height":5690.399,"width":30445.944,"x":320714.303,"y":27669.597,"original_width":202,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_35_number_1_v2.jpg","height":5883.187,"width":18241.352,"x":332872.867,"y":591774.618,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_35_header_2_v2.jpg","height":5825.975,"width":42885.875,"x":47730.191,"y":27788.826,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_35_image_1_v2.jpg","height":304322.141,"width":247551.062,"x":103416.248,"y":42598.601,"original_width":1635,"original_height":1553,"rotation":0,"type":"layout_v2_image"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                         Neuroscience","md":"eLife Tools and resources                                                                         Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":98,"endIndex":110}]},{"type":"heading","lvl":2,"value":"Create a simulation of the model","md":"## Create a simulation of the model","bBox":{"x":174.65,"y":58.89,"w":131.16,"h":8.6},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":3,"endIndex":9}]},{"type":"text","value":"```python\nsimulation_id = \"example-single-hindmarshrose1984cell-sim\"\nsimulation = LEMSSimulation(sim_id=simulation_id, duration=1.4e3, dt=0.0025, simulation_seed=123)\nsimulation.assign_simulation_target(net.id)\nsimulation.include_neuroml2_file(nml_file)\n```","md":"```python\nsimulation_id = \"example-single-hindmarshrose1984cell-sim\"\nsimulation = LEMSSimulation(sim_id=simulation_id, duration=1.4e3, dt=0.0025, simulation_seed=123)\nsimulation.assign_simulation_target(net.id)\nsimulation.include_neuroml2_file(nml_file)\n```","bBox":{"x":174.65,"y":75.91,"w":235.49,"h":28.29},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":10,"endIndex":20}]},{"type":"heading","lvl":2,"value":"Record membrane potential to an output file","md":"## Record membrane potential to an output file","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":3,"endIndex":9}]},{"type":"text","value":"```python\nsimulation.create_output_file(\"output0\", \"%s.v.dat\" % simulation_id)\nsimulation.add_column_to_output_file(\"output0\", 'HRPop0[0]', 'HRPop0[0]/v')\n```","md":"```python\nsimulation.create_output_file(\"output0\", \"%s.v.dat\" % simulation_id)\nsimulation.add_column_to_output_file(\"output0\", 'HRPop0[0]', 'HRPop0[0]/v')\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":10,"endIndex":20}]},{"type":"heading","lvl":2,"value":"Save the simulation to file and run it in jNeuroML/jLEMS","md":"## Save the simulation to file and run it in jNeuroML/jLEMS","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":3,"endIndex":7}]},{"type":"text","value":"```python\nlems_simulation_file = simulation.save_to_file()\npynml.run_lems_with_jneuroml(lems_simulation_file, max_memory=\"2G\", nogui=True, plot=False)\n```","md":"```python\nlems_simulation_file = simulation.save_to_file()\npynml.run_lems_with_jneuroml(lems_simulation_file, max_memory=\"2G\", nogui=True, plot=False)\n```","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":10,"endIndex":12}]},{"type":"heading","lvl":2,"value":"LEMS simulation description serialization","md":"## LEMS simulation description serialization","bBox":{"x":174.65,"y":217.62,"w":163.73,"h":8.6},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":3,"endIndex":5}]},{"type":"text","value":"```xml\n<Lems>\n \n <Target component=\"example-single-hindmarshrose1984cell-sim\"/>","md":"```xml\n<Lems>\n \n <Target component=\"example-single-hindmarshrose1984cell-sim\"/>","bBox":{"x":174.65,"y":237.4,"w":267.63,"h":28.29},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":8,"endIndex":10}]},{"type":"text","value":"<Include file=\"Cells.xml\"/>\n <Include file=\"Networks.xml\"/>\n <Include file=\"Simulation.xml\"/>","md":"<Include file=\"Cells.xml\"/>\n <Include file=\"Networks.xml\"/>\n <Include file=\"Simulation.xml\"/>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":92}]},{"type":"text","value":"<Include file=\"hindmarshrose1984_single_cell_network.nml\"/>","md":"<Include file=\"hindmarshrose1984_single_cell_network.nml\"/>","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":1,"endIndex":3}]},{"type":"text","value":"<Simulation id=\"example-single-hindmarshrose1984cell-sim\" length=\"1400.0ms\" step=\"0.0025ms\"\n       target=\"HRNet\" seed=\"123\">  \n       <OutputFile id=\"output0\" fileName=\"example-single-hindmarshrose1984cell-sim.v.dat\">\n          <OutputColumn id=\"HRPop0[0]\" quantity=\"HRPop0[0]/v\"/>\n       </OutputFile>\n </Simulation>\n</Lems>\n```","md":"<Simulation id=\"example-single-hindmarshrose1984cell-sim\" length=\"1400.0ms\" step=\"0.0025ms\"\n       target=\"HRNet\" seed=\"123\">  \n       <OutputFile id=\"output0\" fileName=\"example-single-hindmarshrose1984cell-sim.v.dat\">\n          <OutputColumn id=\"HRPop0[0]\" quantity=\"HRPop0[0]/v\"/>\n       </OutputFile>\n </Simulation>\n</Lems>\n```","bBox":{"x":174.61,"y":350.93,"w":385.31,"h":79.89},"layoutAwareBbox":[{"x":168,"y":53,"w":404,"h":384,"startIndex":1,"endIndex":11}]},{"type":"text","value":"**Figure 15.** An example simulation of the HindmarshRose model description shown in Figure 14 with the LEMS serialization shown at the bottom. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","md":"**Figure 15.** An example simulation of the HindmarshRose model description shown in Figure 14 with the LEMS serialization shown at the bottom. The code used in this example is available here: https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples.","bBox":{"x":168.53,"y":456.31,"w":385.21,"h":19},"layoutAwareBbox":[{"x":165,"y":445,"w":387,"h":30,"startIndex":212,"endIndex":275}]},{"type":"text","value":"have their own specific formats. They are maintained by the NeuroML Editorial Board—jLEMS, jNeuroML, and PyLEMS (Figure 4). jLEMS serves as the reference implementation for the LEMS language and as such it can simulate any model described in LEMS (not necessarily from neuroscience). When coupled with the LEMS definitions of NeuroML standard entity structure/dynamics, it can simulate most NeuroML models, though it does not currently support multi-compartmental neurons. jNeuroML bundles the NeuroML standard LEMS definitions, jLEMS, and other functionality into a single package for ease of installation/usage. There is also a pure Python implementation of a LEMS interpreter, PyLEMS, which can be used in a similar way to jLEMS. The pyNeuroML package encapsulates all of these tools to give easy access (at both command line and in Python) to all of their functionality (Figure 6).","md":"have their own specific formats. They are maintained by the NeuroML Editorial Board—jLEMS, jNeuroML, and PyLEMS (Figure 4). jLEMS serves as the reference implementation for the LEMS language and as such it can simulate any model described in LEMS (not necessarily from neuroscience). When coupled with the LEMS definitions of NeuroML standard entity structure/dynamics, it can simulate most NeuroML models, though it does not currently support multi-compartmental neurons. jNeuroML bundles the NeuroML standard LEMS definitions, jLEMS, and other functionality into a single package for ease of installation/usage. There is also a pure Python implementation of a LEMS interpreter, PyLEMS, which can be used in a similar way to jLEMS. The pyNeuroML package encapsulates all of these tools to give easy access (at both command line and in Python) to all of their functionality (Figure 6).","bBox":{"x":168.53,"y":530.48,"w":408.92,"h":80.98},"layoutAwareBbox":[{"x":165,"y":506,"w":408,"h":117,"startIndex":5,"endIndex":8}]},{"type":"text","value":"The second category consists of other simulators which support NeuroML natively. The EDEN simulator is an independently developed tool that was designed from its inception to read NeuroML and LEMS models for efficient, parallel simulation (Panagiotou et al., 2022).","md":"The second category consists of other simulators which support NeuroML natively. The EDEN simulator is an independently developed tool that was designed from its inception to read NeuroML and LEMS models for efficient, parallel simulation (Panagiotou et al., 2022).","bBox":{"x":168.53,"y":626.45,"w":407.2,"h":21},"layoutAwareBbox":[{"x":165,"y":626,"w":409,"h":33,"startIndex":0,"endIndex":264}]},{"type":"text","value":"The third category involves simulators which have their own internal formats and include methods to translate NeuroMLv2/LEMS models to their own formats. Examples include NetPyNE (Dura-Bernal et al., 2019), MOOSE (Ray and Bhalla, 2008), and N2A (Rothganger et al., 2014).","md":"The third category involves simulators which have their own internal formats and include methods to translate NeuroMLv2/LEMS models to their own formats. Examples include NetPyNE (Dura-Bernal et al., 2019), MOOSE (Ray and Bhalla, 2008), and N2A (Rothganger et al., 2014).","bBox":{"x":180.52,"y":578.46,"w":396.38,"h":92.98},"layoutAwareBbox":[{"x":165,"y":662,"w":409,"h":33,"startIndex":180,"endIndex":184}]},{"type":"text","value":"The fourth category comprises tools for which the NeuroML tools generate simulator specific scripts. The simulation engines then execute these scripts, similar to how they would execute handwritten","md":"The fourth category comprises tools for which the NeuroML tools generate simulator specific scripts. The simulation engines then execute these scripts, similar to how they would execute handwritten","bBox":{"x":168.53,"y":710.43,"w":397.63,"h":9},"layoutAwareBbox":[{"x":165,"y":699,"w":408,"h":21,"startIndex":0,"endIndex":3}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    35 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    35 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","text":"LEMS serialization shown at the bottom. The code used in this example is available here: https://github.com/"},{"url":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","unsafeUrl":"https://github.com/OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples","text":"OpenSourceBrain/HindmarshRose1984/tree/master/NeuroML2/examples."}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                         Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    35 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.945,"layout":[{"image":"page_35_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.64,"w":0.668,"h":0.149},"isLikelyNoise":false},{"image":"page_35_text_2_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.837,"w":0.669,"h":0.042},"isLikelyNoise":false},{"image":"page_35_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.791,"w":0.669,"h":0.042},"isLikelyNoise":false},{"image":"page_35_text_4_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.271,"y":0.883,"w":0.668,"h":0.027},"isLikelyNoise":false},{"image":"page_35_figure_title_1_v2.jpg","confidence":0.91,"label":"figure_title","bbox":{"x":0.271,"y":0.562,"w":0.634,"h":0.039},"isLikelyNoise":false},{"image":"page_35_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_35_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_35_number_1_v2.jpg","confidence":0.86,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_35_header_2_v2.jpg","confidence":0.64,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_35_image_1_v2.jpg","confidence":0.63,"label":"image","bbox":{"x":0.276,"y":0.068,"w":0.661,"h":0.485},"isLikelyNoise":false}]},{"page":36,"text":"Tools  and  resources                                                                                              Neuroscience\n\n                         user scripts. These include NEURON (Hines and Carnevale, 1997) for which the NeuroML tools\n                         generate scripts in Python and the simulator’s hoc and NMODL formats and the Brian simulator (Stim‐\n                         berg et al., 2019) which uses Python scripts.\n                         The ﬁnal category consists of export options to standardized formats in neuroscience and the wider\n                         computational biology ﬁeld, which enable interaction with simulators and applications supporting\n                         those formats. These include the PyNN package (Davison et al., 2008), which can be run in either\n                         NEURON, NEST (Gewaltig and Diesmann, 2007) or Brian, the SONATA data format (Dai et al., 2020)\n                         and the SBML standard (Hucka et al., 2003) (see Reusing NeuroML models for more details).\n                         Having multiple strategies in place for supporting NeuroML gives more freedom to simulator devel-\n                         opers to choose how much they wish to be involved with implementing and supporting NeuroML\n                         functionality in their applications, while maximizing the options available for end users.\n                         The primary tool for simulating NeuroML/LEMS models via different engines is jNeuroML, which\n                         is included in pyNeuroML. jNeuroML supports all simulator engine categories (Figure 5). It includes\n                         jLEMS for simulation of LEMS and single compartmental NeuroML models. It can also pass simula-\n                         tions to the EDEN simulator (Panagiotou et al., 2022) for direct simulation. Using the    org.neuroml.\n                         export library (https://github.com/NeuroML/org.neuroml.export), jNeuroML can also generate import\n                         scripts for simulators (e.g. NetPyNE Dura‐ Bernal et al., 2019) or convert NeuroML/LEMS models to\n                         simulator speciﬁc formats (e.g. NEURON Hines and Carnevale, 1997). Supporting a new simulation\n                         engine that requires translation of NeuroML/LEMS into another format can be done by adding a\n                         new ‘writer’ to the org.neuroml.export library. Finally, jNeuroML also includes the\n                                                                                                   org.neuroml.import\n                         (https://github.com/NeuroML/jNeuroML) library that converts from other formats (e.g. SBML Hucka\n                         et al., 2003) to LEMS for combination with NeuroML models.\n                         It is important to note though that not all NeuroML models can be exported to/are supported by\n                         each of these target simulators (Table 7). This depends on the capabilities of the simulator in ques-\n                         tion (whether it supports networks, or morphologically detailed cells) and pyNeuroML/jNeuroML will\n                         provide feedback if a feature of the model is not supported in a chosen environment.\n                         All NeuroML and LEMS software packages are made available under FOSS licenses. The source\n                         code for all NeuroML packages and the standard can be obtained from the NeuroML GitHub orga-\n                         nization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEn-\n                         semble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://\n                         github.com/NeuralEnsemble/), which also maintains other commonly used Python packages such as\n                         PyNN (Davison et al., 2008), Neo (Garcia et al., 2014) and Elephant (Denker, 2018). LEMS packages\n                         are available from the LEMS GitHub organization (https://github.com/LEMS).\n                         To ensure replication and reproduction of studies, it is important to note the exact versions of\n                         software used in studies. For NeuroML and LEMS packages, archives of each release along with cita-\n                         tions are published on Zenodo (https://zenodo.org) to enable researchers to cite them in their work\n                         (Gleeson, 2021; Gleeson, 2024a; Gleeson et al., 2019b; Gleeson, 2024b; Sinha, 2024).\n\n                         Documentation\n                         A standard and its accompanying software ecosystem must be supported by comprehensive docu-\n                         mentation if it is to be of use to the research community. The primary NeuroML documentation for\n                         users that accompanies this paper has been consolidated into a JupyterBook (Executable Books\n                         Community, 2020) at https://docs.neuroml.org. This includes explanations of NeuroML and compu-\n                         tational modeling concepts, interactive tutorials with varying levels of complexity, information about\n                         tools and what functions they provide to support different stages of the model life cycle. The Jupy-\n                         terBook framework supports ‘executable’ documentation through the inclusion of interactive Jupyter\n                         notebooks which may be run in the users’ web browser on free services such as OSBv2,      Binder.org\n                         (https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine\n                         readable nature of the schema and LEMS also enables the automated generation of human readable\n                         documentation for the standard and low level APIs (Figure  16) along with their examples (https://\n                         docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). In addition, the individual\n                         NeuroML software packages each have their own individual documentation (e.g. pyNeuroML (https://\n                         pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/)).\n                         As with the rest of the NeuroML ecosystem, the documentation is hosted on GitHub (https://\n                         github.com/NeuroML/Documentation), licensed under a FOSS license, and community contributions\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    36 of 44","md":"\n\neLife Tools and resources                                                                                              Neuroscience\n\nuser scripts. These include NEURON (Hines and Carnevale, 1997) for which the NeuroML tools generate scripts in Python and the simulator's hoc and NMODL formats and the Brian simulator (Stimberg et al., 2019) which uses Python scripts.\n\nThe final category consists of export options to standardized formats in neuroscience and the wider computational biology field, which enable interaction with simulators and applications supporting those formats. These include the PyNN package (Davison et al., 2008), which can be run in either NEURON, NEST (Gewaltig and Diesmann, 2007) or Brian, the SONATA data format (Dai et al., 2020) and the SBML standard (Hucka et al., 2003) (see Reusing NeuroML models for more details).\n\nHaving multiple strategies in place for supporting NeuroML gives more freedom to simulator developers to choose how much they wish to be involved with implementing and supporting NeuroML functionality in their applications, while maximizing the options available for end users.\n\nThe primary tool for simulating NeuroML/LEMS models via different engines is jNeuroML, which is included in pyNeuroML. jNeuroML supports all simulator engine categories (Figure 5). It includes jLEMS for simulation of LEMS and single compartmental NeuroML models. It can also pass simulations to the EDEN simulator (Panagiotou et al., 2022) for direct simulation. Using the org.neuroml.export library (https://github.com/NeuroML/org.neuroml.export), jNeuroML can also generate import scripts for simulators (e.g. NetPyNE Dura-Bernal et al., 2019) or convert NeuroML/LEMS models to simulator specific formats (e.g. NEURON Hines and Carnevale, 1997). Supporting a new simulation engine that requires translation of NeuroML/LEMS into another format can be done by adding a new 'writer' to the org.neuroml.export library. Finally, jNeuroML also includes the org.neuroml.import (https://github.com/NeuroML/jNeuroML) library that converts from other formats (e.g. SBML Hucka et al., 2003) to LEMS for combination with NeuroML models.\n\nIt is important to note though that not all NeuroML models can be exported to/are supported by each of these target simulators (Table 7). This depends on the capabilities of the simulator in question (whether it supports networks, or morphologically detailed cells) and pyNeuroML/jNeuroML will provide feedback if a feature of the model is not supported in a chosen environment.\n\nAll NeuroML and LEMS software packages are made available under FOSS licenses. The source code for all NeuroML packages and the standard can be obtained from the NeuroML GitHub organization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEnsemble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://github.com/NeuralEnsemble/), which also maintains other commonly used Python packages such as PyNN (Davison et al., 2008), Neo (Garcia et al., 2014) and Elephant (Denker, 2018). LEMS packages are available from the LEMS GitHub organization (https://github.com/LEMS).\n\nTo ensure replication and reproduction of studies, it is important to note the exact versions of software used in studies. For NeuroML and LEMS packages, archives of each release along with citations are published on Zenodo (https://zenodo.org) to enable researchers to cite them in their work (Gleeson, 2021; Gleeson, 2024a; Gleeson et al., 2019b; Gleeson, 2024b; Sinha, 2024).\n\n## Documentation\n\nA standard and its accompanying software ecosystem must be supported by comprehensive documentation if it is to be of use to the research community. The primary NeuroML documentation for users that accompanies this paper has been consolidated into a JupyterBook (Executable Books Community, 2020) at https://docs.neuroml.org. This includes explanations of NeuroML and computational modeling concepts, interactive tutorials with varying levels of complexity, information about tools and what functions they provide to support different stages of the model life cycle. The JupyterBook framework supports 'executable' documentation through the inclusion of interactive Jupyter notebooks which may be run in the users' web browser on free services such as OSBv2, Binder.org (https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine readable nature of the schema and LEMS also enables the automated generation of human readable documentation for the standard and low level APIs (Figure 16) along with their examples (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). In addition, the individual NeuroML software packages each have their own individual documentation (e.g. pyNeuroML (https://pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/)).\n\nAs with the rest of the NeuroML ecosystem, the documentation is hosted on GitHub (https://github.com/NeuroML/Documentation), licensed under a FOSS license, and community contributions\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    36 of 44\n","images":[{"name":"page_36.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_36_text_1_v2.jpg","height":131860.203,"width":250448.829,"x":101178.575,"y":419713.515,"original_width":1654,"original_height":673,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_2_v2.jpg","height":102884.272,"width":250393.598,"x":101147.144,"y":146682.765,"original_width":1654,"original_height":525,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_3_v2.jpg","height":64723.373,"width":250477.61,"x":101267.307,"y":290217.058,"original_width":1654,"original_height":331,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_4_v2.jpg","height":45682.637,"width":250307.346,"x":101207.544,"y":70274.894,"original_width":1653,"original_height":234,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_5_v2.jpg","height":36047.685,"width":250252.868,"x":101360.042,"y":251866.47,"original_width":1653,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_6_v2.jpg","height":35704.572,"width":250425.767,"x":101230.489,"y":357198.307,"original_width":1654,"original_height":183,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_7_v2.jpg","height":26522.031,"width":250463.191,"x":101134.785,"y":41478.659,"original_width":1654,"original_height":136,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_8_v2.jpg","height":26204.902,"width":250152.273,"x":101347.35,"y":118198.452,"original_width":1652,"original_height":134,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_text_9_v2.jpg","height":17224.159,"width":250602.581,"x":101402.502,"y":553744.346,"original_width":1655,"original_height":88,"rotation":0,"type":"layout_v2_text"},{"name":"page_36_footer_1_v2.jpg","height":6913.899,"width":191831.66,"x":21610.333,"y":591493.564,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_36_paragraph_title_1_v2.jpg","height":7317.112,"width":54742.097,"x":101636.55,"y":408364.741,"original_width":362,"original_height":38,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_36_header_1_v2.jpg","height":5555.904,"width":30359.055,"x":320766.327,"y":27755.177,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_36_number_1_v2.jpg","height":5828.262,"width":18279.912,"x":332878.562,"y":591849.654,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_36_header_2_v2.jpg","height":5628.183,"width":42932.299,"x":47722.453,"y":27947.816,"original_width":284,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_36_header_3_v2.jpg","height":10671.582,"width":24414.445,"x":21843.343,"y":22451.586,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                              Neuroscience","md":"eLife Tools and resources                                                                                              Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":119,"endIndex":131}]},{"type":"text","value":"user scripts. These include NEURON (Hines and Carnevale, 1997) for which the NeuroML tools generate scripts in Python and the simulator's hoc and NMODL formats and the Brian simulator (Stimberg et al., 2019) which uses Python scripts.","md":"user scripts. These include NEURON (Hines and Carnevale, 1997) for which the NeuroML tools generate scripts in Python and the simulator's hoc and NMODL formats and the Brian simulator (Stimberg et al., 2019) which uses Python scripts.","bBox":{"x":168.53,"y":51.8,"w":389.28,"h":9},"layoutAwareBbox":[{"x":165,"y":52,"w":409,"h":33,"startIndex":36,"endIndex":41}]},{"type":"text","value":"The final category consists of export options to standardized formats in neuroscience and the wider computational biology field, which enable interaction with simulators and applications supporting those formats. These include the PyNN package (Davison et al., 2008), which can be run in either NEURON, NEST (Gewaltig and Diesmann, 2007) or Brian, the SONATA data format (Dai et al., 2020) and the SBML standard (Hucka et al., 2003) (see Reusing NeuroML models for more details).","md":"The final category consists of export options to standardized formats in neuroscience and the wider computational biology field, which enable interaction with simulators and applications supporting those formats. These include the PyNN package (Davison et al., 2008), which can be run in either NEURON, NEST (Gewaltig and Diesmann, 2007) or Brian, the SONATA data format (Dai et al., 2020) and the SBML standard (Hucka et al., 2003) (see Reusing NeuroML models for more details).","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":165,"y":88,"w":408,"h":57,"startIndex":0,"endIndex":478}]},{"type":"text","value":"Having multiple strategies in place for supporting NeuroML gives more freedom to simulator developers to choose how much they wish to be involved with implementing and supporting NeuroML functionality in their applications, while maximizing the options available for end users.","md":"Having multiple strategies in place for supporting NeuroML gives more freedom to simulator developers to choose how much they wish to be involved with implementing and supporting NeuroML functionality in their applications, while maximizing the options available for end users.","bBox":{"x":168.53,"y":160.42,"w":395.23,"h":21.07},"layoutAwareBbox":[{"x":165,"y":149,"w":408,"h":33,"startIndex":0,"endIndex":276}]},{"type":"text","value":"The primary tool for simulating NeuroML/LEMS models via different engines is jNeuroML, which is included in pyNeuroML. jNeuroML supports all simulator engine categories (Figure 5). It includes jLEMS for simulation of LEMS and single compartmental NeuroML models. It can also pass simulations to the EDEN simulator (Panagiotou et al., 2022) for direct simulation. Using the org.neuroml.export library (https://github.com/NeuroML/org.neuroml.export), jNeuroML can also generate import scripts for simulators (e.g. NetPyNE Dura-Bernal et al., 2019) or convert NeuroML/LEMS models to simulator specific formats (e.g. NEURON Hines and Carnevale, 1997). Supporting a new simulation engine that requires translation of NeuroML/LEMS into another format can be done by adding a new 'writer' to the org.neuroml.export library. Finally, jNeuroML also includes the org.neuroml.import (https://github.com/NeuroML/jNeuroML) library that converts from other formats (e.g. SBML Hucka et al., 2003) to LEMS for combination with NeuroML models.","md":"The primary tool for simulating NeuroML/LEMS models via different engines is jNeuroML, which is included in pyNeuroML. jNeuroML supports all simulator engine categories (Figure 5). It includes jLEMS for simulation of LEMS and single compartmental NeuroML models. It can also pass simulations to the EDEN simulator (Panagiotou et al., 2022) for direct simulation. Using the org.neuroml.export library (https://github.com/NeuroML/org.neuroml.export), jNeuroML can also generate import scripts for simulators (e.g. NetPyNE Dura-Bernal et al., 2019) or convert NeuroML/LEMS models to simulator specific formats (e.g. NEURON Hines and Carnevale, 1997). Supporting a new simulation engine that requires translation of NeuroML/LEMS into another format can be done by adding a new 'writer' to the org.neuroml.export library. Finally, jNeuroML also includes the org.neuroml.import (https://github.com/NeuroML/jNeuroML) library that converts from other formats (e.g. SBML Hucka et al., 2003) to LEMS for combination with NeuroML models.","bBox":{"x":168.53,"y":184.56,"w":412.55,"h":117.62},"layoutAwareBbox":[{"x":165,"y":185,"w":409,"h":129,"startIndex":32,"endIndex":39}]},{"type":"text","value":"It is important to note though that not all NeuroML models can be exported to/are supported by each of these target simulators (Table 7). This depends on the capabilities of the simulator in question (whether it supports networks, or morphologically detailed cells) and pyNeuroML/jNeuroML will provide feedback if a feature of the model is not supported in a chosen environment.","md":"It is important to note though that not all NeuroML models can be exported to/are supported by each of these target simulators (Table 7). This depends on the capabilities of the simulator in question (whether it supports networks, or morphologically detailed cells) and pyNeuroML/jNeuroML will provide feedback if a feature of the model is not supported in a chosen environment.","bBox":{"x":168.53,"y":317.32,"w":407.32,"h":45.21},"layoutAwareBbox":[{"x":165,"y":318,"w":408,"h":45,"startIndex":116,"endIndex":126}]},{"type":"text","value":"All NeuroML and LEMS software packages are made available under FOSS licenses. The source code for all NeuroML packages and the standard can be obtained from the NeuroML GitHub organization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEnsemble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://github.com/NeuralEnsemble/), which also maintains other commonly used Python packages such as PyNN (Davison et al., 2008), Neo (Garcia et al., 2014) and Elephant (Denker, 2018). LEMS packages are available from the LEMS GitHub organization (https://github.com/LEMS).","md":"All NeuroML and LEMS software packages are made available under FOSS licenses. The source code for all NeuroML packages and the standard can be obtained from the NeuroML GitHub organization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEnsemble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://github.com/NeuralEnsemble/), which also maintains other commonly used Python packages such as PyNN (Davison et al., 2008), Neo (Garcia et al., 2014) and Elephant (Denker, 2018). LEMS packages are available from the LEMS GitHub organization (https://github.com/LEMS).","bBox":{"x":168.53,"y":365.6,"w":405.22,"h":81.41},"layoutAwareBbox":[{"x":165,"y":366,"w":409,"h":81,"startIndex":459,"endIndex":463}]},{"type":"text","value":"To ensure replication and reproduction of studies, it is important to note the exact versions of software used in studies. For NeuroML and LEMS packages, archives of each release along with citations are published on Zenodo (https://zenodo.org) to enable researchers to cite them in their work (Gleeson, 2021; Gleeson, 2024a; Gleeson et al., 2019b; Gleeson, 2024b; Sinha, 2024).","md":"To ensure replication and reproduction of studies, it is important to note the exact versions of software used in studies. For NeuroML and LEMS packages, archives of each release along with citations are published on Zenodo (https://zenodo.org) to enable researchers to cite them in their work (Gleeson, 2021; Gleeson, 2024a; Gleeson et al., 2019b; Gleeson, 2024b; Sinha, 2024).","bBox":{"x":168.53,"y":450.08,"w":403.6,"h":33.14},"layoutAwareBbox":[{"x":165,"y":451,"w":409,"h":45,"startIndex":22,"endIndex":25}]},{"type":"heading","lvl":2,"value":"Documentation","md":"## Documentation","bBox":{"x":168.53,"y":513.31,"w":86.86,"h":12},"layoutAwareBbox":[{"x":166,"y":515,"w":89,"h":9,"startIndex":3,"endIndex":16}]},{"type":"text","value":"A standard and its accompanying software ecosystem must be supported by comprehensive documentation if it is to be of use to the research community. The primary NeuroML documentation for users that accompanies this paper has been consolidated into a JupyterBook (Executable Books Community, 2020) at https://docs.neuroml.org. This includes explanations of NeuroML and computational modeling concepts, interactive tutorials with varying levels of complexity, information about tools and what functions they provide to support different stages of the model life cycle. The JupyterBook framework supports 'executable' documentation through the inclusion of interactive Jupyter notebooks which may be run in the users' web browser on free services such as OSBv2, Binder.org (https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine readable nature of the schema and LEMS also enables the automated generation of human readable documentation for the standard and low level APIs (Figure 16) along with their examples (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). In addition, the individual NeuroML software packages each have their own individual documentation (e.g. pyNeuroML (https://pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/)).","md":"A standard and its accompanying software ecosystem must be supported by comprehensive documentation if it is to be of use to the research community. The primary NeuroML documentation for users that accompanies this paper has been consolidated into a JupyterBook (Executable Books Community, 2020) at https://docs.neuroml.org. This includes explanations of NeuroML and computational modeling concepts, interactive tutorials with varying levels of complexity, information about tools and what functions they provide to support different stages of the model life cycle. The JupyterBook framework supports 'executable' documentation through the inclusion of interactive Jupyter notebooks which may be run in the users' web browser on free services such as OSBv2, Binder.org (https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine readable nature of the schema and LEMS also enables the automated generation of human readable documentation for the standard and low level APIs (Figure 16) along with their examples (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). In addition, the individual NeuroML software packages each have their own individual documentation (e.g. pyNeuroML (https://pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/)).","bBox":{"x":168.53,"y":541.45,"w":409.84,"h":153.83},"layoutAwareBbox":[{"x":165,"y":529,"w":409,"h":166,"startIndex":2,"endIndex":10}]},{"type":"text","value":"As with the rest of the NeuroML ecosystem, the documentation is hosted on GitHub (https://github.com/NeuroML/Documentation), licensed under a FOSS license, and community contributions","md":"As with the rest of the NeuroML ecosystem, the documentation is hosted on GitHub (https://github.com/NeuroML/Documentation), licensed under a FOSS license, and community contributions","bBox":{"x":168.53,"y":698.35,"w":407.89,"h":21.07},"layoutAwareBbox":[{"x":165,"y":699,"w":409,"h":21,"startIndex":0,"endIndex":182}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    36 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    36 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/NeuroML/org.neuroml.export","unsafeUrl":"https://github.com/NeuroML/org.neuroml.export","text":"export library (https://github.com/NeuroML/org.neuroml.export), jNeuroML can also generate import "},{"url":"https://github.com/NeuroML/jNeuroML","unsafeUrl":"https://github.com/NeuroML/jNeuroML","text":"(https://github.com/NeuroML/jNeuroML) "},{"url":"https://github.com/NeuroML","unsafeUrl":"https://github.com/NeuroML","text":"nization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEn-"},{"url":"https://github.com/NeuralEnsemble/libNeuroML","unsafeUrl":"https://github.com/NeuralEnsemble/libNeuroML","text":"nization (https://github.com/NeuroML). The NeuroML Python API (https://github.com/NeuralEn-"},{"url":"https://github.com/NeuralEnsemble/libNeuroML","unsafeUrl":"https://github.com/NeuralEnsemble/libNeuroML","text":"semble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://"},{"url":"https://github.com/NeuralEnsemble/","unsafeUrl":"https://github.com/NeuralEnsemble/","text":"semble/libNeuroML) was developed in collaboration with the NeuralEnsemble initiative (https://"},{"url":"https://github.com/NeuralEnsemble/","unsafeUrl":"https://github.com/NeuralEnsemble/","text":"github.com/NeuralEnsemble/), which also maintains other commonly used Python packages such as "},{"url":"https://github.com/LEMS","unsafeUrl":"https://github.com/LEMS","text":"are available from the LEMS GitHub organization (https://github.com/LEMS)."},{"url":"https://zenodo.org/","unsafeUrl":"https://zenodo.org","text":"tions are published on Zenodo (https://zenodo.org) to enable researchers to cite them in their work "},{"url":"https://docs.neuroml.org/","unsafeUrl":"https://docs.neuroml.org","text":") at https://docs.neuroml.org. This includes explanations of NeuroML and compu-"},{"url":"https://mybinder.org/","unsafeUrl":"https://mybinder.org/","text":"(https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine "},{"url":"https://colab.research.google.com/","unsafeUrl":"https://colab.research.google.com/","text":"(https://mybinder.org/) and Google Colab (https://colab.research.google.com/). Finally, the machine "},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","text":"(https://"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","text":"docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). In "},{"url":"https://pyneuroml.readthedocs.io/en/stable/","unsafeUrl":"https://pyneuroml.readthedocs.io/en/stable/","text":"pyNeuroML "},{"url":"https://pyneuroml.readthedocs.io/en/stable/","unsafeUrl":"https://pyneuroml.readthedocs.io/en/stable/","text":"pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/))."},{"url":"https://libneuroml.readthedocs.io/en/stable/","unsafeUrl":"https://libneuroml.readthedocs.io/en/stable/","text":"pyneuroml.readthedocs.io/en/stable/,) libNeuroML (https://libneuroml.readthedocs.io/en/stable/))."},{"url":"https://github.com/NeuroML/Documentation","unsafeUrl":"https://github.com/NeuroML/Documentation","text":"As with the rest of the NeuroML ecosystem, the documentation is hosted on GitHub (https://"},{"url":"https://github.com/NeuroML/Documentation","unsafeUrl":"https://github.com/NeuroML/Documentation","text":"github.com/NeuroML/Documentation), licensed under a FOSS license, and community contributions "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                              Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    36 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.987,"layout":[{"image":"page_36_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.669,"w":0.669,"h":0.21},"isLikelyNoise":false},{"image":"page_36_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.234,"w":0.669,"h":0.164},"isLikelyNoise":false},{"image":"page_36_text_3_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.463,"w":0.669,"h":0.103},"isLikelyNoise":false},{"image":"page_36_text_4_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.27,"y":0.112,"w":0.668,"h":0.073},"isLikelyNoise":false},{"image":"page_36_text_5_v2.jpg","confidence":0.98,"label":"text","bbox":{"x":0.271,"y":0.402,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_36_text_6_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.569,"w":0.669,"h":0.057},"isLikelyNoise":false},{"image":"page_36_text_7_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.669,"h":0.042},"isLikelyNoise":false},{"image":"page_36_text_8_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.271,"y":0.188,"w":0.668,"h":0.042},"isLikelyNoise":false},{"image":"page_36_text_9_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.271,"y":0.883,"w":0.669,"h":0.027},"isLikelyNoise":false},{"image":"page_36_footer_1_v2.jpg","confidence":0.89,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_36_paragraph_title_1_v2.jpg","confidence":0.89,"label":"paragraph_title","bbox":{"x":0.271,"y":0.651,"w":0.146,"h":0.012},"isLikelyNoise":false},{"image":"page_36_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_36_number_1_v2.jpg","confidence":0.83,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_36_header_2_v2.jpg","confidence":0.7,"label":"header","bbox":{"x":0.127,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_36_header_3_v2.jpg","confidence":0.54,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":37,"text":"Tools  and  resources    Neuroscience\n\n\n≡                                                                                                                      proximalDetails\n                                                                                                                       distalDetails\n\n hindmarshRose1984Cell                                                                                                 morphology\n                                                                                                                       specificCapacitance\n extends baseCellMembPotCap                                                                                           initMembPotential\n                                                                                                                      spikeThresh\n The Hindmarsh Rose model is a simplified point cell model which captures complex firing patterns of single            membraneProperties\n neurons, such as periodic and chaotic bursting. It has a fast spiking subsystem, which is a generalization of the     membraneProperties2CaPools\n FitzHugh-Nagumo system, coupled to a slower subsystem which allows the model to fire bursts. The dynamical            biophysicalProperties\n variables x, y, z correspond to the membrane potential, a recovery variable, and a slower adaptation current,         biophysicalProperties2CaPools\n respectively. See Hindmarsh J. L., and Rose R. M. ( 1984 ) A model of neuronal bursting using three coupled           intracellularProperties\n first order differential equations. Proc. R. Soc. London. Ser. B 221:87-102.                                          intracellularProperties2CaPools\n                                                                                                                       resistivity\n     Parameters     Constants         Exposures      Event Ports  Attachments    Dynamics                              concentrationModel\n\n     Schema         Usage: Python                                                                                      decayingPoolConcentrationModel\n                                                                                                                       fixedFactorConcentrationModel\n State Variables                                                                                                       fixedFactorConcentrationModeITraub\n     v: voltage     (exposed as v)                                                                                    species\n                                                                                                                      cell\n     y: Dimensionless       (exposed as y)                                                                            cell2CaPools\n\n      z: Dimensionless (exposed as z)                                                                                  baseCellMembPotCap\n                                                                                                                       baselaf\n      spiking: Dimensionless (exposed as spiking)                                                                      iafTauCell\n                                                                                                                       iafTauRefCell\n On Start                                                                                                              baselafCapCell\n     v = x0 * v_scaling                                                                                               iafCell\n\n     y = y0                                                                                                            iafRefCell\n                                                                                                                       izhikevichCell\n     Z =zO                                                                                                             izhikevich2007Cell\n\n On Conditions                                                                                                         adExlaFCell\n      IF v > 0 AND spiking < 0.5 THEN                                                                                  fitzHughNagumoCell\n                                                                                                                       pinskyRinzelCA3Cell\n             spiking = 1                                                                                               hindmarshRose1984Cell\n\n             EVENT OUT on port: spike\n\n      IF v < 0 THEN\n\n             spiking = 0\n\n Derived Variables\n      iSyn = synapses[*]->i(reduce method: add) (exposed as iSyn)\n\n      x = v /v_ scaling (exposed as x)\n\n      phi = y - a * x^3 + b * x^2 (exposed as phi)\n\n      chi = c - d * x^2 - y (exposed as chi)\n\n      rho = s*(x - x1 ) - z (exposed as rho)\n\n      iMemb = (C * (v_ scaling * (phi - z) / MSEC)) + iSyn (exposed as iMemb)\n\n Time Derivatives\n      d v /dt = iMemb/C\n\n      d y /dt = chi / MSEC\n\n      d z /dt = r * rho / MSEC\n\n Previous                                                                                    Next\n NeuroMLCoreCompTypes                                                            Channels\n\nFigure 16. Documentation for the HindmarshRose1984Cell NeuroMLv2 ComponentType                                                                generated from the\nXSD schema and LEMS definitions on the NeuroML documentation website showing its dynamics (https://docs.\nneuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). More information about the ComponentType\ncan be obtained from the tabs provided.\n\n\n\n\n\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    37 of 44","md":"\n\neLife Tools and resources                                                    Neuroscience\n\n**Figure 16.** Documentation for the `HindmarshRose1984Cell` NeuroMLv2 ComponentType generated from the XSD schema and LEMS definitions on the NeuroML documentation website showing its dynamics (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). More information about the ComponentType can be obtained from the tabs provided.\n\n## hindmarshRose1984Cell\n\n**extends** baseCellMembPotCap\n\n*The Hindmarsh Rose model is a simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting. It has a fast spiking subsystem, which is a generalization of the FitzHugh-Nagumo system, coupled to a slower subsystem which allows the model to fire bursts. The dynamical variables x, y, z correspond to the membrane potential, a recovery variable, and a slower adaptation current, respectively. See Hindmarsh J. L., and Rose R. M. ( 1984 ) A model of neuronal bursting using three coupled first order differential equations. Proc. R. Soc. London. Ser. B 221:87-102.*\n\n**Parameters** | **Constants** | **Exposures** | **Event Ports** | **Attachments** | **Dynamics**\n\n**Schema** | **Usage: Python**\n\n### State Variables\n- **v**: voltage (exposed as **v**)\n- **y**: Dimensionless (exposed as **y**)\n- **z**: Dimensionless (exposed as **z**)\n- **spiking**: Dimensionless (exposed as **spiking**)\n\n### On Start\n- v = x0 * v_scaling\n- y = y0\n- z = z0\n\n### On Conditions\nIF v > 0 AND spiking < 0.5 THEN\n- spiking = 1\n- EVENT OUT on port: spike\n\nIF v < 0 THEN\n- spiking = 0\n\n### Derived Variables\n- **iSyn** = synapses[*]->i(reduce method: add) (exposed as **iSyn**)\n- **x** = v / v_scaling (exposed as **x**)\n- **phi** = y - a * x<sup>3</sup> + b * x<sup>2</sup> (exposed as **phi**)\n- **chi** = c - d * x<sup>2</sup> - y (exposed as **chi**)\n- **rho** = s * (x - x1) - z (exposed as **rho**)\n- **iMemb** = (C * (v_scaling * (phi - z) / MSEC)) + iSyn (exposed as **iMemb**)\n\n### Time Derivatives\n- d v /dt = iMemb/C\n- d y /dt = chi / MSEC\n- d z /dt = r * rho / MSEC\n\n**Related Components:**\n- proximalDetails\n- distalDetails\n- morphology\n- specificCapacitance\n- initMembPotential\n- spikeThresh\n- membraneProperties\n- membraneProperties2CaPools\n- biophysicalProperties\n- biophysicalProperties2CaPools\n- intracellularProperties\n- intracellularProperties2CaPools\n- resistivity\n- concentrationModel\n- decayingPoolConcentrationModel\n- fixedFactorConcentrationModel\n- fixedFactorConcentrationModelTraub\n- species\n- cell\n- cell2CaPools\n- baseCellMembPotCap\n- baseIaf\n- iafTauCell\n- iafTauRefCell\n- baseIafCapCell\n- iafCell\n- iafRefCell\n- izhikevichCell\n- izhikevich2007Cell\n- adExIaFCell\n- fitzHughNagumoCell\n- pinskyRinzelCA3Cell\n- hindmarshRose1984Cell\n\n**Previous:** NeuroMLCoreCompTypes | **Next:** Channels\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                37 of 44\n","images":[{"name":"img_p36_1.png","height":520.1,"width":359.377,"x":174.651,"y":60.125,"original_width":1498,"original_height":2168,"rotation":0,"ocr":[{"x":29,"y":2136,"w":301,"h":30,"confidence":1,"text":"NeuroMLCoreCompTypes"},{"x":999,"y":2134,"w":116,"h":32,"confidence":1,"text":"Channels"},{"x":29,"y":2109,"w":91,"h":25,"confidence":1,"text":"Previous"},{"x":1057,"y":2105,"w":62,"h":34,"confidence":1,"text":"Next"},{"x":69,"y":2023,"w":232,"h":30,"confidence":0.972,"text":"d z /dt = r * rho / MSEC"},{"x":69,"y":1962,"w":201,"h":30,"confidence":0.991,"text":"d y /dt = chi / MSEC"},{"x":69,"y":1902,"w":181,"h":29,"confidence":0.981,"text":"d v /dt = iMemb/C"},{"x":31,"y":1865,"w":176,"h":23,"confidence":0.999,"text":"Time Derivatives"},{"x":71,"y":1804,"w":718,"h":23,"confidence":0.952,"text":"iMemb = (C * (v_ scaling * (phi - z) / MSEC)) + iSyn (exposed as iMemb)"},{"x":69,"y":1741,"w":397,"h":30,"confidence":0.927,"text":"rho = s*(x - x1 ) - z (exposed as rho)"},{"x":69,"y":1680,"w":372,"h":30,"confidence":0.917,"text":"chi = c - d * x^2 - y (exposed as chi)"},{"x":69,"y":1619,"w":437,"h":30,"confidence":0.926,"text":"phi = y - a * x^3 + b * x^2 (exposed as phi)"},{"x":69,"y":1558,"w":330,"h":30,"confidence":0.91,"text":"x = v /v_ scaling (exposed as x)"},{"x":69,"y":1497,"w":622,"h":30,"confidence":0.974,"text":"iSyn = synapses[*]->i(reduce method: add) (exposed as iSyn)"},{"x":29,"y":1457,"w":189,"h":29,"confidence":1,"text":"Derived Variables"},{"x":134,"y":1396,"w":122,"h":31,"confidence":0.994,"text":"spiking = 0"},{"x":71,"y":1335,"w":143,"h":25,"confidence":0.885,"text":"IF v < 0 THEN"},{"x":136,"y":1274,"w":272,"h":29,"confidence":0.98,"text":"EVENT OUT on port: spike"},{"x":134,"y":1213,"w":122,"h":31,"confidence":0.997,"text":"spiking = 1"},{"x":1173,"y":1204,"w":218,"h":22,"confidence":0.999,"text":"hindmarshRose1984Cell"},{"x":1170,"y":1165,"w":190,"h":30,"confidence":0.994,"text":"pinskyRinzelCA3Cell"},{"x":69,"y":1152,"w":326,"h":29,"confidence":0.975,"text":"IF v > 0 AND spiking < 0.5 THEN"},{"x":1173,"y":1129,"w":185,"h":23,"confidence":0.992,"text":"fitzHughNagumoCell"},{"x":29,"y":1113,"w":154,"h":25,"confidence":1,"text":"On Conditions"},{"x":1173,"y":1091,"w":111,"h":22,"confidence":0.998,"text":"adExlaFCell"},{"x":1173,"y":1052,"w":167,"h":23,"confidence":0.999,"text":"izhikevich2007Cell"},{"x":67,"y":1050,"w":71,"h":32,"confidence":0.717,"text":"Z =zO"},{"x":1173,"y":1016,"w":122,"h":23,"confidence":1,"text":"izhikevichCell"},{"x":65,"y":989,"w":73,"h":34,"confidence":0.987,"text":"y = y0"},{"x":1170,"y":976,"w":94,"h":24,"confidence":0.998,"text":"iafRefCell"},{"x":1168,"y":935,"w":67,"h":32,"confidence":0.999,"text":"iafCell"},{"x":67,"y":930,"w":180,"h":30,"confidence":0.97,"text":"v = x0 * v_scaling"},{"x":1173,"y":901,"w":140,"h":25,"confidence":0.999,"text":"baselafCapCell"},{"x":31,"y":892,"w":92,"h":25,"confidence":0.986,"text":"On Start"},{"x":1173,"y":863,"w":120,"h":25,"confidence":0.999,"text":"iafTauRefCell"},{"x":69,"y":829,"w":470,"h":29,"confidence":0.982,"text":"spiking: Dimensionless (exposed as spiking)"},{"x":1170,"y":827,"w":94,"h":24,"confidence":0.999,"text":"iafTauCell"},{"x":1170,"y":788,"w":74,"h":25,"confidence":1,"text":"baselaf"},{"x":256,"y":770,"w":154,"h":25,"confidence":0.989,"text":"(exposed as z)"},{"x":69,"y":768,"w":176,"h":29,"confidence":0.956,"text":"z: Dimensionless"},{"x":1170,"y":750,"w":201,"h":22,"confidence":1,"text":"baseCellMembPotCap"},{"x":1170,"y":714,"w":121,"h":24,"confidence":1,"text":"cell2CaPools"},{"x":261,"y":709,"w":149,"h":25,"confidence":0.967,"text":"(exposed as y)"},{"x":67,"y":707,"w":178,"h":29,"confidence":0.997,"text":"y: Dimensionless"},{"x":1168,"y":673,"w":42,"h":29,"confidence":1,"text":"cell"},{"x":194,"y":648,"w":147,"h":25,"confidence":0.999,"text":"(exposed as v)"},{"x":67,"y":646,"w":107,"h":32,"confidence":0.963,"text":"v: voltage"},{"x":1168,"y":635,"w":80,"h":31,"confidence":0.977,"text":"species"},{"x":31,"y":607,"w":158,"h":25,"confidence":1,"text":"State Variables"},{"x":1173,"y":601,"w":323,"h":22,"confidence":0.978,"text":"fixedFactorConcentrationModeITraub"},{"x":1173,"y":562,"w":276,"h":23,"confidence":1,"text":"fixedFactorConcentrationModel"},{"x":194,"y":540,"w":160,"h":31,"confidence":0.999,"text":"Usage: Python"},{"x":54,"y":540,"w":95,"h":31,"confidence":1,"text":"Schema"},{"x":1173,"y":526,"w":296,"h":23,"confidence":1,"text":"decayingPoolConcentrationModel"},{"x":1170,"y":488,"w":179,"h":22,"confidence":1,"text":"concentrationModel"},{"x":918,"y":477,"w":112,"h":31,"confidence":1,"text":"Dynamics"},{"x":733,"y":479,"w":136,"h":25,"confidence":1,"text":"Attachments"},{"x":557,"y":479,"w":127,"h":25,"confidence":0.969,"text":"Event Ports"},{"x":392,"y":479,"w":116,"h":25,"confidence":1,"text":"Exposures"},{"x":230,"y":479,"w":111,"h":25,"confidence":1,"text":"Constants"},{"x":56,"y":479,"w":125,"h":25,"confidence":1,"text":"Parameters"},{"x":1170,"y":449,"w":89,"h":25,"confidence":1,"text":"resistivity"},{"x":1173,"y":411,"w":278,"h":23,"confidence":1,"text":"intracellularProperties2CaPools"},{"x":31,"y":404,"w":718,"h":23,"confidence":0.972,"text":"first order differential equations. Proc. R. Soc. London. Ser. B 221:87-102."},{"x":1173,"y":375,"w":193,"h":22,"confidence":1,"text":"intracellularProperties"},{"x":31,"y":370,"w":1052,"h":23,"confidence":0.986,"text":"respectively. See Hindmarsh J. L., and Rose R. M. ( 1984 ) A model of neuronal bursting using three coupled"},{"x":1173,"y":336,"w":274,"h":23,"confidence":0.992,"text":"biophysicalProperties2CaPools"},{"x":29,"y":332,"w":1048,"h":29,"confidence":0.994,"text":"variables x, y, z correspond to the membrane potential, a recovery variable, and a slower adaptation current,"},{"x":1173,"y":298,"w":191,"h":23,"confidence":0.983,"text":"biophysicalProperties"},{"x":29,"y":291,"w":1077,"h":30,"confidence":0.992,"text":"FitzHugh-Nagumo system, coupled to a slower subsystem which allows the model to fire bursts. The dynamical"},{"x":1173,"y":262,"w":271,"h":23,"confidence":1,"text":"membraneProperties2CaPools"},{"x":27,"y":260,"w":1079,"h":29,"confidence":0.991,"text":"neurons, such as periodic and chaotic bursting. It has a fast spiking subsystem, which is a generalization of the"},{"x":31,"y":226,"w":1030,"h":22,"confidence":0.992,"text":"The Hindmarsh Rose model is a simplified point cell model which captures complex firing patterns of single"},{"x":1173,"y":224,"w":187,"h":22,"confidence":1,"text":"membraneProperties"},{"x":1168,"y":178,"w":119,"h":37,"confidence":1,"text":"spikeThresh"},{"x":27,"y":160,"w":310,"h":34,"confidence":0.972,"text":"extends baseCellMembPotCap"},{"x":1170,"y":147,"w":163,"h":22,"confidence":1,"text":"initMembPotential"},{"x":1173,"y":111,"w":178,"h":22,"confidence":1,"text":"specificCapacitance"},{"x":31,"y":90,"w":479,"h":39,"confidence":0.998,"text":"hindmarshRose1984Cell"},{"x":1170,"y":68,"w":112,"h":31,"confidence":1,"text":"morphology"},{"x":1173,"y":34,"w":111,"h":22,"confidence":1,"text":"distalDetails"},{"x":18,"y":16,"w":33,"h":29,"confidence":0.608,"text":"≡"},{"x":1170,"y":0,"w":141,"h":23,"confidence":0.999,"text":"proximalDetails"}]},{"name":"page_37.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_37_footer_1_v2.jpg","height":6873.637,"width":191504.053,"x":22136.298,"y":591515.754,"original_width":1265,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_37_header_1_v2.jpg","height":5566.601,"width":30304.426,"x":320930.744,"y":27808.518,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_37_number_1_v2.jpg","height":5907.689,"width":18363.182,"x":332867.839,"y":591816.821,"original_width":122,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_37_header_2_v2.jpg","height":5793.778,"width":43007.438,"x":47800.08,"y":27887.057,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_37_header_3_v2.jpg","height":10839.374,"width":24414.281,"x":21906.091,"y":22432.471,"original_width":162,"original_height":56,"rotation":0,"type":"layout_v2_header"},{"name":"page_37_figure_title_1_v2.jpg","height":33348.843,"width":249550.806,"x":101663.781,"y":469545.817,"original_width":1648,"original_height":171,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_37_image_1_v2.jpg","height":420709.04,"width":226529.421,"x":103729.832,"y":43585.107,"original_width":1496,"original_height":2147,"rotation":0,"type":"layout_v2_image"},{"name":"page_37_text_1_v2.jpg","height":236239.579,"width":48417.513,"x":277857.715,"y":46231.669,"original_width":320,"original_height":1206,"rotation":0,"type":"layout_v2_text"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                    Neuroscience","md":"eLife Tools and resources                                                    Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":77,"endIndex":89}]},{"type":"text","value":"**Figure 16.** Documentation for the `HindmarshRose1984Cell` NeuroMLv2 ComponentType generated from the XSD schema and LEMS definitions on the NeuroML documentation website showing its dynamics (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). More information about the ComponentType can be obtained from the tabs provided.","md":"**Figure 16.** Documentation for the `HindmarshRose1984Cell` NeuroMLv2 ComponentType generated from the XSD schema and LEMS definitions on the NeuroML documentation website showing its dynamics (https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). More information about the ComponentType can be obtained from the tabs provided.","bBox":{"x":168.53,"y":81.72,"w":408.46,"h":551.63},"layoutAwareBbox":[{"x":166,"y":592,"w":407,"h":42,"startIndex":38,"endIndex":59}]},{"type":"heading","lvl":2,"value":"hindmarshRose1984Cell","md":"## hindmarshRose1984Cell","bBox":{"x":182.09,"y":81.72,"w":114.91,"h":9.36},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":3,"endIndex":24}]},{"type":"text","value":"**extends** baseCellMembPotCap","md":"**extends** baseCellMembPotCap","bBox":{"x":455.34,"y":240.05,"w":48.22,"h":5.28},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":12,"endIndex":30}]},{"type":"text","value":"*The Hindmarsh Rose model is a simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting. It has a fast spiking subsystem, which is a generalization of the FitzHugh-Nagumo system, coupled to a slower subsystem which allows the model to fire bursts. The dynamical variables x, y, z correspond to the membrane potential, a recovery variable, and a slower adaptation current, respectively. See Hindmarsh J. L., and Rose R. M. ( 1984 ) A model of neuronal bursting using three coupled first order differential equations. Proc. R. Soc. London. Ser. B 221:87-102.*","md":"*The Hindmarsh Rose model is a simplified point cell model which captures complex firing patterns of single neurons, such as periodic and chaotic bursting. It has a fast spiking subsystem, which is a generalization of the FitzHugh-Nagumo system, coupled to a slower subsystem which allows the model to fire bursts. The dynamical variables x, y, z correspond to the membrane potential, a recovery variable, and a slower adaptation current, respectively. See Hindmarsh J. L., and Rose R. M. ( 1984 ) A model of neuronal bursting using three coupled first order differential equations. Proc. R. Soc. London. Ser. B 221:87-102.*","bBox":{"x":181.13,"y":114.34,"w":258.86,"h":48.22},"layoutAwareBbox":[{"x":181.13,"y":114.34,"w":258.86,"h":48.22,"startIndex":0,"endIndex":623}]},{"type":"text","value":"**Parameters** | **Constants** | **Exposures** | **Event Ports** | **Attachments** | **Dynamics**","md":"**Parameters** | **Constants** | **Exposures** | **Event Ports** | **Attachments** | **Dynamics**","bBox":{"x":188.09,"y":174.56,"w":233.67,"h":7.44},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":2,"endIndex":12}]},{"type":"text","value":"**Schema** | **Usage: Python**","md":"**Schema** | **Usage: Python**","bBox":{"x":187.61,"y":189.67,"w":71.97,"h":7.44},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":2,"endIndex":8}]},{"type":"heading","lvl":3,"value":"State Variables","md":"### State Variables","bBox":{"x":182.09,"y":205.74,"w":37.9,"h":6},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":18}]},{"type":"text","value":"- **v**: voltage (exposed as **v**)\n- **y**: Dimensionless (exposed as **y**)\n- **z**: Dimensionless (exposed as **z**)\n- **spiking**: Dimensionless (exposed as **spiking**)","md":"- **v**: voltage (exposed as **v**)\n- **y**: Dimensionless (exposed as **y**)\n- **z**: Dimensionless (exposed as **z**)\n- **spiking**: Dimensionless (exposed as **spiking**)","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":0,"y":0,"w":612,"h":792,"startIndex":0,"endIndex":172}]},{"type":"heading","lvl":3,"value":"On Start","md":"### On Start","bBox":{"x":182.09,"y":274.11,"w":22.07,"h":6},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":11}]},{"type":"text","value":"- v = x0 * v_scaling\n- y = y0\n- z = z0","md":"- v = x0 * v_scaling\n- y = y0\n- z = z0","bBox":{"x":190.24,"y":283.23,"w":43.66,"h":22.31},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":37}]},{"type":"heading","lvl":3,"value":"On Conditions","md":"### On Conditions","bBox":{"x":181.61,"y":327.13,"w":36.95,"h":6},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":16}]},{"type":"text","value":"IF v > 0 AND spiking < 0.5 THEN\n- spiking = 1\n- EVENT OUT on port: spike","md":"IF v > 0 AND spiking < 0.5 THEN\n- spiking = 1\n- EVENT OUT on port: spike","bBox":{"x":191.2,"y":336.49,"w":81.33,"h":36.22},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":71}]},{"type":"text","value":"IF v < 0 THEN\n- spiking = 0","md":"IF v < 0 THEN\n- spiking = 0","bBox":{"x":191.68,"y":380.39,"w":44.38,"h":22.07},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":26}]},{"type":"heading","lvl":3,"value":"Derived Variables","md":"### Derived Variables","bBox":{"x":181.61,"y":409.66,"w":45.34,"h":6.96},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":20}]},{"type":"text","value":"- **iSyn** = synapses[*]->i(reduce method: add) (exposed as **iSyn**)\n- **x** = v / v_scaling (exposed as **x**)\n- **phi** = y - a * x<sup>3</sup> + b * x<sup>2</sup> (exposed as **phi**)\n- **chi** = c - d * x<sup>2</sup> - y (exposed as **chi**)\n- **rho** = s * (x - x1) - z (exposed as **rho**)\n- **iMemb** = (C * (v_scaling * (phi - z) / MSEC)) + iSyn (exposed as **iMemb**)","md":"- **iSyn** = synapses[*]->i(reduce method: add) (exposed as **iSyn**)\n- **x** = v / v_scaling (exposed as **x**)\n- **phi** = y - a * x<sup>3</sup> + b * x<sup>2</sup> (exposed as **phi**)\n- **chi** = c - d * x<sup>2</sup> - y (exposed as **chi**)\n- **rho** = s * (x - x1) - z (exposed as **rho**)\n- **iMemb** = (C * (v_scaling * (phi - z) / MSEC)) + iSyn (exposed as **iMemb**)","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":376}]},{"type":"heading","lvl":3,"value":"Time Derivatives","md":"### Time Derivatives","bBox":{"x":182.09,"y":507.54,"w":42.22,"h":5.52},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":19}]},{"type":"text","value":"- d v /dt = iMemb/C\n- d y /dt = chi / MSEC\n- d z /dt = r * rho / MSEC","md":"- d v /dt = iMemb/C\n- d y /dt = chi / MSEC\n- d z /dt = r * rho / MSEC","bBox":{"x":191.2,"y":516.41,"w":55.66,"h":36.22},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":0,"endIndex":68}]},{"type":"text","value":"**Related Components:**\n- proximalDetails\n- distalDetails\n- morphology\n- specificCapacitance\n- initMembPotential\n- spikeThresh\n- membraneProperties\n- membraneProperties2CaPools\n- biophysicalProperties\n- biophysicalProperties2CaPools\n- intracellularProperties\n- intracellularProperties2CaPools\n- resistivity\n- concentrationModel\n- decayingPoolConcentrationModel\n- fixedFactorConcentrationModel\n- fixedFactorConcentrationModelTraub\n- species\n- cell\n- cell2CaPools\n- baseCellMembPotCap\n- baseIaf\n- iafTauCell\n- iafTauRefCell\n- baseIafCapCell\n- iafCell\n- iafRefCell\n- izhikevichCell\n- izhikevich2007Cell\n- adExIaFCell\n- fitzHughNagumoCell\n- pinskyRinzelCA3Cell\n- hindmarshRose1984Cell","md":"**Related Components:**\n- proximalDetails\n- distalDetails\n- morphology\n- specificCapacitance\n- initMembPotential\n- spikeThresh\n- membraneProperties\n- membraneProperties2CaPools\n- biophysicalProperties\n- biophysicalProperties2CaPools\n- intracellularProperties\n- intracellularProperties2CaPools\n- resistivity\n- concentrationModel\n- decayingPoolConcentrationModel\n- fixedFactorConcentrationModel\n- fixedFactorConcentrationModelTraub\n- species\n- cell\n- cell2CaPools\n- baseCellMembPotCap\n- baseIaf\n- iafTauCell\n- iafTauRefCell\n- baseIafCapCell\n- iafCell\n- iafRefCell\n- izhikevichCell\n- izhikevich2007Cell\n- adExIaFCell\n- fitzHughNagumoCell\n- pinskyRinzelCA3Cell\n- hindmarshRose1984Cell","bBox":{"x":182.09,"y":60.13,"w":344.98,"h":286.68},"layoutAwareBbox":[{"x":454,"y":58,"w":79,"h":298,"startIndex":26,"endIndex":41}]},{"type":"text","value":"**Previous:** NeuroMLCoreCompTypes | **Next:** Channels","md":"**Previous:** NeuroMLCoreCompTypes | **Next:** Channels","bBox":{"x":181.61,"y":565.11,"w":261.5,"h":14.63},"layoutAwareBbox":[{"x":169,"y":55,"w":370,"h":531,"startIndex":2,"endIndex":10}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                37 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                37 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":36,"y":746,"w":312,"h":8,"startIndex":0,"endIndex":108},{"x":543,"y":747,"w":30,"h":7,"startIndex":0,"endIndex":108}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","text":"XSD schema and LEMS definitions on the NeuroML documentation website showing its dynamics (https://docs."},{"url":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","unsafeUrl":"https://docs.neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell","text":"neuroml.org/Userdocs/Schemas/Cells.html#hindmarshrose1984cell). More information about the ComponentType "}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135                37 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.974,"layout":[{"image":"page_37_footer_1_v2.jpg","confidence":0.94,"label":"footer","bbox":{"x":0.059,"y":0.943,"w":0.511,"h":0.011},"isLikelyNoise":false},{"image":"page_37_header_1_v2.jpg","confidence":0.93,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_37_number_1_v2.jpg","confidence":0.91,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_37_header_2_v2.jpg","confidence":0.74,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_37_header_3_v2.jpg","confidence":0.63,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false},{"image":"page_37_figure_title_1_v2.jpg","confidence":0.6,"label":"figure_title","bbox":{"x":0.271,"y":0.749,"w":0.666,"h":0.053},"isLikelyNoise":false},{"image":"page_37_image_1_v2.jpg","confidence":0.59,"label":"image","bbox":{"x":0.277,"y":0.069,"w":0.605,"h":0.671},"isLikelyNoise":true},{"image":"page_37_text_1_v2.jpg","confidence":0.52,"label":"text","bbox":{"x":0.742,"y":0.074,"w":0.129,"h":0.377},"isLikelyNoise":true}]},{"page":38,"text":"Tools  and  resources                                                                       Neuroscience\n\n                         to it are welcomed. A PDF version of the documentation can also be downloaded for ofﬂine use\n                         (https://docs.neuroml.org/_static/ﬁles/neuroml-documentation.pdf).\n\n                         Maintenance of the Schema and core software\n                         The NeuroML Scientiﬁc Committee (https://docs.neuroml.org/NeuroMLOrg/ScientiﬁcCommittee.\n                         html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html)\n                         oversee the standard, the core tools, and the initiative. The Scientiﬁc Committee sets the scientiﬁc\n                         focus of the NeuroML initiative. It ensures that the standard represents the state of the art—that it\n                         can encapsulate the latest knowledge in neuronal anatomy and physiology in their corresponding\n                         model components. The Scientiﬁc Committee also deﬁnes the governance structure of the initiative\n                         and works with the wider scientiﬁc community to gather feedback on NeuroML and promote its use.\n                         The Editorial Board manages the day- to-day development and maintenance of LEMS, the NeuroML\n                         schema, the core software tools, and critical resources such as the documentation. The Editorial Board\n                         works with simulator developers in the extended ecosystem to help make tools NeuroML compliant\n                         by testing reference implementations and answering technical queries about NeuroML and the core\n                         software tools.\n\n                         Acknowledgements\n                         We thank all the members of the NeuroML Community who have contributed to the development\n                         of the standard over the years, have added support for the language to their applications, or who\n                         have converted published models to NeuroML. We would particularly like to thank the following for\n                         contributions to the NeuroML Scientiﬁc Committee: Upi Bhalla, Avrama Blackwell, Hugo Cornells,\n                         Robert McDougal, Lyle Graham, Cengiz Gunay, and Michael Hines. The following have also contrib-\n                         uted to developments related to the named tools/simulators/resources: EDEN - Mario Negrello and\n                         Christos Strydis, SONATA - Anton Arkhipov and Kael Dai, MOOSE - Subhasis Ray, NeuroML-  DB -\n                         Justas Birgiolas, NeuroMorpho.Org - Giorgio Ascoli, N2A - Fred Rothganger, pyLEMS - Gautham\n                         Ganapathy, MDF - Manifest Chakalov, libNeuroML and NeuroTune - Mike Vella, Open Source Brain\n                         - Matt Earnshaw, Adrian Quintana and Eugenio Piasini, SciUnit/NeuronUnit - Richard C Gerkin, Brian -\n                         Marcel Stimberg and Dominik Krzemiński, Arbor - Nora Abi Akar, Thorsten Hater and Brent Huisman,\n                         BluePyOpt - Jaquier Aurélien Tristan and Werner van Geit, C++/MATLAB APIs - Jonathan Cooper.\n                         We thank Rokas Stanislavos, András Ecker, Jessica Dafﬂon, Ronaldo Nunes, Anuja Negi, and Shayan\n                         Shafquat for their work converting models to NeuroML format as part of the Google Summer of Code\n                         program. We also thank Diccon Coyle for feedback on the manuscript.\n\n\nAdditional information\n\nCompeting interests\nMatteo Cantarelli: MetaCell Ltd. was contracted by UCL to develop some of the NeuroML support\non the Open Source Brain platform; MC has a ﬁnancial interest in MetaCell Ltd. Robert C Cannon:\nEmployee of Opus2 International Ltd. The other authors declare that no competing interests exist.\n\nFunding\nFunder               Grant reference number     Author\nWellcome Trust       10.35802/101445            Padraig Gleeson\n                                                Robin Angus Silver\nWellcome Trust       10.35802/212941            Padraig Gleeson\n                                                Robin Angus Silver\nWellcome Trust       10.35802/203048            Robin Angus Silver\nWellcome Trust       10.35802/224499            Robin Angus Silver\nKavli Foundation     LS-2022-GR-40-2648         Padraig Gleeson\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    38 of 44","md":"\n\neLife Tools and resources                                                                       Neuroscience\n\nto it are welcomed. A PDF version of the documentation can also be downloaded for offline use (https://docs.neuroml.org/_static/files/neuroml-documentation.pdf).\n\n## Maintenance of the Schema and core software\n\nThe NeuroML Scientific Committee (https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html) oversee the standard, the core tools, and the initiative. The Scientific Committee sets the scientific focus of the NeuroML initiative. It ensures that the standard represents the state of the art—that it can encapsulate the latest knowledge in neuronal anatomy and physiology in their corresponding model components. The Scientific Committee also defines the governance structure of the initiative and works with the wider scientific community to gather feedback on NeuroML and promote its use. The Editorial Board manages the day-to-day development and maintenance of LEMS, the NeuroML schema, the core software tools, and critical resources such as the documentation. The Editorial Board works with simulator developers in the extended ecosystem to help make tools NeuroML compliant by testing reference implementations and answering technical queries about NeuroML and the core software tools.\n\n## Acknowledgements\n\nWe thank all the members of the NeuroML Community who have contributed to the development of the standard over the years, have added support for the language to their applications, or who have converted published models to NeuroML. We would particularly like to thank the following for contributions to the NeuroML Scientific Committee: Upi Bhalla, Avrama Blackwell, Hugo Cornells, Robert McDougal, Lyle Graham, Cengiz Gunay, and Michael Hines. The following have also contributed to developments related to the named tools/simulators/resources: EDEN - Mario Negrello and Christos Strydis, SONATA - Anton Arkhipov and Kael Dai, MOOSE - Subhasis Ray, NeuroML-DB - Justas Birgiolas, NeuroMorpho.Org - Giorgio Ascoli, N2A - Fred Rothganger, pyLEMS - Gautham Ganapathy, MDF - Manifest Chakalov, libNeuroML and NeuroTune - Mike Vella, Open Source Brain - Matt Earnshaw, Adrian Quintana and Eugenio Piasini, SciUnit/NeuronUnit - Richard C Gerkin, Brian - Marcel Stimberg and Dominik Krzemiński, Arbor - Nora Abi Akar, Thorsten Hater and Brent Huisman, BluePyOpt - Jaquier Aurélien Tristan and Werner van Geit, C++/MATLAB APIs - Jonathan Cooper. We thank Rokas Stanislavos, András Ecker, Jessica Dafflon, Ronaldo Nunes, Anuja Negi, and Shayan Shafquat for their work converting models to NeuroML format as part of the Google Summer of Code program. We also thank Diccon Coyle for feedback on the manuscript.\n\n## Additional information\n\n### Competing interests\n\nMatteo Cantarelli: MetaCell Ltd. was contracted by UCL to develop some of the NeuroML support on the Open Source Brain platform; MC has a financial interest in MetaCell Ltd. Robert C Cannon: Employee of Opus2 International Ltd. The other authors declare that no competing interests exist.\n\n### Funding\n\n<table>\n<thead>\n<tr>\n<th>Funder</th>\n<th>Grant reference number</th>\n<th>Author</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/101445</td>\n<td>Padraig Gleeson<br>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/212941</td>\n<td>Padraig Gleeson<br>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/203048</td>\n<td>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/224499</td>\n<td>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Kavli Foundation</td>\n<td>LS-2022-GR-40-2648</td>\n<td>Padraig Gleeson</td>\n</tr>\n</tbody>\n</table>\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    38 of 44\n","images":[{"name":"page_38.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_38_text_1_v2.jpg","height":145156.848,"width":250415.671,"x":100967.59,"y":227430.911,"original_width":1654,"original_height":741,"rotation":0,"type":"layout_v2_text"},{"name":"page_38_text_2_v2.jpg","height":114872.957,"width":250419.224,"x":100932.383,"y":85447.544,"original_width":1654,"original_height":587,"rotation":0,"type":"layout_v2_text"},{"name":"page_38_text_3_v2.jpg","height":27301.567,"width":250214.953,"x":101116.344,"y":431595.463,"original_width":1653,"original_height":140,"rotation":0,"type":"layout_v2_text"},{"name":"page_38_text_4_v2.jpg","height":17406.583,"width":249967.463,"x":101079.314,"y":41322.909,"original_width":1651,"original_height":89,"rotation":0,"type":"layout_v2_text"},{"name":"page_38_table_1_v2.jpg","height":88434.971,"width":185118.888,"x":101598.39,"y":480901.903,"original_width":1223,"original_height":452,"rotation":0,"type":"layout_v2_table"},{"name":"page_38_paragraph_title_1_v2.jpg","height":9448.438,"width":92599.711,"x":101512.419,"y":396312.53,"original_width":612,"original_height":49,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_38_paragraph_title_2_v2.jpg","height":8076.243,"width":162764.577,"x":101469.52,"y":73500.847,"original_width":1075,"original_height":42,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_38_paragraph_title_3_v2.jpg","height":10523.627,"width":81611.986,"x":101526.353,"y":213688.125,"original_width":539,"original_height":54,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_38_footer_1_v2.jpg","height":6912.312,"width":191864.416,"x":21563.082,"y":591533.807,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_38_header_1_v2.jpg","height":5599.136,"width":30334.762,"x":320705.609,"y":27711.6,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_38_paragraph_title_4_v2.jpg","height":6978.429,"width":54587.584,"x":101424.864,"y":422098.686,"original_width":361,"original_height":36,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_38_number_1_v2.jpg","height":5747.6,"width":18296.194,"x":332832.338,"y":591876.744,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_38_header_2_v2.jpg","height":5827.523,"width":42929.376,"x":47691.128,"y":27783.576,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_38_figure_title_1_v2.jpg","height":7469.224,"width":21976.463,"x":101894.899,"y":470661.191,"original_width":146,"original_height":39,"rotation":0,"type":"layout_v2_figure_title"},{"name":"page_38_header_3_v2.jpg","height":10637.87,"width":24434.302,"x":21808.477,"y":22428.555,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                       Neuroscience","md":"eLife Tools and resources                                                                       Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":77,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":96,"endIndex":108}]},{"type":"text","value":"to it are welcomed. A PDF version of the documentation can also be downloaded for offline use (https://docs.neuroml.org/_static/files/neuroml-documentation.pdf).","md":"to it are welcomed. A PDF version of the documentation can also be downloaded for offline use (https://docs.neuroml.org/_static/files/neuroml-documentation.pdf).","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":165,"y":52,"w":408,"h":21,"startIndex":0,"endIndex":160}]},{"type":"heading","lvl":2,"value":"Maintenance of the Schema and core software","md":"## Maintenance of the Schema and core software","bBox":{"x":168.53,"y":91.16,"w":263.25,"h":12},"layoutAwareBbox":[{"x":165,"y":92,"w":265,"h":10,"startIndex":0,"endIndex":45}]},{"type":"text","value":"The NeuroML Scientific Committee (https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html) oversee the standard, the core tools, and the initiative. The Scientific Committee sets the scientific focus of the NeuroML initiative. It ensures that the standard represents the state of the art—that it can encapsulate the latest knowledge in neuronal anatomy and physiology in their corresponding model components. The Scientific Committee also defines the governance structure of the initiative and works with the wider scientific community to gather feedback on NeuroML and promote its use. The Editorial Board manages the day-to-day development and maintenance of LEMS, the NeuroML schema, the core software tools, and critical resources such as the documentation. The Editorial Board works with simulator developers in the extended ecosystem to help make tools NeuroML compliant by testing reference implementations and answering technical queries about NeuroML and the core software tools.","md":"The NeuroML Scientific Committee (https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html) oversee the standard, the core tools, and the initiative. The Scientific Committee sets the scientific focus of the NeuroML initiative. It ensures that the standard represents the state of the art—that it can encapsulate the latest knowledge in neuronal anatomy and physiology in their corresponding model components. The Scientific Committee also defines the governance structure of the initiative and works with the wider scientific community to gather feedback on NeuroML and promote its use. The Editorial Board manages the day-to-day development and maintenance of LEMS, the NeuroML schema, the core software tools, and critical resources such as the documentation. The Editorial Board works with simulator developers in the extended ecosystem to help make tools NeuroML compliant by testing reference implementations and answering technical queries about NeuroML and the core software tools.","bBox":{"x":168.53,"y":119.9,"w":414.8,"h":132.66},"layoutAwareBbox":[{"x":164,"y":107,"w":409,"h":145,"startIndex":0,"endIndex":3}]},{"type":"heading","lvl":2,"value":"Acknowledgements","md":"## Acknowledgements","bBox":{"x":168.53,"y":267.47,"w":130.93,"h":14},"layoutAwareBbox":[{"x":165,"y":269,"w":133,"h":13,"startIndex":3,"endIndex":19}]},{"type":"text","value":"We thank all the members of the NeuroML Community who have contributed to the development of the standard over the years, have added support for the language to their applications, or who have converted published models to NeuroML. We would particularly like to thank the following for contributions to the NeuroML Scientific Committee: Upi Bhalla, Avrama Blackwell, Hugo Cornells, Robert McDougal, Lyle Graham, Cengiz Gunay, and Michael Hines. The following have also contributed to developments related to the named tools/simulators/resources: EDEN - Mario Negrello and Christos Strydis, SONATA - Anton Arkhipov and Kael Dai, MOOSE - Subhasis Ray, NeuroML-DB - Justas Birgiolas, NeuroMorpho.Org - Giorgio Ascoli, N2A - Fred Rothganger, pyLEMS - Gautham Ganapathy, MDF - Manifest Chakalov, libNeuroML and NeuroTune - Mike Vella, Open Source Brain - Matt Earnshaw, Adrian Quintana and Eugenio Piasini, SciUnit/NeuronUnit - Richard C Gerkin, Brian - Marcel Stimberg and Dominik Krzemiński, Arbor - Nora Abi Akar, Thorsten Hater and Brent Huisman, BluePyOpt - Jaquier Aurélien Tristan and Werner van Geit, C++/MATLAB APIs - Jonathan Cooper. We thank Rokas Stanislavos, András Ecker, Jessica Dafflon, Ronaldo Nunes, Anuja Negi, and Shayan Shafquat for their work converting models to NeuroML format as part of the Google Summer of Code program. We also thank Diccon Coyle for feedback on the manuscript.","md":"We thank all the members of the NeuroML Community who have contributed to the development of the standard over the years, have added support for the language to their applications, or who have converted published models to NeuroML. We would particularly like to thank the following for contributions to the NeuroML Scientific Committee: Upi Bhalla, Avrama Blackwell, Hugo Cornells, Robert McDougal, Lyle Graham, Cengiz Gunay, and Michael Hines. The following have also contributed to developments related to the named tools/simulators/resources: EDEN - Mario Negrello and Christos Strydis, SONATA - Anton Arkhipov and Kael Dai, MOOSE - Subhasis Ray, NeuroML-DB - Justas Birgiolas, NeuroMorpho.Org - Giorgio Ascoli, N2A - Fred Rothganger, pyLEMS - Gautham Ganapathy, MDF - Manifest Chakalov, libNeuroML and NeuroTune - Mike Vella, Open Source Brain - Matt Earnshaw, Adrian Quintana and Eugenio Piasini, SciUnit/NeuronUnit - Richard C Gerkin, Brian - Marcel Stimberg and Dominik Krzemiński, Arbor - Nora Abi Akar, Thorsten Hater and Brent Huisman, BluePyOpt - Jaquier Aurélien Tristan and Werner van Geit, C++/MATLAB APIs - Jonathan Cooper. We thank Rokas Stanislavos, András Ecker, Jessica Dafflon, Ronaldo Nunes, Anuja Negi, and Shayan Shafquat for their work converting models to NeuroML format as part of the Google Summer of Code program. We also thank Diccon Coyle for feedback on the manuscript.","bBox":{"x":168.53,"y":286.84,"w":414.47,"h":182.12},"layoutAwareBbox":[{"x":164,"y":287,"w":409,"h":183,"startIndex":13,"endIndex":16}]},{"type":"heading","lvl":2,"value":"Additional information","md":"## Additional information","bBox":{"x":168.53,"y":498.39,"w":149.58,"h":14},"layoutAwareBbox":[{"x":165,"y":500,"w":151,"h":11,"startIndex":0,"endIndex":24}]},{"type":"heading","lvl":3,"value":"Competing interests","md":"### Competing interests","bBox":{"x":168.53,"y":532.26,"w":85.83,"h":9},"layoutAwareBbox":[{"x":165,"y":532,"w":89,"h":8,"startIndex":0,"endIndex":22}]},{"type":"text","value":"Matteo Cantarelli: MetaCell Ltd. was contracted by UCL to develop some of the NeuroML support on the Open Source Brain platform; MC has a financial interest in MetaCell Ltd. Robert C Cannon: Employee of Opus2 International Ltd. The other authors declare that no competing interests exist.","md":"Matteo Cantarelli: MetaCell Ltd. was contracted by UCL to develop some of the NeuroML support on the Open Source Brain platform; MC has a financial interest in MetaCell Ltd. Robert C Cannon: Employee of Opus2 International Ltd. The other authors declare that no competing interests exist.","bBox":{"x":168.53,"y":544.63,"w":400.23,"h":33.73},"layoutAwareBbox":[{"x":165,"y":544,"w":408,"h":34,"startIndex":0,"endIndex":287}]},{"type":"heading","lvl":3,"value":"Funding","md":"### Funding","bBox":{"x":168.53,"y":593.73,"w":34.34,"h":9},"layoutAwareBbox":[{"x":166,"y":594,"w":35,"h":9,"startIndex":4,"endIndex":11}]},{"type":"table","rows":[["Funder","Grant reference number","Author"],["Wellcome Trust","10.35802/101445","Padraig Gleeson<br/>Robin Angus Silver"],["Wellcome Trust","10.35802/212941","Padraig Gleeson<br/>Robin Angus Silver"],["Wellcome Trust","10.35802/203048","Robin Angus Silver"],["Wellcome Trust","10.35802/224499","Robin Angus Silver"],["Kavli Foundation","LS-2022-GR-40-2648","Padraig Gleeson"]],"html":"<table>\n<thead>\n<tr>\n<th>Funder</th>\n<th>Grant reference number</th>\n<th>Author</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/101445</td>\n<td>Padraig Gleeson<br />Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/212941</td>\n<td>Padraig Gleeson<br />Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/203048</td>\n<td>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Wellcome Trust</td>\n<td>10.35802/224499</td>\n<td>Robin Angus Silver</td>\n</tr>\n<tr>\n<td>Kavli Foundation</td>\n<td>LS-2022-GR-40-2648</td>\n<td>Padraig Gleeson</td>\n</tr>\n</tbody>\n</table>","md":"| Funder           | Grant reference number | Author                                 |\n| ---------------- | ---------------------- | -------------------------------------- |\n| Wellcome Trust   | 10.35802/101445        | Padraig Gleeson<br/>Robin Angus Silver |\n| Wellcome Trust   | 10.35802/212941        | Padraig Gleeson<br/>Robin Angus Silver |\n| Wellcome Trust   | 10.35802/203048        | Robin Angus Silver                     |\n| Wellcome Trust   | 10.35802/224499        | Robin Angus Silver                     |\n| Kavli Foundation | LS-2022-GR-40-2648     | Padraig Gleeson                        |","isPerfectTable":false,"csv":"\"Funder\",\"Grant reference number\",\"Author\"\n\"Wellcome Trust\",\"10.35802/101445\",\"Padraig Gleeson<br/>Robin Angus Silver\"\n\"Wellcome Trust\",\"10.35802/212941\",\"Padraig Gleeson<br/>Robin Angus Silver\"\n\"Wellcome Trust\",\"10.35802/203048\",\"Robin Angus Silver\"\n\"Wellcome Trust\",\"10.35802/224499\",\"Robin Angus Silver\"\n\"Kavli Foundation\",\"LS-2022-GR-40-2648\",\"Padraig Gleeson\"","bBox":{"x":168.53,"y":569.36,"w":396.58,"h":145.79},"layoutAwareBbox":[{"x":166,"y":607,"w":302,"h":111,"startIndex":2,"endIndex":8}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    38 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    38 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://docs.neuroml.org/_static/files/neuroml-documentation.pdf","unsafeUrl":"https://docs.neuroml.org/_static/files/neuroml-documentation.pdf","text":"(https://docs.neuroml.org/_static/ﬁles/neuroml-documentation.pdf)."},{"url":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","text":"The NeuroML Scientiﬁc Committee (https://docs.neuroml.org/NeuroMLOrg/ScientiﬁcCommittee."},{"url":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/ScientificCommittee.html","text":"html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html) "},{"url":"https://docs.neuroml.org/NeuroMLOrg/Board.html","unsafeUrl":"https://docs.neuroml.org/NeuroMLOrg/Board.html","text":"html) and the elected NeuroML Editorial Board (https://docs.neuroml.org/NeuroMLOrg/Board.html) "},{"url":"https://doi.org/10.35802/101445","unsafeUrl":"https://doi.org/10.35802/101445","text":"10.35802/101445"},{"url":"https://doi.org/10.35802/212941","unsafeUrl":"https://doi.org/10.35802/212941","text":"10.35802/212941"},{"url":"https://doi.org/10.35802/203048","unsafeUrl":"https://doi.org/10.35802/203048","text":"10.35802/203048"},{"url":"https://doi.org/10.35802/224499","unsafeUrl":"https://doi.org/10.35802/224499","text":"10.35802/224499"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                       Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    38 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.973,"layout":[{"image":"page_38_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.363,"w":0.669,"h":0.231},"isLikelyNoise":false},{"image":"page_38_text_2_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.269,"y":0.136,"w":0.669,"h":0.183},"isLikelyNoise":false},{"image":"page_38_text_3_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.688,"w":0.668,"h":0.044},"isLikelyNoise":false},{"image":"page_38_text_4_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.27,"y":0.066,"w":0.667,"h":0.028},"isLikelyNoise":false},{"image":"page_38_table_1_v2.jpg","confidence":0.96,"label":"table","bbox":{"x":0.271,"y":0.767,"w":0.494,"h":0.141},"isLikelyNoise":false},{"image":"page_38_paragraph_title_1_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.271,"y":0.632,"w":0.247,"h":0.015},"isLikelyNoise":false},{"image":"page_38_paragraph_title_2_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.271,"y":0.117,"w":0.435,"h":0.013},"isLikelyNoise":false},{"image":"page_38_paragraph_title_3_v2.jpg","confidence":0.92,"label":"paragraph_title","bbox":{"x":0.271,"y":0.341,"w":0.218,"h":0.017},"isLikelyNoise":false},{"image":"page_38_footer_1_v2.jpg","confidence":0.91,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_38_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.856,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_38_paragraph_title_4_v2.jpg","confidence":0.89,"label":"paragraph_title","bbox":{"x":0.271,"y":0.673,"w":0.146,"h":0.011},"isLikelyNoise":false},{"image":"page_38_number_1_v2.jpg","confidence":0.88,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_38_header_2_v2.jpg","confidence":0.66,"label":"header","bbox":{"x":0.127,"y":0.044,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_38_figure_title_1_v2.jpg","confidence":0.57,"label":"figure_title","bbox":{"x":0.272,"y":0.75,"w":0.059,"h":0.012},"isLikelyNoise":true},{"image":"page_38_header_3_v2.jpg","confidence":0.52,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":39,"text":"Tools  and  resources                                                                                        Neuroscience\n\n                         Funder                       Grant reference number     Author\n                         Engineering and Physical     EP/X011151/1               Padraig Gleeson\n                         Sciences Research Council\n                         National Institutes of       MH081905                   Sharon Crook\n                         Health\n                         National Institutes of       EB014640                   Sharon Crook\n                         Health\n                         National Institutes of       MH106674                   Sharon Crook\n                         Health\n                         National Institutes of       U24EB028998                Salvador Dura-Bernal\n                         Health\n                         New York State               DOH01-C38328GG             Salvador Dura-Bernal\n                         Department of Health -\n                         Wadsworth Center\n                         HORIZON EUROPE               SEPTON (Gr. Agr. No.       Sotirios Panagiotou\n                         Framework Programme          101094901)\n                         The funders had no role in study design, data collection and interpretation, or the\n                         decision to submit the work for publication. For the purpose of Open Access, the\n                         authors have applied a CC BY public copyright license to any Author Accepted\n                         Manuscript version arising from this submission.\n\n                         Author contributions\n                         Ankur Sinha, Conceptualization, Resources, Data curation, Software, Formal analysis, Validation,\n                         Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing –\n                         review and editing; Padraig Gleeson, Conceptualization, Resources, Data curation, Software, Formal\n                         analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology,\n                         Writing – original draft, Project administration, Writing – review and editing; Bóris Marin, Conceptu-\n                         alization, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing;\n                         Salvador Dura- Bernal, Conceptualization, Resources, Software, Funding acquisition, Investigation,\n                         Visualization, Methodology, Writing – review and editing; Sotirios Panagiotou, Resources, Software,\n                         Validation, Investigation, Methodology, Writing – review and editing; Sharon Crook, Conceptualiza-\n                         tion, Resources, Software, Supervision, Funding acquisition, Validation, Investigation, Methodology,\n                         Writing – review and editing; Matteo Cantarelli, Conceptualization, Resources, Software, Validation,\n                         Investigation, Visualization, Methodology, Writing – review and editing; Robert C Cannon, Conceptu-\n                         alization, Resources, Software, Investigation, Methodology; Andrew P Davison, Software, Investiga-\n                         tion, Methodology, Writing – review and editing; Harsha Gurnani, Data curation, Software, Validation,\n                         Investigation, Methodology; Robin Angus Silver, Conceptualization, Formal analysis, Supervision,\n                         Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration,\n                         Writing – review and editing\n\n                         Author ORCIDs\n                         Ankur Sinha        http://orcid.org/0000-0001-7568-7167\n                         Padraig Gleeson            https://orcid.org/0000-0001-5963-8576\n                         Matteo Cantarelli          https://orcid.org/0000-0002-0054-226X\n                         Andrew P Davison           https://orcid.org/0000-0002-4793-7541\n                         Robin Angus Silver         https://orcid.org/0000-0002-5480-6638\n\n                         Peer review material\n                         Reviewer #1 (Public review): https://doi.org/10.7554/eLife.95135.3.sa1\n                         Reviewer #2 (Public review): https://doi.org/10.7554/eLife.95135.3.sa2\n                         Author response https://doi.org/10.7554/eLife.95135.3.sa3\n\n\nAdditional files\n\nSupplementary files\nMDAR checklist\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    39 of 44","md":"\n\neLife Tools and resources                                                                                        Neuroscience\n\n<table>\n<thead>\n<tr>\n<th>Funder</th>\n<th>Grant reference number</th>\n<th>Author</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Engineering and Physical Sciences Research Council</td>\n<td>EP/X011151/1</td>\n<td>Padraig Gleeson</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>MH081905</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>EB014640</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>MH106674</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>U24EB028998</td>\n<td>Salvador Dura-Bernal</td>\n</tr>\n<tr>\n<td>New York State Department of Health - Wadsworth Center</td>\n<td>DOH01-C38328GG</td>\n<td>Salvador Dura-Bernal</td>\n</tr>\n<tr>\n<td>HORIZON EUROPE Framework Programme</td>\n<td>SEPTON (Gr. Agr. No. 101094901)</td>\n<td>Sotirios Panagiotou</td>\n</tr>\n</tbody>\n</table>\n\nThe funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.\n\n## Author contributions\n\nAnkur Sinha, Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Padraig Gleeson, Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Bóris Marin, Conceptualization, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Salvador Dura-Bernal, Conceptualization, Resources, Software, Funding acquisition, Investigation, Visualization, Methodology, Writing – review and editing; Sotirios Panagiotou, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Sharon Crook, Conceptualization, Resources, Software, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing – review and editing; Matteo Cantarelli, Conceptualization, Resources, Software, Validation, Investigation, Visualization, Methodology, Writing – review and editing; Robert C Cannon, Conceptualization, Resources, Software, Investigation, Methodology; Andrew P Davison, Software, Investigation, Methodology, Writing – review and editing; Harsha Gurnani, Data curation, Software, Validation, Investigation, Methodology; Robin Angus Silver, Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing\n\n## Author ORCIDs\n\nAnkur Sinha http://orcid.org/0000-0001-7568-7167\nPadraig Gleeson https://orcid.org/0000-0001-5963-8576\nMatteo Cantarelli https://orcid.org/0000-0002-0054-226X\nAndrew P Davison https://orcid.org/0000-0002-4793-7541\nRobin Angus Silver https://orcid.org/0000-0002-5480-6638\n\n## Peer review material\n\nReviewer #1 (Public review): https://doi.org/10.7554/eLife.95135.3.sa1\nReviewer #2 (Public review): https://doi.org/10.7554/eLife.95135.3.sa2\nAuthor response https://doi.org/10.7554/eLife.95135.3.sa3\n\n## Additional files\n\n### Supplementary files\n\nMDAR checklist\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    39 of 44\n","images":[{"name":"page_39.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_39_text_1_v2.jpg","height":161922.791,"width":250477.034,"x":100978.213,"y":254263.187,"original_width":1654,"original_height":827,"rotation":0,"type":"layout_v2_text"},{"name":"page_39_text_2_v2.jpg","height":43296.309,"width":153293.704,"x":101494.978,"y":430917.901,"original_width":1013,"original_height":221,"rotation":0,"type":"layout_v2_text"},{"name":"page_39_text_3_v2.jpg","height":27447.916,"width":171581.802,"x":101580.664,"y":490039.14,"original_width":1133,"original_height":141,"rotation":0,"type":"layout_v2_text"},{"name":"page_39_text_4_v2.jpg","height":15862.977,"width":52244.813,"x":101894.248,"y":554094.262,"original_width":345,"original_height":81,"rotation":0,"type":"layout_v2_text"},{"name":"page_39_footer_1_v2.jpg","height":6817.83,"width":191772.245,"x":21627.008,"y":591504.561,"original_width":1267,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_39_paragraph_title_1_v2.jpg","height":9671.587,"width":61640.385,"x":102119.504,"y":535920.169,"original_width":407,"original_height":50,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_39_header_1_v2.jpg","height":5558.774,"width":30199.484,"x":320898.137,"y":27699.543,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_39_paragraph_title_2_v2.jpg","height":6474.952,"width":55364.972,"x":101617.988,"y":245120.187,"original_width":366,"original_height":34,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_39_number_1_v2.jpg","height":5905.651,"width":18201.626,"x":332895.1,"y":591736.747,"original_width":121,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_39_paragraph_title_3_v2.jpg","height":6659.387,"width":41230.88,"x":101596.301,"y":422684.394,"original_width":273,"original_height":34,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_39_table_1_v2.jpg","height":154745.35,"width":185049.07,"x":101677.795,"y":44719.081,"original_width":1222,"original_height":790,"rotation":0,"type":"layout_v2_table"},{"name":"page_39_paragraph_title_4_v2.jpg","height":6648.939,"width":54804.889,"x":101871.106,"y":481248.486,"original_width":362,"original_height":34,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_39_header_2_v2.jpg","height":5751.422,"width":42773.327,"x":47778.077,"y":27817.217,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_39_header_3_v2.jpg","height":10707.011,"width":24311.502,"x":21910.774,"y":22402.485,"original_width":161,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_39_text_5_v2.jpg","height":28518.518,"width":178868.801,"x":101697.671,"y":203307.631,"original_width":1182,"original_height":146,"rotation":0,"type":"layout_v2_text"},{"name":"page_39_figure_title_1_v2.jpg","height":6520.542,"width":77996.084,"x":163599.365,"y":44833.047,"original_width":515,"original_height":34,"rotation":0,"type":"layout_v2_figure_title"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                        Neuroscience","md":"eLife Tools and resources                                                                                        Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":113,"endIndex":125}]},{"type":"table","rows":[["Funder","Grant reference number","Author"],["Engineering and Physical Sciences Research Council","EP/X011151/1","Padraig Gleeson"],["National Institutes of Health","MH081905","Sharon Crook"],["National Institutes of Health","EB014640","Sharon Crook"],["National Institutes of Health","MH106674","Sharon Crook"],["National Institutes of Health","U24EB028998","Salvador Dura-Bernal"],["New York State Department of Health - Wadsworth Center","DOH01-C38328GG","Salvador Dura-Bernal"],["HORIZON EUROPE Framework Programme","SEPTON (Gr. Agr. No. 101094901)","Sotirios Panagiotou"]],"html":"<table>\n<thead>\n<tr>\n<th>Funder</th>\n<th>Grant reference number</th>\n<th>Author</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Engineering and Physical Sciences Research Council</td>\n<td>EP/X011151/1</td>\n<td>Padraig Gleeson</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>MH081905</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>EB014640</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>MH106674</td>\n<td>Sharon Crook</td>\n</tr>\n<tr>\n<td>National Institutes of Health</td>\n<td>U24EB028998</td>\n<td>Salvador Dura-Bernal</td>\n</tr>\n<tr>\n<td>New York State Department of Health - Wadsworth Center</td>\n<td>DOH01-C38328GG</td>\n<td>Salvador Dura-Bernal</td>\n</tr>\n<tr>\n<td>HORIZON EUROPE Framework Programme</td>\n<td>SEPTON (Gr. Agr. No. 101094901)</td>\n<td>Sotirios Panagiotou</td>\n</tr>\n</tbody>\n</table>","md":"| Funder                                                 | Grant reference number          | Author               |\n| ------------------------------------------------------ | ------------------------------- | -------------------- |\n| Engineering and Physical Sciences Research Council     | EP/X011151/1                    | Padraig Gleeson      |\n| National Institutes of Health                          | MH081905                        | Sharon Crook         |\n| National Institutes of Health                          | EB014640                        | Sharon Crook         |\n| National Institutes of Health                          | MH106674                        | Sharon Crook         |\n| National Institutes of Health                          | U24EB028998                     | Salvador Dura-Bernal |\n| New York State Department of Health - Wadsworth Center | DOH01-C38328GG                  | Salvador Dura-Bernal |\n| HORIZON EUROPE Framework Programme                     | SEPTON (Gr. Agr. No. 101094901) | Sotirios Panagiotou  |","isPerfectTable":true,"csv":"\"Funder\",\"Grant reference number\",\"Author\"\n\"Engineering and Physical Sciences Research Council\",\"EP/X011151/1\",\"Padraig Gleeson\"\n\"National Institutes of Health\",\"MH081905\",\"Sharon Crook\"\n\"National Institutes of Health\",\"EB014640\",\"Sharon Crook\"\n\"National Institutes of Health\",\"MH106674\",\"Sharon Crook\"\n\"National Institutes of Health\",\"U24EB028998\",\"Salvador Dura-Bernal\"\n\"New York State Department of Health - Wadsworth Center\",\"DOH01-C38328GG\",\"Salvador Dura-Bernal\"\n\"HORIZON EUROPE Framework Programme\",\"SEPTON (Gr. Agr. No. 101094901)\",\"Sotirios Panagiotou\"","bBox":{"x":168.53,"y":56.17,"w":406.4,"h":596.15},"layoutAwareBbox":[{"x":166,"y":56,"w":302,"h":195,"startIndex":2,"endIndex":8}]},{"type":"text","value":"The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.","md":"The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.","bBox":{"x":168.53,"y":256.56,"w":290.69,"h":35},"layoutAwareBbox":[{"x":166,"y":256,"w":292,"h":36,"startIndex":0,"endIndex":289}]},{"type":"heading","lvl":2,"value":"Author contributions","md":"## Author contributions","bBox":{"x":168.53,"y":308.81,"w":87.65,"h":9},"layoutAwareBbox":[{"x":166,"y":309,"w":90,"h":8,"startIndex":0,"endIndex":22}]},{"type":"text","value":"Ankur Sinha, Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Padraig Gleeson, Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Bóris Marin, Conceptualization, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Salvador Dura-Bernal, Conceptualization, Resources, Software, Funding acquisition, Investigation, Visualization, Methodology, Writing – review and editing; Sotirios Panagiotou, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Sharon Crook, Conceptualization, Resources, Software, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing – review and editing; Matteo Cantarelli, Conceptualization, Resources, Software, Validation, Investigation, Visualization, Methodology, Writing – review and editing; Robert C Cannon, Conceptualization, Resources, Software, Investigation, Methodology; Andrew P Davison, Software, Investigation, Methodology, Writing – review and editing; Harsha Gurnani, Data curation, Software, Validation, Investigation, Methodology; Robin Angus Silver, Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing","md":"Ankur Sinha, Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Padraig Gleeson, Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing; Bóris Marin, Conceptualization, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Salvador Dura-Bernal, Conceptualization, Resources, Software, Funding acquisition, Investigation, Visualization, Methodology, Writing – review and editing; Sotirios Panagiotou, Resources, Software, Validation, Investigation, Methodology, Writing – review and editing; Sharon Crook, Conceptualization, Resources, Software, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing – review and editing; Matteo Cantarelli, Conceptualization, Resources, Software, Validation, Investigation, Visualization, Methodology, Writing – review and editing; Robert C Cannon, Conceptualization, Resources, Software, Investigation, Methodology; Andrew P Davison, Software, Investigation, Methodology, Writing – review and editing; Harsha Gurnani, Data curation, Software, Validation, Investigation, Methodology; Robin Angus Silver, Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing","bBox":{"x":168.53,"y":97.27,"w":411.38,"h":489.41},"layoutAwareBbox":[{"x":164,"y":321,"w":409,"h":204,"startIndex":21,"endIndex":30}]},{"type":"heading","lvl":2,"value":"Author ORCIDs","md":"## Author ORCIDs","bBox":{"x":168.53,"y":533.18,"w":64.65,"h":9},"layoutAwareBbox":[{"x":166,"y":533,"w":67,"h":8,"startIndex":0,"endIndex":15}]},{"type":"text","value":"Ankur Sinha http://orcid.org/0000-0001-7568-7167\nPadraig Gleeson https://orcid.org/0000-0001-5963-8576\nMatteo Cantarelli https://orcid.org/0000-0002-0054-226X\nAndrew P Davison https://orcid.org/0000-0002-4793-7541\nRobin Angus Silver https://orcid.org/0000-0002-5480-6638","md":"Ankur Sinha http://orcid.org/0000-0001-7568-7167\nPadraig Gleeson https://orcid.org/0000-0001-5963-8576\nMatteo Cantarelli https://orcid.org/0000-0002-0054-226X\nAndrew P Davison https://orcid.org/0000-0002-4793-7541\nRobin Angus Silver https://orcid.org/0000-0002-5480-6638","bBox":{"x":168.53,"y":72.22,"w":258.98,"h":525.58},"layoutAwareBbox":[{"x":165,"y":544,"w":250,"h":54,"startIndex":12,"endIndex":48}]},{"type":"heading","lvl":2,"value":"Peer review material","md":"## Peer review material","bBox":{"x":168.53,"y":606.93,"w":86.85,"h":9},"layoutAwareBbox":[{"x":166,"y":607,"w":89,"h":8,"startIndex":0,"endIndex":22}]},{"type":"text","value":"Reviewer #1 (Public review): https://doi.org/10.7554/eLife.95135.3.sa1\nReviewer #2 (Public review): https://doi.org/10.7554/eLife.95135.3.sa2\nAuthor response https://doi.org/10.7554/eLife.95135.3.sa3","md":"Reviewer #1 (Public review): https://doi.org/10.7554/eLife.95135.3.sa1\nReviewer #2 (Public review): https://doi.org/10.7554/eLife.95135.3.sa2\nAuthor response https://doi.org/10.7554/eLife.95135.3.sa3","bBox":{"x":168.53,"y":619.06,"w":278.1,"h":33.26},"layoutAwareBbox":[{"x":165,"y":618,"w":280,"h":34,"startIndex":29,"endIndex":70}]},{"type":"heading","lvl":2,"value":"Additional files","md":"## Additional files","bBox":{"x":168.53,"y":675.05,"w":99.85,"h":14},"layoutAwareBbox":[{"x":166,"y":676,"w":100,"h":12,"startIndex":0,"endIndex":18}]},{"type":"heading","lvl":3,"value":"Supplementary files","md":"### Supplementary files","bBox":{"x":168.53,"y":699.18,"w":83.35,"h":9},"layoutAwareBbox":[{"x":166,"y":699,"w":85,"h":20,"startIndex":0,"endIndex":22}]},{"type":"text","value":"MDAR checklist","md":"MDAR checklist","bBox":{"x":168.53,"y":710.31,"w":66.18,"h":9},"layoutAwareBbox":[{"x":166,"y":699,"w":85,"h":20,"startIndex":0,"endIndex":13}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    39 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    39 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"http://orcid.org/0000-0001-7568-7167","unsafeUrl":"http://orcid.org/0000-0001-7568-7167","text":" http://orcid.org/0000-0001-7568-7167   https://orcid.org/0000-0001-5963-8576"},{"url":"https://orcid.org/0000-0001-5963-8576","unsafeUrl":"https://orcid.org/0000-0001-5963-8576","text":" https://orcid.org/0000-0001-5963-8576   https://orcid.org/0000-0002-0054-226X"},{"url":"https://orcid.org/0000-0002-0054-226X","unsafeUrl":"https://orcid.org/0000-0002-0054-226X","text":" https://orcid.org/0000-0002-0054-226X   https://orcid.org/0000-0002-4793-7541"},{"url":"https://orcid.org/0000-0002-4793-7541","unsafeUrl":"https://orcid.org/0000-0002-4793-7541","text":" https://orcid.org/0000-0002-4793-7541 https://orcid.org/0000-0002-5480-6638"},{"url":"https://orcid.org/0000-0002-5480-6638","unsafeUrl":"https://orcid.org/0000-0002-5480-6638","text":" https://orcid.org/0000-0002-5480-6638"},{"url":"https://doi.org/10.7554/eLife.95135.3.sa1","unsafeUrl":"https://doi.org/10.7554/eLife.95135.3.sa1","text":"Reviewer #1 (Public review):  https://doi.org/10.7554/eLife.95135.3.sa1"},{"url":"https://doi.org/10.7554/eLife.95135.3.sa2","unsafeUrl":"https://doi.org/10.7554/eLife.95135.3.sa2","text":"Reviewer #2 (Public review):  https://doi.org/10.7554/eLife.95135.3.sa2"},{"url":"https://doi.org/10.7554/eLife.95135.3.sa3","unsafeUrl":"https://doi.org/10.7554/eLife.95135.3.sa3","text":"Author response  https://doi.org/10.7554/eLife.95135.3.sa3"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                        Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    39 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.995,"layout":[{"image":"page_39_text_1_v2.jpg","confidence":0.99,"label":"text","bbox":{"x":0.27,"y":0.405,"w":0.669,"h":0.258},"isLikelyNoise":false},{"image":"page_39_text_2_v2.jpg","confidence":0.96,"label":"text","bbox":{"x":0.271,"y":0.687,"w":0.409,"h":0.069},"isLikelyNoise":false},{"image":"page_39_text_3_v2.jpg","confidence":0.95,"label":"text","bbox":{"x":0.271,"y":0.781,"w":0.458,"h":0.044},"isLikelyNoise":false},{"image":"page_39_text_4_v2.jpg","confidence":0.93,"label":"text","bbox":{"x":0.272,"y":0.883,"w":0.139,"h":0.025},"isLikelyNoise":false},{"image":"page_39_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_39_paragraph_title_1_v2.jpg","confidence":0.91,"label":"paragraph_title","bbox":{"x":0.273,"y":0.854,"w":0.165,"h":0.015},"isLikelyNoise":false},{"image":"page_39_header_1_v2.jpg","confidence":0.91,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_39_paragraph_title_2_v2.jpg","confidence":0.9,"label":"paragraph_title","bbox":{"x":0.271,"y":0.391,"w":0.148,"h":0.01},"isLikelyNoise":false},{"image":"page_39_number_1_v2.jpg","confidence":0.89,"label":"number","bbox":{"x":0.889,"y":0.943,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_39_paragraph_title_3_v2.jpg","confidence":0.87,"label":"paragraph_title","bbox":{"x":0.271,"y":0.674,"w":0.11,"h":0.011},"isLikelyNoise":false},{"image":"page_39_table_1_v2.jpg","confidence":0.86,"label":"table","bbox":{"x":0.271,"y":0.071,"w":0.494,"h":0.247},"isLikelyNoise":false},{"image":"page_39_paragraph_title_4_v2.jpg","confidence":0.78,"label":"paragraph_title","bbox":{"x":0.272,"y":0.767,"w":0.146,"h":0.011},"isLikelyNoise":false},{"image":"page_39_header_2_v2.jpg","confidence":0.78,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_39_header_3_v2.jpg","confidence":0.65,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false},{"image":"page_39_text_5_v2.jpg","confidence":0.62,"label":"text","bbox":{"x":0.272,"y":0.324,"w":0.478,"h":0.045},"isLikelyNoise":false},{"image":"page_39_figure_title_1_v2.jpg","confidence":0.54,"label":"figure_title","bbox":{"x":0.437,"y":0.071,"w":0.208,"h":0.01},"isLikelyNoise":true}]},{"page":40,"text":"Tools  and  resources                                                           Neuroscience\n\n                         Data availability\n                         No data was generated in this study. All software noted in this manuscript is open source. The\n                         NeuroML core libraries can be found at https://github.com/neuroml (copy archived at Gleeson and\n                         Sinha , 2024). Tables 3 and 4 provide links to the software packages and their source code reposito-\n                         ries include DOI information for each software release.\n\n\nReferences\nAbrams MB, Bjaalie JG, Das S, Egan GF, Ghosh SS, Goscinski WJ, Grethe JS, Kotaleski JH, Ho ETW,\n Kennedy DN, Lanyon LJ, Leergaard TB, Mayberg HS, Milanesi L, Mouček R, Poline JB, Roy PK, Strother SC,\n Tang TB, Tiesinga P, et al. 2022. A standards organization for open and fair neuroscience: the international\n neuroinformatics coordinating facility. Neuroinformatics 20:25–36. DOI: https://doi.org/10.1007/s12021-020-\n 09509-0, PMID: 33506383\nAkar NA, Cumming B, Karakasis V, Kusters A, Klijn W, Peyser A, Yates S. 2019. Arbor — a morphologically-\n detailed neural network simulation library for contemporary high-performance computing architectures. 2019\n 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP.\n 274–282. DOI: https://doi.org/10.1109/EMPDP.2019.8671560\nAscoli GA, Donohue DE, Halavi M. 2007. NeuroMorpho.Org: a central resource for neuronal morphologies. The\n Journal of Neuroscience 27:9247–9251. DOI: https://doi.org/10.1523/JNEUROSCI.2055-07.2007, PMID:\n 17728438\nAwile O, Kumbhar P, Cornu N, Dura-Bernal S, King JG, Lupton O, Magkanaris I, McDougal RA, Newton AJH,\n Pereira F, Săvulescu A, Carnevale NT, Lytton WW, Hines ML, Schürmann F. 2022. Modernizing the NEURON\n simulator for sustainability, portability, and performance. Frontiers in Neuroinformatics 16:884046. DOI: https://\n doi.org/10.3389/fninf.2022.884046, PMID: 35832575\nBahl A, Stemmler MB, Herz AVM, Roth A. 2012. Automated optimization of a reduced layer 5 pyramidal cell\n model based on experimental data. Journal of Neuroscience Methods 210:22–34. DOI: https://doi.org/10.\n 1016/j.jneumeth.2012.04.006, PMID: 22524993\nBergmann FT, Adams R, Moodie S, Cooper J, Glont M, Golebiewski M, Hucka M, Laibe C, Miller AK,\n Nickerson DP, Olivier BG, Rodriguez N, Sauro HM, Scharm M, Soiland-Reyes S, Waltemath D, Yvon F,\n Le Novère N. 2014. COMBINE archive and OMEX format: one ﬁle to share all information to reproduce a\n modeling project. BMC Bioinformatics 15:369. DOI: https://doi.org/10.1186/s12859-014-0369-z, PMID:\n 25494900\nBezaire MJ, Raikov I, Burk K, Vyas D, Soltesz I. 2016. Interneuronal mechanisms of hippocampal theta oscillations\n in a full-scale model of the rodent CA1 circuit. eLife 5:e18566. DOI: https://doi.org/10.7554/eLife.18566,\n PMID: 28009257\nBilleh YN, Cai B, Gratiy SL, Dai K, Iyer R, Gouwens NW, Abbasi-Asl R, Jia X, Siegle JH, Olsen SR, Koch C,\n Mihalas S, Arkhipov A. 2020. Systematic integration of structural and functional data into multi-scale models of\n mouse primary visual cortex. Neuron 106:388–403. DOI: https://doi.org/10.1016/j.neuron.2020.01.040, PMID:\n 32142648\nBillings G, Piasini E, Lőrincz A, Nusser Z, Silver RA. 2014. Network structure within the cerebellar input layer\n enables lossless sparse encoding. Neuron 83:960–974. DOI: https://doi.org/10.1016/j.neuron.2014.07.020,\n PMID: 25123311\nBirgiolas J, Dietrich SW, Crook S, Rajadesingan A, Zhang C, Penchala SV, Addepalli V. 2015. Ontology-assisted\n keyword search for NeuroML models. SSDBM 2015. . DOI: https://doi.org/10.1145/2791347.2791360\nBirgiolas J, Haynes V, Gleeson P, Gerkin RC, Dietrich SW, Crook S. 2023. NeuroML-DB: Sharing and\n characterizing data-driven neuroscience models described in NeuroML. PLOS Computational Biology\n 19:e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658\nBlundell I, Brette R, Cleland TA, Close TG, Coca D, Davison AP, Diaz-Pier S, Fernandez Musoles C, Gleeson P,\n Goodman DFM, Hines M, Hopkins MW, Kumbhar P, Lester DR, Marin B, Morrison A, Müller E, Nowotny T,\n Peyser A, Plotnikov D, et al. 2018. Code generation in computational neuroscience: a review of tools and\n techniques. Frontiers in Neuroinformatics 12:68. DOI: https://doi.org/10.3389/fninf.2018.00068, PMID:\n 30455637\nBower JM, Beeman D. 1998. The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural\n SImu Lation System. Springer. DOI: https://doi.org/10.1007/978-1-4612-1634-6\nBoyle JH, Cohen N. 2008. Caenorhabditis elegans body wall muscles are simple actuators. Biosystems 94:170–\n 181. DOI: https://doi.org/10.1016/j.biosystems.2008.05.025\nBrunel N. 2000. Brunel N. Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons.\n Journal of Computational Neuroscience 8:183–208. DOI: https://doi.org/10.1023/A:1008925309027\nCampagnola L. 2023. Vispy/vispy. 0.13.0. Zenodo. https://doi.org/10.5281/zenodo.7945364\nCannon RC, Gewaltig MO, Gleeson P, Bhalla US, Cornelis H, Hines ML, Howell FW, Muller E, Stiles JR, Wils S,\n De Schutter E. 2007. Interoperability of neuroscience modeling software: current status and future directions.\n Neuroinformatics 5:127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374\nCannon RC, Gleeson P, Crook S, Ganapathy G, Marin B, Piasini E, Silver RA. 2014. LEMS: a language for\n expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2.\n Frontiers in Neuroinformatics 8:79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    40 of 44","md":"\n\neLife Tools and resources                                                           Neuroscience\n\n## Data availability\nNo data was generated in this study. All software noted in this manuscript is open source. The NeuroML core libraries can be found at https://github.com/neuroml (copy archived at Gleeson and Sinha , 2024). Tables 3 and 4 provide links to the software packages and their source code repositories include DOI information for each software release.\n\n## References\nAbrams MB, Bjaalie JG, Das S, Egan GF, Ghosh SS, Goscinski WJ, Grethe JS, Kotaleski JH, Ho ETW, Kennedy DN, Lanyon LJ, Leergaard TB, Mayberg HS, Milanesi L, Mouček R, Poline JB, Roy PK, Strother SC, Tang TB, Tiesinga P, et al. 2022. A standards organization for open and fair neuroscience: the international neuroinformatics coordinating facility. Neuroinformatics 20:25–36. DOI: https://doi.org/10.1007/s12021-020-09509-0, PMID: 33506383\n\nAkar NA, Cumming B, Karakasis V, Kusters A, Klijn W, Peyser A, Yates S. 2019. Arbor — a morphologically-detailed neural network simulation library for contemporary high-performance computing architectures. 2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP. 274–282. DOI: https://doi.org/10.1109/EMPDP.2019.8671560\n\nAscoli GA, Donohue DE, Halavi M. 2007. NeuroMorpho.Org: a central resource for neuronal morphologies. The Journal of Neuroscience 27:9247–9251. DOI: https://doi.org/10.1523/JNEUROSCI.2055-07.2007, PMID: 17728438\n\nAwile O, Kumbhar P, Cornu N, Dura-Bernal S, King JG, Lupton O, Magkanaris I, McDougal RA, Newton AJH, Pereira F, Săvulescu A, Carnevale NT, Lytton WW, Hines ML, Schürmann F. 2022. Modernizing the NEURON simulator for sustainability, portability, and performance. Frontiers in Neuroinformatics 16:884046. DOI: https://doi.org/10.3389/fninf.2022.884046, PMID: 35832575\n\nBahl A, Stemmler MB, Herz AVM, Roth A. 2012. Automated optimization of a reduced layer 5 pyramidal cell model based on experimental data. Journal of Neuroscience Methods 210:22–34. DOI: https://doi.org/10.1016/j.jneumeth.2012.04.006, PMID: 22524993\n\nBergmann FT, Adams R, Moodie S, Cooper J, Glont M, Golebiewski M, Hucka M, Laibe C, Miller AK, Nickerson DP, Olivier BG, Rodriguez N, Sauro HM, Scharm M, Soiland-Reyes S, Waltemath D, Yvon F, Le Novère N. 2014. COMBINE archive and OMEX format: one file to share all information to reproduce a modeling project. BMC Bioinformatics 15:369. DOI: https://doi.org/10.1186/s12859-014-0369-z, PMID: 25494900\n\nBezaire MJ, Raikov I, Burk K, Vyas D, Soltesz I. 2016. Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit. eLife 5:e18566. DOI: https://doi.org/10.7554/eLife.18566, PMID: 28009257\n\nBilleh YN, Cai B, Gratiy SL, Dai K, Iyer R, Gouwens NW, Abbasi-Asl R, Jia X, Siegle JH, Olsen SR, Koch C, Mihalas S, Arkhipov A. 2020. Systematic integration of structural and functional data into multi-scale models of mouse primary visual cortex. Neuron 106:388–403. DOI: https://doi.org/10.1016/j.neuron.2020.01.040, PMID: 32142648\n\nBillings G, Piasini E, Lőrincz A, Nusser Z, Silver RA. 2014. Network structure within the cerebellar input layer enables lossless sparse encoding. Neuron 83:960–974. DOI: https://doi.org/10.1016/j.neuron.2014.07.020, PMID: 25123311\n\nBirgiolas J, Dietrich SW, Crook S, Rajadesingan A, Zhang C, Penchala SV, Addepalli V. 2015. Ontology-assisted keyword search for NeuroML models. SSDBM 2015. . DOI: https://doi.org/10.1145/2791347.2791360\n\nBirgiolas J, Haynes V, Gleeson P, Gerkin RC, Dietrich SW, Crook S. 2023. NeuroML-DB: Sharing and characterizing data-driven neuroscience models described in NeuroML. PLOS Computational Biology 19:e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658\n\nBlundell I, Brette R, Cleland TA, Close TG, Coca D, Davison AP, Diaz-Pier S, Fernandez Musoles C, Gleeson P, Goodman DFM, Hines M, Hopkins MW, Kumbhar P, Lester DR, Marin B, Morrison A, Müller E, Nowotny T, Peyser A, Plotnikov D, et al. 2018. Code generation in computational neuroscience: a review of tools and techniques. Frontiers in Neuroinformatics 12:68. DOI: https://doi.org/10.3389/fninf.2018.00068, PMID: 30455637\n\nBower JM, Beeman D. 1998. The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImu Lation System. Springer. DOI: https://doi.org/10.1007/978-1-4612-1634-6\n\nBoyle JH, Cohen N. 2008. Caenorhabditis elegans body wall muscles are simple actuators. Biosystems 94:170–181. DOI: https://doi.org/10.1016/j.biosystems.2008.05.025\n\nBrunel N. 2000. Brunel N. Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons. Journal of Computational Neuroscience 8:183–208. DOI: https://doi.org/10.1023/A:1008925309027\n\nCampagnola L. 2023. Vispy/vispy. 0.13.0. Zenodo. https://doi.org/10.5281/zenodo.7945364\n\nCannon RC, Gewaltig MO, Gleeson P, Bhalla US, Cornelis H, Hines ML, Howell FW, Muller E, Stiles JR, Wils S, De Schutter E. 2007. Interoperability of neuroscience modeling software: current status and future directions. Neuroinformatics 5:127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374\n\nCannon RC, Gleeson P, Crook S, Ganapathy G, Marin B, Piasini E, Silver RA. 2014. LEMS: a language for expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2. Frontiers in Neuroinformatics 8:79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    40 of 44\n","images":[{"name":"page_40.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_40_reference_1_v2.jpg","height":453589.789,"width":249084.659,"x":101801.018,"y":117081.001,"original_width":1645,"original_height":2314,"rotation":0,"type":"layout_v2_reference"},{"name":"page_40_text_1_v2.jpg","height":36029.548,"width":250290.004,"x":101181.887,"y":50893.339,"original_width":1653,"original_height":184,"rotation":0,"type":"layout_v2_text"},{"name":"page_40_reference_content_1_v2.jpg","height":37808.69,"width":240628.156,"x":102231.889,"y":428241.208,"original_width":1589,"original_height":193,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_2_v2.jpg","height":37595.401,"width":235762.029,"x":102579.832,"y":269183.308,"original_width":1557,"original_height":192,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_3_v2.jpg","height":30184.257,"width":249958.026,"x":102176.943,"y":213398.995,"original_width":1651,"original_height":154,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_4_v2.jpg","height":37766.977,"width":244141.485,"x":102338.672,"y":118254.22,"original_width":1612,"original_height":193,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_5_v2.jpg","height":30306.514,"width":245274.71,"x":102299.879,"y":157558.778,"original_width":1620,"original_height":155,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_6_v2.jpg","height":30050.042,"width":248326.225,"x":102503.172,"y":332485.595,"original_width":1640,"original_height":154,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_7_v2.jpg","height":22830.723,"width":239114.993,"x":102514.419,"y":244941.123,"original_width":1579,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_8_v2.jpg","height":22283.494,"width":247602.61,"x":102224.817,"y":547969.891,"original_width":1635,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_9_v2.jpg","height":22451.385,"width":244496.984,"x":102354.28,"y":523981.983,"original_width":1615,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_10_v2.jpg","height":22442.427,"width":249281.613,"x":102337.764,"y":308606.478,"original_width":1646,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_11_v2.jpg","height":22355.657,"width":247032.032,"x":102238.017,"y":189190.694,"original_width":1632,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_12_v2.jpg","height":22464.793,"width":239325.263,"x":102483.742,"y":364349.881,"original_width":1581,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_13_v2.jpg","height":22534.812,"width":228026.764,"x":102514.843,"y":404401.844,"original_width":1506,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_footer_1_v2.jpg","height":6884.104,"width":191859.867,"x":21696.761,"y":591588.987,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_40_reference_content_14_v2.jpg","height":14976.535,"width":245632.104,"x":102552.328,"y":483764.481,"original_width":1622,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_15_v2.jpg","height":15190.628,"width":244263.411,"x":102424.904,"y":388193.832,"original_width":1613,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_reference_content_16_v2.jpg","height":14923.531,"width":246151.134,"x":102509.33,"y":467841.972,"original_width":1626,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_header_1_v2.jpg","height":5658.572,"width":30214.523,"x":320813.171,"y":27702.091,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_40_reference_content_17_v2.jpg","height":22538.379,"width":248706.322,"x":102279.995,"y":499792.664,"original_width":1643,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_paragraph_title_1_v2.jpg","height":6966.842,"width":42742.876,"x":101685.651,"y":41433.488,"original_width":283,"original_height":36,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_40_number_1_v2.jpg","height":5684.148,"width":18206.533,"x":332981.823,"y":591970.206,"original_width":121,"original_height":29,"rotation":0,"type":"layout_v2_number"},{"name":"page_40_paragraph_title_2_v2.jpg","height":10641.765,"width":45917.852,"x":102309.427,"y":104929.48,"original_width":304,"original_height":55,"rotation":0,"type":"layout_v2_paragraph_title"},{"name":"page_40_reference_content_18_v2.jpg","height":7605.928,"width":204117.589,"x":102486.279,"y":515083.126,"original_width":1348,"original_height":39,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_40_header_2_v2.jpg","height":5754.257,"width":42858.456,"x":47775.92,"y":27804.19,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_40_header_3_v2.jpg","height":10607.035,"width":24421.268,"x":21799.505,"y":22419.86,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                           Neuroscience","md":"eLife Tools and resources                                                           Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":34,"w":49,"h":7,"startIndex":84,"endIndex":96}]},{"type":"heading","lvl":2,"value":"Data availability","md":"## Data availability","bBox":{"x":168.53,"y":51.8,"w":67.37,"h":9},"layoutAwareBbox":[{"x":166,"y":52,"w":69,"h":8,"startIndex":0,"endIndex":19}]},{"type":"text","value":"No data was generated in this study. All software noted in this manuscript is open source. The NeuroML core libraries can be found at https://github.com/neuroml (copy archived at Gleeson and Sinha , 2024). Tables 3 and 4 provide links to the software packages and their source code repositories include DOI information for each software release.","md":"No data was generated in this study. All software noted in this manuscript is open source. The NeuroML core libraries can be found at https://github.com/neuroml (copy archived at Gleeson and Sinha , 2024). Tables 3 and 4 provide links to the software packages and their source code repositories include DOI information for each software release.","bBox":{"x":168.53,"y":63.86,"w":403.03,"h":45.15},"layoutAwareBbox":[{"x":165,"y":64,"w":408,"h":45,"startIndex":0,"endIndex":344}]},{"type":"heading","lvl":2,"value":"References","md":"## References","bBox":{"x":168.53,"y":130.24,"w":73.11,"h":14},"layoutAwareBbox":[{"x":167,"y":132,"w":75,"h":13,"startIndex":3,"endIndex":13}]},{"type":"text","value":"Abrams MB, Bjaalie JG, Das S, Egan GF, Ghosh SS, Goscinski WJ, Grethe JS, Kotaleski JH, Ho ETW, Kennedy DN, Lanyon LJ, Leergaard TB, Mayberg HS, Milanesi L, Mouček R, Poline JB, Roy PK, Strother SC, Tang TB, Tiesinga P, et al. 2022. A standards organization for open and fair neuroscience: the international neuroinformatics coordinating facility. Neuroinformatics 20:25–36. DOI: https://doi.org/10.1007/s12021-020-09509-0, PMID: 33506383","md":"Abrams MB, Bjaalie JG, Das S, Egan GF, Ghosh SS, Goscinski WJ, Grethe JS, Kotaleski JH, Ho ETW, Kennedy DN, Lanyon LJ, Leergaard TB, Mayberg HS, Milanesi L, Mouček R, Poline JB, Roy PK, Strother SC, Tang TB, Tiesinga P, et al. 2022. A standards organization for open and fair neuroscience: the international neuroinformatics coordinating facility. Neuroinformatics 20:25–36. DOI: https://doi.org/10.1007/s12021-020-09509-0, PMID: 33506383","bBox":{"x":168.53,"y":34.63,"w":406.47,"h":161.85},"layoutAwareBbox":[{"x":167,"y":149,"w":398,"h":47,"startIndex":227,"endIndex":229}]},{"type":"text","value":"Akar NA, Cumming B, Karakasis V, Kusters A, Klijn W, Peyser A, Yates S. 2019. Arbor — a morphologically-detailed neural network simulation library for contemporary high-performance computing architectures. 2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP. 274–282. DOI: https://doi.org/10.1109/EMPDP.2019.8671560","md":"Akar NA, Cumming B, Karakasis V, Kusters A, Klijn W, Peyser A, Yates S. 2019. Arbor — a morphologically-detailed neural network simulation library for contemporary high-performance computing architectures. 2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP. 274–282. DOI: https://doi.org/10.1109/EMPDP.2019.8671560","bBox":{"x":168.53,"y":198.53,"w":400.99,"h":38.14},"layoutAwareBbox":[{"x":167,"y":198,"w":400,"h":38,"startIndex":0,"endIndex":366}]},{"type":"text","value":"Ascoli GA, Donohue DE, Halavi M. 2007. NeuroMorpho.Org: a central resource for neuronal morphologies. The Journal of Neuroscience 27:9247–9251. DOI: https://doi.org/10.1523/JNEUROSCI.2055-07.2007, PMID: 17728438","md":"Ascoli GA, Donohue DE, Halavi M. 2007. NeuroMorpho.Org: a central resource for neuronal morphologies. The Journal of Neuroscience 27:9247–9251. DOI: https://doi.org/10.1523/JNEUROSCI.2055-07.2007, PMID: 17728438","bBox":{"x":168.53,"y":238.73,"w":404.14,"h":28.1},"layoutAwareBbox":[{"x":167,"y":238,"w":403,"h":28,"startIndex":102,"endIndex":105}]},{"type":"text","value":"Awile O, Kumbhar P, Cornu N, Dura-Bernal S, King JG, Lupton O, Magkanaris I, McDougal RA, Newton AJH, Pereira F, Săvulescu A, Carnevale NT, Lytton WW, Hines ML, Schürmann F. 2022. Modernizing the NEURON simulator for sustainability, portability, and performance. Frontiers in Neuroinformatics 16:884046. DOI: https://doi.org/10.3389/fninf.2022.884046, PMID: 35832575","md":"Awile O, Kumbhar P, Cornu N, Dura-Bernal S, King JG, Lupton O, Magkanaris I, McDougal RA, Newton AJH, Pereira F, Săvulescu A, Carnevale NT, Lytton WW, Hines ML, Schürmann F. 2022. Modernizing the NEURON simulator for sustainability, portability, and performance. Frontiers in Neuroinformatics 16:884046. DOI: https://doi.org/10.3389/fninf.2022.884046, PMID: 35832575","bBox":{"x":168.53,"y":268.87,"w":406.45,"h":38.14},"layoutAwareBbox":[{"x":166,"y":269,"w":408,"h":38,"startIndex":293,"endIndex":295}]},{"type":"text","value":"Bahl A, Stemmler MB, Herz AVM, Roth A. 2012. Automated optimization of a reduced layer 5 pyramidal cell model based on experimental data. Journal of Neuroscience Methods 210:22–34. DOI: https://doi.org/10.1016/j.jneumeth.2012.04.006, PMID: 22524993","md":"Bahl A, Stemmler MB, Herz AVM, Roth A. 2012. Automated optimization of a reduced layer 5 pyramidal cell model based on experimental data. Journal of Neuroscience Methods 210:22–34. DOI: https://doi.org/10.1016/j.jneumeth.2012.04.006, PMID: 22524993","bBox":{"x":168.53,"y":309.06,"w":390.31,"h":28.1},"layoutAwareBbox":[{"x":167,"y":309,"w":390,"h":28,"startIndex":170,"endIndex":173}]},{"type":"text","value":"Bergmann FT, Adams R, Moodie S, Cooper J, Glont M, Golebiewski M, Hucka M, Laibe C, Miller AK, Nickerson DP, Olivier BG, Rodriguez N, Sauro HM, Scharm M, Soiland-Reyes S, Waltemath D, Yvon F, Le Novère N. 2014. COMBINE archive and OMEX format: one file to share all information to reproduce a modeling project. BMC Bioinformatics 15:369. DOI: https://doi.org/10.1186/s12859-014-0369-z, PMID: 25494900","md":"Bergmann FT, Adams R, Moodie S, Cooper J, Glont M, Golebiewski M, Hucka M, Laibe C, Miller AK, Nickerson DP, Olivier BG, Rodriguez N, Sauro HM, Scharm M, Soiland-Reyes S, Waltemath D, Yvon F, Le Novère N. 2014. COMBINE archive and OMEX format: one file to share all information to reproduce a modeling project. BMC Bioinformatics 15:369. DOI: https://doi.org/10.1186/s12859-014-0369-z, PMID: 25494900","bBox":{"x":168.53,"y":339.21,"w":379.91,"h":48.19},"layoutAwareBbox":[{"x":167,"y":339,"w":385,"h":47,"startIndex":330,"endIndex":332}]},{"type":"text","value":"Bezaire MJ, Raikov I, Burk K, Vyas D, Soltesz I. 2016. Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit. eLife 5:e18566. DOI: https://doi.org/10.7554/eLife.18566, PMID: 28009257","md":"Bezaire MJ, Raikov I, Burk K, Vyas D, Soltesz I. 2016. Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit. eLife 5:e18566. DOI: https://doi.org/10.7554/eLife.18566, PMID: 28009257","bBox":{"x":168.53,"y":389.45,"w":408.52,"h":28.1},"layoutAwareBbox":[{"x":167,"y":389,"w":407,"h":28,"startIndex":163,"endIndex":168}]},{"type":"text","value":"Billeh YN, Cai B, Gratiy SL, Dai K, Iyer R, Gouwens NW, Abbasi-Asl R, Jia X, Siegle JH, Olsen SR, Koch C, Mihalas S, Arkhipov A. 2020. Systematic integration of structural and functional data into multi-scale models of mouse primary visual cortex. Neuron 106:388–403. DOI: https://doi.org/10.1016/j.neuron.2020.01.040, PMID: 32142648","md":"Billeh YN, Cai B, Gratiy SL, Dai K, Iyer R, Gouwens NW, Abbasi-Asl R, Jia X, Siegle JH, Olsen SR, Koch C, Mihalas S, Arkhipov A. 2020. Systematic integration of structural and functional data into multi-scale models of mouse primary visual cortex. Neuron 106:388–403. DOI: https://doi.org/10.1016/j.neuron.2020.01.040, PMID: 32142648","bBox":{"x":168.53,"y":419.59,"w":406.01,"h":38.14},"layoutAwareBbox":[{"x":167,"y":419,"w":405,"h":37,"startIndex":248,"endIndex":254}]},{"type":"text","value":"Billings G, Piasini E, Lőrincz A, Nusser Z, Silver RA. 2014. Network structure within the cerebellar input layer enables lossless sparse encoding. Neuron 83:960–974. DOI: https://doi.org/10.1016/j.neuron.2014.07.020, PMID: 25123311","md":"Billings G, Piasini E, Lőrincz A, Nusser Z, Silver RA. 2014. Network structure within the cerebellar input layer enables lossless sparse encoding. Neuron 83:960–974. DOI: https://doi.org/10.1016/j.neuron.2014.07.020, PMID: 25123311","bBox":{"x":168.53,"y":459.78,"w":392.41,"h":28.1},"layoutAwareBbox":[{"x":167,"y":460,"w":391,"h":28,"startIndex":147,"endIndex":153}]},{"type":"text","value":"Birgiolas J, Dietrich SW, Crook S, Rajadesingan A, Zhang C, Penchala SV, Addepalli V. 2015. Ontology-assisted keyword search for NeuroML models. SSDBM 2015. . DOI: https://doi.org/10.1145/2791347.2791360","md":"Birgiolas J, Dietrich SW, Crook S, Rajadesingan A, Zhang C, Penchala SV, Addepalli V. 2015. Ontology-assisted keyword search for NeuroML models. SSDBM 2015. . DOI: https://doi.org/10.1145/2791347.2791360","bBox":{"x":168.53,"y":489.93,"w":399.58,"h":18.05},"layoutAwareBbox":[{"x":167,"y":490,"w":399,"h":19,"startIndex":101,"endIndex":109}]},{"type":"text","value":"Birgiolas J, Haynes V, Gleeson P, Gerkin RC, Dietrich SW, Crook S. 2023. NeuroML-DB: Sharing and characterizing data-driven neuroscience models described in NeuroML. PLOS Computational Biology 19:e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658","md":"Birgiolas J, Haynes V, Gleeson P, Gerkin RC, Dietrich SW, Crook S. 2023. NeuroML-DB: Sharing and characterizing data-driven neuroscience models described in NeuroML. PLOS Computational Biology 19:e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658","bBox":{"x":168.53,"y":510.02,"w":369.99,"h":28.1},"layoutAwareBbox":[{"x":167,"y":510,"w":372,"h":28,"startIndex":193,"endIndex":195}]},{"type":"text","value":"Blundell I, Brette R, Cleland TA, Close TG, Coca D, Davison AP, Diaz-Pier S, Fernandez Musoles C, Gleeson P, Goodman DFM, Hines M, Hopkins MW, Kumbhar P, Lester DR, Marin B, Morrison A, Müller E, Nowotny T, Peyser A, Plotnikov D, et al. 2018. Code generation in computational neuroscience: a review of tools and techniques. Frontiers in Neuroinformatics 12:68. DOI: https://doi.org/10.3389/fninf.2018.00068, PMID: 30455637","md":"Blundell I, Brette R, Cleland TA, Close TG, Coca D, Davison AP, Diaz-Pier S, Fernandez Musoles C, Gleeson P, Goodman DFM, Hines M, Hopkins MW, Kumbhar P, Lester DR, Marin B, Morrison A, Müller E, Nowotny T, Peyser A, Plotnikov D, et al. 2018. Code generation in computational neuroscience: a review of tools and techniques. Frontiers in Neuroinformatics 12:68. DOI: https://doi.org/10.3389/fninf.2018.00068, PMID: 30455637","bBox":{"x":168.53,"y":34.63,"w":406.47,"h":553.72},"layoutAwareBbox":[{"x":167,"y":540,"w":393,"h":47,"startIndex":312,"endIndex":322}]},{"type":"text","value":"Bower JM, Beeman D. 1998. The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImu Lation System. Springer. DOI: https://doi.org/10.1007/978-1-4612-1634-6","md":"Bower JM, Beeman D. 1998. The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImu Lation System. Springer. DOI: https://doi.org/10.1007/978-1-4612-1634-6","bBox":{"x":168.53,"y":590.41,"w":402.53,"h":18.05},"layoutAwareBbox":[{"x":167,"y":590,"w":402,"h":18,"startIndex":0,"endIndex":180}]},{"type":"text","value":"Boyle JH, Cohen N. 2008. Caenorhabditis elegans body wall muscles are simple actuators. Biosystems 94:170–181. DOI: https://doi.org/10.1016/j.biosystems.2008.05.025","md":"Boyle JH, Cohen N. 2008. Caenorhabditis elegans body wall muscles are simple actuators. Biosystems 94:170–181. DOI: https://doi.org/10.1016/j.biosystems.2008.05.025","bBox":{"x":168.53,"y":610.5,"w":398.98,"h":18.05},"layoutAwareBbox":[{"x":167,"y":610,"w":401,"h":18,"startIndex":88,"endIndex":98}]},{"type":"text","value":"Brunel N. 2000. Brunel N. Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons. Journal of Computational Neuroscience 8:183–208. DOI: https://doi.org/10.1023/A:1008925309027","md":"Brunel N. 2000. Brunel N. Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons. Journal of Computational Neuroscience 8:183–208. DOI: https://doi.org/10.1023/A:1008925309027","bBox":{"x":168.53,"y":630.6,"w":407.77,"h":18.05},"layoutAwareBbox":[{"x":167,"y":631,"w":406,"h":28,"startIndex":0,"endIndex":204}]},{"type":"text","value":"Campagnola L. 2023. Vispy/vispy. 0.13.0. Zenodo. https://doi.org/10.5281/zenodo.7945364","md":"Campagnola L. 2023. Vispy/vispy. 0.13.0. Zenodo. https://doi.org/10.5281/zenodo.7945364","bBox":{"x":168.53,"y":650.69,"w":330.68,"h":8},"layoutAwareBbox":[{"x":167,"y":650,"w":333,"h":9,"startIndex":0,"endIndex":86}]},{"type":"text","value":"Cannon RC, Gewaltig MO, Gleeson P, Bhalla US, Cornelis H, Hines ML, Howell FW, Muller E, Stiles JR, Wils S, De Schutter E. 2007. Interoperability of neuroscience modeling software: current status and future directions. Neuroinformatics 5:127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374","md":"Cannon RC, Gewaltig MO, Gleeson P, Bhalla US, Cornelis H, Hines ML, Howell FW, Muller E, Stiles JR, Wils S, De Schutter E. 2007. Interoperability of neuroscience modeling software: current status and future directions. Neuroinformatics 5:127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374","bBox":{"x":168.53,"y":660.74,"w":400.6,"h":28.1},"layoutAwareBbox":[{"x":167,"y":661,"w":399,"h":28,"startIndex":219,"endIndex":235}]},{"type":"text","value":"Cannon RC, Gleeson P, Crook S, Ganapathy G, Marin B, Piasini E, Silver RA. 2014. LEMS: a language for expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2. Frontiers in Neuroinformatics 8:79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419","md":"Cannon RC, Gleeson P, Crook S, Ganapathy G, Marin B, Piasini E, Silver RA. 2014. LEMS: a language for expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2. Frontiers in Neuroinformatics 8:79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419","bBox":{"x":168.53,"y":690.89,"w":405.83,"h":28.1},"layoutAwareBbox":[{"x":167,"y":691,"w":404,"h":28,"startIndex":0,"endIndex":307}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    40 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    40 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://github.com/neuroml","unsafeUrl":"https://github.com/neuroml","text":"NeuroML core libraries can be found at https://github.com/neuroml (copy archived at "},{"url":"https://doi.org/10.1007/s12021-020-09509-0","unsafeUrl":"https://doi.org/10.1007/s12021-020-09509-0","text":":25–36. DOI: https://doi.org/10.1007/s12021-020-"},{"url":"https://doi.org/10.1007/s12021-020-09509-0","unsafeUrl":"https://doi.org/10.1007/s12021-020-09509-0","text":"09509-0, PMID: 33506383 , Cumming B, Karakasis V, Kusters A, Klijn W, Peyser A, Yates S. 2019. Arbor — a morphologically-"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/33506383","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/33506383","text":"09509-0, PMID: 33506383"},{"url":"https://doi.org/10.1109/EMPDP.2019.8671560","unsafeUrl":"https://doi.org/10.1109/EMPDP.2019.8671560","text":"274–282. DOI: https://doi.org/10.1109/EMPDP.2019.8671560"},{"url":"https://doi.org/10.1523/JNEUROSCI.2055-07.2007","unsafeUrl":"https://doi.org/10.1523/JNEUROSCI.2055-07.2007","text":":9247–9251. DOI: https://doi.org/10.1523/JNEUROSCI.2055-07.2007, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/17728438","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/17728438","text":"17728438 , Kumbhar P, Cornu N, Dura-"},{"url":"https://doi.org/10.3389/fninf.2022.884046","unsafeUrl":"https://doi.org/10.3389/fninf.2022.884046","text":":884046. DOI: https://"},{"url":"https://doi.org/10.3389/fninf.2022.884046","unsafeUrl":"https://doi.org/10.3389/fninf.2022.884046","text":"doi.org/10.3389/fninf.2022.884046, PMID: 35832575 , Stemmler MB, Herz AVM, Roth A. 2012. Automated optimization of a reduced layer 5 pyramidal cell "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/35832575","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/35832575","text":"doi.org/10.3389/fninf.2022.884046, PMID: 35832575"},{"url":"https://doi.org/10.1016/j.jneumeth.2012.04.006","unsafeUrl":"https://doi.org/10.1016/j.jneumeth.2012.04.006","text":":22–34. DOI: https://doi.org/10."},{"url":"https://doi.org/10.1016/j.jneumeth.2012.04.006","unsafeUrl":"https://doi.org/10.1016/j.jneumeth.2012.04.006","text":"1016/j.jneumeth.2012.04.006, PMID: 22524993 , Adams R, Moodie S, Cooper J, Glont M, Golebiewski M, Hucka M, Laibe C, Miller AK, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/22524993","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/22524993","text":"1016/j.jneumeth.2012.04.006, PMID: 22524993"},{"url":"https://doi.org/10.1186/s12859-014-0369-z","unsafeUrl":"https://doi.org/10.1186/s12859-014-0369-z","text":":369. DOI: https://doi.org/10.1186/s12859-014-0369-z, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25494900","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25494900","text":"25494900 , Raikov I, Burk K, Vyas D, Soltesz I. 2016. Interneuronal mechanisms of hippocampal theta oscillations "},{"url":"https://doi.org/10.7554/eLife.18566","unsafeUrl":"https://doi.org/10.7554/eLife.18566","text":":e18566. DOI: https://doi.org/10.7554/eLife.18566, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/28009257","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/28009257","text":"PMID: 28009257 , Cai B, Gratiy SL, Dai K, Iyer R, Gouwens NW, Abbasi-"},{"url":"https://doi.org/10.1016/j.neuron.2020.01.040","unsafeUrl":"https://doi.org/10.1016/j.neuron.2020.01.040","text":":388–403. DOI: https://doi.org/10.1016/j.neuron.2020.01.040, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/32142648","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/32142648","text":"32142648 , Piasini E, L"},{"url":"https://doi.org/10.1016/j.neuron.2014.07.020","unsafeUrl":"https://doi.org/10.1016/j.neuron.2014.07.020","text":":960–974. DOI: https://doi.org/10.1016/j.neuron.2014.07.020, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25123311","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25123311","text":"PMID: 25123311 , Dietrich SW, Crook S, Rajadesingan A, Zhang C, Penchala SV, Addepalli V. 2015. Ontology-"},{"url":"https://doi.org/10.1145/2791347.2791360","unsafeUrl":"https://doi.org/10.1145/2791347.2791360","text":"keyword search for NeuroML models. SSDBM 2015. . DOI: https://doi.org/10.1145/2791347.2791360   DB: Sharing and "},{"url":"https://doi.org/10.1371/journal.pcbi.1010941","unsafeUrl":"https://doi.org/10.1371/journal.pcbi.1010941","text":":e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/36867658","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/36867658","text":":e1010941. DOI: https://doi.org/10.1371/journal.pcbi.1010941, PMID: 36867658"},{"url":"https://doi.org/10.3389/fninf.2018.00068","unsafeUrl":"https://doi.org/10.3389/fninf.2018.00068","text":":68. DOI: https://doi.org/10.3389/fninf.2018.00068, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/30455637","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/30455637","text":"30455637 , Beeman D. 1998. "},{"url":"https://doi.org/10.1007/978-1-4612-1634-6","unsafeUrl":"https://doi.org/10.1007/978-1-4612-1634-6","text":". Springer. DOI: https://doi.org/10.1007/978-1-4612-1634-6  body wall muscles are simple actuators. "},{"url":"https://doi.org/10.1016/j.biosystems.2008.05.025","unsafeUrl":"https://doi.org/10.1016/j.biosystems.2008.05.025","text":"181. DOI: https://doi.org/10.1016/j.biosystems.2008.05.025"},{"url":"https://doi.org/10.1023/A:1008925309027","unsafeUrl":"https://doi.org/10.1023/A:1008925309027","text":":183–208. DOI: https://doi.org/10.1023/A:1008925309027"},{"url":"https://doi.org/10.5281/zenodo.7945364","unsafeUrl":"https://doi.org/10.5281/zenodo.7945364","text":". 2023. Vispy/vispy. 0.13.0. Zenodo. https://doi.org/10.5281/zenodo.7945364"},{"url":"https://doi.org/10.1007/s12021-007-0004-5","unsafeUrl":"https://doi.org/10.1007/s12021-007-0004-5","text":":127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/17873374","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/17873374","text":":127–138. DOI: https://doi.org/10.1007/s12021-007-0004-5, PMID: 17873374"},{"url":"https://doi.org/10.3389/fninf.2014.00079","unsafeUrl":"https://doi.org/10.3389/fninf.2014.00079","text":":79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25309419","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25309419","text":":79. DOI: https://doi.org/10.3389/fninf.2014.00079, PMID: 25309419"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                           Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    40 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.996,"layout":[{"image":"page_40_reference_1_v2.jpg","confidence":0.99,"label":"reference","bbox":{"x":0.272,"y":0.187,"w":0.665,"h":0.723},"isLikelyNoise":false},{"image":"page_40_text_1_v2.jpg","confidence":0.97,"label":"text","bbox":{"x":0.27,"y":0.081,"w":0.668,"h":0.057},"isLikelyNoise":false},{"image":"page_40_reference_content_1_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.273,"y":0.683,"w":0.642,"h":0.06},"isLikelyNoise":false},{"image":"page_40_reference_content_2_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.274,"y":0.429,"w":0.629,"h":0.06},"isLikelyNoise":false},{"image":"page_40_reference_content_3_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.273,"y":0.34,"w":0.667,"h":0.048},"isLikelyNoise":false},{"image":"page_40_reference_content_4_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.273,"y":0.189,"w":0.652,"h":0.06},"isLikelyNoise":false},{"image":"page_40_reference_content_5_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.251,"w":0.655,"h":0.048},"isLikelyNoise":false},{"image":"page_40_reference_content_6_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.274,"y":0.53,"w":0.663,"h":0.048},"isLikelyNoise":false},{"image":"page_40_reference_content_7_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.39,"w":0.638,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_8_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.874,"w":0.661,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_9_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.835,"w":0.653,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_10_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.492,"w":0.666,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_11_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.302,"w":0.66,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_12_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.581,"w":0.639,"h":0.036},"isLikelyNoise":false},{"image":"page_40_reference_content_13_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.645,"w":0.609,"h":0.036},"isLikelyNoise":false},{"image":"page_40_footer_1_v2.jpg","confidence":0.9,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_40_reference_content_14_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.274,"y":0.771,"w":0.656,"h":0.024},"isLikelyNoise":false},{"image":"page_40_reference_content_15_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.273,"y":0.619,"w":0.652,"h":0.024},"isLikelyNoise":false},{"image":"page_40_reference_content_16_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.274,"y":0.746,"w":0.657,"h":0.024},"isLikelyNoise":false},{"image":"page_40_header_1_v2.jpg","confidence":0.88,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_40_reference_content_17_v2.jpg","confidence":0.84,"label":"reference_content","bbox":{"x":0.273,"y":0.797,"w":0.664,"h":0.036},"isLikelyNoise":false},{"image":"page_40_paragraph_title_1_v2.jpg","confidence":0.84,"label":"paragraph_title","bbox":{"x":0.271,"y":0.066,"w":0.114,"h":0.011},"isLikelyNoise":false},{"image":"page_40_number_1_v2.jpg","confidence":0.82,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_40_paragraph_title_2_v2.jpg","confidence":0.81,"label":"paragraph_title","bbox":{"x":0.273,"y":0.167,"w":0.123,"h":0.017},"isLikelyNoise":false},{"image":"page_40_reference_content_18_v2.jpg","confidence":0.72,"label":"reference_content","bbox":{"x":0.274,"y":0.821,"w":0.545,"h":0.012},"isLikelyNoise":false},{"image":"page_40_header_2_v2.jpg","confidence":0.7,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_40_header_3_v2.jpg","confidence":0.56,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":41,"text":"Tools  and  resources                                                                                            Neuroscience\n\n                         Cayco- Gajic  NA, Clopath C, Silver RA. 2017. Sparse synaptic connectivity is required for decorrelation and\n                          pattern separation in feedforward networks. Nature Communications 8:1116. DOI: https://doi.org/10.1038/\n                          s41467-017-01109-y, PMID: 29061964\n                         Choi K, Medley JK, König M, Stocking K, Smith L, Gu S, Sauro HM. 2018. Tellurium: An extensible python-based\n                          modeling environment for systems and synthetic biology. Bio Systems 171:74–79. DOI: https://doi.org/10.\n                          1016/j.biosystems.2018.07.006, PMID: 30053414\n                         Dai K, Hernando J, Billeh YN, Gratiy SL, Planas J, Davison AP, Dura-Bernal S, Gleeson P, Devresse A, Dichter BK,\n                          Gevaert M, King JG, Van Geit WAH, Povolotsky AV, Muller E, Courcol JD, Arkhipov A. 2020. The SONATA data\n                          format for efﬁcient description of large-scale network models. PLOS Computational Biology 16:e1007696.\n                          DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054\n                         Davison AP, Brüderle D, Eppler J, Kremkow J, Muller E, Pecevski D, Perrinet L, Yger P. 2008. PyNN: a common\n                          interface for neuronal network simulators. Frontiers in Neuroinformatics 2:11. DOI: https://doi.org/10.3389/\n                          neuro.11.011.2008, PMID: 19194529\n                         Denker M. 2018. Collaborative HPC-enabled workﬂows on the HBP Collaboratory using the Elephant\n                          framework. Neuroinformatics 19:0019. DOI: https://doi.org/10.12751/incf.ni2018.0019\n                         De Schutter E, Bower JM. 1994. An active membrane model of the cerebellar Purkinje cell. I. Simulation of\n                          current clamps in slice. Journal of Neurophysiology 71:375–400. DOI: https://doi.org/10.1152/jn.1994.71.1.\n                          375, PMID: 7512629\n                         Druckmann S, Banitt Y, Gidon A, Schürmann F, Markram H, Segev I. 2007. A novel multiple objective\n                          optimization framework for constraining conductance-based neuron models by experimental data. Frontiers in\n                          Neuroscience 1:7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116\n                         Dura- Bernal  S, Neymotin SA, Kerr CC, Sivagnanam S, Majumdar A, Francis JT, Lytton WW. 2017. Evolutionary\n                          algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis. IBM Journal of\n                          Research and Development 61:6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477\n                         Dura- Bernal  S, Suter BA, Gleeson P, Cantarelli M, Quintana A, Rodriguez F, Kedziora DJ, Chadderdon GL,\n                          Kerr CC, Neymotin SA, McDougal RA, Hines M, Shepherd GM, Lytton WW. 2019. NetPyNE, a tool for\n                          data-driven multiscale modeling of brain circuits. eLife 8:e44494. DOI: https://doi.org/10.7554/eLife.44494,\n                          PMID: 31025934\n                         Einevoll GT, Destexhe A, Diesmann M, Grün S, Jirsa V, de Kamps M, Migliore M, Ness TV, Plesser HE,\n                          Schürmann F. 2019. The scientiﬁc case for brain simulations. Neuron 102:735–744. DOI: https://doi.org/10.\n                          1016/j.neuron.2019.03.027, PMID: 31121126\n                         Executable Books Community. 2020. Executable books community, jupyter book. 01. Zenodo. https://doi.org/\n                          10.5281/zenodo.4539666\n                         Ferguson KA, Huh CYL, Amilhon B, Williams S, Skinner FK. 2013. Experimentally constrained CA1 fast-ﬁring\n                          parvalbumin-positive interneuron network models exhibit sharp transitions into coherent high frequency\n                          rhythms. Frontiers in Computational Neuroscience 7:144. DOI: https://doi.org/10.3389/fncom.2013.00144,\n                          PMID: 24155715\n                         Ferguson KA, Huh CYL, Amilhon B, Williams S, Skinner FK. 2014. Simple, biologically-constrained CA1\n                          pyramidal cell models using an intact, whole hippocampus context. F1000Research 3:104. DOI: https://doi.org/\n                          10.12688/f1000research.3894.1, PMID: 25383182\n                         FitzHugh R. 1961. Impulses and physiological states in theoretical models of nerve membrane. Biophysical\n                          Journal 1:445–466. DOI: https://doi.org/10.1016/S0006-3495(61)86902-6\n                         Garcia S, Guarino D, Jaillet F, Jennings T, Pröpper R, Rautenberg PL, Rodgers CC, Sobolev A, Wachtler T, Yger P,\n                          Davison AP. 2014. Neo: an object model for handling electrophysiology data in multiple formats. Frontiers in\n                          Neuroinformatics 8:10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386\n                         Garcia Del Molino LC, Yang GR, Mejias JF, Wang X-J. 2017. Paradoxical response reversal of top-down\n                          modulation in cortical circuits with three interneuron types. eLife 6:e29742. DOI: https://doi.org/10.7554/eLife.\n                          29742, PMID: 29256863\n                         Gerkin RC, Birgiolas J, Jarvis RJ, Omar C, Crook SM. 2019. NeuronUnit: a package for data-driven validation of\n                          neuron models using sciunit. bioRxiv. DOI: https://doi.org/10.1101/665331\n                         Gewaltig MO, Diesmann M. 2007. NEST (NEural Simulation Tool). Scholarpedia 2:1430. DOI: https://doi.org/10.\n                          4249/scholarpedia.1430\n                         Gleeson P, Steuber V, Silver RA. 2007. neuroConstruct: a tool for modeling networks of neurons in 3D space.\n                          Neuron 54:219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244\n                         Gleeson P, Crook S, Cannon RC, Hines ML, Billings GO, Farinella M, Morse TM, Davison AP, Ray S, Bhalla US,\n                          Barnes SR, Dimitrova YD, Silver RA. 2010. NeuroML: a language for describing data driven models of neurons\n                          and networks with a high degree of biological detail. PLOS Computational Biology 6:e1000815. DOI: https://\n                          doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541\n                         Gleeson P, Lung D, Grosu R, Hasani R, Larson SD. 2018. c302: a multiscale framework for modelling the nervous\n                          system of Caenorhabditis elegans. Philosophical Transactions of the Royal Society of London. Series B,\n                          Biological Sciences 373:20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842\n                         Gleeson P. 2019a. OpenSourceBrain/thalamocortical. 0.4. Zenodo. https://doi.org/10.5281/zenodo.2535506\n                         Gleeson P, Cantarelli M, Marin B, Quintana A, Earnshaw M, Sadeh S, Piasini E, Birgiolas J, Cannon RC,\n                          Cayco-Gajic NA, Crook S, Davison AP, Dura-Bernal S, Ecker A, Hines ML, Idili G, Lanore F, Larson SD,\n                          Lytton WW, Majumdar A, et al. 2019b. Open source brain: a collaborative resource for visualizing, analyzing,\n                          simulating, and developing standardized models of neurons and circuits. Neuron 103:395–411. DOI: https://\n                          doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    41 of 44","md":"\n\neLife Tools and resources                                                                                            Neuroscience\n\n**Cayco-Gajic NA**, Clopath C, Silver RA. 2017. Sparse synaptic connectivity is required for decorrelation and pattern separation in feedforward networks. *Nature Communications* **8**:1116. DOI: https://doi.org/10.1038/s41467-017-01109-y, PMID: 29061964\n\n**Choi K**, Medley JK, König M, Stocking K, Smith L, Gu S, Sauro HM. 2018. Tellurium: An extensible python-based modeling environment for systems and synthetic biology. *Bio Systems* **171**:74–79. DOI: https://doi.org/10.1016/j.biosystems.2018.07.006, PMID: 30053414\n\n**Dai K**, Hernando J, Billeh YN, Gratiy SL, Planas J, Davison AP, Dura-Bernal S, Gleeson P, Devresse A, Dichter BK, Gevaert M, King JG, Van Geit WAH, Povolotsky AV, Muller E, Courcol JD, Arkhipov A. 2020. The SONATA data format for efficient description of large-scale network models. *PLOS Computational Biology* **16**:e1007696. DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054\n\n**Davison AP**, Brüderle D, Eppler J, Kremkow J, Muller E, Pecevski D, Perrinet L, Yger P. 2008. PyNN: a common interface for neuronal network simulators. *Frontiers in Neuroinformatics* **2**:11. DOI: https://doi.org/10.3389/neuro.11.011.2008, PMID: 19194529\n\n**Denker M**. 2018. Collaborative HPC-enabled workflows on the HBP Collaboratory using the Elephant framework. *Neuroinformatics* **19**:0019. DOI: https://doi.org/10.12751/incf.ni2018.0019\n\n**De Schutter E**, Bower JM. 1994. An active membrane model of the cerebellar Purkinje cell. I. Simulation of current clamps in slice. *Journal of Neurophysiology* **71**:375–400. DOI: https://doi.org/10.1152/jn.1994.71.1.375, PMID: 7512629\n\n**Druckmann S**, Banitt Y, Gidon A, Schürmann F, Markram H, Segev I. 2007. A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data. *Frontiers in Neuroscience* **1**:7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116\n\n**Dura-Bernal S**, Neymotin SA, Kerr CC, Sivagnanam S, Majumdar A, Francis JT, Lytton WW. 2017. Evolutionary algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis. *IBM Journal of Research and Development* **61**:6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477\n\n**Dura-Bernal S**, Suter BA, Gleeson P, Cantarelli M, Quintana A, Rodriguez F, Kedziora DJ, Chadderdon GL, Kerr CC, Neymotin SA, McDougal RA, Hines M, Shepherd GM, Lytton WW. 2019. NetPyNE, a tool for data-driven multiscale modeling of brain circuits. *eLife* **8**:e44494. DOI: https://doi.org/10.7554/eLife.44494, PMID: 31025934\n\n**Einevoll GT**, Destexhe A, Diesmann M, Grün S, Jirsa V, de Kamps M, Migliore M, Ness TV, Plesser HE, Schürmann F. 2019. The scientific case for brain simulations. *Neuron* **102**:735–744. DOI: https://doi.org/10.1016/j.neuron.2019.03.027, PMID: 31121126\n\n**Executable Books Community**. 2020. Executable books community, jupyter book. 01. Zenodo. https://doi.org/10.5281/zenodo.4539666\n\n**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2013. Experimentally constrained CA1 fast-firing parvalbumin-positive interneuron network models exhibit sharp transitions into coherent high frequency rhythms. *Frontiers in Computational Neuroscience* **7**:144. DOI: https://doi.org/10.3389/fncom.2013.00144, PMID: 24155715\n\n**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2014. Simple, biologically-constrained CA1 pyramidal cell models using an intact, whole hippocampus context. *F1000Research* **3**:104. DOI: https://doi.org/10.12688/f1000research.3894.1, PMID: 25383182\n\n**FitzHugh R**. 1961. Impulses and physiological states in theoretical models of nerve membrane. *Biophysical Journal* **1**:445–466. DOI: https://doi.org/10.1016/S0006-3495(61)86902-6\n\n**Garcia S**, Guarino D, Jaillet F, Jennings T, Pröpper R, Rautenberg PL, Rodgers CC, Sobolev A, Wachtler T, Yger P, Davison AP. 2014. Neo: an object model for handling electrophysiology data in multiple formats. *Frontiers in Neuroinformatics* **8**:10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386\n\n**Garcia Del Molino LC**, Yang GR, Mejias JF, Wang X-J. 2017. Paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types. *eLife* **6**:e29742. DOI: https://doi.org/10.7554/eLife.29742, PMID: 29256863\n\n**Gerkin RC**, Birgiolas J, Jarvis RJ, Omar C, Crook SM. 2019. NeuronUnit: a package for data-driven validation of neuron models using sciunit. *bioRxiv*. DOI: https://doi.org/10.1101/665331\n\n**Gewaltig MO**, Diesmann M. 2007. NEST (NEural Simulation Tool). *Scholarpedia* **2**:1430. DOI: https://doi.org/10.4249/scholarpedia.1430\n\n**Gleeson P**, Steuber V, Silver RA. 2007. neuroConstruct: a tool for modeling networks of neurons in 3D space. *Neuron* **54**:219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244\n\n**Gleeson P**, Crook S, Cannon RC, Hines ML, Billings GO, Farinella M, Morse TM, Davison AP, Ray S, Bhalla US, Barnes SR, Dimitrova YD, Silver RA. 2010. NeuroML: a language for describing data driven models of neurons and networks with a high degree of biological detail. *PLOS Computational Biology* **6**:e1000815. DOI: https://doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541\n\n**Gleeson P**, Lung D, Grosu R, Hasani R, Larson SD. 2018. c302: a multiscale framework for modelling the nervous system of Caenorhabditis elegans. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* **373**:20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842\n\n**Gleeson P**. 2019a. OpenSourceBrain/thalamocortical. 0.4. Zenodo. https://doi.org/10.5281/zenodo.2535506\n\n**Gleeson P**, Cantarelli M, Marin B, Quintana A, Earnshaw M, Sadeh S, Piasini E, Birgiolas J, Cannon RC, Cayco-Gajic NA, Crook S, Davison AP, Dura-Bernal S, Ecker A, Hines ML, Idili G, Lanore F, Larson SD, Lytton WW, Majumdar A, et al. 2019b. Open source brain: a collaborative resource for visualizing, analyzing, simulating, and developing standardized models of neurons and circuits. *Neuron* **103**:395–411. DOI: https://doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    41 of 44\n","images":[{"name":"page_41.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_41_reference_1_v2.jpg","height":529403.588,"width":248816.688,"x":101826.467,"y":42178.146,"original_width":1643,"original_height":2701,"rotation":0,"type":"layout_v2_reference"},{"name":"page_41_reference_content_1_v2.jpg","height":30748.806,"width":248514.814,"x":102324.533,"y":88781.746,"original_width":1641,"original_height":157,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_2_v2.jpg","height":30426.42,"width":245882.774,"x":102439.207,"y":469226.893,"original_width":1624,"original_height":156,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_3_v2.jpg","height":30261.724,"width":239461.009,"x":102460.632,"y":302773.256,"original_width":1582,"original_height":155,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_4_v2.jpg","height":29904.242,"width":241007.121,"x":102492.163,"y":231869.294,"original_width":1592,"original_height":153,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_footer_1_v2.jpg","height":6859.308,"width":191908.042,"x":21715.724,"y":591578.892,"original_width":1268,"original_height":35,"rotation":0,"type":"layout_v2_footer"},{"name":"page_41_reference_content_5_v2.jpg","height":22577.338,"width":247029.51,"x":102422.721,"y":65102.897,"original_width":1632,"original_height":116,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_6_v2.jpg","height":22926.44,"width":247510.114,"x":102199.24,"y":501017.22,"original_width":1635,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_7_v2.jpg","height":22207.276,"width":241547.999,"x":102275.38,"y":41639.77,"original_width":1595,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_8_v2.jpg","height":22491.027,"width":245151.194,"x":102366.494,"y":120797.893,"original_width":1619,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_9_v2.jpg","height":22752.296,"width":248171.37,"x":102306.277,"y":373998.77,"original_width":1639,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_10_v2.jpg","height":22007.273,"width":240959.255,"x":102419.715,"y":160429.364,"original_width":1591,"original_height":113,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_11_v2.jpg","height":22785.776,"width":239753.438,"x":102462.794,"y":263311.254,"original_width":1584,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_12_v2.jpg","height":22646.327,"width":242233.998,"x":102421.678,"y":208063.488,"original_width":1600,"original_height":116,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_13_v2.jpg","height":22840.158,"width":247351.689,"x":102300.839,"y":184325.009,"original_width":1634,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_14_v2.jpg","height":22366.626,"width":247809.786,"x":102316.656,"y":398110.876,"original_width":1637,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_15_v2.jpg","height":22484.434,"width":250045.672,"x":102283.581,"y":334646.676,"original_width":1651,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_header_1_v2.jpg","height":5526.997,"width":30412.654,"x":320806.326,"y":27837.511,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_41_reference_content_16_v2.jpg","height":36765.138,"width":243079.888,"x":102529.17,"y":534058.587,"original_width":1605,"original_height":188,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_17_v2.jpg","height":14884.339,"width":224832.891,"x":102384.831,"y":144350.88,"original_width":1485,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_18_v2.jpg","height":14788.591,"width":240365.982,"x":102404.327,"y":453281.038,"original_width":1588,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_19_v2.jpg","height":15016.739,"width":246492.622,"x":102333.093,"y":421556.848,"original_width":1628,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_20_v2.jpg","height":14784.436,"width":247556.545,"x":102308.851,"y":437516.404,"original_width":1635,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_21_v2.jpg","height":15041.653,"width":236572.455,"x":102318.272,"y":358122.012,"original_width":1563,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_reference_content_22_v2.jpg","height":14750.681,"width":246395.11,"x":102418.337,"y":286947.601,"original_width":1627,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_41_number_1_v2.jpg","height":5865.31,"width":18417.265,"x":332821.343,"y":591873.569,"original_width":122,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_41_header_2_v2.jpg","height":5745.577,"width":42791.285,"x":47862.144,"y":27831.454,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_41_header_3_v2.jpg","height":10646.424,"width":24384.122,"x":21881.678,"y":22424.039,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                            Neuroscience","md":"eLife Tools and resources                                                                                            Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":6,"startIndex":117,"endIndex":129}]},{"type":"text","value":"**Cayco-Gajic NA**, Clopath C, Silver RA. 2017. Sparse synaptic connectivity is required for decorrelation and pattern separation in feedforward networks. *Nature Communications* **8**:1116. DOI: https://doi.org/10.1038/s41467-017-01109-y, PMID: 29061964","md":"**Cayco-Gajic NA**, Clopath C, Silver RA. 2017. Sparse synaptic connectivity is required for decorrelation and pattern separation in feedforward networks. *Nature Communications* **8**:1116. DOI: https://doi.org/10.1038/s41467-017-01109-y, PMID: 29061964","bBox":{"x":175.53,"y":72.05,"w":136.98,"h":8},"layoutAwareBbox":[{"x":167,"y":52,"w":394,"h":28,"startIndex":2,"endIndex":7}]},{"type":"text","value":"**Choi K**, Medley JK, König M, Stocking K, Smith L, Gu S, Sauro HM. 2018. Tellurium: An extensible python-based modeling environment for systems and synthetic biology. *Bio Systems* **171**:74–79. DOI: https://doi.org/10.1016/j.biosystems.2018.07.006, PMID: 30053414","md":"**Choi K**, Medley JK, König M, Stocking K, Smith L, Gu S, Sauro HM. 2018. Tellurium: An extensible python-based modeling environment for systems and synthetic biology. *Bio Systems* **171**:74–79. DOI: https://doi.org/10.1016/j.biosystems.2018.07.006, PMID: 30053414","bBox":{"x":175.53,"y":102.05,"w":175.81,"h":8},"layoutAwareBbox":[{"x":167,"y":82,"w":403,"h":28,"startIndex":107,"endIndex":112}]},{"type":"text","value":"**Dai K**, Hernando J, Billeh YN, Gratiy SL, Planas J, Davison AP, Dura-Bernal S, Gleeson P, Devresse A, Dichter BK, Gevaert M, King JG, Van Geit WAH, Povolotsky AV, Muller E, Courcol JD, Arkhipov A. 2020. The SONATA data format for efficient description of large-scale network models. *PLOS Computational Biology* **16**:e1007696. DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054","md":"**Dai K**, Hernando J, Billeh YN, Gratiy SL, Planas J, Davison AP, Dura-Bernal S, Gleeson P, Devresse A, Dichter BK, Gevaert M, King JG, Van Geit WAH, Povolotsky AV, Muller E, Courcol JD, Arkhipov A. 2020. The SONATA data format for efficient description of large-scale network models. *PLOS Computational Biology* **16**:e1007696. DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054","bBox":{"x":175.53,"y":122.05,"w":400.12,"h":28},"layoutAwareBbox":[{"x":167,"y":112,"w":406,"h":38,"startIndex":317,"endIndex":319}]},{"type":"text","value":"**Davison AP**, Brüderle D, Eppler J, Kremkow J, Muller E, Pecevski D, Perrinet L, Yger P. 2008. PyNN: a common interface for neuronal network simulators. *Frontiers in Neuroinformatics* **2**:11. DOI: https://doi.org/10.3389/neuro.11.011.2008, PMID: 19194529","md":"**Davison AP**, Brüderle D, Eppler J, Kremkow J, Muller E, Pecevski D, Perrinet L, Yger P. 2008. PyNN: a common interface for neuronal network simulators. *Frontiers in Neuroinformatics* **2**:11. DOI: https://doi.org/10.3389/neuro.11.011.2008, PMID: 19194529","bBox":{"x":175.53,"y":172.05,"w":131.96,"h":8},"layoutAwareBbox":[{"x":167,"y":152,"w":400,"h":28,"startIndex":0,"endIndex":258}]},{"type":"text","value":"**Denker M**. 2018. Collaborative HPC-enabled workflows on the HBP Collaboratory using the Elephant framework. *Neuroinformatics* **19**:0019. DOI: https://doi.org/10.12751/incf.ni2018.0019","md":"**Denker M**. 2018. Collaborative HPC-enabled workflows on the HBP Collaboratory using the Elephant framework. *Neuroinformatics* **19**:0019. DOI: https://doi.org/10.12751/incf.ni2018.0019","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":182,"w":367,"h":18,"startIndex":100,"endIndex":109}]},{"type":"text","value":"**De Schutter E**, Bower JM. 1994. An active membrane model of the cerebellar Purkinje cell. I. Simulation of current clamps in slice. *Journal of Neurophysiology* **71**:375–400. DOI: https://doi.org/10.1152/jn.1994.71.1.375, PMID: 7512629","md":"**De Schutter E**, Bower JM. 1994. An active membrane model of the cerebellar Purkinje cell. I. Simulation of current clamps in slice. *Journal of Neurophysiology* **71**:375–400. DOI: https://doi.org/10.1152/jn.1994.71.1.375, PMID: 7512629","bBox":{"x":175.53,"y":222.05,"w":73.38,"h":8},"layoutAwareBbox":[{"x":167,"y":202,"w":393,"h":27,"startIndex":166,"endIndex":168}]},{"type":"text","value":"**Druckmann S**, Banitt Y, Gidon A, Schürmann F, Markram H, Segev I. 2007. A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data. *Frontiers in Neuroscience* **1**:7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116","md":"**Druckmann S**, Banitt Y, Gidon A, Schürmann F, Markram H, Segev I. 2007. A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data. *Frontiers in Neuroscience* **1**:7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":232,"w":404,"h":28,"startIndex":210,"endIndex":222}]},{"type":"text","value":"**Dura-Bernal S**, Neymotin SA, Kerr CC, Sivagnanam S, Majumdar A, Francis JT, Lytton WW. 2017. Evolutionary algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis. *IBM Journal of Research and Development* **61**:6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477","md":"**Dura-Bernal S**, Neymotin SA, Kerr CC, Sivagnanam S, Majumdar A, Francis JT, Lytton WW. 2017. Evolutionary algorithm optimization of biological learning parameters in a biomimetic neuroprosthesis. *IBM Journal of Research and Development* **61**:6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":262,"w":395,"h":28,"startIndex":2,"endIndex":6}]},{"type":"text","value":"**Dura-Bernal S**, Suter BA, Gleeson P, Cantarelli M, Quintana A, Rodriguez F, Kedziora DJ, Chadderdon GL, Kerr CC, Neymotin SA, McDougal RA, Hines M, Shepherd GM, Lytton WW. 2019. NetPyNE, a tool for data-driven multiscale modeling of brain circuits. *eLife* **8**:e44494. DOI: https://doi.org/10.7554/eLife.44494, PMID: 31025934","md":"**Dura-Bernal S**, Suter BA, Gleeson P, Cantarelli M, Quintana A, Rodriguez F, Kedziora DJ, Chadderdon GL, Kerr CC, Neymotin SA, McDougal RA, Hines M, Shepherd GM, Lytton WW. 2019. NetPyNE, a tool for data-driven multiscale modeling of brain circuits. *eLife* **8**:e44494. DOI: https://doi.org/10.7554/eLife.44494, PMID: 31025934","bBox":{"x":175.53,"y":302.05,"w":367.02,"h":28},"layoutAwareBbox":[{"x":167,"y":292,"w":393,"h":37,"startIndex":2,"endIndex":6}]},{"type":"text","value":"**Einevoll GT**, Destexhe A, Diesmann M, Grün S, Jirsa V, de Kamps M, Migliore M, Ness TV, Plesser HE, Schürmann F. 2019. The scientific case for brain simulations. *Neuron* **102**:735–744. DOI: https://doi.org/10.1016/j.neuron.2019.03.027, PMID: 31121126","md":"**Einevoll GT**, Destexhe A, Diesmann M, Grün S, Jirsa V, de Kamps M, Migliore M, Ness TV, Plesser HE, Schürmann F. 2019. The scientific case for brain simulations. *Neuron* **102**:735–744. DOI: https://doi.org/10.1016/j.neuron.2019.03.027, PMID: 31121126","bBox":{"x":175.53,"y":352.05,"w":161.3,"h":8},"layoutAwareBbox":[{"x":167,"y":332,"w":391,"h":28,"startIndex":166,"endIndex":172}]},{"type":"text","value":"**Executable Books Community**. 2020. Executable books community, jupyter book. 01. Zenodo. https://doi.org/10.5281/zenodo.4539666","md":"**Executable Books Community**. 2020. Executable books community, jupyter book. 01. Zenodo. https://doi.org/10.5281/zenodo.4539666","bBox":{"x":175.53,"y":372.05,"w":92.07,"h":8},"layoutAwareBbox":[{"x":167,"y":362,"w":402,"h":18,"startIndex":108,"endIndex":130}]},{"type":"text","value":"**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2013. Experimentally constrained CA1 fast-firing parvalbumin-positive interneuron network models exhibit sharp transitions into coherent high frequency rhythms. *Frontiers in Computational Neuroscience* **7**:144. DOI: https://doi.org/10.3389/fncom.2013.00144, PMID: 24155715","md":"**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2013. Experimentally constrained CA1 fast-firing parvalbumin-positive interneuron network models exhibit sharp transitions into coherent high frequency rhythms. *Frontiers in Computational Neuroscience* **7**:144. DOI: https://doi.org/10.3389/fncom.2013.00144, PMID: 24155715","bBox":{"x":175.53,"y":34.63,"w":399.46,"h":385.41},"layoutAwareBbox":[{"x":167,"y":382,"w":391,"h":38,"startIndex":105,"endIndex":109}]},{"type":"text","value":"**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2014. Simple, biologically-constrained CA1 pyramidal cell models using an intact, whole hippocampus context. *F1000Research* **3**:104. DOI: https://doi.org/10.12688/f1000research.3894.1, PMID: 25383182","md":"**Ferguson KA**, Huh CYL, Amilhon B, Williams S, Skinner FK. 2014. Simple, biologically-constrained CA1 pyramidal cell models using an intact, whole hippocampus context. *F1000Research* **3**:104. DOI: https://doi.org/10.12688/f1000research.3894.1, PMID: 25383182","bBox":{"x":175.53,"y":442.05,"w":177.91,"h":8},"layoutAwareBbox":[{"x":167,"y":422,"w":408,"h":28,"startIndex":171,"endIndex":184}]},{"type":"text","value":"**FitzHugh R**. 1961. Impulses and physiological states in theoretical models of nerve membrane. *Biophysical Journal* **1**:445–466. DOI: https://doi.org/10.1016/S0006-3495(61)86902-6","md":"**FitzHugh R**. 1961. Impulses and physiological states in theoretical models of nerve membrane. *Biophysical Journal* **1**:445–466. DOI: https://doi.org/10.1016/S0006-3495(61)86902-6","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":452,"w":386,"h":18,"startIndex":98,"endIndex":109}]},{"type":"text","value":"**Garcia S**, Guarino D, Jaillet F, Jennings T, Pröpper R, Rautenberg PL, Rodgers CC, Sobolev A, Wachtler T, Yger P, Davison AP. 2014. Neo: an object model for handling electrophysiology data in multiple formats. *Frontiers in Neuroinformatics* **8**:10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386","md":"**Garcia S**, Guarino D, Jaillet F, Jennings T, Pröpper R, Rautenberg PL, Rodgers CC, Sobolev A, Wachtler T, Yger P, Davison AP. 2014. Neo: an object model for handling electrophysiology data in multiple formats. *Frontiers in Neuroinformatics* **8**:10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":472,"w":405,"h":28,"startIndex":227,"endIndex":243}]},{"type":"text","value":"**Garcia Del Molino LC**, Yang GR, Mejias JF, Wang X-J. 2017. Paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types. *eLife* **6**:e29742. DOI: https://doi.org/10.7554/eLife.29742, PMID: 29256863","md":"**Garcia Del Molino LC**, Yang GR, Mejias JF, Wang X-J. 2017. Paradoxical response reversal of top-down modulation in cortical circuits with three interneuron types. *eLife* **6**:e29742. DOI: https://doi.org/10.7554/eLife.29742, PMID: 29256863","bBox":{"x":175.53,"y":522.05,"w":86.73,"h":8},"layoutAwareBbox":[{"x":167,"y":502,"w":404,"h":28,"startIndex":99,"endIndex":103}]},{"type":"text","value":"**Gerkin RC**, Birgiolas J, Jarvis RJ, Omar C, Crook SM. 2019. NeuronUnit: a package for data-driven validation of neuron models using sciunit. *bioRxiv*. DOI: https://doi.org/10.1101/665331","md":"**Gerkin RC**, Birgiolas J, Jarvis RJ, Omar C, Crook SM. 2019. NeuronUnit: a package for data-driven validation of neuron models using sciunit. *bioRxiv*. DOI: https://doi.org/10.1101/665331","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":532,"w":402,"h":18,"startIndex":145,"endIndex":152}]},{"type":"text","value":"**Gewaltig MO**, Diesmann M. 2007. NEST (NEural Simulation Tool). *Scholarpedia* **2**:1430. DOI: https://doi.org/10.4249/scholarpedia.1430","md":"**Gewaltig MO**, Diesmann M. 2007. NEST (NEural Simulation Tool). *Scholarpedia* **2**:1430. DOI: https://doi.org/10.4249/scholarpedia.1430","bBox":{"x":175.53,"y":562.05,"w":86.42,"h":8},"layoutAwareBbox":[{"x":167,"y":552,"w":404,"h":18,"startIndex":67,"endIndex":79}]},{"type":"text","value":"**Gleeson P**, Steuber V, Silver RA. 2007. neuroConstruct: a tool for modeling networks of neurons in 3D space. *Neuron* **54**:219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244","md":"**Gleeson P**, Steuber V, Silver RA. 2007. neuroConstruct: a tool for modeling networks of neurons in 3D space. *Neuron* **54**:219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":572,"w":392,"h":18,"startIndex":91,"endIndex":97}]},{"type":"text","value":"**Gleeson P**, Crook S, Cannon RC, Hines ML, Billings GO, Farinella M, Morse TM, Davison AP, Ray S, Bhalla US, Barnes SR, Dimitrova YD, Silver RA. 2010. NeuroML: a language for describing data driven models of neurons and networks with a high degree of biological detail. *PLOS Computational Biology* **6**:e1000815. DOI: https://doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541","md":"**Gleeson P**, Crook S, Cannon RC, Hines ML, Billings GO, Farinella M, Morse TM, Davison AP, Ray S, Bhalla US, Barnes SR, Dimitrova YD, Silver RA. 2010. NeuroML: a language for describing data driven models of neurons and networks with a high degree of biological detail. *PLOS Computational Biology* **6**:e1000815. DOI: https://doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541","bBox":{"x":175.53,"y":602.05,"w":395.18,"h":28},"layoutAwareBbox":[{"x":167,"y":592,"w":401,"h":38,"startIndex":0,"endIndex":381}]},{"type":"text","value":"**Gleeson P**, Lung D, Grosu R, Hasani R, Larson SD. 2018. c302: a multiscale framework for modelling the nervous system of Caenorhabditis elegans. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* **373**:20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842","md":"**Gleeson P**, Lung D, Grosu R, Hasani R, Larson SD. 2018. c302: a multiscale framework for modelling the nervous system of Caenorhabditis elegans. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* **373**:20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":166,"y":632,"w":404,"h":28,"startIndex":241,"endIndex":244}]},{"type":"text","value":"**Gleeson P**. 2019a. OpenSourceBrain/thalamocortical. 0.4. Zenodo. https://doi.org/10.5281/zenodo.2535506","md":"**Gleeson P**. 2019a. OpenSourceBrain/thalamocortical. 0.4. Zenodo. https://doi.org/10.5281/zenodo.2535506","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":166,"y":53,"w":406,"h":668,"startIndex":17,"endIndex":19}]},{"type":"text","value":"**Gleeson P**, Cantarelli M, Marin B, Quintana A, Earnshaw M, Sadeh S, Piasini E, Birgiolas J, Cannon RC, Cayco-Gajic NA, Crook S, Davison AP, Dura-Bernal S, Ecker A, Hines ML, Idili G, Lanore F, Larson SD, Lytton WW, Majumdar A, et al. 2019b. Open source brain: a collaborative resource for visualizing, analyzing, simulating, and developing standardized models of neurons and circuits. *Neuron* **103**:395–411. DOI: https://doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122","md":"**Gleeson P**, Cantarelli M, Marin B, Quintana A, Earnshaw M, Sadeh S, Piasini E, Birgiolas J, Cannon RC, Cayco-Gajic NA, Crook S, Davison AP, Dura-Bernal S, Ecker A, Hines ML, Idili G, Lanore F, Larson SD, Lytton WW, Majumdar A, et al. 2019b. Open source brain: a collaborative resource for visualizing, analyzing, simulating, and developing standardized models of neurons and circuits. *Neuron* **103**:395–411. DOI: https://doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122","bBox":{"x":175.53,"y":682.05,"w":363.15,"h":38},"layoutAwareBbox":[{"x":167,"y":674,"w":397,"h":46,"startIndex":106,"endIndex":111}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    41 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    41 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":30,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://doi.org/10.1038/s41467-017-01109-y","unsafeUrl":"https://doi.org/10.1038/s41467-017-01109-y","text":":1116. DOI: https://doi.org/10.1038/"},{"url":"https://doi.org/10.1038/s41467-017-01109-y","unsafeUrl":"https://doi.org/10.1038/s41467-017-01109-y","text":"s41467-017-01109-y, PMID: 29061964 , Medley JK, König M, Stocking K, Smith L, Gu S, Sauro HM. 2018. Tellurium: An extensible python-"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/29061964","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/29061964","text":"s41467-017-01109-y, PMID: 29061964"},{"url":"https://doi.org/10.1016/j.biosystems.2018.07.006","unsafeUrl":"https://doi.org/10.1016/j.biosystems.2018.07.006","text":":74–79. DOI: https://doi.org/10."},{"url":"https://doi.org/10.1016/j.biosystems.2018.07.006","unsafeUrl":"https://doi.org/10.1016/j.biosystems.2018.07.006","text":"1016/j.biosystems.2018.07.006, PMID: 30053414 , Hernando J, Billeh YN, Gratiy SL, Planas J, Davison AP, Dura-"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/30053414","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/30053414","text":"1016/j.biosystems.2018.07.006, PMID: 30053414"},{"url":"https://doi.org/10.1371/journal.pcbi.1007696","unsafeUrl":"https://doi.org/10.1371/journal.pcbi.1007696","text":"DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054 , Brüderle D, Eppler J, Kremkow J, Muller E, Pecevski D, Perrinet L, Yger P. 2008. PyNN: a common "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/32092054","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/32092054","text":"DOI: https://doi.org/10.1371/journal.pcbi.1007696, PMID: 32092054"},{"url":"https://doi.org/10.3389/neuro.11.011.2008","unsafeUrl":"https://doi.org/10.3389/neuro.11.011.2008","text":":11. DOI: https://doi.org/10.3389/"},{"url":"https://doi.org/10.3389/neuro.11.011.2008","unsafeUrl":"https://doi.org/10.3389/neuro.11.011.2008","text":"neuro.11.011.2008, PMID: 19194529 . 2018. Collaborative HPC-"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/19194529","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/19194529","text":"neuro.11.011.2008, PMID: 19194529   enabled workﬂows on the HBP Collaboratory using the Elephant "},{"url":"https://doi.org/10.12751/incf.ni2018.0019","unsafeUrl":"https://doi.org/10.12751/incf.ni2018.0019","text":":0019. DOI: https://doi.org/10.12751/incf.ni2018.0019"},{"url":"https://doi.org/10.1152/jn.1994.71.1.375","unsafeUrl":"https://doi.org/10.1152/jn.1994.71.1.375","text":":375–400. DOI: https://doi.org/10.1152/jn.1994.71.1."},{"url":"https://doi.org/10.1152/jn.1994.71.1.375","unsafeUrl":"https://doi.org/10.1152/jn.1994.71.1.375","text":"375, PMID: 7512629"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/7512629","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/7512629","text":"375, PMID: 7512629 , Banitt Y, Gidon A, Schürmann F, Markram H, Segev I. 2007. A novel multiple objective "},{"url":"https://doi.org/10.3389/neuro.01.1.1.001.2007","unsafeUrl":"https://doi.org/10.3389/neuro.01.1.1.001.2007","text":":7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/18982116","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/18982116","text":":7–18. DOI: https://doi.org/10.3389/neuro.01.1.1.001.2007, PMID: 18982116"},{"url":"https://doi.org/10.1147/JRD.2017.2656758","unsafeUrl":"https://doi.org/10.1147/JRD.2017.2656758","text":":6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/29200477","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/29200477","text":":6. DOI: https://doi.org/10.1147/JRD.2017.2656758, PMID: 29200477"},{"url":"https://doi.org/10.7554/eLife.44494","unsafeUrl":"https://doi.org/10.7554/eLife.44494","text":":e44494. DOI: https://doi.org/10.7554/eLife.44494, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/31025934","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/31025934","text":"PMID: 31025934 , Destexhe A, Diesmann M, Grün S, Jirsa V, de Kamps M, Migliore M, Ness TV, Plesser HE, "},{"url":"https://doi.org/10.1016/j.neuron.2019.03.027","unsafeUrl":"https://doi.org/10.1016/j.neuron.2019.03.027","text":":735–744. DOI: https://doi.org/10."},{"url":"https://doi.org/10.1016/j.neuron.2019.03.027","unsafeUrl":"https://doi.org/10.1016/j.neuron.2019.03.027","text":"1016/j.neuron.2019.03.027, PMID: 31121126"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/31121126","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/31121126","text":"1016/j.neuron.2019.03.027, PMID: 31121126"},{"url":"https://doi.org/10.5281/zenodo.4539666","unsafeUrl":"https://doi.org/10.5281/zenodo.4539666","text":". 2020. Executable books community, jupyter book. 01. Zenodo. https://doi.org/"},{"url":"https://doi.org/10.5281/zenodo.4539666","unsafeUrl":"https://doi.org/10.5281/zenodo.4539666","text":"10.5281/zenodo.4539666 , Huh CYL, Amilhon B, Williams S, Skinner FK. 2013. Experimentally constrained CA1 fast-"},{"url":"https://doi.org/10.3389/fncom.2013.00144","unsafeUrl":"https://doi.org/10.3389/fncom.2013.00144","text":":144. DOI: https://doi.org/10.3389/fncom.2013.00144, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24155715","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24155715","text":"PMID: 24155715 , Huh CYL, Amilhon B, Williams S, Skinner FK. 2014. Simple, biologically-"},{"url":"https://doi.org/10.12688/f1000research.3894.1","unsafeUrl":"https://doi.org/10.12688/f1000research.3894.1","text":":104. DOI: https://doi.org/"},{"url":"https://doi.org/10.12688/f1000research.3894.1","unsafeUrl":"https://doi.org/10.12688/f1000research.3894.1","text":"10.12688/f1000research.3894.1, PMID: 25383182 . 1961. Impulses and physiological states in theoretical models of nerve membrane. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25383182","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25383182","text":"10.12688/f1000research.3894.1, PMID: 25383182"},{"url":"https://doi.org/10.1016/S0006-3495(61)86902-6","unsafeUrl":"https://doi.org/10.1016/S0006-3495(61)86902-6","text":":445–466. DOI: https://doi.org/10.1016/S0006-3495(61)86902-6"},{"url":"https://doi.org/10.3389/fninf.2014.00010","unsafeUrl":"https://doi.org/10.3389/fninf.2014.00010","text":":10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386   J. 2017. Paradoxical response reversal of top-"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24600386","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24600386","text":":10. DOI: https://doi.org/10.3389/fninf.2014.00010, PMID: 24600386"},{"url":"https://doi.org/10.7554/eLife.29742","unsafeUrl":"https://doi.org/10.7554/eLife.29742","text":":e29742. DOI: https://doi.org/10.7554/eLife."},{"url":"https://doi.org/10.7554/eLife.29742","unsafeUrl":"https://doi.org/10.7554/eLife.29742","text":"29742, PMID: 29256863"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/29256863","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/29256863","text":"29742, PMID: 29256863"},{"url":"https://doi.org/10.1101/665331","unsafeUrl":"https://doi.org/10.1101/665331","text":". DOI: https://doi.org/10.1101/665331 Scholarpedia"},{"url":"https://doi.org/10.4249/scholarpedia.1430","unsafeUrl":"https://doi.org/10.4249/scholarpedia.1430","text":":1430. DOI: https://doi.org/10."},{"url":"https://doi.org/10.4249/scholarpedia.1430","unsafeUrl":"https://doi.org/10.4249/scholarpedia.1430","text":"4249/scholarpedia.1430 , Steuber V, Silver RA. 2007. neuroConstruct: a tool for modeling networks of neurons in 3D space. "},{"url":"https://doi.org/10.1016/j.neuron.2007.03.025","unsafeUrl":"https://doi.org/10.1016/j.neuron.2007.03.025","text":":219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/17442244","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/17442244","text":":219–235. DOI: https://doi.org/10.1016/j.neuron.2007.03.025, PMID: 17442244"},{"url":"https://doi.org/10.1371/journal.pcbi.1000815","unsafeUrl":"https://doi.org/10.1371/journal.pcbi.1000815","text":":e1000815. DOI: https://"},{"url":"https://doi.org/10.1371/journal.pcbi.1000815","unsafeUrl":"https://doi.org/10.1371/journal.pcbi.1000815","text":"doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541 , Lung D, Grosu R, Hasani R, Larson SD. 2018. c302: a multiscale framework for modelling the nervous "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/20585541","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/20585541","text":"doi.org/10.1371/journal.pcbi.1000815, PMID: 20585541"},{"url":"https://doi.org/10.1098/rstb.2017.0379","unsafeUrl":"https://doi.org/10.1098/rstb.2017.0379","text":":20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/30201842","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/30201842","text":":20170379. DOI: https://doi.org/10.1098/rstb.2017.0379, PMID: 30201842"},{"url":"https://doi.org/10.5281/zenodo.2535506","unsafeUrl":"https://doi.org/10.5281/zenodo.2535506","text":". 2019a. OpenSourceBrain/thalamocortical. 0.4. Zenodo. https://doi.org/10.5281/zenodo.2535506"},{"url":"https://doi.org/10.1016/j.neuron.2019.05.019","unsafeUrl":"https://doi.org/10.1016/j.neuron.2019.05.019","text":":395–411. DOI: https://"},{"url":"https://doi.org/10.1016/j.neuron.2019.05.019","unsafeUrl":"https://doi.org/10.1016/j.neuron.2019.05.019","text":"doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/31201122","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/31201122","text":"doi.org/10.1016/j.neuron.2019.05.019, PMID: 31201122"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                            Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    41 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.994,"layout":[{"image":"page_41_reference_1_v2.jpg","confidence":0.98,"label":"reference","bbox":{"x":0.272,"y":0.067,"w":0.664,"h":0.844},"isLikelyNoise":false},{"image":"page_41_reference_content_1_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.142,"w":0.664,"h":0.049},"isLikelyNoise":false},{"image":"page_41_reference_content_2_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.274,"y":0.748,"w":0.656,"h":0.049},"isLikelyNoise":false},{"image":"page_41_reference_content_3_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.274,"y":0.483,"w":0.639,"h":0.048},"isLikelyNoise":false},{"image":"page_41_reference_content_4_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.37,"w":0.643,"h":0.048},"isLikelyNoise":false},{"image":"page_41_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_41_reference_content_5_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.104,"w":0.66,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_6_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.799,"w":0.661,"h":0.037},"isLikelyNoise":false},{"image":"page_41_reference_content_7_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.066,"w":0.645,"h":0.035},"isLikelyNoise":false},{"image":"page_41_reference_content_8_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.193,"w":0.655,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_9_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.596,"w":0.663,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_10_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.256,"w":0.643,"h":0.035},"isLikelyNoise":false},{"image":"page_41_reference_content_11_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.42,"w":0.64,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_12_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.332,"w":0.647,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_13_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.294,"w":0.66,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_14_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.273,"y":0.635,"w":0.662,"h":0.036},"isLikelyNoise":false},{"image":"page_41_reference_content_15_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.273,"y":0.534,"w":0.668,"h":0.036},"isLikelyNoise":false},{"image":"page_41_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_41_reference_content_16_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.274,"y":0.851,"w":0.649,"h":0.059},"isLikelyNoise":false},{"image":"page_41_reference_content_17_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.23,"w":0.6,"h":0.024},"isLikelyNoise":false},{"image":"page_41_reference_content_18_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.723,"w":0.642,"h":0.024},"isLikelyNoise":false},{"image":"page_41_reference_content_19_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.672,"w":0.658,"h":0.024},"isLikelyNoise":false},{"image":"page_41_reference_content_20_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.697,"w":0.661,"h":0.024},"isLikelyNoise":false},{"image":"page_41_reference_content_21_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.571,"w":0.632,"h":0.024},"isLikelyNoise":false},{"image":"page_41_reference_content_22_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.457,"w":0.658,"h":0.024},"isLikelyNoise":false},{"image":"page_41_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_41_header_2_v2.jpg","confidence":0.71,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_41_header_3_v2.jpg","confidence":0.6,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":42,"text":"Tools  and  resources                                                                                               Neuroscience\n\n                         Gleeson P. 2021. LEMS/LEMS. 0.7.6. Zenodo. https://doi.org/10.5281/zenodo.6417333DOI: https://doi.\n                          org/10.5281/zenodo.5788686\n                         Gleeson P, Crook S, Turner D, Mantel K, Raunak M, Willke T, Cohen JD. 2023. Integrating model development\n                          across computational neuroscience, cognitive science, and machine learning. Neuron 111:1526–1530. DOI:\n                          https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054\n                         Gleeson P. 2024a. LEMS/jlems. 0.11.1. Zenodo. https://doi.org/10.5281/zenodo.13350473\n                         Gleeson P. 2024b. NeuroML/jneuroml. 0.13.3. Zenodo. https://doi.org/10.5281/zenodo.13342731\n                         Gleeson P, SinhaA. 2024. NeuroML 2. swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6. Software\n                          Heritage. https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;\n                          origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b801\n                          4dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6\n                         Goddard NH, Hucka M, Howell F, Cornelis H, Shankar K, Beeman D. 2001. Towards NeuroML: model description\n                          methods for collaborative modelling in neuroscience. Philosophical Transactions of the Royal Society of\n                          London. Series B, Biological Sciences 356:1209–1228. DOI: https://doi.org/10.1098/rstb.2001.0910, PMID:\n                          11545699\n                         Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, Flandin G, Ghosh SS, Glatard T,\n                          Halchenko YO, Handwerker DA, Hanke M, Keator D, Li X, Michael Z, Maumet C, Nichols BN, Nichols TE,\n                          Pellman J, Poline J-B, et al. 2016. The brain imaging data structure, a format for organizing and describing\n                          outputs of neuroimaging experiments. Scientiﬁc Data 3:160044. DOI: https://doi.org/10.1038/sdata.2016.44,\n                          PMID: 27326542\n                         Gurnani H, Silver RA. 2021. Multidimensional population activity in an electrically coupled inhibitory circuit in the\n                          cerebellar cortex. Neuron 109:1739–1753.. DOI: https://doi.org/10.1016/j.neuron.2021.03.027, PMID:\n                          33848473\n                         Harris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D, Wieser E, Taylor J, Berg S,\n                          Smith NJ, Kern R, Picus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, Del Río JF, Wiebe M, Peterson P,\n                          Gérard-Marchant P, et al. 2020. Array programming with NumPy. Nature 585:357–362. DOI: https://doi.org/10.\n                          1038/s41586-020-2649-2, PMID: 32939066\n                         Hay E, Hill S, Schürmann F, Markram H, Segev I. 2011. Models of neocortical layer 5b pyramidal cells capturing a\n                          wide range of dendritic and perisomatic active properties. PLOS Computational Biology 7:e1002107. DOI:\n                          https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333\n                         Hindmarsh JL, Rose RM. 1984. A model of neuronal bursting using three coupled ﬁrst order differential\n                          equations. Proceedings of the Royal Society of London. Series B, Biological Sciences 221:87–102. DOI: https://\n                          doi.org/10.1098/rspb.1984.0024, PMID: 6144106\n                         Hines ML, Carnevale NT. 1997. The NEURON simulation environment. Neural Computation 9:1179–1209. DOI:\n                          https://doi.org/10.1162/neco.1997.9.6.1179\n                         Hodgkin AL, Huxley AF. 1952. A quantitative description of membrane current and its application to conduction\n                          and excitation in nerve. The Journal of Physiology 117:500–544. DOI: https://doi.org/10.1113/jphysiol.1952.\n                          sp004764, PMID: 12991237\n                         Hucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin AP, Bornstein BJ, Bray D, Cornish-Bowden A,\n                          Cuellar AA, Dronov S, Gilles ED, Ginkel M, Gor V, Goryanin II, Hedley WJ, Hodgman TC, Hofmeyr JH,\n                          Hunter PJ, et al. 2003. The systems biology markup language (SBML): a medium for representation and\n                          exchange of biochemical network models. Bioinformatics 19:524–531. DOI: https://doi.org/10.1093/\n                          bioinformatics/btg015, PMID: 12611808\n                         Hucka M, Nickerson DP, Bader GD, Bergmann FT, Cooper J, Demir E, Garny A, Golebiewski M, Myers CJ,\n                          Schreiber F, Waltemath D, Le Novère N. 2015. Promoting coordinated development of community-based\n                          information standards for modeling in biology: the COMBINE initiative. Frontiers in Bioengineering and\n                          Biotechnology 3:19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811\n                         Hunter JD. 2007. Matplotlib: A 2D graphics environment. Computing in Science & Engineering 9:90–95. DOI:\n                          https://doi.org/10.1109/MCSE.2007.55\n                         INCF. 2023. Role of community standards. https://www.incf.org/role-community-standards [Accessed November\n                          9, 2023].\n                         Izhikevich EM. 2004. Which model to use for cortical spiking neurons? IEEE Transactions on Neural Networks\n                          15:1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883\n                         Kriener B, Hu H, Vervaeke K. 2022. Parvalbumin interneuron dendrites enhance gamma oscillations. Cell Reports\n                          39:110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055\n                         Lapicque L. 1907. Recherches quantitatives sur L’excitation électrique des nerfs traitée comme une polarisation.\n                          Journal de Physiologie et de Pathologie Generale 9:620–635.\n                         Larson SD, Martone ME. 2013. NeuroLex.org: an online framework for neuroscience knowledge. Frontiers in\n                          Neuroinformatics 7:18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581\n                         Lloyd CM, Halstead MDB, Nielsen PF. 2004. CellML: its future, present and past. Progress in Biophysics and\n                          Molecular Biology 85:433–450. DOI: https://doi.org/10.1016/j.pbiomolbio.2004.01.004\n                         Maex R, Schutter ED. 1998. Synchronization of golgi and granule cell ﬁring in a detailed network model of the\n                          cerebellar granule cell layer. Journal of Neurophysiology 80:2521–2537. DOI: https://doi.org/10.1152/jn.1998.\n                          80.5.2521\n                         Markram H, Muller E, Ramaswamy S, Reimann MW, Abdellah M, Sanchez CA, Ailamaki A, Alonso-Nanclares L,\n                          Antille N, Arsever S, Kahou GAA, Berger TK, Bilgili A, Buncic N, Chalimourda A, Chindemi G, Courcol JD,\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    42 of 44","md":"\n\neLife Tools and resources                                                                                               Neuroscience\n\nGleeson P. 2021. LEMS/LEMS. 0.7.6. Zenodo. https://doi.org/10.5281/zenodo.6417333DOI: https://doi.org/10.5281/zenodo.5788686\n\nGleeson P, Crook S, Turner D, Mantel K, Raunak M, Willke T, Cohen JD. 2023. Integrating model development across computational neuroscience, cognitive science, and machine learning. *Neuron* 111:1526–1530. DOI: https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054\n\nGleeson P. 2024a. LEMS/jlems. 0.11.1. Zenodo. https://doi.org/10.5281/zenodo.13350473\n\nGleeson P. 2024b. NeuroML/jneuroml. 0.13.3. Zenodo. https://doi.org/10.5281/zenodo.13342731\n\nGleeson P, SinhaA. 2024. NeuroML 2. swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6. Software Heritage. https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8; origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b801 4dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6\n\nGoddard NH, Hucka M, Howell F, Cornelis H, Shankar K, Beeman D. 2001. Towards NeuroML: model description methods for collaborative modelling in neuroscience. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* 356:1209–1228. DOI: https://doi.org/10.1098/rstb.2001.0910, PMID: 11545699\n\nGorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, Flandin G, Ghosh SS, Glatard T, Halchenko YO, Handwerker DA, Hanke M, Keator D, Li X, Michael Z, Maumet C, Nichols BN, Nichols TE, Pellman J, Poline J-B, et al. 2016. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. *Scientific Data* 3:160044. DOI: https://doi.org/10.1038/sdata.2016.44, PMID: 27326542\n\nGurnani H, Silver RA. 2021. Multidimensional population activity in an electrically coupled inhibitory circuit in the cerebellar cortex. *Neuron* 109:1739–1753.. DOI: https://doi.org/10.1016/j.neuron.2021.03.027, PMID: 33848473\n\nHarris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D, Wieser E, Taylor J, Berg S, Smith NJ, Kern R, Picus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, Del Río JF, Wiebe M, Peterson P, Gérard-Marchant P, et al. 2020. Array programming with NumPy. *Nature* 585:357–362. DOI: https://doi.org/10.1038/s41586-020-2649-2, PMID: 32939066\n\nHay E, Hill S, Schürmann F, Markram H, Segev I. 2011. Models of neocortical layer 5b pyramidal cells capturing a wide range of dendritic and perisomatic active properties. *PLOS Computational Biology* 7:e1002107. DOI: https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333\n\nHindmarsh JL, Rose RM. 1984. A model of neuronal bursting using three coupled first order differential equations. *Proceedings of the Royal Society of London. Series B, Biological Sciences* 221:87–102. DOI: https://doi.org/10.1098/rspb.1984.0024, PMID: 6144106\n\nHines ML, Carnevale NT. 1997. The NEURON simulation environment. *Neural Computation* 9:1179–1209. DOI: https://doi.org/10.1162/neco.1997.9.6.1179\n\nHodgkin AL, Huxley AF. 1952. A quantitative description of membrane current and its application to conduction and excitation in nerve. *The Journal of Physiology* 117:500–544. DOI: https://doi.org/10.1113/jphysiol.1952.sp004764, PMID: 12991237\n\nHucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin AP, Bornstein BJ, Bray D, Cornish-Bowden A, Cuellar AA, Dronov S, Gilles ED, Ginkel M, Gor V, Goryanin II, Hedley WJ, Hodgman TC, Hofmeyr JH, Hunter PJ, et al. 2003. The systems biology markup language (SBML): a medium for representation and exchange of biochemical network models. *Bioinformatics* 19:524–531. DOI: https://doi.org/10.1093/bioinformatics/btg015, PMID: 12611808\n\nHucka M, Nickerson DP, Bader GD, Bergmann FT, Cooper J, Demir E, Garny A, Golebiewski M, Myers CJ, Schreiber F, Waltemath D, Le Novère N. 2015. Promoting coordinated development of community-based information standards for modeling in biology: the COMBINE initiative. *Frontiers in Bioengineering and Biotechnology* 3:19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811\n\nHunter JD. 2007. Matplotlib: A 2D graphics environment. *Computing in Science & Engineering* 9:90–95. DOI: https://doi.org/10.1109/MCSE.2007.55\n\nINCF. 2023. Role of community standards. https://www.incf.org/role-community-standards [Accessed November 9, 2023].\n\nIzhikevich EM. 2004. Which model to use for cortical spiking neurons? *IEEE Transactions on Neural Networks* 15:1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883\n\nKriener B, Hu H, Vervaeke K. 2022. Parvalbumin interneuron dendrites enhance gamma oscillations. *Cell Reports* 39:110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055\n\nLapicque L. 1907. Recherches quantitatives sur L'excitation électrique des nerfs traitée comme une polarisation. *Journal de Physiologie et de Pathologie Generale* 9:620–635.\n\nLarson SD, Martone ME. 2013. NeuroLex.org: an online framework for neuroscience knowledge. *Frontiers in Neuroinformatics* 7:18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581\n\nLloyd CM, Halstead MDB, Nielsen PF. 2004. CellML: its future, present and past. *Progress in Biophysics and Molecular Biology* 85:433–450. DOI: https://doi.org/10.1016/j.pbiomolbio.2004.01.004\n\nMaex R, Schutter ED. 1998. Synchronization of golgi and granule cell firing in a detailed network model of the cerebellar granule cell layer. *Journal of Neurophysiology* 80:2521–2537. DOI: https://doi.org/10.1152/jn.1998.80.5.2521\n\nMarkram H, Muller E, Ramaswamy S, Reimann MW, Abdellah M, Sanchez CA, Ailamaki A, Alonso-Nanclares L, Antille N, Arsever S, Kahou GAA, Berger TK, Bilgili A, Buncic N, Chalimourda A, Chindemi G, Courcol JD,\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    42 of 44\n","images":[{"name":"page_42.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_42_reference_1_v2.jpg","height":529803.602,"width":249219.381,"x":102070.812,"y":41849.621,"original_width":1646,"original_height":2703,"rotation":0,"type":"layout_v2_reference"},{"name":"page_42_reference_content_1_v2.jpg","height":39056.416,"width":249577.488,"x":102083.19,"y":346585.039,"original_width":1648,"original_height":200,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_2_v2.jpg","height":30789.449,"width":248767.944,"x":102347.745,"y":129606.346,"original_width":1643,"original_height":158,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_3_v2.jpg","height":38543.373,"width":244976.402,"x":102365.752,"y":161846.245,"original_width":1618,"original_height":197,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_4_v2.jpg","height":30987.292,"width":248303.27,"x":102361.466,"y":226135.669,"original_width":1640,"original_height":159,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_5_v2.jpg","height":31360.2,"width":236972.05,"x":102324.194,"y":386759.593,"original_width":1565,"original_height":160,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_6_v2.jpg","height":22188.699,"width":246392.611,"x":102513.98,"y":531615.433,"original_width":1627,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_footer_1_v2.jpg","height":6892.043,"width":191728.517,"x":21867.867,"y":591556.016,"original_width":1266,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_42_reference_content_7_v2.jpg","height":23172.606,"width":243937.941,"x":102386.523,"y":57643.332,"original_width":1611,"original_height":119,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_8_v2.jpg","height":30902.837,"width":236001.113,"x":102411.582,"y":97530.378,"original_width":1559,"original_height":158,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_9_v2.jpg","height":22945.513,"width":247415.224,"x":102234.2,"y":322547.518,"original_width":1634,"original_height":118,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_10_v2.jpg","height":22645.073,"width":248671.038,"x":102281.687,"y":201925.337,"original_width":1642,"original_height":116,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_11_v2.jpg","height":23099.33,"width":248257.668,"x":102252.586,"y":258183.312,"original_width":1640,"original_height":118,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_12_v2.jpg","height":23061.38,"width":248634.005,"x":102493.558,"y":282417.383,"original_width":1642,"original_height":118,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_header_1_v2.jpg","height":5618.172,"width":30307.364,"x":320882.431,"y":27796.612,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_42_reference_content_13_v2.jpg","height":15662.331,"width":243229.473,"x":102380.283,"y":555277.752,"original_width":1606,"original_height":80,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_14_v2.jpg","height":15226.245,"width":238610.941,"x":102415.141,"y":515249.762,"original_width":1576,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_15_v2.jpg","height":14917.004,"width":239842.538,"x":102347.069,"y":499519.647,"original_width":1584,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_16_v2.jpg","height":15216.542,"width":248987.279,"x":102350.789,"y":467097.371,"original_width":1644,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_17_v2.jpg","height":15211.379,"width":230444.488,"x":101994.056,"y":41264.981,"original_width":1522,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_18_v2.jpg","height":15017.739,"width":248206.801,"x":102308.3,"y":434975.515,"original_width":1639,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_19_v2.jpg","height":15189.511,"width":245998.393,"x":102259.478,"y":306369.655,"original_width":1625,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_20_v2.jpg","height":15175.045,"width":246837.399,"x":102424.955,"y":483193.416,"original_width":1630,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_21_v2.jpg","height":14788.062,"width":241753.551,"x":102453.565,"y":451116.311,"original_width":1597,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_22_v2.jpg","height":14954.561,"width":242736.014,"x":102308.67,"y":418974.559,"original_width":1603,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_number_1_v2.jpg","height":5894.537,"width":18343.674,"x":332901.113,"y":591865.336,"original_width":122,"original_height":31,"rotation":0,"type":"layout_v2_number"},{"name":"page_42_reference_content_23_v2.jpg","height":7861.766,"width":201173.554,"x":102499.466,"y":81565.993,"original_width":1329,"original_height":41,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_reference_content_24_v2.jpg","height":7735.96,"width":217156.067,"x":102532.487,"y":89082.21,"original_width":1434,"original_height":40,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_42_header_2_v2.jpg","height":5731.417,"width":42873.795,"x":47865.614,"y":27854.865,"original_width":284,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_42_header_3_v2.jpg","height":10642.409,"width":24373.354,"x":21907.325,"y":22430.901,"original_width":161,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                               Neuroscience","md":"eLife Tools and resources                                                                                               Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":120,"endIndex":132}]},{"type":"text","value":"Gleeson P. 2021. LEMS/LEMS. 0.7.6. Zenodo. https://doi.org/10.5281/zenodo.6417333DOI: https://doi.org/10.5281/zenodo.5788686","md":"Gleeson P. 2021. LEMS/LEMS. 0.7.6. Zenodo. https://doi.org/10.5281/zenodo.6417333DOI: https://doi.org/10.5281/zenodo.5788686","bBox":{"x":168.53,"y":52.05,"w":374.71,"h":18.14},"layoutAwareBbox":[{"x":166,"y":52,"w":376,"h":19,"startIndex":98,"endIndex":124}]},{"type":"text","value":"Gleeson P, Crook S, Turner D, Mantel K, Raunak M, Willke T, Cohen JD. 2023. Integrating model development across computational neuroscience, cognitive science, and machine learning. *Neuron* 111:1526–1530. DOI: https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054","md":"Gleeson P, Crook S, Turner D, Mantel K, Raunak M, Willke T, Cohen JD. 2023. Integrating model development across computational neuroscience, cognitive science, and machine learning. *Neuron* 111:1526–1530. DOI: https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054","bBox":{"x":168.53,"y":34.63,"w":406.46,"h":65.98},"layoutAwareBbox":[{"x":167,"y":72,"w":398,"h":29,"startIndex":183,"endIndex":189}]},{"type":"text","value":"Gleeson P. 2024a. LEMS/jlems. 0.11.1. Zenodo. https://doi.org/10.5281/zenodo.13350473","md":"Gleeson P. 2024a. LEMS/jlems. 0.11.1. Zenodo. https://doi.org/10.5281/zenodo.13350473","bBox":{"x":168.53,"y":102.76,"w":326.39,"h":8},"layoutAwareBbox":[{"x":167,"y":102,"w":328,"h":9,"startIndex":11,"endIndex":16}]},{"type":"text","value":"Gleeson P. 2024b. NeuroML/jneuroml. 0.13.3. Zenodo. https://doi.org/10.5281/zenodo.13342731","md":"Gleeson P. 2024b. NeuroML/jneuroml. 0.13.3. Zenodo. https://doi.org/10.5281/zenodo.13342731","bBox":{"x":168.53,"y":112.9,"w":353.39,"h":8},"layoutAwareBbox":[{"x":167,"y":112,"w":354,"h":9,"startIndex":11,"endIndex":16}]},{"type":"text","value":"Gleeson P, SinhaA. 2024. NeuroML 2. swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6. Software Heritage. https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8; origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b801 4dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","md":"Gleeson P, SinhaA. 2024. NeuroML 2. swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6. Software Heritage. https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8; origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b801 4dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","bBox":{"x":168.53,"y":123.04,"w":385.42,"h":38.43},"layoutAwareBbox":[{"x":167,"y":123,"w":385,"h":39,"startIndex":196,"endIndex":287}]},{"type":"text","value":"Goddard NH, Hucka M, Howell F, Cornelis H, Shankar K, Beeman D. 2001. Towards NeuroML: model description methods for collaborative modelling in neuroscience. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* 356:1209–1228. DOI: https://doi.org/10.1098/rstb.2001.0910, PMID: 11545699","md":"Goddard NH, Hucka M, Howell F, Cornelis H, Shankar K, Beeman D. 2001. Towards NeuroML: model description methods for collaborative modelling in neuroscience. *Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences* 356:1209–1228. DOI: https://doi.org/10.1098/rstb.2001.0910, PMID: 11545699","bBox":{"x":168.53,"y":34.63,"w":407.37,"h":167.41},"layoutAwareBbox":[{"x":167,"y":163,"w":406,"h":38,"startIndex":249,"endIndex":252}]},{"type":"text","value":"Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, Flandin G, Ghosh SS, Glatard T, Halchenko YO, Handwerker DA, Hanke M, Keator D, Li X, Michael Z, Maumet C, Nichols BN, Nichols TE, Pellman J, Poline J-B, et al. 2016. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. *Scientific Data* 3:160044. DOI: https://doi.org/10.1038/sdata.2016.44, PMID: 27326542","md":"Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, Flandin G, Ghosh SS, Glatard T, Halchenko YO, Handwerker DA, Hanke M, Keator D, Li X, Michael Z, Maumet C, Nichols BN, Nichols TE, Pellman J, Poline J-B, et al. 2016. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. *Scientific Data* 3:160044. DOI: https://doi.org/10.1038/sdata.2016.44, PMID: 27326542","bBox":{"x":168.53,"y":204.18,"w":384.36,"h":48.58},"layoutAwareBbox":[{"x":167,"y":204,"w":400,"h":48,"startIndex":0,"endIndex":427}]},{"type":"text","value":"Gurnani H, Silver RA. 2021. Multidimensional population activity in an electrically coupled inhibitory circuit in the cerebellar cortex. *Neuron* 109:1739–1753.. DOI: https://doi.org/10.1016/j.neuron.2021.03.027, PMID: 33848473","md":"Gurnani H, Silver RA. 2021. Multidimensional population activity in an electrically coupled inhibitory circuit in the cerebellar cortex. *Neuron* 109:1739–1753.. DOI: https://doi.org/10.1016/j.neuron.2021.03.027, PMID: 33848473","bBox":{"x":168.53,"y":254.89,"w":407.07,"h":28.29},"layoutAwareBbox":[{"x":167,"y":254,"w":406,"h":28,"startIndex":138,"endIndex":144}]},{"type":"text","value":"Harris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D, Wieser E, Taylor J, Berg S, Smith NJ, Kern R, Picus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, Del Río JF, Wiebe M, Peterson P, Gérard-Marchant P, et al. 2020. Array programming with NumPy. *Nature* 585:357–362. DOI: https://doi.org/10.1038/s41586-020-2649-2, PMID: 32939066","md":"Harris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D, Wieser E, Taylor J, Berg S, Smith NJ, Kern R, Picus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, Del Río JF, Wiebe M, Peterson P, Gérard-Marchant P, et al. 2020. Array programming with NumPy. *Nature* 585:357–362. DOI: https://doi.org/10.1038/s41586-020-2649-2, PMID: 32939066","bBox":{"x":168.53,"y":285.32,"w":394.84,"h":38.42},"layoutAwareBbox":[{"x":167,"y":285,"w":405,"h":39,"startIndex":211,"endIndex":217}]},{"type":"text","value":"Hay E, Hill S, Schürmann F, Markram H, Segev I. 2011. Models of neocortical layer 5b pyramidal cells capturing a wide range of dendritic and perisomatic active properties. *PLOS Computational Biology* 7:e1002107. DOI: https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333","md":"Hay E, Hill S, Schürmann F, Markram H, Segev I. 2011. Models of neocortical layer 5b pyramidal cells capturing a wide range of dendritic and perisomatic active properties. *PLOS Computational Biology* 7:e1002107. DOI: https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333","bBox":{"x":168.53,"y":325.89,"w":406.18,"h":28.29},"layoutAwareBbox":[{"x":167,"y":325,"w":405,"h":29,"startIndex":0,"endIndex":277}]},{"type":"text","value":"Hindmarsh JL, Rose RM. 1984. A model of neuronal bursting using three coupled first order differential equations. *Proceedings of the Royal Society of London. Series B, Biological Sciences* 221:87–102. DOI: https://doi.org/10.1098/rspb.1984.0024, PMID: 6144106","md":"Hindmarsh JL, Rose RM. 1984. A model of neuronal bursting using three coupled first order differential equations. *Proceedings of the Royal Society of London. Series B, Biological Sciences* 221:87–102. DOI: https://doi.org/10.1098/rspb.1984.0024, PMID: 6144106","bBox":{"x":175.53,"y":376.61,"w":177,"h":8},"layoutAwareBbox":[{"x":167,"y":356,"w":406,"h":29,"startIndex":103,"endIndex":112}]},{"type":"text","value":"Hines ML, Carnevale NT. 1997. The NEURON simulation environment. *Neural Computation* 9:1179–1209. DOI: https://doi.org/10.1162/neco.1997.9.6.1179","md":"Hines ML, Carnevale NT. 1997. The NEURON simulation environment. *Neural Computation* 9:1179–1209. DOI: https://doi.org/10.1162/neco.1997.9.6.1179","bBox":{"x":175.53,"y":396.9,"w":158.33,"h":8},"layoutAwareBbox":[{"x":167,"y":386,"w":401,"h":19,"startIndex":104,"endIndex":146}]},{"type":"text","value":"Hodgkin AL, Huxley AF. 1952. A quantitative description of membrane current and its application to conduction and excitation in nerve. *The Journal of Physiology* 117:500–544. DOI: https://doi.org/10.1113/jphysiol.1952.sp004764, PMID: 12991237","md":"Hodgkin AL, Huxley AF. 1952. A quantitative description of membrane current and its application to conduction and excitation in nerve. *The Journal of Physiology* 117:500–544. DOI: https://doi.org/10.1113/jphysiol.1952.sp004764, PMID: 12991237","bBox":{"x":168.53,"y":407.04,"w":405.01,"h":28.29},"layoutAwareBbox":[{"x":167,"y":407,"w":404,"h":28,"startIndex":163,"endIndex":166}]},{"type":"text","value":"Hucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin AP, Bornstein BJ, Bray D, Cornish-Bowden A, Cuellar AA, Dronov S, Gilles ED, Ginkel M, Gor V, Goryanin II, Hedley WJ, Hodgman TC, Hofmeyr JH, Hunter PJ, et al. 2003. The systems biology markup language (SBML): a medium for representation and exchange of biochemical network models. *Bioinformatics* 19:524–531. DOI: https://doi.org/10.1093/bioinformatics/btg015, PMID: 12611808","md":"Hucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin AP, Bornstein BJ, Bray D, Cornish-Bowden A, Cuellar AA, Dronov S, Gilles ED, Ginkel M, Gor V, Goryanin II, Hedley WJ, Hodgman TC, Hofmeyr JH, Hunter PJ, et al. 2003. The systems biology markup language (SBML): a medium for representation and exchange of biochemical network models. *Bioinformatics* 19:524–531. DOI: https://doi.org/10.1093/bioinformatics/btg015, PMID: 12611808","bBox":{"x":168.53,"y":437.47,"w":408.7,"h":48.56},"layoutAwareBbox":[{"x":166,"y":437,"w":407,"h":49,"startIndex":349,"endIndex":363}]},{"type":"text","value":"Hucka M, Nickerson DP, Bader GD, Bergmann FT, Cooper J, Demir E, Garny A, Golebiewski M, Myers CJ, Schreiber F, Waltemath D, Le Novère N. 2015. Promoting coordinated development of community-based information standards for modeling in biology: the COMBINE initiative. *Frontiers in Bioengineering and Biotechnology* 3:19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811","md":"Hucka M, Nickerson DP, Bader GD, Bergmann FT, Cooper J, Demir E, Garny A, Golebiewski M, Myers CJ, Schreiber F, Waltemath D, Le Novère N. 2015. Promoting coordinated development of community-based information standards for modeling in biology: the COMBINE initiative. *Frontiers in Bioengineering and Biotechnology* 3:19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811","bBox":{"x":168.53,"y":488.17,"w":386.29,"h":18.14},"layoutAwareBbox":[{"x":167,"y":488,"w":387,"h":39,"startIndex":191,"endIndex":196}]},{"type":"text","value":"Hunter JD. 2007. Matplotlib: A 2D graphics environment. *Computing in Science & Engineering* 9:90–95. DOI: https://doi.org/10.1109/MCSE.2007.55","md":"Hunter JD. 2007. Matplotlib: A 2D graphics environment. *Computing in Science & Engineering* 9:90–95. DOI: https://doi.org/10.1109/MCSE.2007.55","bBox":{"x":175.53,"y":538.87,"w":140.66,"h":8},"layoutAwareBbox":[{"x":167,"y":529,"w":396,"h":18,"startIndex":107,"endIndex":143}]},{"type":"text","value":"INCF. 2023. Role of community standards. https://www.incf.org/role-community-standards [Accessed November 9, 2023].","md":"INCF. 2023. Role of community standards. https://www.incf.org/role-community-standards [Accessed November 9, 2023].","bBox":{"x":168.53,"y":549.01,"w":405.7,"h":18.14},"layoutAwareBbox":[{"x":167,"y":549,"w":405,"h":18,"startIndex":0,"endIndex":4}]},{"type":"text","value":"Izhikevich EM. 2004. Which model to use for cortical spiking neurons? *IEEE Transactions on Neural Networks* 15:1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883","md":"Izhikevich EM. 2004. Which model to use for cortical spiking neurons? *IEEE Transactions on Neural Networks* 15:1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883","bBox":{"x":175.53,"y":579.44,"w":292.76,"h":8},"layoutAwareBbox":[{"x":167,"y":569,"w":395,"h":18,"startIndex":109,"endIndex":111}]},{"type":"text","value":"Kriener B, Hu H, Vervaeke K. 2022. Parvalbumin interneuron dendrites enhance gamma oscillations. *Cell Reports* 39:110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055","md":"Kriener B, Hu H, Vervaeke K. 2022. Parvalbumin interneuron dendrites enhance gamma oscillations. *Cell Reports* 39:110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055","bBox":{"x":175.53,"y":599.72,"w":289.2,"h":8},"layoutAwareBbox":[{"x":167,"y":589,"w":406,"h":19,"startIndex":112,"endIndex":114}]},{"type":"text","value":"Lapicque L. 1907. Recherches quantitatives sur L'excitation électrique des nerfs traitée comme une polarisation. *Journal de Physiologie et de Pathologie Generale* 9:620–635.","md":"Lapicque L. 1907. Recherches quantitatives sur L'excitation électrique des nerfs traitée comme une polarisation. *Journal de Physiologie et de Pathologie Generale* 9:620–635.","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":610,"w":403,"h":19,"startIndex":166,"endIndex":173}]},{"type":"text","value":"Larson SD, Martone ME. 2013. NeuroLex.org: an online framework for neuroscience knowledge. *Frontiers in Neuroinformatics* 7:18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581","md":"Larson SD, Martone ME. 2013. NeuroLex.org: an online framework for neuroscience knowledge. *Frontiers in Neuroinformatics* 7:18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":630,"w":391,"h":18,"startIndex":29,"endIndex":37}]},{"type":"text","value":"Lloyd CM, Halstead MDB, Nielsen PF. 2004. CellML: its future, present and past. *Progress in Biophysics and Molecular Biology* 85:433–450. DOI: https://doi.org/10.1016/j.pbiomolbio.2004.01.004","md":"Lloyd CM, Halstead MDB, Nielsen PF. 2004. CellML: its future, present and past. *Progress in Biophysics and Molecular Biology* 85:433–450. DOI: https://doi.org/10.1016/j.pbiomolbio.2004.01.004","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":650,"w":389,"h":19,"startIndex":127,"endIndex":129}]},{"type":"text","value":"Maex R, Schutter ED. 1998. Synchronization of golgi and granule cell firing in a detailed network model of the cerebellar granule cell layer. *Journal of Neurophysiology* 80:2521–2537. DOI: https://doi.org/10.1152/jn.1998.80.5.2521","md":"Maex R, Schutter ED. 1998. Synchronization of golgi and granule cell firing in a detailed network model of the cerebellar granule cell layer. *Journal of Neurophysiology* 80:2521–2537. DOI: https://doi.org/10.1152/jn.1998.80.5.2521","bBox":{"x":175.53,"y":691,"w":35.58,"h":8},"layoutAwareBbox":[{"x":167,"y":671,"w":402,"h":28,"startIndex":171,"endIndex":173}]},{"type":"text","value":"Markram H, Muller E, Ramaswamy S, Reimann MW, Abdellah M, Sanchez CA, Ailamaki A, Alonso-Nanclares L, Antille N, Arsever S, Kahou GAA, Berger TK, Bilgili A, Buncic N, Chalimourda A, Chindemi G, Courcol JD,","md":"Markram H, Muller E, Ramaswamy S, Reimann MW, Abdellah M, Sanchez CA, Ailamaki A, Alonso-Nanclares L, Antille N, Arsever S, Kahou GAA, Berger TK, Bilgili A, Buncic N, Chalimourda A, Chindemi G, Courcol JD,","bBox":{"x":168.53,"y":701.14,"w":398.48,"h":18.14},"layoutAwareBbox":[{"x":167,"y":701,"w":397,"h":19,"startIndex":0,"endIndex":204}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    42 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    42 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":543,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://doi.org/10.5281/zenodo.6417333","unsafeUrl":"https://doi.org/10.5281/zenodo.6417333","text":". 2021. LEMS/LEMS. 0.7.6. Zenodo. https://doi.org/10.5281/zenodo.6417333"},{"url":"https://doi.org/10.5281/zenodo.5788686","unsafeUrl":"https://doi.org/10.5281/zenodo.5788686","text":"DOI: https://doi."},{"url":"https://doi.org/10.5281/zenodo.5788686","unsafeUrl":"https://doi.org/10.5281/zenodo.5788686","text":"org/10.5281/zenodo.5788686"},{"url":"https://doi.org/10.1016/j.neuron.2023.03.037","unsafeUrl":"https://doi.org/10.1016/j.neuron.2023.03.037","text":"https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/37100054","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/37100054","text":"https://doi.org/10.1016/j.neuron.2023.03.037, PMID: 37100054"},{"url":"https://doi.org/10.5281/zenodo.13350473","unsafeUrl":"https://doi.org/10.5281/zenodo.13350473","text":". 0.11.1. Zenodo. https://doi.org/10.5281/zenodo.13350473"},{"url":"https://doi.org/10.5281/zenodo.13342731","unsafeUrl":"https://doi.org/10.5281/zenodo.13342731","text":". 0.13.3. Zenodo. https://doi.org/10.5281/zenodo.13342731"},{"url":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","unsafeUrl":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","text":"Heritage. https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;"},{"url":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","unsafeUrl":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","text":"origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b801"},{"url":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","unsafeUrl":"https://archive.softwareheritage.org/swh:1:dir:154dee293f0193f24f7a66dc41d07442168ef9b8;origin=https://github.com/NeuroML/NeuroML2;visit=swh:1:snp:afc51d39c98b0e7463ca75776835b8014dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6","text":"4dc7b4c2;anchor=swh:1:rev:50aacc6f0b97cf4a70f6887d4beb6b3b67c32eb6"},{"url":"https://doi.org/10.1098/rstb.2001.0910","unsafeUrl":"https://doi.org/10.1098/rstb.2001.0910","text":":1209–1228. DOI: https://doi.org/10.1098/rstb.2001.0910, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/11545699","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/11545699","text":"11545699"},{"url":"https://doi.org/10.1038/sdata.2016.44","unsafeUrl":"https://doi.org/10.1038/sdata.2016.44","text":":160044. DOI: https://doi.org/10.1038/sdata.2016.44, "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/27326542","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/27326542","text":"PMID: 27326542"},{"url":"https://doi.org/10.1016/j.neuron.2021.03.027","unsafeUrl":"https://doi.org/10.1016/j.neuron.2021.03.027","text":":1739–1753.. DOI: https://doi.org/10.1016/j.neuron.2021.03.027, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/33848473","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/33848473","text":"33848473"},{"url":"https://doi.org/10.1038/s41586-020-2649-2","unsafeUrl":"https://doi.org/10.1038/s41586-020-2649-2","text":":357–362. DOI: https://doi.org/10."},{"url":"https://doi.org/10.1038/s41586-020-2649-2","unsafeUrl":"https://doi.org/10.1038/s41586-020-2649-2","text":"1038/s41586-020-2649-2, PMID: 32939066"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/32939066","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/32939066","text":"1038/s41586-020-2649-2, PMID: 32939066"},{"url":"https://doi.org/10.1371/journal.pcbi.1002107","unsafeUrl":"https://doi.org/10.1371/journal.pcbi.1002107","text":"https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/21829333","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/21829333","text":"https://doi.org/10.1371/journal.pcbi.1002107, PMID: 21829333"},{"url":"https://doi.org/10.1098/rspb.1984.0024","unsafeUrl":"https://doi.org/10.1098/rspb.1984.0024","text":":87–102. DOI: https://"},{"url":"https://doi.org/10.1098/rspb.1984.0024","unsafeUrl":"https://doi.org/10.1098/rspb.1984.0024","text":"doi.org/10.1098/rspb.1984.0024, PMID: 6144106"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/6144106","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/6144106","text":"doi.org/10.1098/rspb.1984.0024, PMID: 6144106"},{"url":"https://doi.org/10.1162/neco.1997.9.6.1179","unsafeUrl":"https://doi.org/10.1162/neco.1997.9.6.1179","text":"https://doi.org/10.1162/neco.1997.9.6.1179"},{"url":"https://doi.org/10.1113/jphysiol.1952.sp004764","unsafeUrl":"https://doi.org/10.1113/jphysiol.1952.sp004764","text":":500–544. DOI: https://doi.org/10.1113/jphysiol.1952."},{"url":"https://doi.org/10.1113/jphysiol.1952.sp004764","unsafeUrl":"https://doi.org/10.1113/jphysiol.1952.sp004764","text":"sp004764, PMID: 12991237"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/12991237","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/12991237","text":"sp004764, PMID: 12991237"},{"url":"https://doi.org/10.1093/bioinformatics/btg015","unsafeUrl":"https://doi.org/10.1093/bioinformatics/btg015","text":":524–531. DOI: https://doi.org/10.1093/"},{"url":"https://doi.org/10.1093/bioinformatics/btg015","unsafeUrl":"https://doi.org/10.1093/bioinformatics/btg015","text":"bioinformatics/btg015, PMID: 12611808"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/12611808","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/12611808","text":"bioinformatics/btg015, PMID: 12611808"},{"url":"https://doi.org/10.3389/fbioe.2015.00019","unsafeUrl":"https://doi.org/10.3389/fbioe.2015.00019","text":":19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811 Computing in Science & Engineering"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25759811","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25759811","text":":19. DOI: https://doi.org/10.3389/fbioe.2015.00019, PMID: 25759811"},{"url":"https://doi.org/10.1109/MCSE.2007.55","unsafeUrl":"https://doi.org/10.1109/MCSE.2007.55","text":"https://doi.org/10.1109/MCSE.2007.55"},{"url":"https://www.incf.org/role-community-standards","unsafeUrl":"https://www.incf.org/role-community-standards","text":". 2023. Role of community standards. https://www.incf.org/role-community-standards [Accessed November "},{"url":"https://doi.org/10.1109/TNN.2004.832719","unsafeUrl":"https://doi.org/10.1109/TNN.2004.832719","text":":1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/15484883","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/15484883","text":":1063–1070. DOI: https://doi.org/10.1109/TNN.2004.832719, PMID: 15484883"},{"url":"https://doi.org/10.1016/j.celrep.2022.110948","unsafeUrl":"https://doi.org/10.1016/j.celrep.2022.110948","text":":110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/35705055","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/35705055","text":":110948. DOI: https://doi.org/10.1016/j.celrep.2022.110948, PMID: 35705055"},{"url":"https://doi.org/10.3389/fninf.2013.00018","unsafeUrl":"https://doi.org/10.3389/fninf.2013.00018","text":":18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24009581","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24009581","text":":18. DOI: https://doi.org/10.3389/fninf.2013.00018, PMID: 24009581 Progress in Biophysics and "},{"url":"https://doi.org/10.1016/j.pbiomolbio.2004.01.004","unsafeUrl":"https://doi.org/10.1016/j.pbiomolbio.2004.01.004","text":":433–450. DOI: https://doi.org/10.1016/j.pbiomolbio.2004.01.004"},{"url":"https://doi.org/10.1152/jn.1998.80.5.2521","unsafeUrl":"https://doi.org/10.1152/jn.1998.80.5.2521","text":":2521–2537. DOI: https://doi.org/10.1152/jn.1998."},{"url":"https://doi.org/10.1152/jn.1998.80.5.2521","unsafeUrl":"https://doi.org/10.1152/jn.1998.80.5.2521","text":"80.5.2521"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                               Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    42 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.995,"layout":[{"image":"page_42_reference_1_v2.jpg","confidence":0.98,"label":"reference","bbox":{"x":0.273,"y":0.067,"w":0.665,"h":0.845},"isLikelyNoise":false},{"image":"page_42_reference_content_1_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.273,"y":0.553,"w":0.666,"h":0.062},"isLikelyNoise":false},{"image":"page_42_reference_content_2_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.207,"w":0.664,"h":0.049},"isLikelyNoise":false},{"image":"page_42_reference_content_3_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.258,"w":0.654,"h":0.061},"isLikelyNoise":false},{"image":"page_42_reference_content_4_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.361,"w":0.663,"h":0.049},"isLikelyNoise":false},{"image":"page_42_reference_content_5_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.617,"w":0.633,"h":0.05},"isLikelyNoise":false},{"image":"page_42_reference_content_6_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.848,"w":0.658,"h":0.035},"isLikelyNoise":false},{"image":"page_42_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_42_reference_content_7_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.092,"w":0.651,"h":0.037},"isLikelyNoise":false},{"image":"page_42_reference_content_8_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.155,"w":0.63,"h":0.049},"isLikelyNoise":false},{"image":"page_42_reference_content_9_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.514,"w":0.661,"h":0.037},"isLikelyNoise":false},{"image":"page_42_reference_content_10_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.322,"w":0.664,"h":0.036},"isLikelyNoise":false},{"image":"page_42_reference_content_11_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.412,"w":0.663,"h":0.037},"isLikelyNoise":false},{"image":"page_42_reference_content_12_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.45,"w":0.664,"h":0.037},"isLikelyNoise":false},{"image":"page_42_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_42_reference_content_13_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.273,"y":0.885,"w":0.649,"h":0.025},"isLikelyNoise":false},{"image":"page_42_reference_content_14_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.273,"y":0.821,"w":0.637,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_15_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.273,"y":0.796,"w":0.64,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_16_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.273,"y":0.745,"w":0.665,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_17_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.272,"y":0.066,"w":0.615,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_18_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.693,"w":0.663,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_19_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.488,"w":0.657,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_20_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.77,"w":0.659,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_21_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.274,"y":0.719,"w":0.645,"h":0.024},"isLikelyNoise":false},{"image":"page_42_reference_content_22_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.668,"w":0.648,"h":0.024},"isLikelyNoise":false},{"image":"page_42_number_1_v2.jpg","confidence":0.85,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_42_reference_content_23_v2.jpg","confidence":0.82,"label":"reference_content","bbox":{"x":0.274,"y":0.13,"w":0.537,"h":0.013},"isLikelyNoise":false},{"image":"page_42_reference_content_24_v2.jpg","confidence":0.8,"label":"reference_content","bbox":{"x":0.274,"y":0.142,"w":0.58,"h":0.012},"isLikelyNoise":false},{"image":"page_42_header_2_v2.jpg","confidence":0.71,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_42_header_3_v2.jpg","confidence":0.61,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false}]},{"page":43,"text":"Tools  and  resources                                                                                               Neuroscience\n\n                          Delalondre F, Delattre V, Druckmann S, et al. 2015. Reconstruction and simulation of neocortical microcircuitry.\n                          Cell 163:456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489\n                         Martone M, Das S. 2019. Call for community review of NeuroML — a model description language for\n                          computational neuroscience. F1000 Research 8:75. DOI: https://doi.org/10.7490/F1000RESEARCH.1116398.1\n                         McDougal RA, Morse TM, Carnevale T, Marenco L, Wang R, Migliore M, Miller PL, Shepherd GM, Hines ML.\n                          2017. Twenty years of ModelDB and beyond: building essential modeling tools for the future of neuroscience.\n                          Journal of Computational Neuroscience 42:1–10. DOI: https://doi.org/10.1007/s10827-016-0623-7, PMID:\n                          27629590\n                         Mejias JF, Murray JD, Kennedy H, Wang XJ. 2016. Feedforward and feedback frequency-dependent interactions\n                          in a large-scale laminar network of the primate cortex. Science Advances 2:e1601335. DOI: https://doi.org/10.\n                          1126/sciadv.1601335, PMID: 28138530\n                         Migliore M, Morse TM, Davison AP, Marenco L, Shepherd GM, Hines ML. 2003. ModelDB: making models\n                          publicly accessible to support computational neuroscience. Neuroinformatics 1:135–139. DOI: https://doi.org/\n                          10.1385/NI:1:1:135, PMID: 15055399\n                         Migliore M, Ferrante M, Ascoli GA. 2005. Signal propagation in oblique dendrites of CA1 pyramidal cells.\n                          Journal of Neurophysiology 94:4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591\n                         Migliore M, Cavarretta F, Hines ML, Shepherd GM. 2014. Distributed organization of a brain microcircuit\n                          analyzed by three-dimensional modeling: the olfactory bulb. Frontiers in Computational Neuroscience 8:50.\n                          DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855\n                         Morris C, Lecar H. 1981. Voltage oscillations in the barnacle giant muscle ﬁber. Biophysical Journal 35:193–213.\n                          DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316\n                         Muller E, Bednar JA, Diesmann M, Gewaltig MO, Hines M, Davison AP. 2015. Python in neuroscience. Frontiers\n                          in Neuroinformatics 9:11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788\n                         Neal ML, König M, Nickerson D, Mısırlı G, Kalbasi R, Dräger A, Atalag K, Chelliah V, Cooling MT, Cook DL,\n                          Crook S, de Alba M, Friedman SH, Garny A, Gennari JH, Gleeson P, Golebiewski M, Hucka M, Juty N, Myers C,\n                          et al. 2019. Harmonizing semantic annotations for computational models in biology. Brieﬁngs in Bioinformatics\n                          20:540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164\n                         Omar C, Aldrich J, Gerkin RC. 2014 Collaborative infrastructure for test-driven scientiﬁc model validation. ICSE\n                          ’14 Association for Computing Machinery. . DOI: https://doi.org/10.1145/2591062.2591129\n                         Panagiotou S, Sidiropoulos H, Soudris D, Negrello M, Strydis C. 2022. EDEN: a high-performance, general-\n                          purpose, NeuroML-based neural simulator. Frontiers in Neuroinformatics 16:724336. DOI: https://doi.org/10.\n                          3389/fninf.2022.724336\n                         Pinsky PF, Rinzel J. 1994. Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons.\n                          Journal of Computational Neuroscience 1:39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224\n                         Poirazi P, Papoutsi A. 2020. Illuminating dendritic function with computational models. Nature Reviews\n                          Neuroscience 21:303–321. DOI: https://doi.org/10.1038/s41583-020-0301-7\n                         Pospischil M, Toledo-Rodriguez M, Monier C, Piwkowska Z, Bal T, Frégnac Y, Markram H, Destexhe A. 2008.\n                          Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons. Biological\n                          Cybernetics 99:427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929\n                         Potjans TC, Diesmann M. 2014. The cell-type speciﬁc cortical microcircuit: relating structure and activity in a\n                          full-scale spiking network model. Cerebral Cortex 24:785–806. DOI: https://doi.org/10.1093/cercor/bhs358\n                         Prinz AA, Bucher D, Marder E. 2004. Similar network activity from disparate circuit parameters. Nature\n                          Neuroscience 7:1345–1352. DOI: https://doi.org/10.1038/nn1352\n                         Ranjan R, Khazen G, Gambazzi L, Ramaswamy S, Hill SL, Schürmann F, Markram H. 2011. Channelpedia: an\n                          integrative and interactive database for ion channels. Frontiers in Neuroinformatics 5:36. DOI: https://doi.org/\n                          10.3389/fninf.2011.00036, PMID: 22232598\n                         Ray S, Bhalla US. 2008. PyMOOSE: interoperable scripting in python for MOOSE. Frontiers in Neuroinformatics\n                          2:6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924\n                         Ray S, Aldworth ZN, Stopfer MA. 2020. Feedback inhibition and its control in an insect olfactory circuit. eLife\n                          9:e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034\n                         Rossant C, Goodman DFM, Fontaine B, Platkiewicz J, Magnusson AK, Brette R. 2011. Fitting neuron models to\n                          spike trains. Frontiers in Neuroscience 5:9. DOI: https://doi.org/10.3389/fnins.2011.00009\n                         Rothganger F, Warrender CE, Trumbo D, Aimone JB. 2014. N2A: a computational tool for modeling from\n                          neurons to algorithms. Frontiers in Neural Circuits 8:1. DOI: https://doi.org/10.3389/fncir.2014.00001, PMID:\n                          24478635\n                         Sadeh S, Silver RA, Mrsic-Flogel TD, Muir DR. 2017. Assessing the role of inhibition in stabilizing neocortical\n                          networks requires large-scale perturbation of the inhibitory population. The Journal of Neuroscience\n                          37:12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575\n                         Shaikh B, Smith LP, Vasilescu D, Marupilla G, Wilson M, Agmon E, Agnew H, Andrews SS, Anwar A, Beber ME,\n                          Bergmann FT, Brooks D, Brusch L, Calzone L, Choi K, Cooper J, Detloff J, Drawert B, Dumontier M,\n                          Ermentrout GB, et al. 2022. BioSimulators: a central registry of simulation engines and services for\n                          recommending speciﬁc tools. Nucleic Acids Research 50:W108–W114. DOI: https://doi.org/10.1093/nar/\n                          gkac331, PMID: 35524558\n                         Sinha A. 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786\n                         Sinha A. 2024. NeuroML/pyneuroml. v1.2.5. Zenodo. https://doi.org/10.5281/zenodo.10783062\n                         Sinha A, Garrett A. 2024. inspyred -- A framework for creating bio-inspired computational intelligence algorithms\n                          in python. 1d0089c. GitHub. https://github.com/aarongarrett/inspyred\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    43 of 44","md":"\n\neLife Tools and resources                                                                                               Neuroscience\n\n**Delalondre F, Delattre V, Druckmann S, et al.** 2015. Reconstruction and simulation of neocortical microcircuitry. Cell **163**:456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489\n\n**Martone M, Das S.** 2019. Call for community review of NeuroML — a model description language for computational neuroscience. F1000 Research **8**:75. DOI: https://doi.org/10.7490/F1000RESEARCH.1116398.1\n\n**McDougal RA, Morse TM, Carnevale T, Marenco L, Wang R, Migliore M, Miller PL, Shepherd GM, Hines ML.** 2017. Twenty years of ModelDB and beyond: building essential modeling tools for the future of neuroscience. Journal of Computational Neuroscience **42**:1–10. DOI: https://doi.org/10.1007/s10827-016-0623-7, PMID: 27629590\n\n**Mejias JF, Murray JD, Kennedy H, Wang XJ.** 2016. Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cortex. Science Advances **2**:e1601335. DOI: https://doi.org/10.1126/sciadv.1601335, PMID: 28138530\n\n**Migliore M, Morse TM, Davison AP, Marenco L, Shepherd GM, Hines ML.** 2003. ModelDB: making models publicly accessible to support computational neuroscience. Neuroinformatics **1**:135–139. DOI: https://doi.org/10.1385/NI:1:1:135, PMID: 15055399\n\n**Migliore M, Ferrante M, Ascoli GA.** 2005. Signal propagation in oblique dendrites of CA1 pyramidal cells. Journal of Neurophysiology **94**:4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591\n\n**Migliore M, Cavarretta F, Hines ML, Shepherd GM.** 2014. Distributed organization of a brain microcircuit analyzed by three-dimensional modeling: the olfactory bulb. Frontiers in Computational Neuroscience **8**:50. DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855\n\n**Morris C, Lecar H.** 1981. Voltage oscillations in the barnacle giant muscle fiber. Biophysical Journal **35**:193–213. DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316\n\n**Muller E, Bednar JA, Diesmann M, Gewaltig MO, Hines M, Davison AP.** 2015. Python in neuroscience. Frontiers in Neuroinformatics **9**:11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788\n\n**Neal ML, König M, Nickerson D, Mısırlı G, Kalbasi R, Dräger A, Atalag K, Chelliah V, Cooling MT, Cook DL, Crook S, de Alba M, Friedman SH, Garny A, Gennari JH, Gleeson P, Golebiewski M, Hucka M, Juty N, Myers C, et al.** 2019. Harmonizing semantic annotations for computational models in biology. Briefings in Bioinformatics **20**:540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164\n\n**Omar C, Aldrich J, Gerkin RC.** 2014 Collaborative infrastructure for test-driven scientific model validation. ICSE '14 Association for Computing Machinery. . DOI: https://doi.org/10.1145/2591062.2591129\n\n**Panagiotou S, Sidiropoulos H, Soudris D, Negrello M, Strydis C.** 2022. EDEN: a high-performance, general-purpose, NeuroML-based neural simulator. Frontiers in Neuroinformatics **16**:724336. DOI: https://doi.org/10.3389/fninf.2022.724336\n\n**Pinsky PF, Rinzel J.** 1994. Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons. Journal of Computational Neuroscience **1**:39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224\n\n**Poirazi P, Papoutsi A.** 2020. Illuminating dendritic function with computational models. Nature Reviews Neuroscience **21**:303–321. DOI: https://doi.org/10.1038/s41583-020-0301-7\n\n**Pospischil M, Toledo-Rodriguez M, Monier C, Piwkowska Z, Bal T, Frégnac Y, Markram H, Destexhe A.** 2008. Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons. Biological Cybernetics **99**:427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929\n\n**Potjans TC, Diesmann M.** 2014. The cell-type specific cortical microcircuit: relating structure and activity in a full-scale spiking network model. Cerebral Cortex **24**:785–806. DOI: https://doi.org/10.1093/cercor/bhs358\n\n**Prinz AA, Bucher D, Marder E.** 2004. Similar network activity from disparate circuit parameters. Nature Neuroscience **7**:1345–1352. DOI: https://doi.org/10.1038/nn1352\n\n**Ranjan R, Khazen G, Gambazzi L, Ramaswamy S, Hill SL, Schürmann F, Markram H.** 2011. Channelpedia: an integrative and interactive database for ion channels. Frontiers in Neuroinformatics **5**:36. DOI: https://doi.org/10.3389/fninf.2011.00036, PMID: 22232598\n\n**Ray S, Bhalla US.** 2008. PyMOOSE: interoperable scripting in python for MOOSE. Frontiers in Neuroinformatics **2**:6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924\n\n**Ray S, Aldworth ZN, Stopfer MA.** 2020. Feedback inhibition and its control in an insect olfactory circuit. eLife **9**:e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034\n\n**Rossant C, Goodman DFM, Fontaine B, Platkiewicz J, Magnusson AK, Brette R.** 2011. Fitting neuron models to spike trains. Frontiers in Neuroscience **5**:9. DOI: https://doi.org/10.3389/fnins.2011.00009\n\n**Rothganger F, Warrender CE, Trumbo D, Aimone JB.** 2014. N2A: a computational tool for modeling from neurons to algorithms. Frontiers in Neural Circuits **8**:1. DOI: https://doi.org/10.3389/fncir.2014.00001, PMID: 24478635\n\n**Sadeh S, Silver RA, Mrsic-Flogel TD, Muir DR.** 2017. Assessing the role of inhibition in stabilizing neocortical networks requires large-scale perturbation of the inhibitory population. The Journal of Neuroscience **37**:12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575\n\n**Shaikh B, Smith LP, Vasilescu D, Marupilla G, Wilson M, Agmon E, Agnew H, Andrews SS, Anwar A, Beber ME, Bergmann FT, Brooks D, Brusch L, Calzone L, Choi K, Cooper J, Detloff J, Drawert B, Dumontier M, Ermentrout GB, et al.** 2022. BioSimulators: a central registry of simulation engines and services for recommending specific tools. Nucleic Acids Research **50**:W108–W114. DOI: https://doi.org/10.1093/nar/gkac331, PMID: 35524558\n\n**Sinha A.** 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786\n\n**Sinha A.** 2024. NeuroML/pyneuroml. v1.2.5. Zenodo. https://doi.org/10.5281/zenodo.10783062\n\n**Sinha A, Garrett A.** 2024. inspyred -- A framework for creating bio-inspired computational intelligence algorithms in python. 1d0089c. GitHub. https://github.com/aarongarrett/inspyred\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    43 of 44\n","images":[{"name":"page_43.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_43_reference_1_v2.jpg","height":530542.233,"width":247631.681,"x":101974.473,"y":41726.297,"original_width":1636,"original_height":2707,"rotation":0,"type":"layout_v2_reference"},{"name":"page_43_reference_content_1_v2.jpg","height":38117.265,"width":242837.297,"x":102326.732,"y":501134.342,"original_width":1604,"original_height":195,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_2_v2.jpg","height":29979.334,"width":245781.917,"x":102502.58,"y":73198.478,"original_width":1623,"original_height":153,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_3_v2.jpg","height":30671.445,"width":247953.816,"x":102469.625,"y":223748.165,"original_width":1638,"original_height":157,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_4_v2.jpg","height":22282.052,"width":247117.88,"x":102469.312,"y":128741.89,"original_width":1632,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_5_v2.jpg","height":22520.045,"width":248805.844,"x":102439.943,"y":104914.345,"original_width":1643,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_footer_1_v2.jpg","height":6896.846,"width":191828.063,"x":21749.056,"y":591573.384,"original_width":1267,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_43_reference_content_6_v2.jpg","height":22469.733,"width":246249.149,"x":102576.218,"y":382074.107,"original_width":1626,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_7_v2.jpg","height":21838.666,"width":243278.626,"x":102464.772,"y":453527.2,"original_width":1607,"original_height":112,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_8_v2.jpg","height":22751.237,"width":238381.02,"x":102517.281,"y":326626.42,"original_width":1574,"original_height":117,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_9_v2.jpg","height":22160.296,"width":243897.555,"x":102558.734,"y":271543.232,"original_width":1611,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_10_v2.jpg","height":22603.556,"width":238712.35,"x":102323.062,"y":477053.148,"original_width":1577,"original_height":116,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_11_v2.jpg","height":22481.945,"width":241473.257,"x":102649.182,"y":168608.014,"original_width":1595,"original_height":115,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_header_1_v2.jpg","height":5606.311,"width":30249.827,"x":320889.458,"y":27817.77,"original_width":200,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_43_reference_content_12_v2.jpg","height":14761.031,"width":244567.847,"x":102486.227,"y":437638.917,"original_width":1615,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_13_v2.jpg","height":14791.371,"width":243098.269,"x":105737.094,"y":41590.194,"original_width":1606,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_14_v2.jpg","height":15003.566,"width":245689.345,"x":102509.292,"y":191911.499,"original_width":1623,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_15_v2.jpg","height":14981.867,"width":245743.619,"x":102493.7,"y":207735.762,"original_width":1623,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_16_v2.jpg","height":15401.605,"width":240881.296,"x":102427.233,"y":350418.132,"original_width":1591,"original_height":79,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_17_v2.jpg","height":15524.097,"width":249436.807,"x":102330.736,"y":556080.552,"original_width":1647,"original_height":80,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_18_v2.jpg","height":14849.181,"width":241033.73,"x":102392.826,"y":421663.718,"original_width":1592,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_19_v2.jpg","height":15070.703,"width":245778.65,"x":102384.851,"y":405612.522,"original_width":1623,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_20_v2.jpg","height":14860.864,"width":227241,"x":102344.24,"y":366281.403,"original_width":1501,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_21_v2.jpg","height":15054.512,"width":243541.654,"x":102601.671,"y":294992.713,"original_width":1609,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_22_v2.jpg","height":15141.074,"width":244769.873,"x":102317.34,"y":255403.141,"original_width":1617,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_23_v2.jpg","height":14954.248,"width":228569.315,"x":102402.54,"y":310804.235,"original_width":1510,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_24_v2.jpg","height":14924.249,"width":246240.334,"x":102499.734,"y":57505.858,"original_width":1626,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_reference_content_25_v2.jpg","height":15369.496,"width":237008.096,"x":102419.23,"y":152324.005,"original_width":1565,"original_height":79,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_number_1_v2.jpg","height":5823.322,"width":18274.778,"x":332958.166,"y":591874.255,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_43_reference_content_26_v2.jpg","height":15088.561,"width":225316.219,"x":102292.934,"y":540326.013,"original_width":1488,"original_height":77,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_43_header_2_v2.jpg","height":5804.283,"width":42793.472,"x":47866.258,"y":27814.455,"original_width":283,"original_height":30,"rotation":0,"type":"layout_v2_header"},{"name":"page_43_header_3_v2.jpg","height":10700.685,"width":24408.188,"x":21883.824,"y":22414.251,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                               Neuroscience","md":"eLife Tools and resources                                                                                               Neuroscience","bBox":{"x":77.92,"y":34.63,"w":497.08,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":69,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":7,"startIndex":120,"endIndex":132}]},{"type":"text","value":"**Delalondre F, Delattre V, Druckmann S, et al.** 2015. Reconstruction and simulation of neocortical microcircuitry. Cell **163**:456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489","md":"**Delalondre F, Delattre V, Druckmann S, et al.** 2015. Reconstruction and simulation of neocortical microcircuitry. Cell **163**:456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":172,"y":52,"w":397,"h":18,"startIndex":117,"endIndex":121}]},{"type":"text","value":"**Martone M, Das S.** 2019. Call for community review of NeuroML — a model description language for computational neuroscience. F1000 Research **8**:75. DOI: https://doi.org/10.7490/F1000RESEARCH.1116398.1","md":"**Martone M, Das S.** 2019. Call for community review of NeuroML — a model description language for computational neuroscience. F1000 Research **8**:75. DOI: https://doi.org/10.7490/F1000RESEARCH.1116398.1","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":72,"w":402,"h":18,"startIndex":182,"endIndex":195}]},{"type":"text","value":"**McDougal RA, Morse TM, Carnevale T, Marenco L, Wang R, Migliore M, Miller PL, Shepherd GM, Hines ML.** 2017. Twenty years of ModelDB and beyond: building essential modeling tools for the future of neuroscience. Journal of Computational Neuroscience **42**:1–10. DOI: https://doi.org/10.1007/s10827-016-0623-7, PMID: 27629590","md":"**McDougal RA, Morse TM, Carnevale T, Marenco L, Wang R, Migliore M, Miller PL, Shepherd GM, Hines ML.** 2017. Twenty years of ModelDB and beyond: building essential modeling tools for the future of neuroscience. Journal of Computational Neuroscience **42**:1–10. DOI: https://doi.org/10.1007/s10827-016-0623-7, PMID: 27629590","bBox":{"x":168.53,"y":92.05,"w":402.79,"h":38},"layoutAwareBbox":[{"x":167,"y":92,"w":401,"h":37,"startIndex":253,"endIndex":255}]},{"type":"text","value":"**Mejias JF, Murray JD, Kennedy H, Wang XJ.** 2016. Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cortex. Science Advances **2**:e1601335. DOI: https://doi.org/10.1126/sciadv.1601335, PMID: 28138530","md":"**Mejias JF, Murray JD, Kennedy H, Wang XJ.** 2016. Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cortex. Science Advances **2**:e1601335. DOI: https://doi.org/10.1126/sciadv.1601335, PMID: 28138530","bBox":{"x":175.53,"y":152.05,"w":140.09,"h":8},"layoutAwareBbox":[{"x":167,"y":132,"w":406,"h":28,"startIndex":0,"endIndex":257}]},{"type":"text","value":"**Migliore M, Morse TM, Davison AP, Marenco L, Shepherd GM, Hines ML.** 2003. ModelDB: making models publicly accessible to support computational neuroscience. Neuroinformatics **1**:135–139. DOI: https://doi.org/10.1385/NI:1:1:135, PMID: 15055399","md":"**Migliore M, Morse TM, Davison AP, Marenco L, Shepherd GM, Hines ML.** 2003. ModelDB: making models publicly accessible to support computational neuroscience. Neuroinformatics **1**:135–139. DOI: https://doi.org/10.1385/NI:1:1:135, PMID: 15055399","bBox":{"x":175.53,"y":34.63,"w":399.46,"h":155.41},"layoutAwareBbox":[{"x":167,"y":162,"w":403,"h":28,"startIndex":160,"endIndex":176}]},{"type":"text","value":"**Migliore M, Ferrante M, Ascoli GA.** 2005. Signal propagation in oblique dendrites of CA1 pyramidal cells. Journal of Neurophysiology **94**:4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591","md":"**Migliore M, Ferrante M, Ascoli GA.** 2005. Signal propagation in oblique dendrites of CA1 pyramidal cells. Journal of Neurophysiology **94**:4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":192,"w":387,"h":19,"startIndex":138,"endIndex":140}]},{"type":"text","value":"**Migliore M, Cavarretta F, Hines ML, Shepherd GM.** 2014. Distributed organization of a brain microcircuit analyzed by three-dimensional modeling: the olfactory bulb. Frontiers in Computational Neuroscience **8**:50. DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855","md":"**Migliore M, Cavarretta F, Hines ML, Shepherd GM.** 2014. Distributed organization of a brain microcircuit analyzed by three-dimensional modeling: the olfactory bulb. Frontiers in Computational Neuroscience **8**:50. DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855","bBox":{"x":175.53,"y":34.63,"w":399.46,"h":205.41},"layoutAwareBbox":[{"x":167,"y":212,"w":394,"h":28,"startIndex":214,"endIndex":216}]},{"type":"text","value":"**Morris C, Lecar H.** 1981. Voltage oscillations in the barnacle giant muscle fiber. Biophysical Journal **35**:193–213. DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316","md":"**Morris C, Lecar H.** 1981. Voltage oscillations in the barnacle giant muscle fiber. Biophysical Journal **35**:193–213. DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316","bBox":{"x":175.53,"y":252.05,"w":252.01,"h":8},"layoutAwareBbox":[{"x":167,"y":242,"w":401,"h":18,"startIndex":108,"endIndex":110}]},{"type":"text","value":"**Muller E, Bednar JA, Diesmann M, Gewaltig MO, Hines M, Davison AP.** 2015. Python in neuroscience. Frontiers in Neuroinformatics **9**:11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788","md":"**Muller E, Bednar JA, Diesmann M, Gewaltig MO, Hines M, Davison AP.** 2015. Python in neuroscience. Frontiers in Neuroinformatics **9**:11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":262,"w":401,"h":18,"startIndex":101,"endIndex":110}]},{"type":"text","value":"**Neal ML, König M, Nickerson D, Mısırlı G, Kalbasi R, Dräger A, Atalag K, Chelliah V, Cooling MT, Cook DL, Crook S, de Alba M, Friedman SH, Garny A, Gennari JH, Gleeson P, Golebiewski M, Hucka M, Juty N, Myers C, et al.** 2019. Harmonizing semantic annotations for computational models in biology. Briefings in Bioinformatics **20**:540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164","md":"**Neal ML, König M, Nickerson D, Mısırlı G, Kalbasi R, Dräger A, Atalag K, Chelliah V, Cooling MT, Cook DL, Crook S, de Alba M, Friedman SH, Garny A, Gennari JH, Gleeson P, Golebiewski M, Hucka M, Juty N, Myers C, et al.** 2019. Harmonizing semantic annotations for computational models in biology. Briefings in Bioinformatics **20**:540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164","bBox":{"x":168.53,"y":282.05,"w":406.93,"h":18},"layoutAwareBbox":[{"x":167,"y":282,"w":405,"h":38,"startIndex":223,"endIndex":225}]},{"type":"text","value":"**Omar C, Aldrich J, Gerkin RC.** 2014 Collaborative infrastructure for test-driven scientific model validation. ICSE '14 Association for Computing Machinery. . DOI: https://doi.org/10.1145/2591062.2591129","md":"**Omar C, Aldrich J, Gerkin RC.** 2014 Collaborative infrastructure for test-driven scientific model validation. ICSE '14 Association for Computing Machinery. . DOI: https://doi.org/10.1145/2591062.2591129","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":322,"w":399,"h":19,"startIndex":0,"endIndex":204}]},{"type":"text","value":"**Panagiotou S, Sidiropoulos H, Soudris D, Negrello M, Strydis C.** 2022. EDEN: a high-performance, general-purpose, NeuroML-based neural simulator. Frontiers in Neuroinformatics **16**:724336. DOI: https://doi.org/10.3389/fninf.2022.724336","md":"**Panagiotou S, Sidiropoulos H, Soudris D, Negrello M, Strydis C.** 2022. EDEN: a high-performance, general-purpose, NeuroML-based neural simulator. Frontiers in Neuroinformatics **16**:724336. DOI: https://doi.org/10.3389/fninf.2022.724336","bBox":{"x":175.53,"y":362.05,"w":85.54,"h":8},"layoutAwareBbox":[{"x":167,"y":342,"w":398,"h":27,"startIndex":181,"endIndex":183}]},{"type":"text","value":"**Pinsky PF, Rinzel J.** 1994. Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons. Journal of Computational Neuroscience **1**:39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224","md":"**Pinsky PF, Rinzel J.** 1994. Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons. Journal of Computational Neuroscience **1**:39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":372,"w":397,"h":19,"startIndex":0,"endIndex":214}]},{"type":"text","value":"**Poirazi P, Papoutsi A.** 2020. Illuminating dendritic function with computational models. Nature Reviews Neuroscience **21**:303–321. DOI: https://doi.org/10.1038/s41583-020-0301-7","md":"**Poirazi P, Papoutsi A.** 2020. Illuminating dendritic function with computational models. Nature Reviews Neuroscience **21**:303–321. DOI: https://doi.org/10.1038/s41583-020-0301-7","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":392,"w":373,"h":18,"startIndex":107,"endIndex":119}]},{"type":"text","value":"**Pospischil M, Toledo-Rodriguez M, Monier C, Piwkowska Z, Bal T, Frégnac Y, Markram H, Destexhe A.** 2008. Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons. Biological Cybernetics **99**:427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929","md":"**Pospischil M, Toledo-Rodriguez M, Monier C, Piwkowska Z, Bal T, Frégnac Y, Markram H, Destexhe A.** 2008. Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons. Biological Cybernetics **99**:427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929","bBox":{"x":175.53,"y":422.05,"w":365.49,"h":8},"layoutAwareBbox":[{"x":167,"y":412,"w":389,"h":28,"startIndex":16,"endIndex":22}]},{"type":"text","value":"**Potjans TC, Diesmann M.** 2014. The cell-type specific cortical microcircuit: relating structure and activity in a full-scale spiking network model. Cerebral Cortex **24**:785–806. DOI: https://doi.org/10.1093/cercor/bhs358","md":"**Potjans TC, Diesmann M.** 2014. The cell-type specific cortical microcircuit: relating structure and activity in a full-scale spiking network model. Cerebral Cortex **24**:785–806. DOI: https://doi.org/10.1093/cercor/bhs358","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":442,"w":393,"h":19,"startIndex":117,"endIndex":121}]},{"type":"text","value":"**Prinz AA, Bucher D, Marder E.** 2004. Similar network activity from disparate circuit parameters. Nature Neuroscience **7**:1345–1352. DOI: https://doi.org/10.1038/nn1352","md":"**Prinz AA, Bucher D, Marder E.** 2004. Similar network activity from disparate circuit parameters. Nature Neuroscience **7**:1345–1352. DOI: https://doi.org/10.1038/nn1352","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":462,"w":371,"h":18,"startIndex":100,"endIndex":106}]},{"type":"text","value":"**Ranjan R, Khazen G, Gambazzi L, Ramaswamy S, Hill SL, Schürmann F, Markram H.** 2011. Channelpedia: an integrative and interactive database for ion channels. Frontiers in Neuroinformatics **5**:36. DOI: https://doi.org/10.3389/fninf.2011.00036, PMID: 22232598","md":"**Ranjan R, Khazen G, Gambazzi L, Ramaswamy S, Hill SL, Schürmann F, Markram H.** 2011. Channelpedia: an integrative and interactive database for ion channels. Frontiers in Neuroinformatics **5**:36. DOI: https://doi.org/10.3389/fninf.2011.00036, PMID: 22232598","bBox":{"x":175.53,"y":502.05,"w":156.7,"h":8},"layoutAwareBbox":[{"x":167,"y":482,"w":402,"h":28,"startIndex":0,"endIndex":260}]},{"type":"text","value":"**Ray S, Bhalla US.** 2008. PyMOOSE: interoperable scripting in python for MOOSE. Frontiers in Neuroinformatics **2**:6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924","md":"**Ray S, Bhalla US.** 2008. PyMOOSE: interoperable scripting in python for MOOSE. Frontiers in Neuroinformatics **2**:6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":512,"w":401,"h":19,"startIndex":0,"endIndex":182}]},{"type":"text","value":"**Ray S, Aldworth ZN, Stopfer MA.** 2020. Feedback inhibition and its control in an insect olfactory circuit. eLife **9**:e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034","md":"**Ray S, Aldworth ZN, Stopfer MA.** 2020. Feedback inhibition and its control in an insect olfactory circuit. eLife **9**:e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":532,"w":393,"h":18,"startIndex":110,"endIndex":115}]},{"type":"text","value":"**Rossant C, Goodman DFM, Fontaine B, Platkiewicz J, Magnusson AK, Brette R.** 2011. Fitting neuron models to spike trains. Frontiers in Neuroscience **5**:9. DOI: https://doi.org/10.3389/fnins.2011.00009","md":"**Rossant C, Goodman DFM, Fontaine B, Platkiewicz J, Magnusson AK, Brette R.** 2011. Fitting neuron models to spike trains. Frontiers in Neuroscience **5**:9. DOI: https://doi.org/10.3389/fnins.2011.00009","bBox":{"x":525.63,"y":34.63,"w":49.36,"h":8},"layoutAwareBbox":[{"x":167,"y":552,"w":399,"h":18,"startIndex":0,"endIndex":203}]},{"type":"text","value":"**Rothganger F, Warrender CE, Trumbo D, Aimone JB.** 2014. N2A: a computational tool for modeling from neurons to algorithms. Frontiers in Neural Circuits **8**:1. DOI: https://doi.org/10.3389/fncir.2014.00001, PMID: 24478635","md":"**Rothganger F, Warrender CE, Trumbo D, Aimone JB.** 2014. N2A: a computational tool for modeling from neurons to algorithms. Frontiers in Neural Circuits **8**:1. DOI: https://doi.org/10.3389/fncir.2014.00001, PMID: 24478635","bBox":{"x":175.53,"y":592.05,"w":35.58,"h":8},"layoutAwareBbox":[{"x":167,"y":572,"w":397,"h":27,"startIndex":217,"endIndex":225}]},{"type":"text","value":"**Sadeh S, Silver RA, Mrsic-Flogel TD, Muir DR.** 2017. Assessing the role of inhibition in stabilizing neocortical networks requires large-scale perturbation of the inhibitory population. The Journal of Neuroscience **37**:12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575","md":"**Sadeh S, Silver RA, Mrsic-Flogel TD, Muir DR.** 2017. Assessing the role of inhibition in stabilizing neocortical networks requires large-scale perturbation of the inhibitory population. The Journal of Neuroscience **37**:12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575","bBox":{"x":175.53,"y":612.05,"w":359.78,"h":8},"layoutAwareBbox":[{"x":167,"y":602,"w":390,"h":28,"startIndex":219,"endIndex":221}]},{"type":"text","value":"**Shaikh B, Smith LP, Vasilescu D, Marupilla G, Wilson M, Agmon E, Agnew H, Andrews SS, Anwar A, Beber ME, Bergmann FT, Brooks D, Brusch L, Calzone L, Choi K, Cooper J, Detloff J, Drawert B, Dumontier M, Ermentrout GB, et al.** 2022. BioSimulators: a central registry of simulation engines and services for recommending specific tools. Nucleic Acids Research **50**:W108–W114. DOI: https://doi.org/10.1093/nar/gkac331, PMID: 35524558","md":"**Shaikh B, Smith LP, Vasilescu D, Marupilla G, Wilson M, Agmon E, Agnew H, Andrews SS, Anwar A, Beber ME, Bergmann FT, Brooks D, Brusch L, Calzone L, Choi K, Cooper J, Detloff J, Drawert B, Dumontier M, Ermentrout GB, et al.** 2022. BioSimulators: a central registry of simulation engines and services for recommending specific tools. Nucleic Acids Research **50**:W108–W114. DOI: https://doi.org/10.1093/nar/gkac331, PMID: 35524558","bBox":{"x":168.53,"y":632.05,"w":398.41,"h":48},"layoutAwareBbox":[{"x":167,"y":632,"w":396,"h":48,"startIndex":361,"endIndex":363}]},{"type":"text","value":"**Sinha A.** 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786","md":"**Sinha A.** 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":682,"w":368,"h":19,"startIndex":0,"endIndex":99}]},{"type":"text","value":"**Sinha A.** 2024. NeuroML/pyneuroml. v1.2.5. Zenodo. https://doi.org/10.5281/zenodo.10783062","md":"**Sinha A.** 2024. NeuroML/pyneuroml. v1.2.5. Zenodo. https://doi.org/10.5281/zenodo.10783062","bBox":{"x":0,"y":0,"w":612,"h":792},"layoutAwareBbox":[{"x":167,"y":682,"w":368,"h":19,"startIndex":0,"endIndex":92}]},{"type":"text","value":"**Sinha A, Garrett A.** 2024. inspyred -- A framework for creating bio-inspired computational intelligence algorithms in python. 1d0089c. GitHub. https://github.com/aarongarrett/inspyred","md":"**Sinha A, Garrett A.** 2024. inspyred -- A framework for creating bio-inspired computational intelligence algorithms in python. 1d0089c. GitHub. https://github.com/aarongarrett/inspyred","bBox":{"x":175.53,"y":712.05,"w":253.01,"h":8},"layoutAwareBbox":[{"x":167,"y":702,"w":407,"h":19,"startIndex":0,"endIndex":185}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    43 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    43 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://doi.org/10.1016/j.cell.2015.09.029","unsafeUrl":"https://doi.org/10.1016/j.cell.2015.09.029","text":":456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/26451489","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/26451489","text":":456–492. DOI: https://doi.org/10.1016/j.cell.2015.09.029, PMID: 26451489"},{"url":"https://doi.org/10.7490/F1000RESEARCH.1116398.1","unsafeUrl":"https://doi.org/10.7490/F1000RESEARCH.1116398.1","text":":75. DOI: https://doi.org/10.7490/F1000RESEARCH.1116398.1"},{"url":"https://doi.org/10.1007/s10827-016-0623-7","unsafeUrl":"https://doi.org/10.1007/s10827-016-0623-7","text":":1–10. DOI: https://doi.org/10.1007/s10827-016-0623-7, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/27629590","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/27629590","text":"27629590 , Murray JD, Kennedy H, Wang XJ. 2016. Feedforward and feedback frequency-"},{"url":"https://doi.org/10.1126/sciadv.1601335","unsafeUrl":"https://doi.org/10.1126/sciadv.1601335","text":":e1601335. DOI: https://doi.org/10."},{"url":"https://doi.org/10.1126/sciadv.1601335","unsafeUrl":"https://doi.org/10.1126/sciadv.1601335","text":"1126/sciadv.1601335, PMID: 28138530 , Morse TM, Davison AP, Marenco L, Shepherd GM, Hines ML. 2003. ModelDB: making models "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/28138530","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/28138530","text":"1126/sciadv.1601335, PMID: 28138530"},{"url":"https://doi.org/10.1385/NI:1:1:135","unsafeUrl":"https://doi.org/10.1385/NI:1:1:135","text":":135–139. DOI: https://doi.org/"},{"url":"https://doi.org/10.1385/NI:1:1:135","unsafeUrl":"https://doi.org/10.1385/NI:1:1:135","text":"10.1385/NI:1:1:135, PMID: 15055399 , Ferrante M, Ascoli GA. 2005. Signal propagation in oblique dendrites of CA1 pyramidal cells. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/15055399","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/15055399","text":"10.1385/NI:1:1:135, PMID: 15055399"},{"url":"https://doi.org/10.1152/jn.00521.2005","unsafeUrl":"https://doi.org/10.1152/jn.00521.2005","text":":4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/16293591","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/16293591","text":":4145–4155. DOI: https://doi.org/10.1152/jn.00521.2005, PMID: 16293591"},{"url":"https://doi.org/10.3389/fncom.2014.00050","unsafeUrl":"https://doi.org/10.3389/fncom.2014.00050","text":"DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855 , Lecar H. 1981. Voltage oscillations in the barnacle giant muscle ﬁber. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24808855","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24808855","text":"DOI: https://doi.org/10.3389/fncom.2014.00050, PMID: 24808855"},{"url":"https://doi.org/10.1016/S0006-3495(81)84782-0","unsafeUrl":"https://doi.org/10.1016/S0006-3495(81)84782-0","text":"DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316 , Bednar JA, Diesmann M, Gewaltig MO, Hines M, Davison AP. 2015. Python in neuroscience. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/7260316","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/7260316","text":"DOI: https://doi.org/10.1016/S0006-3495(81)84782-0, PMID: 7260316"},{"url":"https://doi.org/10.3389/fninf.2015.00011","unsafeUrl":"https://doi.org/10.3389/fninf.2015.00011","text":":11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/25926788","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/25926788","text":":11. DOI: https://doi.org/10.3389/fninf.2015.00011, PMID: 25926788"},{"url":"https://doi.org/10.1093/bib/bby087","unsafeUrl":"https://doi.org/10.1093/bib/bby087","text":":540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/30462164","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/30462164","text":":540–550. DOI: https://doi.org/10.1093/bib/bby087, PMID: 30462164   driven scientiﬁc model validation. ICSE "},{"url":"https://doi.org/10.1145/2591062.2591129","unsafeUrl":"https://doi.org/10.1145/2591062.2591129","text":"’14 Association for Computing Machinery. . DOI: https://doi.org/10.1145/2591062.2591129   performance, general-"},{"url":"https://doi.org/10.3389/fninf.2022.724336","unsafeUrl":"https://doi.org/10.3389/fninf.2022.724336","text":":724336. DOI: https://doi.org/10."},{"url":"https://doi.org/10.3389/fninf.2022.724336","unsafeUrl":"https://doi.org/10.3389/fninf.2022.724336","text":"3389/fninf.2022.724336 , Rinzel J. 1994. Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons. "},{"url":"https://doi.org/10.1007/BF00962717","unsafeUrl":"https://doi.org/10.1007/BF00962717","text":":39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224 Nature Reviews "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/8792224","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/8792224","text":":39–60. DOI: https://doi.org/10.1007/BF00962717, PMID: 8792224"},{"url":"https://doi.org/10.1038/s41583-020-0301-7","unsafeUrl":"https://doi.org/10.1038/s41583-020-0301-7","text":":303–321. DOI: https://doi.org/10.1038/s41583-020-0301-7"},{"url":"https://doi.org/10.1007/s00422-008-0263-8","unsafeUrl":"https://doi.org/10.1007/s00422-008-0263-8","text":":427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929   type speciﬁc cortical microcircuit: relating structure and activity in a "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/19011929","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/19011929","text":":427–441. DOI: https://doi.org/10.1007/s00422-008-0263-8, PMID: 19011929"},{"url":"https://doi.org/10.1093/cercor/bhs358","unsafeUrl":"https://doi.org/10.1093/cercor/bhs358","text":":785–806. DOI: https://doi.org/10.1093/cercor/bhs358 Nature "},{"url":"https://doi.org/10.1038/nn1352","unsafeUrl":"https://doi.org/10.1038/nn1352","text":":1345–1352. DOI: https://doi.org/10.1038/nn1352"},{"url":"https://doi.org/10.3389/fninf.2011.00036","unsafeUrl":"https://doi.org/10.3389/fninf.2011.00036","text":":36. DOI: https://doi.org/"},{"url":"https://doi.org/10.3389/fninf.2011.00036","unsafeUrl":"https://doi.org/10.3389/fninf.2011.00036","text":"10.3389/fninf.2011.00036, PMID: 22232598 , Bhalla US. 2008. PyMOOSE: interoperable scripting in python for MOOSE. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/22232598","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/22232598","text":"10.3389/fninf.2011.00036, PMID: 22232598"},{"url":"https://doi.org/10.3389/neuro.11.006.2008","unsafeUrl":"https://doi.org/10.3389/neuro.11.006.2008","text":":6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/19129924","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/19129924","text":":6. DOI: https://doi.org/10.3389/neuro.11.006.2008, PMID: 19129924"},{"url":"https://doi.org/10.7554/eLife.53281","unsafeUrl":"https://doi.org/10.7554/eLife.53281","text":":e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/32163034","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/32163034","text":":e53281. DOI: https://doi.org/10.7554/eLife.53281, PMID: 32163034"},{"url":"https://doi.org/10.3389/fnins.2011.00009","unsafeUrl":"https://doi.org/10.3389/fnins.2011.00009","text":":9. DOI: https://doi.org/10.3389/fnins.2011.00009"},{"url":"https://doi.org/10.3389/fncir.2014.00001","unsafeUrl":"https://doi.org/10.3389/fncir.2014.00001","text":":1. DOI: https://doi.org/10.3389/fncir.2014.00001, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24478635","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24478635","text":"24478635 , Silver RA, Mrsic-"},{"url":"https://doi.org/10.1523/JNEUROSCI.0963-17.2017","unsafeUrl":"https://doi.org/10.1523/JNEUROSCI.0963-17.2017","text":":12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/29074575","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/29074575","text":":12050–12067. DOI: https://doi.org/10.1523/JNEUROSCI.0963-17.2017, PMID: 29074575"},{"url":"https://doi.org/10.1093/nar/gkac331","unsafeUrl":"https://doi.org/10.1093/nar/gkac331","text":":W108–W114. DOI: https://doi.org/10.1093/nar/"},{"url":"https://doi.org/10.1093/nar/gkac331","unsafeUrl":"https://doi.org/10.1093/nar/gkac331","text":"gkac331, PMID: 35524558 . 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/35524558","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/35524558","text":"gkac331, PMID: 35524558"},{"url":"https://doi.org/10.5281/zenodo.8364786","unsafeUrl":"https://doi.org/10.5281/zenodo.8364786","text":". 2023. NeuralEnsemble/libneuroml. v0.5.5. Zenodo. https://doi.org/10.5281/zenodo.8364786"},{"url":"https://doi.org/10.5281/zenodo.10783062","unsafeUrl":"https://doi.org/10.5281/zenodo.10783062","text":". 2024. NeuroML/pyneuroml. v1.2.5. Zenodo. https://doi.org/10.5281/zenodo.10783062   inspired computational intelligence algorithms "},{"url":"https://github.com/aarongarrett/inspyred","unsafeUrl":"https://github.com/aarongarrett/inspyred","text":"in python. 1d0089c. GitHub. https://github.com/aarongarrett/inspyred"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                               Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    43 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.993,"layout":[{"image":"page_43_reference_1_v2.jpg","confidence":0.98,"label":"reference","bbox":{"x":0.272,"y":0.067,"w":0.661,"h":0.846},"isLikelyNoise":false},{"image":"page_43_reference_content_1_v2.jpg","confidence":0.94,"label":"reference_content","bbox":{"x":0.273,"y":0.799,"w":0.648,"h":0.061},"isLikelyNoise":false},{"image":"page_43_reference_content_2_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.274,"y":0.117,"w":0.656,"h":0.048},"isLikelyNoise":false},{"image":"page_43_reference_content_3_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.357,"w":0.662,"h":0.049},"isLikelyNoise":false},{"image":"page_43_reference_content_4_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.205,"w":0.66,"h":0.036},"isLikelyNoise":false},{"image":"page_43_reference_content_5_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.274,"y":0.167,"w":0.664,"h":0.036},"isLikelyNoise":false},{"image":"page_43_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_43_reference_content_6_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.609,"w":0.657,"h":0.036},"isLikelyNoise":false},{"image":"page_43_reference_content_7_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.723,"w":0.65,"h":0.035},"isLikelyNoise":false},{"image":"page_43_reference_content_8_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.521,"w":0.636,"h":0.036},"isLikelyNoise":false},{"image":"page_43_reference_content_9_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.274,"y":0.433,"w":0.651,"h":0.035},"isLikelyNoise":false},{"image":"page_43_reference_content_10_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.761,"w":0.637,"h":0.036},"isLikelyNoise":false},{"image":"page_43_reference_content_11_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.274,"y":0.269,"w":0.645,"h":0.036},"isLikelyNoise":false},{"image":"page_43_header_1_v2.jpg","confidence":0.89,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_43_reference_content_12_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.274,"y":0.698,"w":0.653,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_13_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.282,"y":0.066,"w":0.649,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_14_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.274,"y":0.306,"w":0.656,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_15_v2.jpg","confidence":0.89,"label":"reference_content","bbox":{"x":0.274,"y":0.331,"w":0.656,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_16_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.559,"w":0.643,"h":0.025},"isLikelyNoise":false},{"image":"page_43_reference_content_17_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.887,"w":0.666,"h":0.025},"isLikelyNoise":false},{"image":"page_43_reference_content_18_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.672,"w":0.644,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_19_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.647,"w":0.656,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_20_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.584,"w":0.607,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_21_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.274,"y":0.47,"w":0.65,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_22_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.407,"w":0.654,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_23_v2.jpg","confidence":0.87,"label":"reference_content","bbox":{"x":0.273,"y":0.495,"w":0.61,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_24_v2.jpg","confidence":0.87,"label":"reference_content","bbox":{"x":0.274,"y":0.092,"w":0.657,"h":0.024},"isLikelyNoise":false},{"image":"page_43_reference_content_25_v2.jpg","confidence":0.87,"label":"reference_content","bbox":{"x":0.273,"y":0.243,"w":0.633,"h":0.025},"isLikelyNoise":false},{"image":"page_43_number_1_v2.jpg","confidence":0.86,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_43_reference_content_26_v2.jpg","confidence":0.81,"label":"reference_content","bbox":{"x":0.273,"y":0.861,"w":0.602,"h":0.024},"isLikelyNoise":false},{"image":"page_43_header_2_v2.jpg","confidence":0.67,"label":"header","bbox":{"x":0.128,"y":0.044,"w":0.114,"h":0.009},"isLikelyNoise":false},{"image":"page_43_header_3_v2.jpg","confidence":0.57,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":true}]},{"page":44,"text":"Tools  and  resources                                                                                                    Neuroscience\n\n                         Sivagnanam S. 2013. Introducing the Neuroscience Gateway. IWSG.\n                         Smith SL, Smith IT, Branco T, Häusser M. 2013. Dendritic spikes enhance stimulus selectivity in cortical neurons in\n                          vivo. Nature 503:115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850\n                         Solinas S, Forti L, Cesana E, Mapelli J, De Schutter E, D’Angelo E. 2007. Computational reconstruction of\n                          pacemaking and intrinsic electroresponsiveness in cerebellar Golgi cells. Frontiers in Cellular Neuroscience 1:2.\n                          DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520\n                         Stimberg M, Brette R, Goodman DF. 2019. Brian 2, an intuitive and efﬁcient neural simulator. eLife 8:e47314.\n                          DOI: https://doi.org/10.7554/eLife.47314\n                         Teeters JL, Godfrey K, Young R, Dang C, Friedsam C, Wark B, Asari H, Peron S, Li N, Peyrache A, Denisov G,\n                          Siegle JH, Olsen SR, Martin C, Chun M, Tripathy S, Blanche TJ, Harris K, Buzsáki G, Koch C, et al. 2015.\n                          Neurodata without borders: creating a common data format for neurophysiology. Neuron 88:629–634. DOI:\n                          https://doi.org/10.1016/j.neuron.2015.10.025\n                         Traub RD, Contreras D, Cunningham MO, Murray H, LeBeau FEN, Roopun A, Bibbig A, Wilent WB, Higley MJ,\n                          Whittington MA. 2005. Single-column thalamocortical network model exhibiting gamma oscillations, sleep\n                          spindles, and epileptogenic bursts. Journal of Neurophysiology 93:2194–2232. DOI: https://doi.org/10.1152/\n                          jn.00983.2004, PMID: 15525801\n                         Van Geit W, Gevaert M, Chindemi G, Rössert C, Courcol JD, Muller EB, Schürmann F, Segev I, Markram H. 2016.\n                          BluePyOpt: leveraging open source software and cloud infrastructure to optimise model parameters in\n                          neuroscience. Frontiers in Neuroinformatics 10:17. DOI: https://doi.org/10.3389/fninf.2016.00017, PMID:\n                          27375471\n                         Vella M, Cannon RC, Crook S, Davison AP, Ganapathy G, Robinson HPC, Silver RA, Gleeson P. 2014. libNeuroML\n                          and PyLEMS: using Python to combine procedural and declarative modeling approaches in computational\n                          neuroscience. Frontiers in Neuroinformatics 8:38. DOI: https://doi.org/10.3389/fninf.2014.00038\n                         Vella M, Gleeson P. 2023. Neurotune. 66ba110. GitHub. https://github.com/NeuralEnsemble/neurotune\n                         Vervaeke K, Lőrincz A, Gleeson P, Farinella M, Nusser Z, Silver RA. 2010. Rapid desynchronization of an\n                          electrically coupled interneuron network with sparse excitatory synaptic input. Neuron 67:435–451. DOI:\n                          https://doi.org/10.1016/j.neuron.2010.06.028\n                         Waltemath D, Adams R, Bergmann FT, Hucka M, Kolpakov F, Miller AK, Moraru II, Nickerson D, Sahle S,\n                          Snoep JL, Le Novère N. 2011. Reproducible computational biology experiments with SED-ML--the simulation\n                          experiment description markup language. BMC Systems Biology 5:198. DOI: https://doi.org/10.1186/\n                          1752-0509-5-198, PMID: 22172142\n                         Wang XJ, Buzsáki G. 1996. Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network\n                          model. The Journal of Neuroscience 16:6402–6413. DOI: https://doi.org/10.1523/JNEUROSCI.16-20-06402.\n                          1996, PMID: 8815919\n                         Wilkinson MD, Dumontier M, Aalbersberg IJJ, Appleton G, Axton M, Baak A, Blomberg N, Boiten JW,\n                          da Silva Santos LB, Bourne PE, Bouwman J, Brookes AJ, Clark T, Crosas M, Dillo I, Dumon O, Edmunds S,\n                          Evelo CT, Finkers R, Gonzalez-Beltran A, et al. 2016. The FAIR guiding principles for scientiﬁc data\n                          management and stewardship. Scientiﬁc Data 3:160018. DOI: https://doi.org/10.1038/sdata.2016.18, PMID:\n                          26978244\n                         Wilson HR, Cowan JD. 1972. Excitatory and inhibitory interactions in localized populations of model neurons.\n                          Biophysical Journal 12:1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108\n                         Yao HK, Guet-McCreight A, Mazza F, Moradi Chameh H, Prevot TD, Grifﬁths JD, Tripathy SJ, Valiante TA,\n                          Sibille E, Hay E. 2022. Reduced inhibition in depression impairs stimulus processing in human cortical\n                          microcircuits. Cell Reports 38:110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088\n\n\n\n\n\n\n\n\n\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    44 of 44","md":"\n\neLife Tools and resources                                                                                                    Neuroscience\n\nSivagnanam S. 2013. Introducing the Neuroscience Gateway. IWSG.\n\nSmith SL, Smith IT, Branco T, Häusser M. 2013. Dendritic spikes enhance stimulus selectivity in cortical neurons in vivo. Nature 503:115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850\n\nSolinas S, Forti L, Cesana E, Mapelli J, De Schutter E, D'Angelo E. 2007. Computational reconstruction of pacemaking and intrinsic electroresponsiveness in cerebellar Golgi cells. Frontiers in Cellular Neuroscience 1:2. DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520\n\nStimberg M, Brette R, Goodman DF. 2019. Brian 2, an intuitive and efficient neural simulator. eLife 8:e47314. DOI: https://doi.org/10.7554/eLife.47314\n\nTeeters JL, Godfrey K, Young R, Dang C, Friedsam C, Wark B, Asari H, Peron S, Li N, Peyrache A, Denisov G, Siegle JH, Olsen SR, Martin C, Chun M, Tripathy S, Blanche TJ, Harris K, Buzsáki G, Koch C, et al. 2015. Neurodata without borders: creating a common data format for neurophysiology. Neuron 88:629–634. DOI: https://doi.org/10.1016/j.neuron.2015.10.025\n\nTraub RD, Contreras D, Cunningham MO, Murray H, LeBeau FEN, Roopun A, Bibbig A, Wilent WB, Higley MJ, Whittington MA. 2005. Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts. Journal of Neurophysiology 93:2194–2232. DOI: https://doi.org/10.1152/jn.00983.2004, PMID: 15525801\n\nVan Geit W, Gevaert M, Chindemi G, Rössert C, Courcol JD, Muller EB, Schürmann F, Segev I, Markram H. 2016. BluePyOpt: leveraging open source software and cloud infrastructure to optimise model parameters in neuroscience. Frontiers in Neuroinformatics 10:17. DOI: https://doi.org/10.3389/fninf.2016.00017, PMID: 27375471\n\nVella M, Cannon RC, Crook S, Davison AP, Ganapathy G, Robinson HPC, Silver RA, Gleeson P. 2014. libNeuroML and PyLEMS: using Python to combine procedural and declarative modeling approaches in computational neuroscience. Frontiers in Neuroinformatics 8:38. DOI: https://doi.org/10.3389/fninf.2014.00038\n\nVella M, Gleeson P. 2023. Neurotune. 66ba110. GitHub. https://github.com/NeuralEnsemble/neurotune\n\nVervaeke K, Lőrincz A, Gleeson P, Farinella M, Nusser Z, Silver RA. 2010. Rapid desynchronization of an electrically coupled interneuron network with sparse excitatory synaptic input. Neuron 67:435–451. DOI: https://doi.org/10.1016/j.neuron.2010.06.028\n\nWaltemath D, Adams R, Bergmann FT, Hucka M, Kolpakov F, Miller AK, Moraru II, Nickerson D, Sahle S, Snoep JL, Le Novère N. 2011. Reproducible computational biology experiments with SED-ML--the simulation experiment description markup language. BMC Systems Biology 5:198. DOI: https://doi.org/10.1186/1752-0509-5-198, PMID: 22172142\n\nWang XJ, Buzsáki G. 1996. Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model. The Journal of Neuroscience 16:6402–6413. DOI: https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996, PMID: 8815919\n\nWilkinson MD, Dumontier M, Aalbersberg IJJ, Appleton G, Axton M, Baak A, Blomberg N, Boiten JW, da Silva Santos LB, Bourne PE, Bouwman J, Brookes AJ, Clark T, Crosas M, Dillo I, Dumon O, Edmunds S, Evelo CT, Finkers R, Gonzalez-Beltran A, et al. 2016. The FAIR guiding principles for scientific data management and stewardship. Scientific Data 3:160018. DOI: https://doi.org/10.1038/sdata.2016.18, PMID: 26978244\n\nWilson HR, Cowan JD. 1972. Excitatory and inhibitory interactions in localized populations of model neurons. Biophysical Journal 12:1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108\n\nYao HK, Guet-McCreight A, Mazza F, Moradi Chameh H, Prevot TD, Griffiths JD, Tripathy SJ, Valiante TA, Sibille E, Hay E. 2022. Reduced inhibition in depression impairs stimulus processing in human cortical microcircuits. Cell Reports 38:110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088\n\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    44 of 44\n","images":[{"name":"page_44.jpg","height":792,"width":612,"x":0,"y":0,"original_width":2473,"original_height":3200,"rotation":0,"type":"full_page_screenshot"},{"name":"page_44_reference_1_v2.jpg","height":347745.192,"width":246713.094,"x":101760.492,"y":42010.724,"original_width":1629,"original_height":1775,"rotation":0,"type":"layout_v2_reference"},{"name":"page_44_reference_content_1_v2.jpg","height":30190.441,"width":245326.274,"x":102188.673,"y":136527.39,"original_width":1620,"original_height":155,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_2_v2.jpg","height":37870.123,"width":242810.097,"x":102052.085,"y":310816.858,"original_width":1604,"original_height":194,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_3_v2.jpg","height":30258.431,"width":245171.625,"x":102291.737,"y":255429.447,"original_width":1619,"original_height":155,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_4_v2.jpg","height":30232.635,"width":248212.247,"x":102305.065,"y":168149.268,"original_width":1639,"original_height":155,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_5_v2.jpg","height":30556.166,"width":242665.27,"x":102176.466,"y":104960.222,"original_width":1603,"original_height":156,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_footer_1_v2.jpg","height":6924.602,"width":191940.858,"x":21711.094,"y":591499.562,"original_width":1268,"original_height":36,"rotation":0,"type":"layout_v2_footer"},{"name":"page_44_reference_content_6_v2.jpg","height":22225.649,"width":243091.862,"x":102163.826,"y":286990.49,"original_width":1606,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_7_v2.jpg","height":23171.426,"width":247927.924,"x":102210.24,"y":199732.658,"original_width":1637,"original_height":119,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_8_v2.jpg","height":22580.543,"width":240960.065,"x":102137.156,"y":366353.794,"original_width":1591,"original_height":116,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_9_v2.jpg","height":22211.939,"width":247912.385,"x":102360.618,"y":65463.244,"original_width":1637,"original_height":114,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_header_1_v2.jpg","height":5543.886,"width":30310.393,"x":320890.11,"y":27903.164,"original_width":201,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_44_reference_content_10_v2.jpg","height":14706.741,"width":248624.103,"x":102195.828,"y":49537.735,"original_width":1642,"original_height":76,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_11_v2.jpg","height":15126.157,"width":241463.624,"x":102165.455,"y":350194.473,"original_width":1595,"original_height":78,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_12_v2.jpg","height":14700.57,"width":240079.564,"x":102257.347,"y":88783.013,"original_width":1586,"original_height":75,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_number_1_v2.jpg","height":5740.563,"width":18303.191,"x":332943.959,"y":591936.805,"original_width":121,"original_height":30,"rotation":0,"type":"layout_v2_number"},{"name":"page_44_reference_content_13_v2.jpg","height":23107.837,"width":235226.036,"x":102254.358,"y":231124.535,"original_width":1554,"original_height":118,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_reference_content_14_v2.jpg","height":7428.665,"width":151768.394,"x":101993.783,"y":41594.536,"original_width":1003,"original_height":38,"rotation":0,"type":"layout_v2_reference_content"},{"name":"page_44_header_2_v2.jpg","height":5645.617,"width":42904.159,"x":47854.091,"y":27955.004,"original_width":284,"original_height":29,"rotation":0,"type":"layout_v2_header"},{"name":"page_44_header_3_v2.jpg","height":10656.592,"width":24402.806,"x":21884.864,"y":22469.091,"original_width":162,"original_height":55,"rotation":0,"type":"layout_v2_header"},{"name":"page_44_reference_content_15_v2.jpg","height":7158.611,"width":230490.435,"x":102055.005,"y":223776.373,"original_width":1522,"original_height":37,"rotation":0,"type":"layout_v2_reference_content"}],"charts":[],"items":[{"type":"text","value":"eLife Tools and resources                                                                                                    Neuroscience","md":"eLife Tools and resources                                                                                                    Neuroscience","bBox":{"x":77.93,"y":34.63,"w":497.06,"h":8.15},"layoutAwareBbox":[{"x":78,"y":35,"w":70,"h":7,"startIndex":6,"endIndex":11},{"x":524,"y":35,"w":49,"h":6,"startIndex":125,"endIndex":137}]},{"type":"text","value":"Sivagnanam S. 2013. Introducing the Neuroscience Gateway. IWSG.","md":"Sivagnanam S. 2013. Introducing the Neuroscience Gateway. IWSG.","bBox":{"x":168.53,"y":52.05,"w":246.07,"h":8},"layoutAwareBbox":[{"x":166,"y":52,"w":247,"h":9,"startIndex":14,"endIndex":18}]},{"type":"text","value":"Smith SL, Smith IT, Branco T, Häusser M. 2013. Dendritic spikes enhance stimulus selectivity in cortical neurons in vivo. Nature 503:115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850","md":"Smith SL, Smith IT, Branco T, Häusser M. 2013. Dendritic spikes enhance stimulus selectivity in cortical neurons in vivo. Nature 503:115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850","bBox":{"x":168.53,"y":62.05,"w":407.42,"h":18},"layoutAwareBbox":[{"x":166,"y":62,"w":406,"h":18,"startIndex":116,"endIndex":120}]},{"type":"text","value":"Solinas S, Forti L, Cesana E, Mapelli J, De Schutter E, D'Angelo E. 2007. Computational reconstruction of pacemaking and intrinsic electroresponsiveness in cerebellar Golgi cells. Frontiers in Cellular Neuroscience 1:2. DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520","md":"Solinas S, Forti L, Cesana E, Mapelli J, De Schutter E, D'Angelo E. 2007. Computational reconstruction of pacemaking and intrinsic electroresponsiveness in cerebellar Golgi cells. Frontiers in Cellular Neuroscience 1:2. DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520","bBox":{"x":175.53,"y":92.05,"w":399.72,"h":18},"layoutAwareBbox":[{"x":167,"y":82,"w":405,"h":28,"startIndex":0,"endIndex":281}]},{"type":"text","value":"Stimberg M, Brette R, Goodman DF. 2019. Brian 2, an intuitive and efficient neural simulator. eLife 8:e47314. DOI: https://doi.org/10.7554/eLife.47314","md":"Stimberg M, Brette R, Goodman DF. 2019. Brian 2, an intuitive and efficient neural simulator. eLife 8:e47314. DOI: https://doi.org/10.7554/eLife.47314","bBox":{"x":175.53,"y":122.05,"w":148.38,"h":8},"layoutAwareBbox":[{"x":167,"y":112,"w":392,"h":18,"startIndex":94,"endIndex":99}]},{"type":"text","value":"Teeters JL, Godfrey K, Young R, Dang C, Friedsam C, Wark B, Asari H, Peron S, Li N, Peyrache A, Denisov G, Siegle JH, Olsen SR, Martin C, Chun M, Tripathy S, Blanche TJ, Harris K, Buzsáki G, Koch C, et al. 2015. Neurodata without borders: creating a common data format for neurophysiology. Neuron 88:629–634. DOI: https://doi.org/10.1016/j.neuron.2015.10.025","md":"Teeters JL, Godfrey K, Young R, Dang C, Friedsam C, Wark B, Asari H, Peron S, Li N, Peyrache A, Denisov G, Siegle JH, Olsen SR, Martin C, Chun M, Tripathy S, Blanche TJ, Harris K, Buzsáki G, Koch C, et al. 2015. Neurodata without borders: creating a common data format for neurophysiology. Neuron 88:629–634. DOI: https://doi.org/10.1016/j.neuron.2015.10.025","bBox":{"x":168.53,"y":132.05,"w":396.04,"h":38},"layoutAwareBbox":[{"x":166,"y":132,"w":396,"h":38,"startIndex":290,"endIndex":296}]},{"type":"text","value":"Traub RD, Contreras D, Cunningham MO, Murray H, LeBeau FEN, Roopun A, Bibbig A, Wilent WB, Higley MJ, Whittington MA. 2005. Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts. Journal of Neurophysiology 93:2194–2232. DOI: https://doi.org/10.1152/jn.00983.2004, PMID: 15525801","md":"Traub RD, Contreras D, Cunningham MO, Murray H, LeBeau FEN, Roopun A, Bibbig A, Wilent WB, Higley MJ, Whittington MA. 2005. Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts. Journal of Neurophysiology 93:2194–2232. DOI: https://doi.org/10.1152/jn.00983.2004, PMID: 15525801","bBox":{"x":168.53,"y":172.05,"w":399.11,"h":38},"layoutAwareBbox":[{"x":166,"y":172,"w":400,"h":38,"startIndex":268,"endIndex":270}]},{"type":"text","value":"Van Geit W, Gevaert M, Chindemi G, Rössert C, Courcol JD, Muller EB, Schürmann F, Segev I, Markram H. 2016. BluePyOpt: leveraging open source software and cloud infrastructure to optimise model parameters in neuroscience. Frontiers in Neuroinformatics 10:17. DOI: https://doi.org/10.3389/fninf.2016.00017, PMID: 27375471","md":"Van Geit W, Gevaert M, Chindemi G, Rössert C, Courcol JD, Muller EB, Schürmann F, Segev I, Markram H. 2016. BluePyOpt: leveraging open source software and cloud infrastructure to optimise model parameters in neuroscience. Frontiers in Neuroinformatics 10:17. DOI: https://doi.org/10.3389/fninf.2016.00017, PMID: 27375471","bBox":{"x":168.53,"y":212.05,"w":407.39,"h":38},"layoutAwareBbox":[{"x":167,"y":212,"w":405,"h":38,"startIndex":208,"endIndex":220}]},{"type":"text","value":"Vella M, Cannon RC, Crook S, Davison AP, Ganapathy G, Robinson HPC, Silver RA, Gleeson P. 2014. libNeuroML and PyLEMS: using Python to combine procedural and declarative modeling approaches in computational neuroscience. Frontiers in Neuroinformatics 8:38. DOI: https://doi.org/10.3389/fninf.2014.00038","md":"Vella M, Cannon RC, Crook S, Davison AP, Ganapathy G, Robinson HPC, Silver RA, Gleeson P. 2014. libNeuroML and PyLEMS: using Python to combine procedural and declarative modeling approaches in computational neuroscience. Frontiers in Neuroinformatics 8:38. DOI: https://doi.org/10.3389/fninf.2014.00038","bBox":{"x":168.53,"y":252.05,"w":406.12,"h":28},"layoutAwareBbox":[{"x":167,"y":252,"w":405,"h":29,"startIndex":207,"endIndex":219}]},{"type":"text","value":"Vella M, Gleeson P. 2023. Neurotune. 66ba110. GitHub. https://github.com/NeuralEnsemble/neurotune","md":"Vella M, Gleeson P. 2023. Neurotune. 66ba110. GitHub. https://github.com/NeuralEnsemble/neurotune","bBox":{"x":168.53,"y":282.05,"w":373.28,"h":8},"layoutAwareBbox":[{"x":166,"y":282,"w":376,"h":9,"startIndex":0,"endIndex":96}]},{"type":"text","value":"Vervaeke K, Lőrincz A, Gleeson P, Farinella M, Nusser Z, Silver RA. 2010. Rapid desynchronization of an electrically coupled interneuron network with sparse excitatory synaptic input. Neuron 67:435–451. DOI: https://doi.org/10.1016/j.neuron.2010.06.028","md":"Vervaeke K, Lőrincz A, Gleeson P, Farinella M, Nusser Z, Silver RA. 2010. Rapid desynchronization of an electrically coupled interneuron network with sparse excitatory synaptic input. Neuron 67:435–451. DOI: https://doi.org/10.1016/j.neuron.2010.06.028","bBox":{"x":168.53,"y":292.05,"w":383.94,"h":28},"layoutAwareBbox":[{"x":167,"y":291,"w":384,"h":29,"startIndex":130,"endIndex":136}]},{"type":"text","value":"Waltemath D, Adams R, Bergmann FT, Hucka M, Kolpakov F, Miller AK, Moraru II, Nickerson D, Sahle S, Snoep JL, Le Novère N. 2011. Reproducible computational biology experiments with SED-ML--the simulation experiment description markup language. BMC Systems Biology 5:198. DOI: https://doi.org/10.1186/1752-0509-5-198, PMID: 22172142","md":"Waltemath D, Adams R, Bergmann FT, Hucka M, Kolpakov F, Miller AK, Moraru II, Nickerson D, Sahle S, Snoep JL, Le Novère N. 2011. Reproducible computational biology experiments with SED-ML--the simulation experiment description markup language. BMC Systems Biology 5:198. DOI: https://doi.org/10.1186/1752-0509-5-198, PMID: 22172142","bBox":{"x":168.53,"y":322.05,"w":401.26,"h":38},"layoutAwareBbox":[{"x":167,"y":322,"w":400,"h":38,"startIndex":0,"endIndex":330}]},{"type":"text","value":"Wang XJ, Buzsáki G. 1996. Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model. The Journal of Neuroscience 16:6402–6413. DOI: https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996, PMID: 8815919","md":"Wang XJ, Buzsáki G. 1996. Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model. The Journal of Neuroscience 16:6402–6413. DOI: https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996, PMID: 8815919","bBox":{"x":168.53,"y":362.05,"w":395.54,"h":28},"layoutAwareBbox":[{"x":166,"y":362,"w":397,"h":28,"startIndex":106,"endIndex":111}]},{"type":"text","value":"Wilkinson MD, Dumontier M, Aalbersberg IJJ, Appleton G, Axton M, Baak A, Blomberg N, Boiten JW, da Silva Santos LB, Bourne PE, Bouwman J, Brookes AJ, Clark T, Crosas M, Dillo I, Dumon O, Edmunds S, Evelo CT, Finkers R, Gonzalez-Beltran A, et al. 2016. The FAIR guiding principles for scientific data management and stewardship. Scientific Data 3:160018. DOI: https://doi.org/10.1038/sdata.2016.18, PMID: 26978244","md":"Wilkinson MD, Dumontier M, Aalbersberg IJJ, Appleton G, Axton M, Baak A, Blomberg N, Boiten JW, da Silva Santos LB, Bourne PE, Bouwman J, Brookes AJ, Clark T, Crosas M, Dillo I, Dumon O, Edmunds S, Evelo CT, Finkers R, Gonzalez-Beltran A, et al. 2016. The FAIR guiding principles for scientific data management and stewardship. Scientific Data 3:160018. DOI: https://doi.org/10.1038/sdata.2016.18, PMID: 26978244","bBox":{"x":168.53,"y":392.05,"w":386.51,"h":48},"layoutAwareBbox":[{"x":166,"y":392,"w":396,"h":47,"startIndex":404,"endIndex":412}]},{"type":"text","value":"Wilson HR, Cowan JD. 1972. Excitatory and inhibitory interactions in localized populations of model neurons. Biophysical Journal 12:1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108","md":"Wilson HR, Cowan JD. 1972. Excitatory and inhibitory interactions in localized populations of model neurons. Biophysical Journal 12:1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108","bBox":{"x":168.53,"y":442.05,"w":395.16,"h":18},"layoutAwareBbox":[{"x":166,"y":442,"w":394,"h":19,"startIndex":129,"endIndex":131}]},{"type":"text","value":"Yao HK, Guet-McCreight A, Mazza F, Moradi Chameh H, Prevot TD, Griffiths JD, Tripathy SJ, Valiante TA, Sibille E, Hay E. 2022. Reduced inhibition in depression impairs stimulus processing in human cortical microcircuits. Cell Reports 38:110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088","md":"Yao HK, Guet-McCreight A, Mazza F, Moradi Chameh H, Prevot TD, Griffiths JD, Tripathy SJ, Valiante TA, Sibille E, Hay E. 2022. Reduced inhibition in depression impairs stimulus processing in human cortical microcircuits. Cell Reports 38:110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088","bBox":{"x":175.53,"y":472.05,"w":384.94,"h":18},"layoutAwareBbox":[{"x":166,"y":462,"w":393,"h":28,"startIndex":8,"endIndex":12}]},{"type":"text","value":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    44 of 44","md":"Sinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    44 of 44","bBox":{"x":545.34,"y":746.76,"w":29.66,"h":8},"layoutAwareBbox":[{"x":35,"y":746,"w":313,"h":8,"startIndex":0,"endIndex":96},{"x":544,"y":747,"w":29,"h":7,"startIndex":0,"endIndex":96}]}],"status":"OK","originalOrientationAngle":0,"links":[{"url":"https://doi.org/10.7554/eLife.95135","unsafeUrl":"https://doi.org/10.7554/eLife.95135","text":". eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135"},{"url":"https://doi.org/10.1038/nature12600","unsafeUrl":"https://doi.org/10.1038/nature12600","text":":115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/24162850","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/24162850","text":":115–120. DOI: https://doi.org/10.1038/nature12600, PMID: 24162850"},{"url":"https://doi.org/10.3389/neuro.03.002.2007","unsafeUrl":"https://doi.org/10.3389/neuro.03.002.2007","text":"DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520 , Brette R, Goodman DF. 2019. Brian 2, an intuitive and efﬁcient neural simulator. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/18946520","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/18946520","text":"DOI: https://doi.org/10.3389/neuro.03.002.2007, PMID: 18946520"},{"url":"https://doi.org/10.7554/eLife.47314","unsafeUrl":"https://doi.org/10.7554/eLife.47314","text":"DOI: https://doi.org/10.7554/eLife.47314 , Godfrey K, Young R, Dang C, Friedsam C, Wark B, Asari H, Peron S, Li N, Peyrache A, Denisov G, "},{"url":"https://doi.org/10.1016/j.neuron.2015.10.025","unsafeUrl":"https://doi.org/10.1016/j.neuron.2015.10.025","text":"https://doi.org/10.1016/j.neuron.2015.10.025 , Contreras D, Cunningham MO, Murray H, LeBeau FEN, Roopun A, Bibbig A, Wilent WB, Higley MJ, "},{"url":"https://doi.org/10.1152/jn.00983.2004","unsafeUrl":"https://doi.org/10.1152/jn.00983.2004","text":":2194–2232. DOI: https://doi.org/10.1152/"},{"url":"https://doi.org/10.1152/jn.00983.2004","unsafeUrl":"https://doi.org/10.1152/jn.00983.2004","text":"jn.00983.2004, PMID: 15525801 , Gevaert M, Chindemi G, Rössert C, Courcol JD, Muller EB, Schürmann F, Segev I, Markram H. 2016. "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/15525801","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/15525801","text":"jn.00983.2004, PMID: 15525801"},{"url":"https://doi.org/10.3389/fninf.2016.00017","unsafeUrl":"https://doi.org/10.3389/fninf.2016.00017","text":":17. DOI: https://doi.org/10.3389/fninf.2016.00017, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/27375471","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/27375471","text":"27375471 , Cannon RC, Crook S, Davison AP, Ganapathy G, Robinson HPC, Silver RA, Gleeson P. 2014. libNeuroML "},{"url":"https://doi.org/10.3389/fninf.2014.00038","unsafeUrl":"https://doi.org/10.3389/fninf.2014.00038","text":":38. DOI: https://doi.org/10.3389/fninf.2014.00038"},{"url":"https://github.com/NeuralEnsemble/neurotune","unsafeUrl":"https://github.com/NeuralEnsemble/neurotune","text":", Gleeson P. 2023. Neurotune. 66ba110. GitHub. https://github.com/NeuralEnsemble/neurotune"},{"url":"https://doi.org/10.1016/j.neuron.2010.06.028","unsafeUrl":"https://doi.org/10.1016/j.neuron.2010.06.028","text":"https://doi.org/10.1016/j.neuron.2010.06.028 , Adams R, Bergmann FT, Hucka M, Kolpakov F, Miller AK, Moraru II, Nickerson D, Sahle S, "},{"url":"https://doi.org/10.1186/1752-0509-5-198","unsafeUrl":"https://doi.org/10.1186/1752-0509-5-198","text":":198. DOI: https://doi.org/10.1186/"},{"url":"https://doi.org/10.1186/1752-0509-5-198","unsafeUrl":"https://doi.org/10.1186/1752-0509-5-198","text":"1752-0509-5-198, PMID: 22172142 , Buzsáki G. 1996. Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/22172142","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/22172142","text":"1752-0509-5-198, PMID: 22172142"},{"url":"https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996","unsafeUrl":"https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996","text":":6402–6413. DOI: https://doi.org/10.1523/JNEUROSCI.16-20-06402."},{"url":"https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996","unsafeUrl":"https://doi.org/10.1523/JNEUROSCI.16-20-06402.1996","text":"1996, PMID: 8815919"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/8815919","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/8815919","text":"1996, PMID: 8815919"},{"url":"https://doi.org/10.1038/sdata.2016.18","unsafeUrl":"https://doi.org/10.1038/sdata.2016.18","text":":160018. DOI: https://doi.org/10.1038/sdata.2016.18, PMID: "},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/26978244","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/26978244","text":"26978244 , Cowan JD. 1972. Excitatory and inhibitory interactions in localized populations of model neurons. "},{"url":"https://doi.org/10.1016/S0006-3495(72)86068-5","unsafeUrl":"https://doi.org/10.1016/S0006-3495(72)86068-5","text":":1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/4332108","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/4332108","text":":1–24. DOI: https://doi.org/10.1016/S0006-3495(72)86068-5, PMID: 4332108"},{"url":"https://doi.org/10.1016/j.celrep.2021.110232","unsafeUrl":"https://doi.org/10.1016/j.celrep.2021.110232","text":":110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088"},{"url":"http://www.ncbi.nlm.nih.gov/pubmed/35021088","unsafeUrl":"http://www.ncbi.nlm.nih.gov/pubmed/35021088","text":":110232. DOI: https://doi.org/10.1016/j.celrep.2021.110232, PMID: 35021088"}],"width":612,"height":792,"triggeredAutoMode":false,"parsingMode":"premium","structuredData":null,"noStructuredContent":false,"noTextContent":false,"pageHeaderMarkdown":"\neLife Tools and resources                                                                                                    Neuroscience\n","pageFooterMarkdown":"\nSinha, Gleeson et al. eLife 2024;13:RP95135. DOI: https://doi.org/10.7554/eLife.95135    44 of 44\n","slideSpeakerNotes":null,"slideSectionName":null,"confidence":0.991,"layout":[{"image":"page_44_reference_1_v2.jpg","confidence":0.98,"label":"reference","bbox":{"x":0.272,"y":0.067,"w":0.659,"h":0.554},"isLikelyNoise":false},{"image":"page_44_reference_content_1_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.273,"y":0.218,"w":0.655,"h":0.048},"isLikelyNoise":false},{"image":"page_44_reference_content_2_v2.jpg","confidence":0.93,"label":"reference_content","bbox":{"x":0.272,"y":0.496,"w":0.648,"h":0.06},"isLikelyNoise":false},{"image":"page_44_reference_content_3_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.407,"w":0.655,"h":0.048},"isLikelyNoise":false},{"image":"page_44_reference_content_4_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.268,"w":0.663,"h":0.048},"isLikelyNoise":false},{"image":"page_44_reference_content_5_v2.jpg","confidence":0.92,"label":"reference_content","bbox":{"x":0.273,"y":0.167,"w":0.648,"h":0.049},"isLikelyNoise":false},{"image":"page_44_footer_1_v2.jpg","confidence":0.92,"label":"footer","bbox":{"x":0.058,"y":0.943,"w":0.512,"h":0.011},"isLikelyNoise":false},{"image":"page_44_reference_content_6_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.458,"w":0.649,"h":0.035},"isLikelyNoise":false},{"image":"page_44_reference_content_7_v2.jpg","confidence":0.91,"label":"reference_content","bbox":{"x":0.273,"y":0.318,"w":0.662,"h":0.037},"isLikelyNoise":false},{"image":"page_44_reference_content_8_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.273,"y":0.584,"w":0.643,"h":0.036},"isLikelyNoise":false},{"image":"page_44_reference_content_9_v2.jpg","confidence":0.9,"label":"reference_content","bbox":{"x":0.273,"y":0.104,"w":0.662,"h":0.035},"isLikelyNoise":false},{"image":"page_44_header_1_v2.jpg","confidence":0.9,"label":"header","bbox":{"x":0.857,"y":0.044,"w":0.081,"h":0.009},"isLikelyNoise":false},{"image":"page_44_reference_content_10_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.079,"w":0.664,"h":0.023},"isLikelyNoise":false},{"image":"page_44_reference_content_11_v2.jpg","confidence":0.88,"label":"reference_content","bbox":{"x":0.273,"y":0.558,"w":0.645,"h":0.024},"isLikelyNoise":false},{"image":"page_44_reference_content_12_v2.jpg","confidence":0.87,"label":"reference_content","bbox":{"x":0.273,"y":0.142,"w":0.641,"h":0.023},"isLikelyNoise":false},{"image":"page_44_number_1_v2.jpg","confidence":0.87,"label":"number","bbox":{"x":0.889,"y":0.944,"w":0.049,"h":0.009},"isLikelyNoise":false},{"image":"page_44_reference_content_13_v2.jpg","confidence":0.87,"label":"reference_content","bbox":{"x":0.273,"y":0.368,"w":0.628,"h":0.037},"isLikelyNoise":false},{"image":"page_44_reference_content_14_v2.jpg","confidence":0.75,"label":"reference_content","bbox":{"x":0.272,"y":0.066,"w":0.405,"h":0.012},"isLikelyNoise":false},{"image":"page_44_header_2_v2.jpg","confidence":0.73,"label":"header","bbox":{"x":0.128,"y":0.045,"w":0.115,"h":0.009},"isLikelyNoise":false},{"image":"page_44_header_3_v2.jpg","confidence":0.63,"label":"header","bbox":{"x":0.058,"y":0.036,"w":0.065,"h":0.017},"isLikelyNoise":false},{"image":"page_44_reference_content_15_v2.jpg","confidence":0.53,"label":"reference_content","bbox":{"x":0.272,"y":0.357,"w":0.615,"h":0.011},"isLikelyNoise":true}]}],"job_metadata":{"credits_used":0,"job_credits_usage":0,"job_pages":44,"job_auto_mode_triggered_pages":0,"job_is_cache_hit":false}}